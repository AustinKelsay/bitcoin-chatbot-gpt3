{"prompt": "Bitcoin: A Peer-to-Peer Electronic Cash System", "completion": "A purely peer-to-peer version of electronic cash would allow online payments to be sent directly from one party to another without going through a financial institution. Digital signatures provide part of the solution, but the main benefits are lost if a trusted third party is still required to prevent double-spending. We propose a solution to the double-spending problem using a peer-to-peer network. The network timestamps transactions by hashing them into an ongoing chain of hash-based proof-of-work, forming a record that cannot be changed without redoing the proof-of-work. The longest chain not only serves as proof of the sequence of events witnessed, but proof that it came from the largest pool of CPU power. As long as a majority of CPU power is controlled by nodes that are not cooperating to attack the network, they'll generate the longest chain and outpace attackers. The network itself requires minimal structure. Messages are broadcast on a best effort basis, and nodes can leave and rejoin the network at will, accepting the longest proof-of-work chain as proof of what happened while they were gone.Commerce on the Internet has come to rely almost exclusively on financial institutions serving as trusted third parties to process electronic payments. While the system works well enough for most transactions, it still suffers from the inherent weaknesses of the trust based model. Completely non-reversible transactions are not really possible, since financial institutions cannot avoid mediating disputes. The cost of mediation increases transaction costs, limiting the minimum practical transaction size and cutting off the possibility for small casual transactions, and there is a broader cost in the loss of ability to make non-reversible payments for non-reversible services. With the possibility of reversal, the need for trust spreads. Merchants must be wary of their customers, hassling them for more information than they would otherwise need. A certain percentage of fraud is accepted as unavoidable. These costs and payment uncertainties can be avoided in person by using physical currency, but no mechanism exists to make payments over a communications channel without a trusted party.What is needed is an electronic payment system based on cryptographic proof instead of trust, allowing any two willing parties to transact directly with each other without the need for a trusted third party. Transactions that are computationally impractical to reverse would protect sellers from fraud, and routine escrow mechanisms could easily be implemented to protect buyers. In this paper, we propose a solution to the double-spending problem using a peer-to-peer distributed timestamp server to generate computational proof of the chronological order of transactions. The system is secure as long as honest nodes collectively control more CPU power than any cooperating group of attacker nodes.We define an electronic coin as a chain of digital signatures. Each owner transfers the coin to the next by digitally signing a hash of the previous transaction and the public key of the next owner and adding these to the end of the coin. A payee can verify the signatures to verify the chain of ownership.The problem of course is the payee can't verify that one of the owners did not double-spend the coin. A common solution is to introduce a trusted central authority, or mint, that checks every transaction for double spending. After each transaction, the coin must be returned to the mint to issue a new coin, and only coins issued directly from the mint are trusted not to be double-spent. The problem with this solution is that the fate of the entire money system depends on the company running the mint, with every transaction having to go through them, just like a bank.We need a way for the payee to know that the previous owners did not sign any earlier transactions. For our purposes, the earliest transaction is the one that counts, so we don't care about later attempts to double-spend. The only way to confirm the absence of a transaction is to be aware of all transactions. In the mint based model, the mint was aware of all transactions and decided which arrived first. To accomplish this without a trusted party, transactions must be publicly announced[1], and we need a system for participants to agree on a single history of the order in which they were received. The payee needs proof that at the time of each transaction, the majority of nodes agreed it was the first received.The solution we propose begins with a timestamp server. A timestamp server works by taking a hash of a block of items to be timestamped and widely publishing the hash, such as in a newspaper or Usenet post[2-5]. The timestamp proves that the data must have existed at the time, obviously, in order to get into the hash. Each timestamp includes the previous timestamp in its hash, forming a chain, with each additional timestamp reinforcing the ones before it.To implement a distributed timestamp server on a peer-to-peer basis, we will need to use a proof-of-work system similar to Adam Back's Hashcash[6], rather than newspaper or Usenet posts. The proof-of-work involves scanning for a value that when hashed, such as with SHA-256, the hash begins with a number of zero bits. The average work required is exponential in the number of zero bits required and can be verified by executing a single hash.For our timestamp network, we implement the proof-of-work by incrementing a nonce in the block until a value is found that gives the block's hash the required zero bits. Once the CPU effort has been expended to make it satisfy the proof-of-work, the block cannot be changed without redoing the work. As later blocks are chained after it, the work to change the block would include redoing all the blocks after it.The proof-of-work also solves the problem of determining representation in majority decision making. If the majority were based on one-IP-address-one-vote, it could be subverted by anyone able to allocate many IPs. Proof-of-work is essentially one-CPU-one-vote. The majority decision is represented by the longest chain, which has the greatest proof-of-work effort invested in it. If a majority of CPU power is controlled by honest nodes, the honest chain will grow the fastest and outpace any competing chains. To modify a past block, an attacker would have to redo the proof-of-work of the block and all blocks after it and then catch up with and surpass the work of the honest nodes. We will show later that the probability of a slower attacker catching up diminishes exponentially as subsequent blocks are added.To compensate for increasing hardware speed and varying interest in running nodes over time, the proof-of-work difficulty is determined by a moving average targeting an average number of blocks per hour. If they're generated too fast, the difficulty increases.The steps to run the network are as follows:Nodes always consider the longest chain to be the correct one and will keep working on extending it. If two nodes broadcast different versions of the next block simultaneously, some nodes may receive one or the other first. In that case, they work on the first one they received, but save the other branch in case it becomes longer. The tie will be broken when the next proof-of-work is found and one branch becomes longer; the nodes that were working on the other branch will then switch to the longer one.New transaction broadcasts do not necessarily need to reach all nodes. As long as they reach many nodes, they will get into a block before long. Block broadcasts are also tolerant of dropped messages. If a node does not receive a block, it will request it when it receives the next block and realizes it missed one.By convention, the first transaction in a block is a special transaction that starts a new coin owned by the creator of the block. This adds an incentive for nodes to support the network, and provides a way to initially distribute coins into circulation, since there is no central authority to issue them. The steady addition of a constant of amount of new coins is analogous to gold miners expending resources to add gold to circulation. In our case, it is CPU time and electricity that is expended.The incentive can also be funded with transaction fees. If the output value of a transaction is less than its input value, the difference is a transaction fee that is added to the incentive value of the block containing the transaction. Once a predetermined number of coins have entered circulation, the incentive can transition entirely to transaction fees and be completely inflation free.The incentive may help encourage nodes to stay honest. If a greedy attacker is able to assemble more CPU power than all the honest nodes, he would have to choose between using it to defraud people by stealing back his payments, or using it to generate new coins. He ought to find it more profitable to play by the rules, such rules that favour him with more new coins than everyone else combined, than to undermine the system and the validity of his own wealth.Once the latest transaction in a coin is buried under enough blocks, the spent transactions before it can be discarded to save disk space. To facilitate this without breaking the block's hash, transactions are hashed in a Merkle Tree [7][2][5], with only the root included in the block's hash. Old blocks can then be compacted by stubbing off branches of the tree. The interior hashes do not need to be stored.A block header with no transactions would be about 80 bytes. If we suppose blocks are generated every 10 minutes, 80 bytes * 6 * 24 * 365 = 4.2MB per year. With computer systems typically selling with 2GB of RAM as of 2008, and Moore's Law predicting current growth of 1.2GB per year, storage should not be a problem even if the block headers must be kept in memory.It is possible to verify payments without running a full network node. A user only needs to keep a copy of the block headers of the longest proof-of-work chain, which he can get by querying network nodes until he's convinced he has the longest chain, and obtain the Merkle branch linking the transaction to the block it's timestamped in. He can't check the transaction for himself, but by linking it to a place in the chain, he can see that a network node has accepted it, and blocks added after it further confirm the network has accepted it.As such, the verification is reliable as long as honest nodes control the network, but is more vulnerable if the network is overpowered by an attacker. While network nodes can verify transactions for themselves, the simplified method can be fooled by an attacker's fabricated transactions for as long as the attacker can continue to overpower the network. One strategy to protect against this would be to accept alerts from network nodes when they detect an invalid block, prompting the user's software to download the full block and alerted transactions to confirm the inconsistency. Businesses that receive frequent payments will probably still want to run their own nodes for more independent security and quicker verification.Although it would be possible to handle coins individually, it would be unwieldy to make a separate transaction for every cent in a transfer. To allow value to be split and combined, transactions contain multiple inputs and outputs. Normally there will be either a single input from a larger previous transaction or multiple inputs combining smaller amounts, and at most two outputs: one for the payment, and one returning the change, if any, back to the sender.It should be noted that fan-out, where a transaction depends on several transactions, and those transactions depend on many more, is not a problem here. There is never the need to extract a complete standalone copy of a transaction's history.The traditional banking model achieves a level of privacy by limiting access to information to the parties involved and the trusted third party. The necessity to announce all transactions publicly precludes this method, but privacy can still be maintained by breaking the flow of information in another place: by keeping public keys anonymous. The public can see that someone is sending an amount to someone else, but without information linking the transaction to anyone. This is similar to the level of information released by stock exchanges, where the time and size of individual trades, the \"tape\", is made public, but without telling who the parties were.As an additional firewall, a new key pair should be used for each transaction to keep them from being linked to a common owner. Some linking is still unavoidable with multi-input transactions, which necessarily reveal that their inputs were owned by the same owner. The risk is that if the owner of a key is revealed, linking could reveal other transactions that belonged to the same owner.We consider the scenario of an attacker trying to generate an alternate chain faster than the honest chain. Even if this is accomplished, it does not throw the system open to arbitrary changes, such as creating value out of thin air or taking money that never belonged to the attacker. Nodes are not going to accept an invalid transaction as payment, and honest nodes will never accept a block containing them. An attacker can only try to change one of his own transactions to take back money he recently spent.The race between the honest chain and an attacker chain can be characterized as a Binomial Random Walk. The success event is the honest chain being extended by one block, increasing its lead by +1, and the failure event is the attacker's chain being extended by one block, reducing the gap by -1.The probability of an attacker catching up from a given deficit is analogous to a Gambler's Ruin problem. Suppose a gambler with unlimited credit starts at a deficit and plays potentially an infinite number of trials to try to reach breakeven. We can calculate the probability he ever reaches breakeven, or that an attacker ever catches up with the honest chain, as follows[8]:p\nq\nq\nz\n=\n=\n=\n probability an honest node finds the next block\n probability the attacker finds the next block\n probability the attacker will ever catch up from z blocks behindq\nz\n={\n1\n(q/p\n)\nz\nifp\u2264q\nifp>q\n}Given our assumption that\np>q\n, the probability drops exponentially as the number of blocks the attacker has to catch up with increases. With the odds against him, if he doesn't make a lucky lunge forward early on, his chances become vanishingly small as he falls further behind.We now consider how long the recipient of a new transaction needs to wait before being sufficiently certain the sender can't change the transaction. We assume the sender is an attacker who wants to make the recipient believe he paid him for a while, then switch it to pay back to himself after some time has passed. The receiver will be alerted when that happens, but the sender hopes it will be too late.The receiver generates a new key pair and gives the public key to the sender shortly before signing. This prevents the sender from preparing a chain of blocks ahead of time by working on it continuously until he is lucky enough to get far enough ahead, then executing the transaction at that moment. Once the transaction is sent, the dishonest sender starts working in secret on a parallel chain containing an alternate version of his transaction.The recipient waits until the transaction has been added to a block and\nz\nblocks have been linked after it. He doesn't know the exact amount of progress the attacker has made, but assuming the honest blocks took the average expected time per block, the attacker's potential progress will be a Poisson distribution with expected value:\u03bb=z\nq\npTo get the probability the attacker could still catch up now, we multiply the Poisson density for each amount of progress he could have made by the probability he could catch up from that point:\u2211\nk=0\n\u221e\n\u03bb\nk\ne\n\u2212\u03bb\nk!\n\u22c5{\n(q/p\n)\n(z\u2212k)\n1\nifk\u2264z\nifk>z\n}Rearranging to avoid summing the infinite tail of the distribution...1\u2212\n\u2211\nk=0\nz\n\u03bb\nk\ne\n\u2212\u03bb\nk!\n(1\u2212(q/p\n)\n(z\u2212k)\n)Converting to C code...Running some results, we can see the probability drop off exponentially with\nz\n.Solving for P less than 0.1%...We have proposed a system for electronic transactions without relying on trust. We started with the usual framework of coins made from digital signatures, which provides strong control of ownership, but is incomplete without a way to prevent double-spending. To solve this, we proposed a peer-to-peer network using proof-of-work to record a public history of transactions that quickly becomes computationally impractical for an attacker to change if honest nodes control a majority of CPU power. The network is robust in its unstructured simplicity. Nodes work all at once with little coordination. They do not need to be identified, since messages are not routed to any particular place and only need to be delivered on a best effort basis. Nodes can leave and rejoin the network at will, accepting the proof-of-work chain as proof of what happened while they were gone. They vote with their CPU power, expressing their acceptance of valid blocks by working on extending them and rejecting invalid blocks by refusing to work on them. Any needed rules and incentives can be enforced with this consensus mechanism.W. Dai, \"b-money,\" http://www.weidai.com/bmoney.txt, 1998. \u21a9H. Massias, X.S. Avila, and J.-J. Quisquater, \"Design of a secure timestamping service with minimal trust requirements,\" In 20th Symposium on Information Theory in the Benelux, May 1999. \u21a9 \u21a9S. Haber, W.S. Stornetta, \"How to time-stamp a digital document,\" In Journal of Cryptology, vol 3, no 2, pages 99-111, 1991. \u21a9D. Bayer, S. Haber, W.S. Stornetta, \"Improving the efficiency and reliability of digital time-stamping,\" In Sequences II: Methods in Communication, Security and Computer Science, pages 329-334, 1993. \u21a9S. Haber, W.S. Stornetta, \"Secure names for bit-strings,\" In Proceedings of the 4th ACM Conference on Computer and Communications Security, pages 28-35, April 1997. \u21a9 \u21a9A. Back, \"Hashcash - a denial of service counter-measure,\" http://www.hashcash.org/papers/hashcash.pdf, 2002. \u21a9R.C. Merkle, \"Protocols for public key cryptosystems,\" In Proc. 1980 Symposium on Security and Privacy, IEEE Computer Society, pages 122-133, April 1980. \u21a9W. Feller, \"An introduction to probability theory and its applications,\" 1957. \u21a9PDF available in English, Chinese (Simplified), Chinese (Traditional), Hebrew, Italian, Japanese, Russian, Spanish, and Vietnamese"}
{"prompt": "b-money", "completion": "I am fascinated by Tim May's crypto-anarchy. Unlike the communities traditionally associated with the word \"anarchy\", in a crypto-anarchy the government is not temporarily destroyed but permanently forbidden and permanently unnecessary. It's a community where the threat of violence is impotent because violence is impossible, and violence is impossible because its participants cannot be linked to their true names or physical locations.Until now it's not clear, even theoretically, how such a community could operate. A community is defined by the cooperation of its participants, and efficient cooperation requires a medium of exchange (money) and a way to enforce contracts. Traditionally these services have been provided by the government or government sponsored institutions and only to legal entities. In this article I describe a protocol by which these services can be provided to and by untraceable entities.I will actually describe two protocols. The first one is impractical, because it makes heavy use of a synchronous and unjammable anonymous broadcast channel. However it will motivate the second, more practical protocol. In both cases I will assume the existence of an untraceable network, where senders and receivers are identified only by digital pseudonyms (i.e. public keys) and every messages is signed by its sender and encrypted to its receiver.In the first protocol, every participant maintains a (seperate) database of how much money belongs to each pseudonym. These accounts collectively define the ownership of money, and how these accounts are updated is the subject of this protocol.The creation of money. Anyone can create money by broadcasting the solution to a previously unsolved computational problem. The only conditions are that it must be easy to determine how much computing effort it took to solve the problem and the solution must otherwise have no value, either practical or intellectual. The number of monetary units created is equal to the cost of the computing effort in terms of a standard basket of commodities. For example if a problem takes 100 hours to solve on the computer that solves it most economically, and it takes 3 standard baskets to purchase 100 hours of computing time on that computer on the open market, then upon the broadcast of the solution to that problem everyone credits the broadcaster's account by 3 units.The transfer of money. If Alice (owner of pseudonym KA) wishes to transfer X units of money to Bob (owner of pseudonym KB), she broadcasts the message \"I give X units of money to KB\" signed by KA. Upon the broadcast of this message, everyone debits KA's account by X units and credits KB's account by X units, unless this would create a negative balance in KA's account in which case the message is ignored.The effecting of contracts. A valid contract must include a maximum reparation in case of default for each participant party to it. It should also include a party who will perform arbitration should there be a dispute. All parties to a contract including the arbitrator must broadcast their signatures of it before it becomes effective. Upon the broadcast of the contract and all signatures, every participant debits the account of each party by the amount of his maximum reparation and credits a special account identified by a secure hash of the contract by the sum the maximum reparations. The contract becomes effective if the debits succeed for every party without producing a negative balance, otherwise the contract is ignored and the accounts are rolled back. A sample contract might look like this:KA agrees to send KB the solution to problem P before 0:0:0 1/1/2000. KB agrees to pay KA 100 MU (monetary units) before 0:0:0 1/1/2000. KC agrees to perform arbitration in case of dispute. KA agrees to pay a maximum of 1000 MU in case of default. KB agrees to pay a maximum of 200 MU in case of default. KC agrees to pay a maximum of 500 MU in case of default.The conclusion of contracts. If a contract concludes without dispute, each party broadcasts a signed message \"The contract with SHA-1 hash H concludes without reparations.\" or possibly \"The contract with SHA-1 hash H concludes with the following reparations: ...\" Upon the broadcast of all signatures, every participant credits the account of each party by the amount of his maximum reparation, removes the contract account, then credits or debits the account of each party according to the reparation schedule if there is one.The enforcement of contracts. If the parties to a contract cannot agree on an appropriate conclusion even with the help of the arbitrator, each party broadcasts a suggested reparation/fine schedule and any arguments or evidence in his favor. Each participant makes a determination as to the actual reparations and/or fines, and modifies his accounts accordingly.In the second protocol, the accounts of who has how much money are kept by a subset of the participants (called servers from now on) instead of everyone. These servers are linked by a Usenet-style broadcast channel. The format of transaction messages broadcasted on this channel remain the same as in the first protocol, but the affected participants of each transaction should verify that the message has been received and successfully processed by a randomly selected subset of the servers.Since the servers must be trusted to a degree, some mechanism is needed to keep them honest. Each server is required to deposit a certain amount of money in a special account to be used as potential fines or rewards for proof of misconduct. Also, each server must periodically publish and commit to its current money creation and money ownership databases. Each participant should verify that his own account balances are correct and that the sum of the account balances is not greater than the total amount of money created. This prevents the servers, even in total collusion, from permanently and costlessly expanding the money supply. New servers can also use the published databases to synchronize with existing servers.The protocol proposed in this article allows untraceable pseudonymous entities to cooperate with each other more efficiently, by providing them with a medium of exchange and a method of enforcing contracts. The protocol can probably be made more efficient and secure, but I hope this is a step toward making crypto-anarchy a practical as well as theoretical possibility.One of the more problematic parts in the b-money protocol is money creation. This part of the protocol requires that all of the account keepers decide and agree on the cost of particular computations. Unfortunately because computing technology tends to advance rapidly and not always publicly, this information may be unavailable, inaccurate, or outdated, all of which would cause serious problems for the protocol.So I propose an alternative money creation subprotocol, in which account keepers (everyone in the first protocol, or the servers in the second protocol) instead decide and agree on the amount of b-money to be created each period, with the cost of creating that money determined by an auction. Each money creation period is divided up into four phases, as follows:Planning. The account keepers compute and negotiate with each other to determine an optimal increase in the money supply for the next period. Whether or not the account keepers can reach a consensus, they each broadcast their money creation quota and any macroeconomic calculations done to support the figures.Bidding. Anyone who wants to create b-money broadcasts a bid in the form of <x, y> where x is the amount of b-money he wants to create, and y is an unsolved problem from a predetermined problem class. Each problem in this class should have a nominal cost (in MIPS-years say) which is publicly agreed on.Computation. After seeing the bids, the ones who placed bids in the bidding phase may now solve the problems in their bids and broadcast the solutions.Money creation. Each account keeper accepts the highest bids (among those who actually broadcasted solutions) in terms of nominal cost per unit of b-money created and credits the bidders' accounts accordingly."}
{"prompt": "The Crypto Anarchist Manifesto", "completion": "A specter is haunting the modern world, the specter of crypto anarchy.Computer technology is on the verge of providing the ability for individuals and groups to communicate and interact with each other in a totally anonymous manner. Two persons may exchange messages, conduct business, and negotiate electronic contracts without ever knowing the True Name, or legal identity, of the other. Interactions over networks will be untraceable, via extensive re- routing of encrypted packets and tamper-proof boxes which implement cryptographic protocols with nearly perfect assurance against any tampering. Reputations will be of central importance, far more important in dealings than even the credit ratings of today. These developments will alter completely the nature of government regulation, the ability to tax and control economic interactions, the ability to keep information secret, and will even alter the nature of trust and reputation.The technology for this revolution--and it surely will be both a social and economic revolution--has existed in theory for the past decade. The methods are based upon public-key encryption, zero-knowledge interactive proof systems, and various software protocols for interaction, authentication, and verification. The focus has until now been on academic conferences in Europe and the U.S., conferences monitored closely by the National Security Agency. But only recently have computer networks and personal computers attained sufficient speed to make the ideas practically realizable. And the next ten years will bring enough additional speed to make the ideas economically feasible and essentially unstoppable. High-speed networks, ISDN, tamper-proof boxes, smart cards, satellites, Ku-band transmitters, multi-MIPS personal computers, and encryption chips now under development will be some of the enabling technologies.The State will of course try to slow or halt the spread of this technology, citing national security concerns, use of the technology by drug dealers and tax evaders, and fears of societal disintegration. Many of these concerns will be valid; crypto anarchy will allow national secrets to be trade freely and will allow illicit and stolen materials to be traded. An anonymous computerized market will even make possible abhorrent markets for assassinations and extortion. Various criminal and foreign elements will be active users of CryptoNet. But this will not halt the spread of crypto anarchy.Just as the technology of printing altered and reduced the power of medieval guilds and the social power structure, so too will cryptologic methods fundamentally alter the nature of corporations and of government interference in economic transactions. Combined with emerging information markets, crypto anarchy will create a liquid market for any and all material which can be put into words and pictures. And just as a seemingly minor invention like barbed wire made possible the fencing-off of vast ranches and farms, thus altering forever the concepts of land and property rights in the frontier West, so too will the seemingly minor discovery out of an arcane branch of mathematics come to be the wire clippers which dismantle the barbed wire around intellectual property.Arise, you have nothing to lose but your barbed wire fences!"}
{"prompt": "Crypto Anarchy and Virtual Communities", "completion": "The combination of strong, unbreakable public key cryptography and virtual network communities in cyberspace will produce interesting and profound changes in the nature of economic and social systems. Crypto anarchy is the cyberspatial realization of anarcho-capitalism, transcending national boundaries and freeing individuals to make the economic arrangements they wish to make consensually.Strong cryptography, exemplified by RSA (a public key algorithm) and PGP (Pretty Good Privacy), provides encryption that essentially cannot be broken with all the computing power in the universe. This ensures security and privacy. Public key cryptography is rightly considered to be a revolution.Digital mixes, or anonymous remailers, use crypto to create untraceable e-mail, which has many uses. (Numerous anonymous remailers, in several countries, are now operating. Message traffic is growing exponentially.)Digital pseudonyms, the creation of persistent network personas that cannot be forged by others and yet which are unlinkable to the \"true names\" of their owners, are finding major uses in ensuring free speech, in allowing controversial opinions to be aired, and in providing for economic transactions that cannot be blocked by local governments. The technology being deployed by the Cypherpunks and others, means their identities, nationalities, and even which continents they are on are untraceable -- unless they choose to reveal this information. This alters the conventional \"relationship topology\" of the world, allowing diverse interactions without external governmental regulation, taxation, or interference.Digital cash, untraceable and anonymous (like real cash), is also coming, though various technical and practical hurdles remain. \"Swiss banks in cyberspace\" will make economic transactions much more liquid and much less subject to local rules and regulations. Tax avoidance is likely to be a major attraction for many. An example of local interest to Monte Carlo might be the work underway to develop anonymous, untraceable systems for \"cyberspace casinos.\" While not as attractive to many as elegant casinos, the popularity of \"numbers games\" and bookies in general suggests a opportunity to pursue.Data havens and information markets are already springing up, using the methods described to make information retrievable anonymously and untraceably.Governments see their powers eroded by these technologies, and are taking various well-known steps to try to limit the use of strong crypto by their subjects. The U.S. has several well-publicized efforts, including the Clipper chip, the Digital Telephony wiretap law, and proposals for \"voluntary\" escrow of cryptographic keys. Cypherpunks and others expect these efforts to be bypassed. Technology has let the genie out of the bottle. Crypto anarchy is liberating individuals from coercion by their physical neighbors\u2014who cannot know who they are on the Net\u2014and from governments. For libertarians, strong crypto provides the means by which government will be avoided.The presentation will describe how several of these systems work, briefly, and will outline the likely implications of this combination of crypto anarchy and virtual cyberspace communities.This paper describes the combination of two major technologies:This paper describes the combination of two major technologies:These areas have generally remained separate, at least in published papers. Certainly the developers of cyberspace systems, such as MUDs, MOOs, and Habitat-like systems, appreciate the importance of cryptography for user authentication, overall security, and certainly for (eventual) digital purchase of services. But for the most part the combination of these two areas has been the province of the science fiction writer, notably writers such as Vernor Vinge, William Gibson, Bruce Sterling, and Orson Scott Card.The \"Cypherpunks\" group, a loose, anarchic mailing list and group of hackers, was formed by several of us in 1992 as a group to make concrete some of the abstract ideas often presented at conferences. We've had some successes, and some failures.[1] The Cypherpunks group also appeared at a fortuitous time, as PGP was becoming popular, as Wired magazine appeared (they featured us on the cover of their second issue), and as the publicity (hype?) about the Information Superhighway and the World Wide Web reached a crescendo.The site ftp.csua.berkeley.edu has a number of essays and files, including crypto files, in the directory pub/cypherpunks. I have also written/ compiled a very large 1.3 MB FAQ on these issues, the Cyphernomicon, available at various sites, including my ftp directory, ftp.netcom.com, in the directory pub/tc/tcmay.The Cypherpunks group is also a pretty good example of a \"virtual community.\" Scattered around the world, communicating electronically in matters of minutes, and seeming oblivious to local laws, the Cypherpunks are indeed a community, and a virtual one. Many members use pseudonyms, and use anonymous remailers to communicate with the list. The list itself thus behaves as a \"message pool,\" a place where information of all sort may be anonymous deposited\u2014and anonymous received (since everyone sees the entire list, like a newspaper, the intended recipient is anonymized).Legal Caveat: Consult your local laws before applying any of the methods described here. In some jurisdictions, it may be illegal to even read papers like this (seriously). In particular, I generally won't be giving ftp site addresses for copies of PGP, remailer access, digital cash systems, etc. These are well-covered in more current forums, e.g., sci.crypt or talk.politics.crypto, and there are some unresolved issues about whether giving the address of such sites constitutes (or \"aids and abets\") violation of various export and munitions laws (crypto is considered a munition in the U.S. and probably elsewhere....some nations consider a laser printer to be a munitions item!).The past two decades have produced a revolution in cryptography (crypto, for short) the science of the making of ciphers and codes. Beyond just simple ciphers, useful mainly for keeping communications secret, modern crypto includes diverse tools for authentication of messages, for digital timestamping of documents, for hiding messages in other documents (steganography), and even for schemes for digital cash.Public key cryptography, the creation of Diffie and Hellman, has dramatically altered the role of crypto. Coming at the same time as the wholesale conversion to computer networks and worldwide communications, it has been a key element of security, confidence, and success. The role of crypto will only become more important over the coming decades.Pretty Good Privacy, PGP, is a popular version of the algorithm developed by Rivest, Shamir, and Adleman, known of course as RSA. The RSA algorithm was given a patent in the U.S., though not in any European countries, and is licensed commercially.[2]These tools are described in detail in various texts and Conference proceedings, and are not the subject of this paper.[3] The focus here is on the implications of strong crypto for cyberspace, especially on virtual communities.Mention should be made of the role of David Chaum in defining the key concepts here. In several seminal papers (for example,[4][5]), Chaum introduced the ideas of using public key cryptography methods for anonymous, untraceable electronic mail, for digital money systems in which spender identity is not revealed, and in schemes related to these. (I make no claims of course that Chaum agrees with my conclusions about the political and socioeconomic implications of these results.)Notes: cyberspace, Habitat, VR, Vinge, etc. Crypto holds up the \"walls\" of these cyberspatial realities. Access control, access rights, modification privileges.Virtual communities are the networks of individuals or groups which are not necessarily closely-connected geographically. The \"virtual\" is meant to imply a non-physical linking, but should not be taken to mean that these are any less community-like than are conventional physical communities.Examples include churches, service organizations, clubs, criminal gangs, cartels, fan groups, etc. The Catholic Church and the Boy Scouts are both examples of virtual communities which span the globe, transcend national borders, and create a sense of allegiance, of belonging, and a sense of \"community.\" Likewise, the Mafia is a virtual community (with its enforcement mechanisms, its own extra-legal rules, etc.) Lots of other examples: Masons, Triads, Red Cross, Interpol, Islam, Judaism, Mormons, Sindero Luminoso, the IRA, drug cartels, terrorist groups, Aryan Nation, Greenpeace, the Animal Liberation Front, and so on. There are undoubtedly many more such virtual communities than there are nation-states, and the ties that bind them are for the most part much stronger than are the chauvinist nationalism emotions. Any group in which the common interests of the group, be it a shared ideology or a particular interest, are enough to create a cohesive community.Corporations are another prime example of a virtual community, having scattered sites, private communication channels (generally inaccessible to the outside world, including the authorities), and their own goals and methods. In fact, many \"cyberpunk\" (not cypherpunk) fiction authors make a mistake, I think, in assuming the future world will be dominated by transnational megacorporate \"states.\" In fact, corporations are just one example\u2014of many\u2014of such virtual communities which will be effectively on a par with nation-states. (Note especially that any laws designed to limit use of crypto cause immediate and profound problems for corporations-countries like France and the Philippines, which have attempted to limit the use of crypto, have mostly been ignored by corporations. Any attempts to outlaw crypto will produce a surge of sudden \"incorporations,\" thus gaining for the new corporate members the aegis of corporate privacy.)In an academic setting, \"invisible colleges\" are the communities of researchers.These virtual communities typically are \"opaque\" to outsiders. Attempts to gain access to the internals of these communities are rarely successful. Law enforcement and intelligence agencies (such as the NSA in the U.S., Chobetsu in Japan, SDECE in France, and so on, in every country) may infiltrate such groups and use electronic surveillance (ELINT) to monitor these virtual communities. Not surprisingly, these communities are early adopters of encryption technology, ranging from scrambled cellphones to full-blown PGP encryption.[6]The use of encryption by \"evil\" groups, such as child pornographers, terrorists, abortionists, abortion protestors, etc., is cited by those who wish to limit civilian access to crypto tools. We call these the \"Four Horseman of the Infocalypse,\" as they are so often cited as the reason why ordinary citizen-units of the nation-state are not to have access to crypto.This is clearly a dangerous argument to make, for various good reasons. The basic right of free speech is the right to speak in a language one's neighbors or governing leaders may not find comprehensible: encrypted speech. There's not enough space here to go into the many good arguments against a limit on access to privacy, communications tools, and crypto.The advent of full-featured communications systems for computer-mediated virtual communities will have even more profound implications. MUDs and MOOs (multi-user domains, etc.) and 3D virtual realities are one avenue, and text-centric Net communications are another. (Someday, soon, they'll merge, as described in Vernor Vinge's prophetic 1980 novella, True Names.)An interesting way to view issues of network visibility is in terms of the \"transparency\" of nodes and links between nodes. Transparent means visible to outsiders, perhaps those in law enforcement or the intelligence community. Opaque mean not transparent, not visible. A postcard is transparent, a sealed letter is opaque. PGP inventor Phil Zimmermann has likened the requirement for transparency to being ordered to use postcards for all correspondence, with encryption the equivalent of an opaque envelope (envelopes can be opened, of course, and long have been).Transparent links and nodes are the norm in a police state, such as the U.S.S.R., Iraq, China, and so forth. Communications channels are tapped, and private use of computers is restricted. (This is becoming increasingly hard to do, even for police states; many cite the spread of communications options as a proximate cause of the collapse of communism in recent years.)There are interesting \"chemistries\" or \"algebras\" of transparent vs. opaque links and nodes. What happens if links must be transparent, but nodes are allowed to be opaque? (The answer: the result is as if opaque links and nodes were allowed, i.e., full implications of strong crypto. Hence, any attempt to ban communications crypto while still allowing private CPUs to exist....)If Alice and Bob are free to communicate, and to choose routing paths, then Alice can use \"crypto arbitrage\" (a variation on the term, \"regulatory arbitrage,\" the term Eric Hughes uses to capture this idea of moving transactions to other jurisdictions) to communicate with sites\u2014perhaps in other countries\u2014that will perform as she wishes. This can mean remailing, mixing, etc. As an example, Canadian citizens who are told they cannot access information on the Homolka-Teale murder case (a controversial case in which the judge has ordered the media in Canada, and entering Canada, not to discuss the gory details) nevertheless have a vast array of options, including using telnet, gopher, ftp, the Web, etc., to access sites in many other countries--or even in no country in particular.Most of the consequences described here arise from this chemistry of links and nodes: unless nearly all node and links are forced to be transparent, including links to other nations and the nodes in those nations, then the result is that private communication can still occur. Crypto anarchy results.\"The Net is an anarchy.\" This truism is the core of crypto anarchy. No central control, no ruler, no leader (except by example, reputation), no \"laws.\" No single nation controls the Net, no administrative body sets policy. The Ayatollah in Iran is as powerless to stop a newsgroup\u2014alt.wanted.moslem.women or alt.wanted.moslem.gay come to mind\u2014he doesn't like as the President of France is as powerless to stop, say, the abuse of French in soc.culture.french. Likewise, the CIA can't stop newsgroups, or sites, or Web pages, which give away their secrets. At least not in terms of the Net itself...what non-Net steps might be taken is left as an exercise for the paranoid and the cautious.This essential anarchy is much more common than many think. Anarchy\u2014the absence of a ruler telling one what to do\u2014is common in many walks of life: choice of books to read, movies to see, friends to socialize with, etc. Anarchy does not mean complete freedom\u2014one can, after all, only read the books which someone has written and had published\u2014but it does mean freedom from external coercion. Anarchy as a concept, though, has been tainted by other associations.First, the \"anarchy\" here is not the anarchy of popular conception: lawlessness, disorder, chaos, and \"anarchy.\" Nor is it the bomb-throwing anarchy of the 19th century \"black\" anarchists, usually associated with Russia and labor movements. Nor is it the \"black flag\" anarchy of anarcho-syndicalism and writers such as Proudhon. Rather, the anarchy being spoken of here is the anarchy of \"absence of government\" (literally, \"an arch,\" without a chief or head).This is the same sense of anarchy used in \"anarchocapitalism,\" the libertarian free market ideology which promotes voluntary, uncoerced economic transactions.[7] I devised the term crypto anarchy as a pun on crypto, meaning \"hidden,\" on the use of \"crypto\" in combination with political views (as in Gore Vidal's famous charge to William F. Buckley: \"You crypto fascist!\"), and of course because the technology of crypto makes this form of anarchy possible. The first presentation of this was in a 1988 \"Manifesto,\" whimsically patterned after another famous manifesto.[8] Perhaps a more popularly understandable term, such as \"cyber liberty,\" might have some advantages, but crypto anarchy has its own charm, I think.And anarchy in this sense does not mean local hierarchies don't exist, nor does it mean that no rulers exist. Groups outside the direct control of local governmental authorities may still have leaders, rulers, club presidents, elected bodies, etc. Many will not, though.Politically, virtual communities outside the scope of local governmental control may present problems of law enforcement and tax collection. (Some of us like this aspect.) Avoidance of coerced transactions can mean avoidance of taxes, avoidance of laws saying who one can sell to and who one can't, and so forth. It is likely that many will be unhappy that some are using cryptography to avoid laws designed to control behavior.National borders are becoming more transparent than ever to data. A flood of bits crosses the borders of most developed countries\u2014phone lines, cables, fibers, satellite up/downlinks, and millions of diskettes, tapes, CDs, etc. Stopping data at the borders is less than hopeless.Finally, the ability to move data around the world at will, the ability to communicate to remote sites at will, means that a kind of \"regulatory arbitrage\" can be used to avoid legal roadblocks. For example, remailing into the U.S. from a site in the Netherlands...whose laws apply? (If one thinks that U.S. laws should apply to sites in the Netherlands, does Iraqi law apply in the U.S.? And so on.)This regulatory arbitrage is also useful for avoiding the welter of laws and regulations which operations in one country may face, including the \"deep pockets\" lawsuits so many in the U.S. face. Moving operations on the Net outside a litigious jurisdiction is one step to reduce this business liability. Like Swiss banks, but different.Something needs to be said about the role of anonymity and digital pseudonyms. This is a topic for an essay unto itself, of course.Are true names really needed? Why are they asked for? Does the nation-state have any valid reason to demand they be used?People want to know who they are dealing with, for psychological/evolutionary reasons and to better ensure traceability should they need to locate a person to enforce the terms of a transaction. The purely anonymous person is perhaps justifiably viewed with suspicion.And yet pseudonyms are successful in many cases. And we rarely know whether someone who presents himself by some name is \"actually\" that person. Authors, artists, performers, etc., often use pseudonyms. What matters is persistence, and nonforgeability. Crypto provides this.On the Cypherpunks list, well-respected digital pseudonyms have appeared and are thought of no less highly than their \"real\" colleagues are.The whole area of digitally-authenticated reputations, and the \"reputation capital\" that accumulates or is affected by the opinions of others, is an area that combines economics, game theory, psychology, and expectations. A lot more study is needed.It is unclear if governments will move to a system of demanding \"Information Highway Driver's Licenses,\" figuratively speaking, or how systems like this could ever be enforced. (The chemistry of opaque nodes and links, again.)It surprises many people that some of these uses are already being intensively explored. Anonymous remailers are used by tens of thousands of persons-and perhaps abused.[9] And of course encryption, via RSA, PGP, etc., is very common in some communities. (Hackers, Net users, freedom fighters, white separatists, etc....I make no moral judgments here about those using these methods).Remailers are a good example to look at in more detail. There are two current main flavors of remailers:\"Cypherpunk\"-style remailers, which process text messages to redirect mail to another sites, using a command syntax that allows arbitrary nesting of remailing (as many sites as one wishes), with PGP encryption at each level of nesting.\"Julf\"-style remailer(s), based on the original work of Karl Kleinpaste and operated/maintained by Julf Helsingius, in Finland. No encryption, and only one such site at present. (This system has been used extensively for messages posted to the Usenet, and is basically successful. The model is based on operator trustworthiness, and his location in Finland, beyond the reach of court orders and subpoenas from most countries.)The Cypherpunks remailers currently number about 20, with more being added every month. There is no reason not to expect hundreds of such remailers in a few years.One experimental \"information market\" is BlackNet, a system which appeared in 1993 and which allows fully-anonymous, two-way exchanges of information of all sorts. There are reports that U.S. authorities have investigated this because of its presence on networks at Defense Department research labs. Not much they can do about it, of course, and more such entities are expected.(The implications for espionage are profound, and largely unstoppable. Anyone with a home computer and access to the Net or Web, in various forms, can use these methods to communicate securely, anonymously or pseudonymously, and with little fear of detection. \"Digital dead drops\" can be used to post information obtained, far more securely than the old physical dead drops...no more messages left in Coke cans at the bases of trees on remote roads.)Whistleblowing is another growing use of anonymous remailers, with folks fearing retaliation using remailers to publicly post information. (Of course, there's a fine line between whistleblowing, revenge, and espionage.)Data havens, for the storage and marketing of controversial information is another area of likely future growth. Nearly any kind of information, medical, religious, chemical, etc., is illegal or proscribed in one or more countries, so those seeking this illegal information will turn to anonymous messaging systems to access\u2014and perhaps purchase, with anonymous digital cash\u2014this information. This might include credit data bases, deadbeat renter files, organ bank markets, etc. (These are all things which have various restrictions on them in the U.S., for example....one cannot compile credit data bases, or lists of deadbeat renters, without meeting various restrictions. A good reason to move them into cyberspace, or at least outside the U.S., and then sell access through remailers.)Matching buyers and sellers of organs is another such market. A huge demand (life and death), but various laws tightly controlling such markets.Digital cash efforts. A lot has been written about digital cash.[10] [11] David Chaum's company, DigiCash, has the most interesting technology, and has recently begun market testing. Stefan Brands may or may not have a competing system which gets around some of Chaum's patents. (The attitude crypto anarchists might take about patents is another topic for discussion. Suffice it to say that patents and other intellectual property issues continue to have relevance in the practical world, despite erosion by technological trends.)Credit card-based systems, such as the First Virtual system, are not exactly digital cash, in the Chaumian sense of blinded notes, but offer some advantages the market may find useful until more advanced systems are available.I expect to see many more such experiments over the next several years, and some of them will likely be market successes.How will these ideas affect the development of cyberspace?\"You can't eat cyberspace\" is a criticism often levelled at argument about the role of cyberspace in everyday life. The argument made is that money and resources \"accumulated\" in some future (or near-future) cyberspatial system will not be able to be \"laundered\" into the real world. Even such a prescient thinker as Neal Stephenson, in Snow Crash, had his protagonist a vastly wealthy man in \"The Multiverse,\" but a near-pauper in the physical world.This is implausible for several reasons. First, we routinely see transfers of wealth from the abstract world of stock tips, arcane consulting knowledge, etc., to the real world. \"Consulting\" is the operative word. Second, a variety of means of laundering money, via phony invoices, uncollected loans, art objects, etc., are well-known to those who launder money...these methods, and more advanced ones to come, are likely to be used by those who wish their cyberspace profits moved into the real world.(Doing this anonymously, untraceably, is another complication. There may be methods of doing this--proposals have looked pretty solid, but more work is needed.)The World Wide Web is growing at an explosive pace. Combined with cryptographically-protected communication and digital cash of some form (and there are several being tried), this should produce the long-awaited colonization of cyberspace.Most Net and Web users already pay little attention to the putative laws of their local regions or nations, apparently seeing themselves more as members of various virtual communities than as members of locally-governed entities. This trend is accelerating.Most importantly, information can be bought and sold (anonymously, too) and then used in the real world. There is no reason to expect that this won't be a major reason to move into cyberspace.I've touched on the implications in several places. Many thoughtful people are worried about some of the possibilities made apparent by strong crypto and anonymous communication systems. Some are proposing restrictions on access to crypto tools. The recent debate in the U.S. over \"Clipper\" and other key escrow systems shows the strength of emotions on this issue.Abhorrent markets may arise. For example, anonymous systems and untraceable digital cash have some obvious implications for the arranging of contract killings and such. (The greatest risk in arranging such hits is that physical meetings expose the buyers and sellers of such services to stings. Crypto anarchy lessens, or even eliminates, this risk, thus lowering transaction costs. The risks to the actual triggermen are not lessened, but this is a risk the buyers need not worry about. Think of anonymous escrow services which hold the digital money until the deed is done. Lots of issues here. It is unfortunate that this area is so little-discussed....people seem to have an aversion for exploring the logical consequences in such areas.)The implications for corporate and national espionage have already been touched upon. Combined with liquid markets in information, this may make secrets much harder to keep. (Imagine a \"Digital Jane's,\" after the military weapons handbooks, anonymously compiled and sold for digital money, beyond the reach of various governments which don't want their secrets told.)New money-laundering approaches are of course another area to explore.Something that is inevitable is the increased role of individuals, leading to a new kind of elitism. Those who are comfortable with the tools described here can avoid the restrictions and taxes that others cannot. If local laws can be bypassed technologically, the implications are pretty clear.The implications for personal liberty are of course profound. No longer can nation-states tell their citizen-units what they can have access to, not if these citizens can access the cyberspace world through anonymous systems.I am making no bold predictions that these changes will sweep the world anytime soon. Most people are ignorant of these methods, and the methods themselves are still under development. A wholesale conversion to \"living in cyberspace\" is just not in the cards, at least not in the next few decades.But to an increasingly large group, the Net is reality. It is where friends are made, where business is negotiated, where intellectual stimulation is found. And many of these people are using crypto anarchy tools. Anonymous remailers, message pools, information markets. Consulting via pseudonyms has begun to appear, and should grow. (As usual, the lack of a robust digital cash system is slowing things down.Can crypto anarchy be stopped? Although the future evolution in unclear, as the future almost always is, it seems unlikely that present trends can be reversed:The Net is integrally tied to economic transactions, and no country can afford to \"disconnect\" itself from it. (The U.S.S.R. couldn't do it, and they were light-years behind the U.S., European, and Asian countries. And in a few more years, no hope of limiting these tools at all, something the U.S. F.B.I. has acknowledged.[13]Technological Inevitability: These tools are already in widespread use, and only draconian steps to limit access to computers and communications channels could significantly impact further use. (Scenarios for restrictions on private use of crypto.)As John Gilmore has noted, \"the Net tends to interpret censorship as damage, and routes around it.\" This applies as well to attempts to legislate behavior on the Net. (The utter impossibility of regulating the worldwide Net, with entry points in more than a hundred nations, with millions of machines, is not yet fully recognized by most national governments. They still speak in terms of \"controlling\" the Net, when in fact the laws of one nation generally have little use in other countries.)Digital money in its various forms is probably the weakest link at this point. Most of the other pieces are operational, at least in basic forms, but digital cash is (understandably) harder to deploy. Hobbyist or \"toy\" experiments have been cumbersome, and the \"toy\" nature is painfully obvious. It is not easy to use digital cash systems at this time (\"To use Magic Money, first create a client...\"), especially as compared to the easily understood alternatives.[14] People are understandably reluctant to entrust actual money to such systems. And it's not yet clear what can be bought with digital cash (a chicken or egg dilemma, likely to be resolved in the next several years).And digital cash, digital banks, etc., are a likely target for legislative moves to limit the deployment of crypto anarchy and digital economies. Whether through banking regulation or tax laws, it is not likely that digital money will be deployed easily. \"Kids, don't try this at home!\" Some of the current schemes may also incorporate methods for reporting transactions to the tax authorities, and may include \"software key escrow\" features which make transactions fully or partly visible to authorities.Strong crypto provides new levels of personal privacy, all the more important in an era of increased surveillance, monitoring, and the temptation to demand proofs of identity and permission slips. Some of the \"credentials without identity\" work of Chaum and others may lessen this move toward a surveillance society.The implications are, as I see it, that the power of nation-states will be lessened, tax collection policies will have to be changed, and economic interactions will be based more on personal calculations of value than on societal mandates.Is this a Good Thing? Mostly yes. Crypto anarchy has some messy aspects, of this there can be little doubt. From relatively unimportant things like price-fixing and insider trading to more serious things like economic espionage, the undermining of corporate knowledge ownership, to extremely dark things like anonymous markets for killings.But let's not forget that nation-states have, under the guise of protecting us from others, killed more than 100 million people in this century alone. Mao, Stalin, Hitler, and Pol Pot, just to name the most extreme examples. It is hard to imagine any level of digital contract killings ever coming close to nationstate barbarism. (But I agree that this is something we cannot accurately speak about; I don't think we have much of a choice in embracing crypto anarchy or not, so I choose to focus on the bright side.)It is hard to argue that the risks of anonymous markets and tax evasion are justification for worldwide suppression of communications and encryption tools. People have always killed each other, and governments have not stopped this (arguably, they make the problem much worse, as the wars of this century have shown).Also, there are various steps that can be taken to lessen the risks of crypto anarchy impinging on personal safety.[15]Strong crypto provides a technological means of ensuring the practical freedom to read and write what one wishes to. (Albeit perhaps not in one's true name, as the nation-state-democracy will likely still try to control behavior through majority votes on what can be said, not said, read, not read, etc.) And of course if speech is free, so are many classes of economic interaction that are essentially tied to free speech.A phase change is coming. Virtual communities are in their ascendancy, displacing conventional notions of nationhood. Geographic proximity is no longer as important as it once was.A lot of work remains. Technical cryptography still hasn't solved all problems, the role of reputations (both positive and negative) needs further study, and the practical issues surrounding many of these areas have barely been explored.We will be the colonizers of cyberspace.My thanks to my colleagues in the Cypherpunks group, all 700 of them, past or present. Well over 100 megabytes of list traffic has passed through he Cypherpunks mailing list, so there have been a lot of stimulating ideas. But especially my appreciation goes to Eric Hughes, Sandy Sandfort, Duncan Frissell, Hal Finney, Perry Metzger, Nick Szabo, John Gilmore, Whit Diffie, Carl Ellison, Bill Stewart, and Harry Bartholomew. Thanks as well to Robin Hanson, Ted Kaehler, Keith Henson, Chip Morningstar, Eric Dean Tribble, Mark Miller, Bob Fleming, Cherie Kushner, Michael Korns, George Gottlieb, Jim Bennett, Dave Ross, Gayle Pergamit, and\u2014especially\u2014the late Phil Salin. Finally, thanks for valuable discussions, sometimes brief, sometimes long, with Vernor Vinge, David Friedman, Rudy Rucker, David Chaum, Kevin Kelly, and Steven Levy.The Cypherpunks group was mainly formed by Eric Hughes, Tim May, and John Gilmore. It began both physical meetings, in the Bay Area and elsewhere, and virtual meetings on an unmoderated mailing list. The name was provided by Judith Milhon, as a play on the \"cyberpunk\" genre and the British spelling of cipher. The mailing list can be subscribed to by sending the single message subscribe cypherpunks in the body of a message to majordomo@toad.com. Expect at least 50 messages a day. About 600 subscribers in many countries are presently on the list. Some are pseudonyms. \u21a9RSA Data Security Inc., Redwood Shores, California, is the license administrator. Contact them for details. \u21a9Many crypto texts exist. A good introduction is Bruce Schneier's Applied Cryptography, John Wiley and Sons, 1994. This text includes pointers to many other sources. The \"Crypto\" Proceedings (Advances in Cryptology, Springer-Verlag, annually) are essential references. The annual Crypto conference in Santa Barbara, and the Eurocrypt and Auscrypt conferences, are where most crypto results are presented. \u21a9David Chaum, \"Untraceable Electronic Mail, Return Addresses, and Digital Pseudonyms,\" Comm. ACM 24, 2, February 1981, pp. 84-88. Cypherpunks-style remailers are a form of Chaum's \"digital mixes,\" albeit far from ideal. \u21a9David Chaum, \"Security without Identification: Transaction Systems to make Big Brother Obsolete,\" Comm. ACM 28, 10, October 1985. This is an early paper on digital cash...be sure to consult more recent papers. \u21a9The political opposition in Myan Mar\u2014formerly Burma\u2014is using Pretty Good Privacy running on DOS laptops in the jungles for communications amongst the rebels, according to Phil Zimmermann, author of PGP. This life-and-death usage underscores the role of crypto. \u21a9David Friedman, The Machinery of Freedom, 2nd edition. A leading theoretician of anarcho-capitalism. (Hayek was another.) \u21a9Tim May, The Crypto Anarchist Manifesto, July 1988, distributed on the Usenet and on various mailing lists. \u21a9Abuse, according to some views, of remailers is already occurring. A Cypherpunks-type remailer was used to post a proprietary hash function of RSA Data Security, Inc. to the Usenet. (Let me hasten to add that it was not a remailer I operate, or have control over, etc.) \u21a9article on digital cash, The Economist, 26 November 1994. pp. 21-23. \u21a9article on digital cash, Steven Levy, Wired. December 1994. \u21a9See Kevin Kelly's Out of Control, 1994, for a discussion of how central control is failing, and how the modern paradigm is one of market mechanisms, personal choice, and technological empowerment. \u21a9During the \"Digital Telephony Bill\" debate, an FBI official said that failure to mandate wiretap capabilities within the next 18 months would make it all moot, as the cost would rise beyond any reasonable budget (currently $500 million for retrofit costs). \u21a9\"Magic Money\" was an experimental implementation of Chaum's digital cash system. It was coded by \"Pr0duct Cypher,\" a pseudonymous member of the Cypherpunks list\u2014none of us knows his real identity, as he used remailers to communicate with the list, and digitally signed his posts. Many of us found it too difficult to use, which is more a measure of the deep issues involved in using digital analogs (no pun intended) to real, physical money. \u21a9Robin Hanson and David Friedman have written extensively about scenarios for dealing with the threats of extortionists, would-be assassins, etc. I am hoping some of their work gets published someday. (Much of the discussion was in 1992-3, on the \"Extropians\" mailing list.) \u21a9"}
{"prompt": "Formalizing and Securing Relationships on Public Networks", "completion": "History has seen successive revolutions in the costs of doing global business. First transportation, then manufacturing, and recently communications costs have fallen dramatically. Yet there are still major barriers to doing business internationally. The cost of doing business globally is increasingly dominated by issues of jurisdiction, security, and trust: the costs of developing, maintaining, and securing our relationships.Despite the recent rise of global computer networks, our institutions still take for granted that we live in a world of paper. We formalize our relationships with written contracts, written laws, and forms designed for paper. Our attitudes and laws regarding intellectual property and privacy have assumed a world of paper which is costly to copy. Increasingly, we can no longer take these deeply embedded, highly evolved paper institutions for granted. Nor, since these institutions involve complex human relationships, can we redesign them overnight. We are entering a period where civilization must once again adapt to a radical new media.Over the long stretch civilization, paper represents only one of many technologies used to mediate commercial relationships. The Inca used quipu \u2013 accounts encoded on strings, a system with interesting tamper-resistance properties. Early Middle Eastern civilizations used clay tokens for thousands of years. These combined the function of, and were a precursor to, both cuneiform writing and coins. Coins started out as lumps of standardize metal and weight. Since these were too expensive to test during a normal business transaction, they came to be stamped by reputable or powerful authorities. Coins played a major role in commerce for thousands of years, but that era is now over.Business is now dominated by paper and institutions of written literacy. Security measures have included chops, seals, and written signatures. Value has been transered via bills of exchange (which evolved into checks), bearer certificates, and accounts using the double-entry bookeeping system. Most importantly, we take for granted that contracts and law are written on this static medium, to be interpreted and enforced by human authorities.We are now entering an era of online communications and software \"literacy\". The \"physics of cyberspace\", studied by computer scientists, are radically different from the properties of paper, to an even greater degree than paper was different from string, clay, and metal. Not only written but also aural, visual, and other sensory media can be combined. Most importantly, digital media are dynamic \u2013 they not only transmit information, but can also make some kinds of decisions. Digital media can perform calculations, directly operate machinery, and work through some kinds of reasoning much more efficiently than humans.The movement from static to dynamic media promises to bring about a fourth cost revolution in the related areas of jurisdiction, trust, and security. Impacts on business will be felt in law, accounting, auditing, billing, collections, contracts, confidentiality, and so on: in short, the entire nature of our business relationships will be altered in ways only partially foreseeable.The main traditional way to formalize a business relationship is the contract, a set of promises agreed to in a \"meeting of the minds\". We naturally think of contracts as written, but oral agreements are also considered contracts, and have been around since prehistory. The contract is the basic building block of a market economy. Over many centuries of cultural evolution has emerged both the concept of contract and principles related to it, encoded into common law. Such evolved structures are often prohibitively costly to rederive. If we started from scratch, using reason and experience, it could take many centuries to redevelop sophisticated ideas like contract law and property rights that make the modern market work. But the digital revolution challenges us to develop new institutions in a much shorter period of time. By extracting from our current laws, procedures, and theories those principles which remain applicable in cyberspace, we can retain much of this deep tradition, and greatly shorten the time needed to develop useful digital institutions.Computers make possible the running of algorithms heretofore prohibitively costly, and networks the quicker transmission of larger and more sophisticated messages. Furthermore, computer scientists and cryptographers have recently discovered many new and quite interesting algorithms. Combining these messages and algorithms makes possible a wide variety of new protocols. These protocols, running on public networks such as the Internet, both challenge and enable us to formalize and secure new kinds of relationships in this new environment, just as contract law, business forms, and accounting controls have long formalized and secured business relationships in the paper-based world.In electronic commerce so far, the design criteria important for automating contract execution have come from disparate fields like economics and cryptography, with little cross-communication: little awareness of the technology on the one hand, and little awareness of its best business uses other. These efforts are striving after common objectives, and converge on the concept of smart contracts[1].Smart contracts reduce mental and computational transaction costs imposed by either principals, third parties, or their tools. The contractual phases of search, negotiation, commitment, performance, and adjudication constitute the realm of smart contracts. This article covers all phases, with an emphasis on performance. Smart contracts utilize protocols and user interfaces to facilitate all steps of the contracting process. This gives us new ways to formalize and secure digital relationships which are far more functional than their inanimate paper-based ancestors.The basic idea behind smart contracts is that many kinds of contractual clauses (such as collateral, bonding, delineation of property rights, etc.) can be embedded in the hardware and software we deal with, in such a way as to make breach of contract expensive (if desired, sometimes prohibitively so) for the breacher. A canonical real-life example, which we might consider to be the primitive ancestor of smart contracts, is the humble vending machine. Within a limited amount of potential loss (the amount in the till should be less than the cost of breaching the mechanism), the machine takes in coins, and via a simple mechanism, which makes a freshman computer science problem in design with finite automata, dispense change and product according to the displayed price. The vending machine is a contract with bearer: anybody with coins can participate in an exchange with the vendor. The lockbox and other security mechanisms protect the stored coins and contents from attackers, sufficiently to allow profitable deployment of vending machines in a wide variety of areas.Smart contracts go beyond the vending machine in proposing to embed contracts in all sorts of property that is valuable and controlled by digital means. Smart contracts reference that property in a dynamic, often proactively enforced form, and provide much better observation and verification where proactive measures must fall short.As another example, consider a hypothetical digital security system for automobiles. The smart contract design strategy suggests that we successively refine security protocols to more fully embed in a property the contractual terms which deal with it. These protocols would give control of the cryptographic keys for operating the property to the person who rightfully owns that property, based on the terms of the contract. In the most straightforward implementation, the car can be rendered inoperable unless the proper challenge-response protocol is completed with its rightful owner, preventing theft. But if the car is being used to secure credit, strong security implemented in this traditional way would create a headache for the creditor \u2013 the repo man would no longer be able to confiscate a deadbeat's car. To redress this problem, we can create a smart lien protocol: if the owner fails to make payments, the smart contract invokes the lien protocol, which returns control of the car keys to the bank. This protocol might be much cheaper and more effective than a repo man. A further reification would provably remove the lien when the loan has been paid off, as well as account for hardship and operational exceptions. For example, it would be rude to revoke operation of the car while it's doing 75 down the freeway.In this process of successive refinement we've gone from a crude security system to a reified contract:Mature security systems will be undertaking different behavior for different contracts. To continue with our example, if the automobile contract were a lease, the final payment would switch off leasee access; for purchase on credit, it would switch off creditor access. A security system, by successive redesign, increasingly approaches the logic of the contract which governs the rights and obligations covering the object, information, or computation being secured. Qualitatively different contractual terms, as well as technological differences in the property, give rise to the need for different protocols.Outside of the financial cryptography community, and long predating it, there is a deep tradition of protocols used in the course of performing contracts. These protocols consist of a flow of forms (\"data flow\", canonically displayed in data flow diagrams), along with checks and procedures called \"controls\". Controls serve many of the same functions as cryptographic protocols: integrity, authorization, and so on. This article uses \"control protocols\" or simply \"controls\" to refer to this combination of data flow and controls.Control protocols, and the professions of auditing and accounting[2] based on them, play a critical but ill-analyzed role in our economy. Economists lump them, along with other costs of negotiating and ensuring the performance of contracts, under their catch-all rubric of \"transaction costs\". But without controls, large corporations and the economies of scale they create would not be possible. Controls allow a quarrelsome species ill-suited to organizations larger than small tribes to work together on vast projects like manufacturing jumbo jets and running hospitals. These control protocols are the result of many centuries of business experience and have a long future ahead of them, but the digital revolution will soon cause these paper-era techniques to be dramatically augmented by, and eventually integrate into, smart contracts.Controls enable auditing of contract performances, allowing more precise inference of the behavior of an agent. Auditing is costly, so it is undertaken by random sampling. Economists study the substitutability between the probability of verifying a breach and the magnitude of legal fines, where physical enforcement is used. Conceivably, one could substitute increasingly high penalties for increasingly rarer and less expensive auditing. However, this is not robust to real-world conditions of imperfect information.Since controls primarily address the implicit contracts between employees and employer, there is little mapping from contract to control. A secondary function of controls to to monitor contracts with other organizations. Here there is some mapping, but it is confounded by the integration of the two functions in most controls. Rather than based on contractual terms, controls are typically based on managerial authorization.Controls are typically based around amounts of money and quantities of goods. A canonical control is double entry bookkeeping, where two books are kept, and there must be arithmetic reconciliation between the books. To conceal an irregularity, necessary to omit from both sides, or to record entries offsetting the irregularity. Notice that there is a problem distinguishing error from fraud. This problem crops up in many areas in both auditing and smart contracts. To illustrate, here are two common control techniques:Imprest: this is a family of controls involving the receipt or disbursement of bearer certificates (usually notes and coins). One example is the protocol used at most movie theaters. Entry is segregated from payment by introducing tickets and establishing two employee roles, the ticket seller in a booth, and the ticket stub salesman at the entrance. Periodically, a bookkeeper reconciles the number of tickets with the total paid. Discrepancy again indicates fraud or error.Customer audit: Techniques to get the customer to generate initial documentation of a transaction. For example, pricing goods at $.99 forces the employee to open the cash register to make change, generating a receipt.A complete control protocol typically features the generation of initial documentation, segregation of duties, and arithmetic reconciliation of quantities of goods, standard service events, and money.Of these, the segregation of duties deserves special comment.In a large business, transactions are divided up so that no single person can commit fraud. Segregation of duties is an instance of the principle of required conspiracy. For example, the functions of warehouse/delivery, sales, and receipt of payments are each performed by different parties, with a policy that each party reports every transaction to a fourth function, accounting. Any singular reported activity (e.g., delivery without receipt of payment) indicates potential fraud (e.g., a delivery was made to a customer and the payment pocketed instead of being put into the corporate treasury). Segregation of duties is the auditor's favorite tool. Where it is absent the auditor cries \"foul\", just as a good engineer would react to a single point of failure. Many cryptographic systems have rightfully gone down to commercial failure because they ground down to trust in a single entity rather than segregating functions so as to require conspiracy.There are least three significant differences between the scope and emphasis of smart contracts and controls. Controls are paper-era protocols designed around static forms, place little emphasis on confidentiality, and are based on management authorizations rather than one-to-one relationships.Smart contracts can be based on a wide variety of interactive protocols and user interfaces, and can be involved in a wide variety of kinds of contractual performance. Control protocols, developed in the era of paper, are based on static forms passed as messages and processed in tables and spreadsheets. Controls focus on money and counts of standardized goods and service events, easily recorded by numbers and manipulated by arithmetic, while mostly ignoring other kinds or aspects of contractual performance. Checksums on numbers, the basis of reconciliation, are crude and forgeable compared to cryptographic hashes. Electronic Data Interchange (EDI) keeps these static forms and maintains reliance on controls. It uses cryptographic hashes for nothing more sophisticated than integrity checks on individual messages.Controls place little emphasis on confidentiality, at least in the modern accounting literature. The emphasis on confidentiality in paper-era protocols is lacking because violation of often implicit confidences, via replication of data, was much more difficult with paper. Furthermore, technologies for protecting confidentiality while auditing were not feasible. Businesses traditionally trusted accounting firms with confidences, a trust that has eroded over the last century, and will erode still further as accounting firms start taking advantage of the vast amounts of inside and marketing information they are collecting from their customers' databases during audits. Using paper-based protocols in a digital world, there are few effective controls against the auditors themselves. Post-unforgeable transaction logs and multiparty secure computation, discussed below, indicate the possibility of cryptographic protocols to implement less relavatory but more effective auditing trails and controls; their use may be able to ameliorate the growing problems with data mining and breach of confidentiality.Auditors place quite a bit of trust in management to authorize transactions in a secure and productive manner. Objecting to this dual trust in management and distrust of employees inherent in the accounting tradition, there has been a trend in the last two decades towards a loosening of controls as a part of hierarchy flattening and empowerment of professional employees. Unfortunately, loose controls have led to several recent scandals in the banking and investment trade. The most recent view is that there must be a learned tradeoff between controls and empowerment. The smart contract view is that we need smarter controls, originating at the ownership of the company, and entailing less asymmetry between management and other professional employees. This means converting many implicit employee contracts to more explicit smart contracts based on more direct relationships between owners (or at least their directors) and employees, and symmetric formalizations between employees.Although most of these differences are biased against controls, these traditional protocols have a long future ahead of them, simply because they have a long past. They are highly evolved, hundreds of years old (double-entry bookkeeping, for example, predates the Renaissance). Smart contracts will incorporate many techniques and strategies from control protocols, such as generation of an initial record, segregation of duties, and reconciliation. It will not be long, however, before smart contracts start augmenting and transforming traditional business procedures, making a wide variety of new business structures possible and in the long run replacing traditional controls.Electronic Data Interchange (EDI) is the computer-to-computer communication of standardized business transactions between organizations, in a standard format that permits the receiver to perform the intended transaction. It renders traditional static business forms in cyberspace, and maintains the dependence on traditional controls. Beyond simple encryption and integrity checks, EDI does not take advantage of algorithms and protocols to add security and \"smarts\" to business relationships. It enables more rapid execution of traditional negotiation and performance monitoring procedures.EDI loses some security features provided by physical paper (such as difficulty of copying) while not gaining advantages from the wide variety of protocols possible beyond simple message-passing of static forms. This article examples a much richer set of protocols.EDI contracts tend to be merely reiterations of existing terms and conditions, with only some timing expectations changed for the electronic environment. By redesigning our business relationships to take advantage of a richer set of protocols, smart contracts can take us far beyond the paper-based paradigm of shipping around forms in a secure manner.The following classification, derived from Sokol[3], illustrates the variety of business forms that have been rendered in electronic form:Focal (or Schelling) points are often designed and submitted into negotiations by one side or another, both to bias the negotiations and to reduce their cost. The fixed price at the supermarket (instead of haggling), the prewritten contract the appliance salesman presents you, etc. are examples of hard focal points. They are simply agreed to right away; they serve as the end as well as the beginning of negotiations, because haggling over whether the nearest neighbor focal point is better is too expensive for both parties.There are many weak enforcement mechanisms which also serve a similar purpose, like the little arms in parking garages that prevent you from leaving without paying, the sawhorses and tape around construction sites, most fences, etc. Civilization is filled with contracts embedded in the world.More subtle examples include taxi meters, cash register readouts, computer displays, and so on. As with hard focal points, the cost of haggling can often be reduced by invoking technology as authority. \"I'm sorry, but that's what the computer says\", argue clerks around the world. \"I know I estimated $50 to get to Manhattan, but the meter reads $75\", says the taxi driver.Economists stress two properties important to good contract design: observability by principals and verifiability by third parties such as auditors and adjudicators. From the traditions behind contract law and the objectives of data security, we derive a third objective, privity. We flesh out the dimensions of contract design by disentangling mental from computational transaction costs, classifying the kinds of enforceability, characterizing the temporal phases of contracting, and discussing the nature of tradeoffs between the three design objectives.The costs that smart contracts address are lumped by economists under the catch-all rubric of \"transaction costs\". We can divide these into mental and computational transaction costs.One major category of costs include the cost of anticipating, agreeing to, and clearly writing down the various eventualities. These are largely mental transaction costs, although online research tools, for example, may bring more information about eventualities.Most contractual dispute involves an unforeseen or unspecified eventuality. We lack a good model for this. Such a model would account for the computational costs of foreseeing these eventualities, some of which may be uncomputable (and therefore of infinite cost). Where eventualities remain unspecified, contracts remain incomplete.Where counterparties lack focal points, they lack a meeting of minds. Negotiation addresses this gap; the farther apart the focal points (in terms of value), the more expensive the negotiations. There are a variety of institutions of negotiation, which economists study under the rubric of \"mechanisms\". These range from simple haggling to sophisticated auctions and exchanges.For the temporal phases of contracting we use the following schema, classified according to the two-phase model used in economics:Smart contracts often involve trusted third parties, exemplified by an intermediary, who is involved in the performance, and an adjudicator, who is invoked to resolve disputes arising out of performance (or lack thereof). Intermediaries can operate during search, negotiation, commitment, and/or performance. Hidden knowledge, or adverse selection, occurs ex-ante; hidden actions (moral hazards) occur ex-post.Here are some examples of contemporary electronic commerce activities and the phases of contracting they deal with:This article covers all phases, with a particular emphasis on performance.The first objective of smart contract design is observability, the ability of the principals to observe each others' performance of the contract, or to prove their performance to other principals. The field of accounting is, roughly speaking, primarily concerned with making contracts an organization is involved in more observable.Economists discuss \"hidden knowledge\", also known as \"adverse selection\", which can occur due to lack of ability to observe potential counterparties during the search and negotiation phases. Another major problem is \"hidden actions\", also known as \"moral hazard\", which can occur due to the lack of observability and ability to drop out of contract during the performance phase of a contract.One important task of smart contracts, that has been largely overlooked by traditional EDI, is critical to \"the meeting of the minds\" that is at the heart of a contract: communicating the semantics of the protocols to the parties involved. There is ample opportunity in smart contracts for \"smart fine print\": actions taken by the software hidden from a party to the transaction.Here's a small example of smart fine print:Without user interfaces smart contracts are largely invisible, like the electronics in newer car engines. This is both a blessing \u2013 counterparties don't have to feel like they're dealing with user-hostile computers \u2013 and a curse \u2013 the \"smart fine print\" problem of hidden actions.To properly communicate transaction semantics, we need good visual metaphors for the elements of the contract. These would hide the details of the protocol without surrendering control over the knowledge and execution of contract terms. For example, encryption can be shown by putting the document in an envelope, and a digital signature by affixing a seal onto the document or envelope.Amid all the hype about \"information warfare\", lost in the noise is the fact that it is impossible to commit an act of physical violence over the Net. That includes not only all physical crimes of coercion, but also arrest, incarceration, and other traditional methods of law enforcement. Because of this fact, and the jurisdictional swamp that is the multinational Internet, this article concentrates on means of protecting against breach and third parties that do not rely on law enforcement.We can categorize the security measures against breach, eavesdropping, and interference in the following manner:Currently, the most prevalent forms of security software are not proactive cryptography, but reactive and panoptic methods like virus scanning software, filtering firewalls, traceroutes of attackers, etc. Once modern cryptographic protocols are more widely deployed, the balance will likely shift towards preventative security.Reactive measures rely upon two areas: verifiability and penalties. As discussed in the section on accounting controls, under ideal economic conditions, the statistical distribution of verification failures is known, so that verification costs and penalties are can be traded off neatly. But with imperfect information, the jurisdictional swamp, and lack of collateral or other security, collection of damage awards is even more severely limited than in contracts confined to traditional geographic jurisdictions. Reputation costs may be the only practical source of penalties in many cases. For reactive measures to work, high verifiability is critical.So our second objective is verifiability, the ability of a principal to prove to an adjudicator that a contract has been performed or breached, or the ability of the adjudicator to find this out by other means. The disciplines of auditing and investigation roughly correspond with verification of contract performance.Our third objective of smart contract design is privity, the principle that knowledge and control over the contents and performance of a contract should be distributed among parties only as much as is necessary for the performance of that contract. This is a generalization of the common law principle of contract privity, which states that third parties, other than the designated adjudicators and intermediaries, should have no say in the enforcement of a contract. To maintain knowledge and control, performance must be encapsulated: protected from outside influences, especially sophisticated attacks. This is the idea behind both the legal doctrine of privity, which restricts redress to the parties to a contract, and the idea of property rights.Attacks against privity are epitomized by third parties Eve the eavesdropper, a passive observer of contents or performance, and malicious Mallet, who actively interferes with performance or steals service. Under this model privacy and confidentiality, or protecting the value of information about a contract, its parties, and its performance from Eve, is subsumed under privity, as are property rights. The most common definitions of \"security\" in the online world roughly correspond to the goal of privity.Our generalized privity thus encompasses property rights as stable objects linked to particular contracts (and thereby the parties in privity to such contracts, the \"owners\"). Privity creates a clear boundary within which operate a coherent set of rights, responsibilities, and the knowledge with which to carry out those responsibilities and protect those rights. Clarified boundaries also allow accountability. Protection from extraneous interference allows us to focus responsibility for the consequences of contract-related activity onto the parties to the contract.Privity says that we want to minimize vulnerability to third parties. Verifiability and observability often require that we invoke them. An intermediary must be trusted with some of the contents and/or performance of the contract. An adjudicator must be trusted with some of the contents, and some of the history of performance, and to resolve disputes and invoke penalties fairly. In smart contract design we want to get the most out of intermediaries and adjudicator, while minimizing exposure to them. One common outcome is that confidentiality is violated only in case of dispute.Many kinds of specific performance are often entrusted to intermediaries. We must be able to trust the intermediary (credit agency, anti-virus software vendor, certificate intermediary, digital cash mint, etc.) with their particular claims (about creditworthiness, dangerous byte patterns, identity, conservation of the money supply, etc.) As Ronald Reagan remarked in a slightly different context, \"trust but verify\". To deserve our trust, intermediaries must convince us that their claims are true. We need to be able to \"ping\" their veracity, verifying that certain claimed transactions in fact occurred. An entire profession exists in market economies to perform this function: auditing.Ideally, observability and verifiability can also include the ability to differentiate between intentional violations of the contract and good faith errors, but this is difficult in practice, since the difference is often largely one of subjective, unrevealed intent.A protocol[5] in computer science is a sequence of messages between at least two computers. At a higher level of abstraction, a protocol consists of algorithms communicating via messages. These programs act as proxies, or agents, for human users, who communicate their preferences via users interfaces. We distinguish protocol endpoints by names such as \"Alice\" and \"Bob\", but it should be kept in mind that the end points are really computer processing units, which may or may not be under the control of, or taking actions contrary to the intent of, the human user. Human users typically do not have full knowledge of the protocol in question, but rather a metaphorical understanding obtained via user interface, manuals, and so on. Unlike most real-world contracts, protocols must be unambiguous and complete.Protocols come in three basic types. I have modified the terminology of Schneier[6] to match more closely to the corresponding business terminology:The corresponding smart contracts elaborate on \"Alice\" to distinguish between the software (in two components, the endpoint of protocol and the user interface), and Alice herself. Cryptographic and other computer security mechanisms give us a kit of tools and parts from which we can build protocols, which form the basis of smart contracts.The security properties of physical media are based on physical properties we often take for granted, for example the unforgeability of an atom of gold. The structural constraints (\"physics\") of cyberspace relevant to security are described by the mathematical theories studied by computer scientists, especially in the specialty called cryptography. Here are the important \"fundamental particles\" of the cryptographic universe:These \"particles\" are potent building blocks for engineering secure protocols. Imagine a material so tough, it is completely impervious to a supernova, and so cheap you could use it to make walls, locks, safes, and envelopes to protect everyday items. This is not just a metaphor: cracking a 4,096 bit RSA key with best known algorithm really would require more electrical power for the computers than the power produced by a supernova. These cryptographic primitives promise to be a main driving force of the fourth cost revolution for global business.A family of protocols, called cryptographic protocols because their first application was computerized \"secret writing\", provide many of the basic building blocks that implement the improved tradeoffs between observability, verifiability, privity, and enforceability in smart contracts. Contrary to the common wisdom, obscurity is often critical to security. Cryptographic protocols are built around foci of obscurity called keys. A key's immense unknown randomness allows the rest of the system to be simple and public. The obscurity of a large random number, so vast that a lucky guess is astronomically unlikely, is the foundation upon which cryptographic protocols, and smart contracts based on them, are built.Two significant cautions are in order when thinking about how cryptographic protocols can be used in online relationships. The first is that protocols usually provide security \"up to\" some assumption. This assumption is a remaining weak point which a complete working system must address in some reasonable manner. One common endpoint is is assumptions about trusted third parties. Often the degree or function of the trust is not well specified, and it is up to the real-world systems analyst to characterize and ameliorate these exposures. The best mediated protocols only trust the intermediary or counterparty with a well limited function.Even without trusted third parties, cryptographic protocols often ground out in trust of the counterparty. For example, encryption of a message provides confidentiality up to the actions of parties with decrypting keys. Encryption does not stop key holders from posting plain text to Usenet. We cannot just say that encryption provides \"confidentiality\" and leave our concern for confidentiality at that.The second caution is that much of the terminology used in the cryptographic literature to name protocols (\"signatures\", \"cash\", etc.) is misleading. Sometimes the terminology falls short on substantial matters: a \"digital signature\", for example, is not biometric and is based on a key that can easily be copied if not protected by another mechanism. Often cryptographic protocols can be generalized to much wider purposes than implied by the label. For example, \"digital cash\" is a very general protocol which can implement a wide variety of bearer certificates and conservation wrappers for distributed objects.Protocols for smart contracts should be structured in such a way as to make their contractsA vandal can be a strategy or sub-strategy of a game whose utility is at least partially a function of one's own negative utility; or it can be a mistake by a contracting party to the same effect. \"Naive\" simply refers to both lack of forethought as to the consequences of an attack , as well as the relatively low amount of resources expended to enable that attack. Naive vandalism is common enough that it must be taken into consideration. A third category, (c) sophisticated vandalism (where the vandals can and are willing to sacrifice substantial resources), for example a military attack by third parties, is of a special and difficult kind that doesn't often arise in typical contracting, so that we can place it in a separate category and ignore it here. The distinction between naive and sophisticated strategies has been computationally formalized in algorithmic information theory.The expected loss due to third party attack is called the exposure. The cost of third parties to defeat the security mechanism is the disruption cost. If the disruption cost is greater than the expected benefit, we can expect an incentive compatible attacker to disrupt the security.One of the drivers of the trust cost revolution will likely be the wide variety of new cryptographic protocols that have emerged in recent years. The most traditional kind of cryptography is secret key cryptography, in which Alice and Bob (our exemplar parties to a smart contract) use a single shared, prearranged key to encrypt messages between them. A fundamental problem we will see throughout these protocols is the need to keep keys secret, and public key cryptography helps solve this. In this technique, Alice generates two keys, called the private and public keys. She keeps the private key secret and well protected, and publishes the public key. When Bob wishes to send a message to Alice, he encrypts a message with her public key, sends the encrypted message, and she decrypts the message with her private key. The private key provides a \"trapdoor\" that allows Alice to compute an easy inverse of the encryption function that used the public key. The public key provides no clue as to what the private key is, even though they are mathematically related. The RSA algorithm is the most widely used method of public key cryptography.Public key cryptography also makes possible a wide variety of digital signatures. These proves that a piece of data (hereafter referred to as just an \"object\") was in active contact with the private key corresponding to the signature: the object was actively \"signed\" with that key. There are two steps to an authentication protocol: signing and verification. These may occur synchronously, or, in many public protocols, a signature may be verified at some distant time in the future.The digital signature probably should have been called a \"digital stamp\" or \"digital seal\" since its function resembles more those methods than an autograph. In particular, it is not biometric like an autograph, although incorporation of a typed-in password as part of the private key used to sign can sometimes substitute for an autograph. In many Asian countries, a hand-carved wooden block, called a \"chop\", is often used instead of autographs. Every chop is unique, and because of the unique carving and wood grain cannot be copied. A digital signature is similar to the chop, since every newly generated key is unique, but it is trivial to copy the key if obtained from the holder. A digital signature relies on the assumption that the holder will keep the private key secret.A blind signature publically authenticates privy information (but can we use non-privy signatures blindly as well?). This is a digital signature and secret-key encryption protocol that together have the mathematical property of commutativity, so that they can be stripped in reverse of the order they were applied. It's like stamping an unknown document through carbon paper (without having to worry about smudging). The effect is that Bob \"signs\" an object, for which he can verify its general form, but cannot see its specific content. Typically the key of the signature defines the meaning of the signed object, rather than the contents of the object signed, so that Bob doesn't sign a blank check. Blind signatures used in digital bearer certificates, where Bob is the clearing agent, and in Chaumian credentials, where Bob is the credential issuer.The blind signature is one example of the many \"magic ink signatures\" cryptographers have invented. Another class of these protocols are used to limit the parties allowed to either verify the signature or to learn the identity of the signer. The most privy are the zero-knowledge proofs, where only the counterparty can authenticate the prover. Designated confirmer signatures allow the signer to designate particular counterparties as verifiers. For example, a business could give particular auditors, investigators, or adjudicators the authority to verify signed objects, while other third parties, such as competitors, can learn nothing from the signature. Group signatures allow members to sign as an authentic member of a group, without revealing which member made the signature.So far, we've assumed parties like Alice and Bob are monolithic. But in the world of smart contracts, they will use computer-based software agents and smart cards to do their electronic bidding. Keys are not necessarily tied to identities, and the task of doing such binding turns out to be more difficult than at first glance. Once keys are bound, they need to be well protected, but wide area network connections are notoriously vulnerable to hacking.If we assume that the attacker has the ability to intercept and redirect any messages in the network protocol, as is the case on wide area networks such as the Internet, then we must also assume, for practical all commercial operating systems, that they would also be able to invade client if not merchant computers and find any keys lying on the disk.There's no completely satisfactory solution to end point operations security from network-based attacks, but here's a strategy for practically defanging this problem for public-key based systems:All public key operation can be performed inside an unreadable hardware board or smart card on a machine with a very narrow serial-line connection (ie, it carries only a simple single-use protocol with well-verified security) to a dedicated firewall. This is economical for high traffic servers, but may be less practical for individual users. Besides better security, it has the added advantage that hardware speeds up the public key computations.If Mallet's capability is to physically seize the machine, a weaker form of key protection will suffice. The trick is to hold the keys in volatile memory. This makes the PC proof from physical attacks \u2013 all that needed to destroy the keys is to turn off the PC. If the key backups can be hidden in a different, secure physical location, this allows the user of this PC to encrypt large amounts of data both on the PC itself and on public computer networks, without fear that physical attack against the PC will compromise that data. The data is still vulnerable to a \"rubber hose attack\" where the owner is coerced into revealing the hidden keys.Object-oriented, or capability, security is a deep and promising area, but beyond the scope of this article. Capabilities can potentially simplify the design of many distributed security protocols. Instead of developing a new or modified cryptographic protocol for each contracting problem, capabilities may allow us to design a rich variety of distributed security protocols over a common cryptographic framework.For more information see Introduction to Capability Based Security.Quorum distribution of performance or control over resources can be based on the secret sharing of keys needed to perform or control a resource. These are also known as threshold techniques. These are methods of splitting a key (and thus control over any object encrypted with that key) into N parts, of which only M are needed to recreate the key, but less than M of the parts provide no information about the key. Secret sharing is a potent tool for distributing control over objects between principals.Markus Jacobsson has designed a quorum of mints for signing digital coins, for example. Quorum establishes a \"required conspiracy\" of M out of N to perform a function, providing an option for stronger protection than the typical 2 out of N used in segregation of duties, and greater confidence in the security underlying the segregation.Traditionally, auditors have contacted counterparties in order to verify that a transaction actually took place (The \"principle of required conspiracy\" at work again). With post-unforgeable logs, via a hierarchical system of one-way hash functions, a party can publically commit to transactions as they are completed by publishing signed cumulative hashes of the transaction stream. The confidentiality of the transaction is fully maintained until an auditor \"pings\" the transaction to determine its actual nature. The counterparty identity can remain confidential, because it is not required to establish the other facts of the transaction. The only attack is to forge transactions in real time, as the transaction itself takes place, which in most practical cases will be unfeasible. Most accounting fraud involves analyzing sets of completed transactions and then forging them to make them compute to a desired counterfactual result.Cryptographers have developed protocols which create virtual machines between two or more parties. Multiparty secure computation allows any number of parties to share a computation, each learning only what can be inferred from their own inputs and the output of the computation. These virtual machines have the exciting property that each party's input is strongly confidential from the other parties. The program and the output are shared by the parties. So, for example, we could run a spreadsheet across the Internet on this virtual computer. We would agree on a set of formulas, set up the virtual computer with these formulas, and each input our own private data. We could only learn only as much about the other participants' inputs as we could infer from our own inputs and the output.There are two major complications. The first is that this virtual computer is very slow: one machine instruction per network message. The second is that some parties learn the results before others. Several papers have disussed the fraction of parties one must trust in order to be assured of learning the correct output. The mechanism must be constructed so that a sufficient number of parties have an incentive to pass on the correct result, or reputation, side contracts, etc. used to the same effect.With these caveats, any algorithmic intermediary can, in principle, be replaced by a trustworthy virtual computer. In practice, because of the two complications, we usually construct more limited protocols out of more efficient elements.Trusted Third Party:Mathematically Trustworthy Protocol:Multiparty secure computer theory, by making possible privy virtual intermediation, has major implications for all phases of contracting. This can be seen most clearly in the area of negotiations. A \"mechanism\" in economics is an abstract model of an institution which communicates with its participants via messages, and whose rules can be specified algorithmically. These institutions can be auctions, exchanges, voting, and so on. They typically implement some kind of negotiation or decision making process.Economists assume a trusted intermediary operates the mechanism. Here's a simple example of using this virtual computer for a mechanism. Alice can submit a bid price, and Bob an ask price, to their shared virtual computer which has one instruction, \"A greater than B?\". The computer then returns \"true\" if Alice's bid is greater than Bob's offer. A slightly more sophisticated computer may then decide the settlement price according to a number of different algorithms (Alice's bid, Bob's ask, split the difference, etc.) This implements the mechanism \"blind bargaining\" with no trusted intermediary.In principle, since any computable problem can be solved on this virtual computer (they are \"Turing complete\"), any computable economic mechanism can be implemented without a trusted intermediary. In practice, these secure virtual computers run very slowly (one virtual machine instruction per network message), and the order in which participants learn results often matters. But the existence proof, that any economic mechanism can be run without a trusted intermediary, up to temporal issues, is very exciting. This means that, in principle, any contract which can be negotiated through a trusted third party (such as an auction or exchange) can be negotiated directly. So, in some abstract sense, the only remaining \"hard\" problems in smart contract negotiations are (a) problems considered hard even with a trusted intermediary (for the standard economic reasons), (b) nonsimultaneity problems in learning the decision, and (c) the task of algorithmically specifying the negotiating rules and output contract terms (This includes cases where an intermediary adds knowledge unavailable to the participants, such as a lawyer giving advice on how to draft a contract).Applying this kind of analysis to the performance phase of contracts is less straightforward. For starters, economic theories of the performance phase are not as well developed or simple as the mechanism theory of negotiations. Indeed, most economic theory simply assumes that all contracts can be perfectly and costlessly enforced. Some of the \"transaction cost\" literature has started to move beyond this assumption, but there are few compelling results or consensus theories in the area of techniques and costs of contract enforcement.Performance phase analysis with multiparty secure computer theory would seem to apply only to those contracts which can be performed inside the virtual computer. But the use of post-unforgeable auditing logs, combined with running auditing protocols inside the shared virtual computer, allows a wide variety of performances outside the virtual computer to at least be observed and verified by selected arbitrators, albeit not proactively self-enforced.The participants in this mutually confidential auditing protocol can verify that the books match the details of transactions stored in a previously committed transaction log, and that the numbers add up correctly. The participants can compute summary statistics on their confidentially shared transaction logs, including cross-checking of the logs against counterparties to a transaction, without revealing those logs. They only learn what can be inferred from the statistics, can't see the details of the transactions. Another intriguing possibility is that the virtual computer can keep state over long periods of time, allowing sophisticated forms of privy and self-enforcing secured credit.With mutually confidential auditing we will be able to gain high confidence in the factuality of counterparties' claims and reports without revealing identifying and other detailed information from the transactions underlying those reports. These provide the basis for solid reputation systems, and other trusted third party systems, that maintain integrity across time, communications, and summarization, and preserve confidentiality for transaction participants. Knowing that mutually confidential auditing can be accomplished in principle may lead us to practical solutions.Bearer certificates implement transferable rights on standardized contracts. Each kind of contract (for example, each denomination of \"coin\" in digital cash) corresponds to a digital signature, just as each issue of Federal Reserve Notes or stock certificates corresponds to a particular plate.In the most straightforward bearer certificate protocol, the issuer and transfer agent (the same entity, for our purposes, though they can easily be unbundled) create a serial number (really a large unguessable random number, rather than a sequence), and add it to a list of issued certificates. The transfer agent clears a transfer by checking the signature to identify and nature of the bearer contract and verify that it was made, then looking on that contract's issued list to make sure the serial number is there, then removing the serial number. Alternatively, the issuer can let the issuee make up the serial number, then, when cleared, check the signature and put the number on the list of cleared certificates. The signature provides the assurance that the certificate is indeed the the particular kind of contract with bearer, while the serial number assures that the same instance of that contract is not cleared or redeemed more than once. In these simple versions, the transfer agent can link the transferee to the transferor for all transfers. To implement the privacy characteristics of coins and physical bearer certificates, we need to add unlinkability features.Unlinkability can be provided by combining the second variation above, a list of cleared certificates, with blind signatures and a mixing effect. Enough instances of a standardized contract are issued over a period of time to create a mix. Between the issuing and clearing of a certificate, many other certificates with the same signature will be cleared, making it highly improbable that a particular clearing can be linked to a particular issue via the signature. There is a tradeoff between the mixing effect and the exposure to the theft of a \"plate\" for a particular issue: the smaller the issue, the smaller the exposure but the greater the linkability; a larger issue has both greater exposure and greater confidentiality.Blind signatures can be used to make certificate transfers unlinkable via serial number. Privacy from the transfer agent can take the form of transferee-unlinkability, transferor-unlinkability, or \"double blinded\" where both transferor and transferee are unlinkable by the transfer agent or a collusion of a transfer agent and counterparty.Bearer certificates come in an \"online\" variety, cleared during every transfer, and thus both verifiable and observable, and an \"offline\" variety, which can be transferred without being cleared, but is only verifiable when finally cleared, by revealing any the clearing name of any intermediate holder who transferred the object multiple times (a breach of contract).This unlinkability is often called \"anonymity\", but the issue of whether accounts are issued to real names or pseudonyms, and whether transferor and transferee identify themselves to each other, is orthogonal to unlinkability by the transfer agent in the online model. In the off-line model, account identification (or at least a highly reputable and/or secured pseudonym) is required: passing an offline certificate a second time reveals this identity. Furthermore, communications channels can allow Eve to link transferor and transferee, unless they take the precaution of using an anonymous remailer. Online clearing does make lack of identification a reasonable option for many kinds of transactions, although common credit and warrantee situations often benefit from or even require identification.When confronting an attempted clearing of a cleared serial number, we face an error-or-fraud dilemma similar to the one we encountered above in double entry bookkeeping. The ecash\u2122 protocol from DigiCash actually takes advantage of this ambiguity, second-transferring certificates on purpose to recover from a network failure. When certificates are lost over the net it is not clear to the transferor whether they have been received and cleared by the transferee or not. Second-transferring directly with the transfer agent resolves the ambiguity. This only works with the online protocol. The issue of distinguishing error from fraud is urgent in the offline protocol, but there is as yet no highly satisfactory solution. This problem is often intractable due to the subjectivity of intent.Issuance and cleared transfer of references to a distributed object conserves the usage of that object. This object becomes \"scarce\" in economic terms, just as use of physical objects is finite. Conserved objects provide the basis for a software economics that more closely resembles economics of scarce physical objects. Conserved objects can be used to selectively exclude not only scarce physical resources (such as CPU time, network bandwidth and response time, etc.), but also fruits of intellectual labor \u2013 as long as one is willing to pay the price to interact with that information over the network rather than locally (cf. content rights management). Conservation immunizes objects and the resources they encapsulate to denial of service attacks. Bearer certificate protocols can be used to transfer references to a particular instance or set of instances of an object, just as they can be used to transfer other kinds of standardized rights.Digital cash is the premier example of a digital bearer certificate. The issue and transfer agent is called a \"mint\". Bearer certificate protocols enable online payment while honoring the characteristics desired of bearer notes, especially unforgeability (via the clearing mechanism) and transfer confidentiality (via mixing and blinding).To implement a full transaction of payment for services, we often need need more than just the digital cash protocol; we need a protocol that guarantees that service will be rendered if payment is made, and vice versa. Current commercial systems use a wide variety of techniques to accomplish this, such as certified mail, face to face exchange, reliance on credit history and collection agencies to extend credit, etc. Potential smart contract protocols in this area are discussed under Credit.Content protection contracts are valuable in that they incentive publishers to allow users to view content directly, rather than indirectly and partially via queries to remote servers. Content protection of software distributed online would allow it to be run locally rather than remotely, while enforcing the contract rights and copyrights of the publisher against the user. This local usage billing of software often goes under the rubric of \"superdistribution\"[11].Watermark schemes work by altering less significant bits of content \u2013 usually a picture; sound works less well and text is difficult. These altered bits typically contain the identities of the publisher and viewer, and perhaps other information related to the contract. The idea is that, when investigators scan released content, the watermark will finger the breacher of the contract (or violator of copyright law).Watermark investigation can be assisted by a quite inexpensive technique, Web spiders. These spiders look for redistributed watermarked material on the Web. The customer originating the copy can then be fingered.One attack against watermarks is to overwrite likely watermark bits with other patterns legitimate to viewing software. The entanglement of watermark bits with bits important to the picture can be made rather obscure, but not strongly so by the standards of cryptography. Another attack is to steal content from a customer and distribute it as is. The watermark will finger the victim, rather than the thief.All watermark schemes can be defeated with sufficient effort. These schemes can then be distributed as software worldwide. Once the initial effort is put into breaking a scheme, the marginal cost of breaking it is minimal. Furthermore, once the watermark is removed, the content can be distributed and even published[12] with secure anonymity.In sum, watermark schemes can add significant risk to the copying of of low value or ephemeral information. This will be sufficient for many kinds of content, such as news or product updates. It won't stop, for long, the redistribution of high-value content. Since watermarks require traceable identification, they reduce customer privacy and require the inconvenience of registration and authentication, adding to the transaction costs of content purchase.Contrary to the hype, there is no strong content protection software. Watermarks are as close as we've come, and they fall far short of the standards of computer security. Large sums have gone into attempts to develop such technology, resulting in hundreds of patents but no substantial results.As a result, some publishers have begun putting their research dollars into a radical alternative, innocuously dubbed the \"secure CPU\" (SPU)[13]. This is a CPU that is \"secure\" against the owner of the computer! To enforce copyright or content contracts, the SPU monitors all content-related activity. Some marketing literature even lists, alongside the traditional copyright, a new \"right\" of publishers to monitor the usage of their content. Remarkably enough, these panoptic non-personal computers are the focus of major R&D efforts.The radical SPU projects demonstrate both the high value of content contracts to publishers and the high price we have to pay to maintain the paper-era intellectual property model online. Strong content protection would be valuable in going beyond indirect and partial viewing of content on servers, to viewing content directly and locally. The price is the loss of control over our own computers, and loss of privacy over our activities on those computers.The online content market is squeezed from above and below. From above, by the ease of redistributing high-value content. From below, by the mental transaction costs of charging for low value content \u2013 costs to which the requirements of registration and traceable identification add substantially. The size of the market in between is an open question. \"Information wants to be free\", but authors and publishers want to be paid for it. The current content market for more difficult to copy media, such as books, films, CD-ROM, and so forth is large, in the hundreds of billions of dollars per year. But on the Internet, free content dominates. Distributing ephemeral content in the form of service subscriptions is in most cases a more viable way to go. It remains to be seen how large the Internet content market will become, and to what extent customers will tolerate impositions on privacy and control of their computers in order to obtain legal content.Reputation can be viewed as the amount of trust an agent has created for himself[14]. Reputation systems ultimately need to be based on fact rather than mere opinion or faith to be effective. For example, if we are to have a good credit rating system, we need to be confident that the credit record assembled by the agency is sufficiently accurate. Reputation information is typical gathered and distributed by intermediaries trusted to perform this task. Reputation can take the form of a public database (such as credit rating services) or credentials issued by the tracking agency and carried by the user. A bearer doesn't want to show his negative credentials, so credentials are often only positive. But we want to protect ourselves against negative behavior sources well as search out positive sources.Tags that bundle the results of a wide variety of transactions - global names, or universal IDs, or \"True Names\" \u2013 may provide the most incentive for parties to carry their negative credentials. Most people have accumulated enough positive reputation is some areas that it is well-nigh impossible for them to start over their entire lives as newcomers.Robin Hanson[15] has observed that in a world of global names, the use of a local name may signal the hiding of negative credentials, so that the use of global names is in equilibrium. A further problem with local names is that our relationships are often not neatly compartmentalizable into standard service types, and even where they are we might like to expand them into new areas. On the other hand, local names are essential for privacy. I suggest that we will want to reveal progressively more local names to our counterparties as our relationships with them become closer and more co-exposed.While the global name equilibrium may hold for many of our relationships, there may be plenty of areas where the privity benefits of localizing names outweigh the costs of being less or unable to differentiate newcomers from hostiles. For example, the preference-tracking service at www.firefly.com increases participation via the use of pseudonyms, thereby protecting customers from exposure to strangers who might abuse that information. On the other hand, credit transactions typically demand identifying information, because the contractual exposure typically outweighs benefits of privity.Global name public keys, which have many drawbacks in terms of privity, may be the best way to track negative reputation, but they are no panacea. There is an important conundrum in an ID-based key system: the conflict between the ability to get a new key when the old one is or could be abused by another (key revocation), and the ability of another to be sure they are dealing with the same person again. This may also provide an opportunity for parties to selectively reveal positive credentials and hide negative ones. For example, a person with a bad credit rating could revoke the key under which that rating is distributed and create a new one, while selectively updating their positive credentials to the new key (e.g., have their alma mater create a new diploma).The current universal (non-cryptographic) key in the U.S., the social security number (SSN), is very difficult to revoke; it's much easier to change your name. This policy is probably no accident, since the biggest economic win of global name identification is the tracking of negative reputations, which revocation can defeat. As long as the SSN is a shared database key, not used for the purpose of securely identifying a faceless transaction, there is little need for revocation beyond the undesired erasure of negative history. Combining a secret authentication key, which must be revocable, with a public universal ID is quite problematic.One of the basic outstanding problems in smart contracts is the ensurement of credit. This comes up not only in loans, but in any other contract which involves a temporal lag between performance and reciprocal performance of the contractual terms.In current practice, there are several partially effective processes for ensuring future performance:These processes have a fundamental property in common \u2013 they violate the privity of credit transactions \u2013 in other words, they bring in third parties to track reputations or enforce repayment. Do credit transactions entail a fundamental imbalance in incentives that can only be redressed by bringing in third parties, or can the security protocols be discovered which allow credit with minimal or no third party involvement?Three important variables have been proposed for reputation economics:In turn, Peter Swire[16] describes two problems facing inadequately secured or unsecured loans to \"credit names\":Adverse selection: Prior deadbeats can start fresh by signing up for the new service. Going in, it will be biased in favor of deadbeats. This problem may be addressed by using Chaumian credentials. These allow the established positive reputations of previous names to be carried over to the credit name, without allowing anyone to link the two names. Entrants without positive reputations can be rejected.The endgame problem: A credit name can establish a good credit rating over time. When the limit is high enough, the borrower can quickly spend it all. A malicious borrower, with a good rating established under a previous name, can systematically profit at the expense of the lender, if the throw-away value is greater than the replacement cost. To address this problem, creditors will have to charge higher rates to new credit names and raise credit limits more slowly than for traceable names. Honest borrowers will subsidize the dishonest, to an even greater extent than they do in the current credit card system.Secured credit need not violate privity if the physical control over the securing property can be shared. So that, for example, automobile credit can be secured as long as repossession is possible, as described in the example above.A standard mechanism of secured credit applicable online is the escrow. An escrow is an intermediary trusted to hold messages until messages from both sides are received, and, optionally, their contents verified - to extent the content is verifiable, and at the expense of some privity. The escrow then sends the messages off to their recipients, along with receipts. Messages can contain any sort of data: content, a bearer certificate, etc.Alice wants a New York City cab ride for which she's willing to pay $100, but she doesn't trust Bob the taxi driver to get her there on time if she pays up front. Bob in turn doesn't trust Alice to pay at the end of the trip. Commerce can be consummated by Alice tearing a $100 bill and giving half to Bob. After the trip she gives the other half to Bob, which he can then reassemble into a negotiable $100 bill. Alice loses her incentive to not pay. Bob gains incentive to get her there on time as promised. Both have made what economists call a \"credible commitment\" to perform their respective parts of the contract. Markus Jacobsson has digitized this idea, coming up with a protocol for ripped digital cash. As with many other aspects of digital cash, the idea can be further generalized to rip some other kinds of bearer instruments \u2013 specifically, those whose value can be divided roughly in half. If the transfer is double-blinded the transfer agent has no knowledge of the participants and therefore no bias to favor one over the other. The transfer agent must, however, be able to assess proof of performance, and the protocol is only workable where such proof (in the form of proof of receipt of a message, for example) is available.The ripped bill is similar to using the transfer agent as an escrow agent. An advantage over using an escrow agent is that the need for extra anonymous channels between the parties and the escrow is avoided. A disadvantage is that the transfer agent now has taken on the major additional job of acting as an adjudicator, assessing proofs of performance (or at the very least, must be responsible for subcontracting out this job and implementing the adjudicator's judgement).Credit cards provide relatively little protection from third parties, especially in the area of privacy, but they do have an interesting contractual feature worth noting, the chargeback. With chargebacks customers can get refunds on allegedly unwanted merchandise. The issuer tracks the number of chargebacks both for customers and merchants; too many chargebacks can get you booted out of the system. This provides an efficient mechanism for refunds without resorting to expensive tort proceedings. Many customers who read the fine print or otherwise learn about chargeback limits often do chargebacks despite receiving and enjoying the merchandise; there is no practical way for the issuer to detect such fraud, and so it can only be pruned by limiting the number of chargebacks per customer. Some merchants complain vociferously about such customer \"theft\", and it seems to make possible coordinated attacks to put merchants out of business, but nevertheless merchants sign up for credit cards, because that's what their customers have signed up for. The chargeback feature makes customers more comfortable purchasing goods of unknown quality, especially mail-order and over the Internet. Chargeback provides a crude but effective partial solution to the information asymmetry problem between retailers and consumers.\"Time release\" money that becomes good only after a certain date, and \"interval money\", that would expire after a certain date have been proposed. These can be implemented by a digital mint expiring or activating special issues of digital cash, or by a third party issuing escrowed keys at specific times. Since these keys are encrypted against the escrow agent, and that agent doesn't know what they will be used for, the escrow agent has no incentive to cheat. A generalization of this is that transfer and redeemability are each associated with interval sets, or validity periods when each can and cannot be performed. This is analogous to clipping coupons on bonds.Hal Finney[17] has described a loan mix, to unlink borrowers from amount borrowed. The identity of the potential borrowers is still public, as well as the system for enforcing payment, but the actual amount loaned or borrowed remains unknown. The system starts with participants putting unknown amounts into a pot and getting receipts (bearer bonds) for these amount. All participants then borrow a standard amount. Whether a participant is a net borrower or a net creditor, and of what amount, remains private. When the loan is due all participants repay the standard amount, and the creditors reclaim the amounts on their bearer bonds. The amount actually borrowed (or, if negative, loaned) is the public amount borrowed minus the amount put into the pot. One consequence is that while negative reputations can still be accumulated when participants fail to pay back the standard amount, positive reputations are minimal, since participants who borrow and loan are indistinguishable. If future creditors put stock in positive participation, one could gain a credit rating by perpetually participating as a net borrower of zero, by loaning and borrowing the same amounts.Smart contracts combine protocols, users interfaces, and promises expressed via those interfaces, to formalize and secure relationships over public networks. This gives us new ways to formalize the digital relationships which are far more functional than their inanimate paper-based ancestors. Smart contracts reduce mental and computational transaction costs, imposed by either principals, third parties, or their tools.Mark Miller[18] foresees that the law of the Internet, and the devices attached to it, will be provided by a grand merger of law and computer security. If so, smart contracts will be a major force behind this merger.A previous version of this paper appeared in the peer-reviewed journal First Monday, at http://www.firstmonday.dk/issues/issue2_9/szabo/index.htmlMany of the links above and references here rely on URLs that can be found in the online edition of this paper, at http://szabo.best.vwh.net/caymanpaper.html.The author has been refining these ideas since the early 1990's. A variety of earlier articles on this topic can be found at http://szabo.best.vwh.net \u21a9George H. Bodnar and William S. Hopwood, 1987.Accounting Information Systems. 3rd ed. Boston: Allyn and Bacon. \u21a9Phyllis K. Sokol, 1995. From EDI to Electronic Commerce: a business initiative. New York: McGraw-Hill. \u21a9Oliver Hart, 1989. \"Incomplete Contracts,\" In: John Eatwell, Murray Milgate, and Peter Newman (eds.), The New Palgrave: Allocation, Information, and Markets. New York: Norton.Bruce Schneier,1996. Applied Cryptography. 2nd ed. New York: Wiley. \u21a9John Bouvier, 1856. A Law Dictionary: Adapted to the Constitution and Laws of the United States of American and of the Several States of the American Union. Rev. 6th ed. \u21a9Michael Polanyi, Personal knowledge: Towards a post-critical philosophy. Chicago: University of Chicago Press.The economics of distributed knowledge is studied by the Austrian school; in particular see Friedrich Hayek, \"On the Use of Knowledge in Society.\"Vernon V. Palmer, 1992. The Paths to Privity: The History of Third-Party Beneficiary Contracts at English Law. San Francisco: Austin and Winfield.Lance Cotrell, 1995. \"Mixmaster & Remailer Attacks.\"Brad Cox, 1995. Superdistribution:: Objects as Property on the Electronic Frontier. Reading, Mass.: Addison-Wesley. \u21a9Ian Goldberg and David Wagner, 1997. \"Enabling Anonymous Publishing on the World Wide Web.\" \u21a9Olin Silbert, David Bernstein, and David Van Wie, 1996. \"Securing the Content, Not the Wire for Information Commerce.\" \u21a9Joseph M. Reagle Jr., 1996. \"Trust in Electronic Markets,\" First Monday, Volume 2, number 2 (August). \u21a9Robin Hanson, personal communication. \u21a9Peter Swire, 1997. \"The Uses and Limits of Financial Cryptography: A Law Professor's Perspective.\" \u21a9Hal Finney, 1997. \"Anonymous Credit\" posts. \u21a9Mark Miller, 1997. \"The Future of Law,\" paper delivered at the Extro 3 Conference (August 9). \u21a9Please send your comments to nszabo (at) law (dot) gwu (dot) edu"}
{"prompt": "A Formal Language for Analyzing Contracts", "completion": "The author presents a mini-language for professionals and researchers interested in drafting and analyzing contracts. It is intended for computers to read, too. The main purpose of this language is to specify, as unambiguously and completely and succinctly as possible, common contracts or contractual terms. These include financial contracts, liens and other kinds of security, transfer of ownership, performance of online services, and supply chain workflow.The following problems may be addressed by the language when interpreted by computer:The process of designing this language is also a great way to explore the basic nature of contracts (what are the \"elements\" out of which a wide variety of useful contracts can be drafted?) and their composibility (what rules for composing these atoms rule out impossible contracts?) The language is also a creative tool for thinking up and \"sketching\" new kinds of contracts. I welcome your participation.The words in our language follow legal terminology as much as possible \u2013 thus for example performance means execution to satisfy the terms of the contract (as in the legal field), rather than measured quantities like speed, memory usage, bandwidth, etc. (as programmers use the term). A law degree is not required to use the language, but some familiarity with contract law and the drafting of contracts is recommended. A lawyer who did reasonably well on the analytical and logical sections of the U.S. LSAT or its overseas equivalent, will, I suspect, have better luck drafting contracts in this language than than a programmer whose sole experience lies in traditional procedural language. That is why I call this a drafting language not a programming language.Our language can specify the output of a negotiation (which could be an auction, an exchange, or two parties drafting the contract, or one party drafting and the other agreeing to it, etc. ). It also can define the input to an engine that drives and monitors the transactions that perform the contract:Performance of the contract, i.e. its reification as a smart contract, can thus be seen as (hypothetical, at this point) execution of a program written in our language. Furthermore, our language incorporates a wide variety of contractual terms, not just abstract monetary terms and their derivatives. These two characteristics make our language very different from special purpose financial contract languages such as[4]. While we use several financial contract examples to introduce our language and demonstrate its flexibility, its scope both in functionality and the kinds of contracts and transaction protocols it can represent is far broader.Each word and phrase in our language has a clear standard meaning. As a result, contracts can be drafted that will be far less subject to disputes over interpretation. On the other hand, the language is not very good at expressing many subjective and ambiguous concepts that are often necessary in contracts. Nor is it any good, in its present state, in referring to jurisdictions or doctrines of law. The language is nevertheless very different from a traditional programming language. Contractual terms are defined in terms of events that trigger their performance. Such events include dates and times, choices made by the parties, observable breaches of contract, and so on.Our language is not a markup language. It is not about manipulating text for the purposes of drafting contracts. It is not about structuring text, specifying fill-out forms, defining static data formats, or similar tasks of languages such as HTML or XML. For those tasks one should use a markup language, or a text-manipulating programming language (e.g. Perl), not this language. Our language does something very different. It models the dynamics of contract performance \u2013 when and under what conditions obligations should be performed.The words and sentences of the language do not consist of instructions followed down the page from one step to the next. Instead, a contract is read (both by human and computer) by following nested definitions of contractual terms as they expand, and by looking at events in when statements and seeing what they trigger. If the drafter does need to explicitly construct a step by step calendar schedule, this can be done by using calendar-driven events or words like for and then.The language encourages composition of contracts. Contracts, rights, and obligations can be nested. We call these nested structures clauses. Contracts and clauses involve two parties, the Holder, from whose point of view we read the contract, and a Counterparty. Multi-party agreements can be drafted by composing several two-party contracts.Our first example is a well-known financial contract, the future. A future is an obligation on the part of the Holder of the futures contract to purchase a certain amount of a certain commodity in a certain month, and the obligation on the part of the future contract writer, the Counterparty, to deliver these goods. For the purposes of introducing this contract, we give it in the abstract form in which financial analysts usually deal with it, leaving out important details that describe the third parties who act as trusted intermediaries to define \"fair bundles\" of commodities, and we also leave out many details about the actual delivery.Since this language is not yet being computer interpreted, the syntax is designed more for human than computer readability. I will be a bit fast and loose with the syntax, and you can be too. I mostly use tabs instead of brackets {} to structure clauses in a way that seems natural and readable to me \u2013 and I hope to you \u2013 but might confuse a computer. Feel free to develop your own style.The top three lines in the contract, in the form name(parameters) = tells us that we are defining a named clause. The named clause can define an entire contract or just a clause in a larger contract. We can pass the names of other named clauses, lists of events, and other kinds of information that the named clause needs \u2013 these are the parameters.when withinPeriod(p) means \"when the first calendar or clock event generated during period p\". The drafter can elsewhere set how often this regular \"clock tick\" event occurs. The first such clock tick after the start of the period, in this case the first scheduled delivery day in the month of July, triggers the clause with the brackets {}. More sophisticated schedules are possible, such as those that minimize delivery costs for the Counterparty by delivering to different Holders on different days in July. Fortunately, we can hide these scheduling details within the calendar event and schedule iterator mechanisms, leaving the drafter free from worrying about exactly when markets are open, which days are weekends or holidays or leap days, and the like. The Counterparty's delivery schedule can be negotiated or this detail can be left up to the Counterparty. In the contract above, the constraints on delivery are that it occur within July and only in conjunction with payment from the Holder.The innermost clause says to swap rightA for rightB. This clause is split into a Holder right and a Counterparty right. The right clause Holder rightA means \"Holder has the right to performance of rightA\", in this case delivery of the pork bellies. The clause Counterparty rightB means \"Counterparty has the right to performance of rightB\", which here is the payment of 1,500 dollars. with indicates a simultaneous swap \u2013 the two transactions should occur together, perhaps intermediated by an escrow agent to enforce both the delivery and payment terms.A then statement allows us to proceed step by step. If we had two clauses written thus:They could be performed in any order \u2013 right2 might be performed first, or right1 might be, or (most likely) performance on both might proceed at the sime time. Several when statements nested together at the same level have any implicit also as they can be triggered in any order.Envision a dancing elf that follows nesting of clauses as they are performed and of events as they are caught. (Programmers call this dancing elf by the boring name \"instruction pointer\"). There can be more than one dancing elf if there is an also or if more than one when statement is triggered while another is active, but usually we only need to think about one at a time.If we wish to add the constraint that right2 cannot be performed until right1 has been, we use then:Traditional programmers will be sorely tempted to fill their contracts with then statements, mimicking the style of procedural programming. Do not! Those experienced with drafting contracts know that in some cases such a constraint is clearly appropriate and in some cases it clearly isn't, and it is important when adding constraints to be explicit. Therefore the following statement is illegal, and will be rejected both by the computer and by any right-thinking drafters working without a computer:Finally, we have already seen this kind of clause:This means that right1 and right2 should be performed simultaneously \u2013 and either both of them should be performed, or neither of them. In the lingo of computer scientists, it should be an \"atomic\" transaction.The then terminate at the end of the named clause ensures that all rights and obligations under the contract are terminated once it has been performed. It is not triggered until the one-line body of the future contract has been completed. as well as any outstanding subordinate clauses with their rights and obligations. This clause is implicit at the end of every named clause, but for this one time we make it explicit. This clause is often used explicitly when the drafter wants to ensure the proper termination of non-named clauses nested within a named clause.Let's now proceed through the futures contract step by step, as clauses are activated and then performed. A normal font indicates the clause is inactive. A bold font indicates an active state \u2013 the clauses is being performed.When the parties commit to the contract its first clauses (the clauses at the highest level of indentation) are awoken. In our futures contract we have only one such clause, and so the when (but not the clauses nested underneath it) go to in an active state, waiting for the withinPeriod() event:When the calendar has advanced to the end of trading on the last trading day of August, the withinPeriod(p) event occurs and the when activates the clauses nested at the next level inside. The when itself becomes inactive \u2013 it is no longer waiting for an event:The then has cause the terminate to wait for the when and its subclauses to be performed. Once the swap of rights has been performed, the performed clauses convert to inactivity and the terminate fires:It is easy to generalize in our language. The generic futures contract looks like this:Instead of pork bellies, we can swap any other rightA for rightB, which can be a wide variety of things beside money. Drafters can specify very general boilerplate and fill in details for specific contracts later.We now present another kind of financial contract. In this American option, the Holder has the right to buy for $20 (the option strike price) per share one round lot (100 shares) of XYZ Corp on or before the last trading day of August. These kinds of contracts are called \"derivatives\" because the call option is derived from the underlying right (here a stock).Think about that dancing elf again. (When reading or writing in our language it's important to follow these dancing elves. If the elves become annoying, think of some other dynamic character or process for a metaphor that suits). As it goes around it wakes up clauses, making them active, causing them to be performed. Sometimes there can be more than one elf dancing through the code at the same time, for example if more than one when statement is triggered while another is active, but usually we only need to think about one at a time.The contract starts out with dancing elves in the two top-level clauses:These when statements are now waiting for their respective events. Since the events are mutually exclusive (it is first beforeTime(time), then afterTime(time), but never both) we only need to worry about the first to be executed. Note that, unless separated by a then, the order of the clauses at the same level is not important. The following code is identical to the code in our example:The beforeTime(time) is immediately activiated, so that we start with the nested clause(s) at the level immediate below it active as well \u2013 in this case, when choiceOf(Holder).A series of whenes at the same level in that clause all start waiting for any of them to be triggered. When a when receives an event thrown below it or at it, the nested clause below it becomes active. Then the clauses below it become active and are performed down to the wheness one level below. The whenes at that level go from inactive to active, now waiting for their events to occur.The when beforeTime(time) becomes active when the option itself is first activated, and remains active until time. Being active it wakes up the when choiceOf(Holder). This when specifies the event that gives the contract its nature as an option -- the choice of its holder to exercise it or not. If the Holder chooses to do so, the Holder gets the stock (rightA) from the Counterparty (the writer of the call option) in exchange for the money (rightB). The dancing elves then move from the when clause to the swap clause:When code gets complicated, we might not be able to easily tell whether the implicit then terminate on the last line will get executed. So it's a good idea to terminate the contract explicitly when the option expires.We will see examples where more than one kind of event, and even sequences of events (such as a calender schedule of payment dates) trigger the execution of contractual terms.Remember that the language does not proceed by default step by step \u2013 instead the reader (human or computer) should follow down the nested contract definitions as they expand, and look at events in when statements to see what they trigger. Explicit step by step calendar schedules can be built using for, then, and calendar events.Here's an example that uses such explicit steps. A bond makes a sequence of fixed payments, called coupons, on a regular schedule, and then makes a final payment, the principal. We don't show here the details of the schedule itself, but in general a schedule could be defined to be any kind of temporal sequence \u2013 we could pay out coupons on the last day of every month, on every Japanese holiday, according to the computation of Easter (don't laugh \u2013 schedulers of medieval fairs had to face this problem), or however we choose. When implemented the calendar events and schedule iterator will contain a very thorough implementation that solves many of the nasty calendar problems that often appear in transaction processing systems.for iterates through the events in the schedule one by one, with the nested when handling them. When it appears after a for clause, a then advances the iterator one more step.Next we sketch a contract to sell a car on credit. Being a sketch rather than a full-fledged design, this is an oversimplified or \"toy\" example \u2013 we leave out fees, any references to a related insurance contract, warrantees, waivers, etc. We also for simplicity have the bank (here the Holder) be the same as the car dealer. Finally, we don't show here any lien on the car to secure the loan. We will make a stab at a lien-like mechanism in an example below.If we want to allow prepayment, our schedule would contain single times rather than periods with a begin time and an end time. And our loan payments would look as follows:We could compute the above payment from other information we are more likely to see in the contract, but this involves just normal programming. We can use a function to perform the computation in the first place:\"=\" sets, for all time (thus constant), the number payment.amount to the value returned by the function computeInterest. We could also do more complicated things \u2013 deduct interest for prepayment, or conversely add prepayment penalties, or a wide variety of other conditions.We can also structure the car purchase contract so that the new owner doesn't get the title until after the downPayment has been received:Let's use our language to analyze some important advances in the history of economic institutions. Genoa was an independent and rather libertarian (for its time) city heavily involved in the Mediterranean sea trade. During its height in the twelth through fifteenth centuries it developed many commercial innovations, including two we will examine here, the \"dry exchange\" loan and pooled-risk insurance.Here is a clause from a contract made in Genoa on June 23 in 1271 A.D. A man is co-signing an obligation being made by his son:Wherefore and for which we promise, both of us [liable] for the whole amount, to give and to pay to you or to your accredited messenger 53 gold hyperpers, good and of correct weight, in Romania [Byzantium], by the Kalends of September. If, however, we do not give you these [hyperpers] within the said time limit, [we promise] for each of the said hyperpers 11 shillings Genoese in Genoa whenever you wish. Otherwise we promise, both of us [liable] for the whole amount, to give to you, making the stipulation, the penalty of the double of the said amount, the aforesaid [conditions] remaining as settled. And we pledge to you as security for the aforesaid [promises] all our goods, existing and future...[5]Now, this is a very clever contract, called by scholars a \"dry exchange\". The Catholic Church forbad the charging of interest, so a loan contract that came right out and charged interest would be unenforceable and expose the drafters to further Church sanctions. But both long-distance exchange (making a trade at a distant market at a later date -- often via a sea voyage, thus a \"wet\" exchange) and currency exchange were quite legal, enforceable, and common. The above contract combined these two, along with damage clauses, in a clever way. None of the above parties had any intention of travelling to Byzantium, or even outside Genoa, to perform on this contract. Its logic can be analyzed as follows (the Holder is the creditor). We've added the statements \"in (geographic location)\", security, and foreclose to highlight important aspects of this contract. The latter sells enough of the goods at auction to satisfy penalty (if there was not enough to satisfy the creditors there was a bankruptcy procedure to fairly allocate the remain security among the creditors, but this is not shown):Neither party expected payment1 to be performed. The amounts of hyperpers and shillings probably reflected accurately the exchange rate between the two coins at the time \u2013 there's no sense being too obvious. But it would have been far too expensive to travel to Byzantium just to do this exchange. So in fact both parties expected payment2, a fake damage clause, to normally be performed. If it wasn't, then we have two real damage clauses \u2013 the somewhat reasonable \"penalty of the double\" and the lethal \"all our goods, existing and future\". Another interpretation of the latter clause is that it would only refer to a value of goods up to the double penalty amount, but the goods could be chosen from among all the goods of the debtor and the co-signer. Certainly a modern court would consider the interpretation I have placed on it in our language to be unconscionable, therefore unenforceable.Above the part we quoted, the contract does not specify how much the original loan amount was \u2013 the debtors simply acknowledge that they have received from the creditor \"a number of Genoese deniers\" and then promise other currencies in return as quoted above. So a Church investigator couldn't prove just from reading the contract that any interest was charged. As for the Genoese judge arbitrating a dispute, he would likely be in favor of loans at interest, and happy to wink and nod and interpret the contract literally.Modern derivatives traders do this all the time, creating synthetic assets or combinations that mimic the financial functionality of some other contract while avoiding its legal limitations. Our language is ideal for drafting and analyzing such contracts.The earliest risk-pooling insurance contracts were structured similarly to, and enforced under the same legal principals as, loans. Indeed, let's start with a simple loan for a purchase of goods with no interest where the Holder (the creditor) can call in the loan any time between days t1 and t2:Let's add to our language a safeArrival(goods) event \u2013 the event that a ship carrying goods arrives safely in port and that goods are offloaded and accounted for. Now by adding to this loan contract only one extra line, whening safeArrival(), and slightly modifying a few others we can transform it into a marine insurance contract. The insured is the Holder, the insurer is the Counterparty. For this simple version damages are paid in a fixed amount (principal) if safeArrival does not occur:Here's an example of an early insurance contract of this kind \u2013 again from Genoa, the birthplace of modern commercial institutions. For the first time we see a pool of insurers \u2013 not one but many counterparties, each pledging their entire property as security. Often these were feudal lords with large landholdings, so the value that could be brought to bear to back these insurance contracts was vast. This is how Lloyds Names still work today. Since several Names back a single contract (e.g. covering a single shipment of goods, as here), each Name puts only a tiny fraction of their estate at risk in that voyage. An insurance exchange like Lloyds allows the agents of goods owners, shippers, and Names to meet and mass-produce these kinds of contracts....Geri, [son] of the late Ser Lapo of Florence, Simone Guascone, [9 more Names listed], each of them [liable] for the amount written below, have acknowledged and in truth have declared to me, notary undersigned, as a public official [holding] a public office, making the stipulation and receiving in the name and stead of Federico Vivaldi, citizen of Genoa, that they have bought, have had, and have received from him a certain amount of goods of the said Frederico...And for these goods and in consideration of their price each of them has promised to give and to pay to said Frederico or to his accredited messenger: [from] the said Geri, 150 gold florins, the said Simone, 50 florins, [100 florins each from the other Names] within the next five months from now. Otherwise they have promised to give and to pay to the said Frederico the penalty of the double of it and of the entire amount to which and to the extent of which [this agreement] is violated or is not observed as above, together with restitution of all losses, unrealized profits, and expenses which might be incurred because of it in court or outside \u2013 the aforesaid remaining as settled, and under hypothecation and pledge of their goods and [the goods] of any one of them, existing and future.[The above is binding] with the exception and special reservation that if the amount of goods, property, and merchandise which was loaded or is to be loaded by Frederico Imperiale or by another in his behalf for the account of the said Frederico Vivaldi in Aigues-Mortes \u2013 to be transported to Ayassoluk and Rhodes or to either of these two localities in a certain ship...and which departed from Aigues-Mortes or is about to depart in order to sail to aforesaid regions \u2013 is brought and unloaded in the said localities of Ayasoluk and Rhodes or in either of them, in safety, then and in such a case the present intrument is cancelled, void, and of no value and pro rata. And be it understood that such a risk begins when the said ship departs and sets sail from Aigues-Mortes, and it remains and lasts, while the captain goes, stays [in port], sails, loads and unloads, from the said locality of Aigues-Mortres up to the said localities of Ayassoluk and Rhodes, in whatever manner and way he wishes, until said amount of goods, property, and merchandise has been brought and unloaded in Ayassoluk and Rhodes or in either of these two localities in safety, and pro rata. Let the present instrument also be cancelled if the said Frederico refrains from asking payments of the aforesaid amounts of money for the space of one year after the time or the time limit has elapsed for asking or obtaining their payment....Done as above, September 15th, around nones. [1393 A.D.][5]Ignoring the pro rata language, the specific definition of the risks that prevent generation or not of the safeArrival() event, and ignoring the multiple Names (i.e. treating them as one Counterparty), the contract can be modelled by the insurance contract we drafted above with its parameters filled in as follows, and with Frederico Vivaldi as the insured (the Holder):This contract was still, legally speaking, a loan. This had at least two interesting consequences on what we now call the insurance premium. Firstly, the premium was treated as goods purchases by the insurer on credit. Secondly, even at this late date, contracts were coy about the actual value of such goods. Leaving the value of those goods unspecified made usury difficult to prove in this \"loan\".Events in a when clause can be combined in logical conditions which must evaluate to true in order to trigger the subclause. This can be used to model conditional clauses in contracts, and, more broadly, procedural and substantive rules of law. When constructing rules we call the primitive events elements. For example, here is, roughly following the Restatement(Second) of Contracts, a legal rule for promissory estoppel:We include a gratuitous \"then\" here for readability. Computer programmers should note that we are following a shorthand here used by lawyers \u2013 we write the logical phrase (A and B and C and D) as (A B C and D). When mixing and and or, write out the complete logic, and use parentheses where appropriate.The rule elements, such as \"there is a promise\", exist in a superimposed state. By default, the logic is ignorant of the facts, and each element is genuinely at issue. As a result, \"there is a promise\" and the other elements of the above rule are both true and false, at the same time. (Those familiar with quantum mechanics or legal reasoning know what I'm talking about here). In the initial state, where every element is genuinely at issue, nontrivial rules will always evaluate to both true and false. Thus, both \"promise will be enforced\" and \"promise will not be enforced\" clauses will be triggered. When the clauses are incompatible, as these appear to be by their label, it is up to the implementor of the clause to deal with this properly. In this case, such a clause should only be treated as advisory until all material elements have been decided \u2013 i.e., they are no longer genuinely at issue, at which point the rule can be used to make a decision, i.e. trigger a single clause which takes a consistent action. A future version of this document will describe how to resolve elements genuinely at issue into elements not genuinely at issue, and thus decide on a single outcome or course of action. It will also describe how to deal with advisory clauses; for example, to analyze which elements are most favorable to one outcome or another. Finally, another future feature will include elements that cover a range of numerical values, rather than just true or false, and a formalized \"balancing test\" that determines outcomes based on underlying numerical estimates.Our rule language is ideal for specifying estates and future interests in real estate deeds. One can also apply these patterns to other kinds of property where appropriate. Here are some examples:Lease for Term: (n.b. \u2013 Grantor = self). This is an old common law lease that actually transfers title for a certain period of time.Life Estate with Reverter: (n.b. \u2013 Grantor = self)Assignable Reverter for Lease. To make future interests assignable, define them separately. Note to make the Grantor explicit. (As usual we are looking at things from the obligor's side):We can now redefine the Life Estate with Reverter in terms of the separately defined future interest:Life Estate with Remainder. The only difference here is that the property is remaindered to a third party instead of reverting to the grantor.Fee Simple Determinable. The Condition can be any verifiable event or change of state of the property or its title. A common real estate condition, for example, is \"used for commercial purposes\" \u2013 i.e., a restriction that the property may not be used for commercial purposes, otherwise the grantee is penalized by losing title to the grantor.Fee Simple Subject to Executory Limitation. Same as Fee Simple Determinable, except the property gets remaindered to a third party instead of revertin to the grantor.Fee Simple Subject to Condition Subsequent. Here title is not automatically transferred upon occurence of the condtion. Instead the Grantor must do some affirmative and verifiable act (in this example \"entering\" the property), to reclaim the title.In this section we will look at ways to construct multiparty agreements, distinguish ambient from thrown events, and examine a number of other more advanced features of or ways to use our language.We will complete the life cycle of the American option we drafted above by \"writing\" the option \u2013 creating it from an underlying security rightA and selling it for rightX. Here the Holder (same party as the Holder above, in this case the person who will buy the written option) first verifies that the Counterparty indeed holds the underlying security (rightA) with Broker. The Broker is trusted by the Holder to make sure Counterparty continues to hold the security until the option is exercised or expired. The contract between the Broker and Holder is escrowRight().)Since Counterparty, the option writer, is not paying anything up front for an option on rightB, this right does not need to be escrowed.We now redraft the option itself to take advantage of the escrow. rightA is transferred to Holder by the throw upon excercise, or back to Counterparty if the option expires.We can think of events as coming in two kinds. The first, ambient events, occur spontaneously in the environment, or are generated by an entity external to our specification such as a user or a schedule. The second, thrown events, are events we explicitly throw as above.In this manual I have expressed contract clauses in terms of rights. Often contract language is expressed in terms of obligations, which can be done as a mirror image \u2013 to Holder right is the same as from Counterparty obligation and vice versa. Use from to distinguish an obligation.Further showing the flexibility of our language we can add sensors and effectors, adding \"smarts\" to our contracts and augmenting legal enforcement with technological constraints.First we draft a specification for the contract-like bevavior of a vending machine:We have here introduced a new language feature, a state variable. Our state variable moneyAmount generates an event upon surpassing the candy price threshold of $0.90. Note that nickels, dimes, etc. are actual physical objects that the sensors (generating events \"nickel\", \"dime\", etc.) detect and treat separately \u2013 they are not merely abstract amounts of money.State variables can be troublesome, and should be avoided unless utterly necessary as here. This one is relatively harmless because the coin slot tends to force the coins to come in one at a time, so that no two clauses are trying to change the state variable at the same time. Even if they were, the addition operation is what mathematicians call \"commutative\", meaning it doesn't matter what order it's done in. But if the operation on the state variable were more complicated or involved certain other kinds of operations, we wouldn't know whether it was commutative. The order in which events occured and changed the state variable might matter very much, and we could get into big trouble. So avoid state variables whenever possible.To simplify things, we've left out making change \u2013 our machine has to have one of those signs you sometimes see, \"exact change only\". If the customer puts in a coin that pushes the amount from, say, $.80 to $1.05 \u2013 too bad, the machine eats it. If the customer puts in $0.90 (or more) and then adds more coins, however, the machine automatically returns the extra coins. The machine will also return whatever has been put in the till, if the customer changes her mind and decides not to buy the candy. Exercise for the reader: verify for yourself that the above behavior descriptions are correct as the code is written.RedirectNewCoinsTo(returnTill) causes any further coins to drop into the return chute instead of onto the sensor that triggers the above events. The reader must here imagine what the mechanism looks like, as part of the behavior is \"encoded\" in its mechaninism rather than explitly in this statement.Think of the nested contracts and rights as an upside-down tree \u2013 a hierarchy of nested clauses. Events propagate from up from the \"leaves\" of the tree towards the \"root\" at the top. They are caught by the first when event they encounter for that event. In this case, once we enter the when threshold() clause, the when (nickel | dime | quarter) clause overrides the when(nickel) and so on clauses above them.Like a perpetuity, our vending machine has no scheduled time or condition where it stops performing \u2013 therefore we have a continue statement to overrid the implicit then terminate on the last line.Alas, neither I nor real world candy machine makers have any code to solve the case where the candy gets stuck in the machine.The above is a transcription of machine behavior. Now we make it even more like a contract. Here we incorporate the customer and his choices, which implicitly generated the coin events in the code above \u2013 here the coins are rights of the Holder. Thinking more about the party, rather than the machine, allows us to recognize that at each step the customer wants feedback on how much money they have put in, thus to Counterparty display(moneyAmount). This display is done by the Holder (the vending machine as an agent of the vendor) as a right of the Counterparty (the customer). To enable better customer choice, we add a new construct to our language: choiceOf(agent, right) which allows the customer multiple choice, based on which right they wish to transfer to the agent's counterparty (here the vending machine, the Holder).How is it that we have specified the behavior of a vending machine in a language designed for drafting contracts? Can nickels, dimes, quarters, and operations like dropping coins from one till to another be thought of as rights and obligations? I think so. They are not legal rights and obligations, to be sure. There is no explicit contract between the vendor and candy machine customers, and if their were it would probably waive liability for violating most of the clauses in our code. What this code describes is the logical and typical behavior of a vending machine. It also reifies the implicit understanding most customers have when using a vending machine. Thus it models a contract-like \"meeting of the minds\" between the customer and the vendor that is mediated by the machine.Here is a stab at formally describing the hypothetical \"auto repo auto\". The car is controlled by a proplet and the proplet looks to property titles to determine ownership authority. The proplet lets only the titled owner enter and drive the car. \"Holder\" is the bank that made the loan and \"Counterparty\" is the new owner. As above we ignore the car dealer; the bank originally owning the car. This example highlights the ability of the language to very succinctly describe contracts but also its inability to describe the actual security that will enforce the contract. There is of course a lot missing here, including the items missing from the above car loan contract. From a smart contracts viewpoint, the biggest thing missing is that there is nothing to motivate the \"Holder getTitle(car)\" in the last when, nor any way specified here to enforce it. And of course all connection between ownership and authority to enter, start, and drive the car is here implicit \u2013 the actual proplet behavior in this regard would have to account for safety, emergency use, etc.For all that work-up, we've only actually added one clause to our car purchase contract above. The clause forfeits the title and is structured much like the damage clauses we have seen. A breachedPerformance() event is generated if it is detected (by the Holder, a third party auditor, or the proplet itself) that the Countparty failed to make a payment according to the schedule specified by loan.Here is a formal specification of the language's grammar in \"Backus-Naur Form\"(BNF). The specification is for a planned computer-readable version of the language and there are a few minor differences, such as the use of brackets {} instead of tabs to denote nesting. BNF is used to define what linguists call \"context-free grammars\". It is also used, as here, to define the syntax of languages that computers can also interpret and execute. I also include some more discussion of the meanings of the words and structures, especially how the computer might interpret them. As you can see, this is an evolving language, a work in progress with many unresolved issues. Your suggestions for changing or adding more kinds of contractual terms to our language are quite welcome.Q: There are already languages for specifying financial contracts[3], what is the novelty here?A: This the first specification language to generalize contractual structures to any kind of exclusive rights, not just money. This is also the first language that incorporates the dynamic nature of many contracts, (their dependence on time or events) in a succinct, complete, and potentially executable manner. Surprisingly, this often makes the specification more not less succinct.Where's the money?A: This language is targeted toward an economy of distributed software and devices performing services for each other. A money economy can be constructed out of a barter economy but not vice versa. Real online money is far more subtle than a mere shared variable (or even the specification of \"bank notes\" in this language). Money is just one kind of fungible exclusive right, and the structure of financial contracts are generalized by converting money terms into any fungible exclusive right.Q: What assumptions are you making?A: This is the most important question to ask of any novel scheme! I have identified at least the following:Q: What are some problems with this language you'd like to see solved?A: Implementations that satisfy the above assumptions for the particular language atoms, and also for compositions of the atoms. (Of course, various protocols in the \"financial cryptography\" field, in my own proposals, in the E language, etc. provide many valuable building blocks for such solutions).There are many instances of deals gone sour at the last minute when the salesfolk check with legal and discover that the deal is not possible due to a clause in another contract \u2013 for example a promise not to sell to a customer's competitors in an industry for a certain period of time. Worse, such a conflict might not be discovered until the contraditory commitment has been made. \u21a9The E programming language \u21a9Proceedings of the Financial Cryptography Conferences, Springer-Verlag \u21a9Composing contracts: an adventure in financial engineering \u2013 A different kind of language for specifying financial contracts in order to compute their risk and value. \u21a9Lopez and Raymond, Medieval Trade in the Mediterranean World: Illustrative Documents, Columbia University Press 2001. \u21a9 \u21a9Please send your comments to nszabo (at) law (dot) gwu (dot) eduCopyright \u00a9 2002 by Nick Szabo\nPreliminary draft -- Redistribution only with written permission of author.Editor's note: Some links may be broken."}
{"prompt": "Secure Property Titles with Owner Authority", "completion": "The advent of writing greatly improved the tracking of property rights, and indeed gave rise to our modern systems of property rights and law. However, written records have proven to be quite vulnerable to abuse. A common pattern during eras of political instability or oppression has been the confiscation of land via the forgery or destruction of public records. Reconstruction from informal records, such as residency recorded in phone books, even when possible is costly and fraught with error and potential for fraud[1]. Large amounts of, in some areas most, property in developing countries is not formally titled[2]. Even during eras of political stability in developed countries, there occur many expensive problems with titles.[3] Straightforward transcription of written records into a centralized online repository would make many of these problems even worse \u2013 electronic records can be highly vulnerable to loss and forgery, and insiders are the most common source of such attacks. This paper proposes a secure, distributed title database to prevent such attacks against property rights in the future.Many kinds of Internet resources have a basic characteristic: users must agree on their control across trust boundaries. A big example is names. The article \"Names: Decentralized, Secure, Human-Meaningful: Choose Two\" dismisses not only the ubiquity and importance of this problem, but also the possibility of solution.[4] Instead petnames are proposed. These are at best mere mnemonics to translate human-readable into cryptographic names; petnames don't do anything to secure naming across trust boundaries. All three attributes \u2013 decentralized, secure, and human-meaningful \u2013 must be provided if people are to communicate and be communicated about securely over the Internet, and this paper along with the article Advances in Distributed Security shows how to provide all three.More generally, we show how to implement transferable global rights, enforced entirely by protocol, to names, attributions, bit gold, and similar purely informatic property owned by a particular entity but possessed and relied upon by the public, and how to implement a secure title database for other kinds of property. For a particular example of cross-trust-boundary rights enforced entirely by protocol, see my proposal for name integrity in cross-trust-boundary file systems.In all cases of property rights there is a defined space, whether a namespace or physical space, and the task is to agree on simple attributes of or rights to control subdivisions of that space. In some cases a name or other symbol corresponds to a person or object owned or controlled by that person. For example, Internet users must agree on which domain name corresponds to which web site operator. In other cases we are simply concerned with control over a subdivision of the space. With real estate we must agree on who owns various rights (to occupy the surface, to mine the minerals under, etc.) to a piece of land. With radio spectrum we must agree on who owns what range of frequencies and in what physical space (or transmitting power as an easily observed approximation of physical space used).It is the author's hypothesis that all such agreements of control, including control over the semantics of symbols, to be made and respected across trust boundaries are problems of agreeing on and maintaining property rights. Thus the results of this paper are far more general than they might first appear \u2013 I believe this paper provides a solution to secure namespaces and similar problems as well as the problem of securely recording agreements on traditional property rights. Highlighting the property rights nature of public directories also highlights the limitations of these mappings \u2013 for example that names, addresses, and other symbols whose semantics are controlled by a person can often be delegated, just as property can be given or rented.New advances in replicated database technology will give us the ability to securely maintain and transfer ownership for a wide variety of kinds of property, including not only land but chattels, securities, names, and addresses. This technology will give us public records which can \"survive a nuclear war\", along the lines of the original design goal of the Internet. While thugs can still take physical property by force, the continued existence of correct ownership records will remain a thorn in the side of usurping claimants.I use political words in this essay as metaphors to describe how our hypothetical property title software, and especially its protocol for distributing the title database across a public network, could work. A group, called a property club, gets together on the Internet[5] and decides to keep track of the ownership of some kind of property. The property is represented by titles: names referring to the property, and the public key corresponding to a private key held by its current owner, signed by the previous owner, along with a chain of previous such titles. Title names may \"completely\" describe the property, for example allocations in a namspace. (Of course, names always refer to something, the semantics, so such a description is not really complete). Or the title names might simply be labels referring to the property. Various descriptions and rules \u2013 maps, deeds, and so on \u2013 may be included.The property club can be thought of as a \"microgovernment\", an entity that performs globally and independently one narrow function normally associated with government. In particular it is a \"constitutional microdemocracy\" with low entry and exit costs. After the rules of property transfer have been decided, each vote should stay within this constitution \u2013 so that normally the vote will simply implement a distributed operation according to the property rules. The voting is necessary not due to a democratic political ideology but because it is the optimal result in analysis of distributed databases with malicious attackers.[6] If the rules are violated by the winning voters, the correct losers can exit the group and reform a new group, inheriting the old titles. Users of the titles (relying parties) who wish to maintain correct titles can securely verify for themselves which splinter group has correctly followed the rules and switch to the correct group. If the rules are violated by losing voters, they can be excluded from further participation both by correct winners and rule-following relying parties.This voting-or-reformation method works well where exit costs are low. Thus in practice users should not \"put all their eggs in one basket\", but different title clubs should be used for different kinds of property. Note that the key security feature of the club is not the voting, but a set of objective, often automated, rules and an unforgeable audit trail that allows both club members and relying parties to check whether each vote followed the rules. So, to go further with the political metaphor, a property club is a \"constitutional microdemocracy\" with most of the emphasis on the \"constitutional\". The voting is necessary, but is quite regulated.To implement a property club, we set up a replicated database so that the club members, hereafter \"servers\", can securely maintain titles of ownership, and securely transfer them upon the request of current owners. Actually getting end users to respect the property rights agreed upon by this system will be dependent on the specific nature of the property, and is beyond the scope of the current inquiry. The purpose of the replicated database is simply to securely agree on who owns what. The entire database is public.The ideal title database would have the following properties:We cannot achieve ideals (1) and (3), so we introduce \"voting\" as follows. A good model of secure replicated databases is the \"Byzantine Quorum System\" of Malkhi & Reiter[6]. In contrast to most recent work in peer-to-peer software, our design is based on mathematical proofs of security rather than hand-waving. For a short discussion of such threshold-of-servers approaches, see my essay \"Coalition Design for Secure Protocols\". The database is replicated across a universe of servers U, |U|=n. The \"quorum system\" is a collection of subsets (quora) of these servers, each pair of which intersect. Each quorum can operate on behalf of the system; intersection guarantees that operations done on distinct quora preserve consistency. A quorum system tolerant of Byzantine (unconditionally malicious) server failures is a collection of subsets of servers, each pair of which intersect in a set containing sufficiently many correct servers to guarantee the consistency of the replicated data. The authors construct a protocol such that any intersection contains at least 2f+1 servers, thus providing resilience against up to f malicious servers, n > 4f.Using these results it looks like we can approach our ideal title database as follows:Sharing control over property, for example as security for a loan, could be accomplished by sharing the private key corresponding to the current owner's public key. Possession of this private key is required to sign over title; multiparty threshold signatures could also be handled. So it may be a good idea to use one keypair for each combination of title and current owner, rather than keypairs representing the identities of owners. When certain contractual conditions are met, such as the last payment on a loan, this could trigger the generation of a new keypair held solely by the owner, and transfer of title from the shared keypair to the new keypair.The initial allocations might occur by mapping existing property rights from their current institutional incarnation, or by using traditional methods of staking and negotiating mutual recognition of claims. Some methods less dependent on an existing legal regime for the rights will be discussed in this section.For some kinds of allocation, such as spatial regions or a hierarchical namespace, we wish to be able to subdivided and re-merge properties. Current owner Alice should be able to transfer various fractional portions of her title to multiple single relying counterparties. One possibility is to have \"divide\" or \"merge\" messages whereby the current owner of a property can retire the old property specifications(s) and link them to new property spec(s), the whole message being signed by the owner. Then the new property spec(s) are introduced and considered active, and the old ones considered deactivated. It would be the responsibility subsequent transferees to ensure that the new specifications do not intersect, and are otherwise in good order.One way to approach the homesteading, or initial allocation, problem, I call the \"emergent respect\" style: Alice claims the entire unallocated universe. Bob also claims it, the same property spec under a different digital signature. They then may choose to subdivide, sell, give away, etc. property. Each conflicting root grows like a tree into an allocation of all property.How to resolve trees with conflicting roots? Eventually, the thugs, mechanisms, or informal agreements which enforce property rights converge on a particular tree as the standard, proper allocation. Roots who give away more property to more people, or who actually deploy mechanisms to protect their property, will gain more respect for the tree they started.In a namespace, conflicts may be resolved by giving names to the conflicting roots, and keeping track of those name-subtree mappings as property.Usurpers may be able to steal property by setting up their own root and enforcing it, but they can't delete the alternative allocations. The history is always there as evidence for claims.Those with no firsthand knowledge of conflicting claims may resolve them by consulting authorities, and weighing the opinions of these authorities according to trust metrics, similar to trust metrics sometimes used for public key certificates.With secure timestamps, homesteading could be done on a first-come rather than emergent respect basis.For some kinds of property we might want to add the right of adverse possession, or formalized squatting. Here's one general way to implement a kind of adverse possession:This method doesn't attempt to define or utilize a state of \"disuse\". Instead it equates activity of the property with the ongoing active online presence of an owner who knows about the title and wishes to continue ownership. Cost of maintaining the title might be made high by requiring a periodic registry fee from owners. However, this introduces the problem of who obtains the benefit, by property club rules, of the profits from this fee, and the problem of that the fee lowers the profit of owning the property, even perhaps making it negative. One possibility, where costs of protecting the property are high, is to charge a \"Georgian tax\" based on some imprecise but objective estimate of the value potential of the property, and allocate the fees to the task of securing the property. To come up with this estimate, or to account for usage of the property itself, would involve mechanisms or observation of characteristics specific to the kind of property, to which subject we now turn.Largely unaddressed above is the problem of divergence between actual conditions and directory rights. For example, squatters might legitimately, in the eyes of most property rights enforcers, occupy and improve unused land which a title registry indicates is owned by others. De Soto[2] describes squatters and emergent property rights on the American frontier and today's developing world. When names are property, a name may violate a pre-existing trademark, causing the confusion that both the new namespace and the old trademark namespace were designed to solve.When divergence becomes too great, a solution to address the unreality of the title registry is needed. One such solution is for the squatters to set up their own rival registry, and then prove the superior correspondence of their registry to actual reality over control and use of the resources. Another solution for squatters is to use the adverse possession mechanism described above \u2013 but this works only if the cost of maintaining the title is sufficiently high.Another solution is to examine the incentives of the titled owner, to see if they correspond to truthfully claiming control over a resource. In most cases there may be incentive to lie, and we can't use this method. In some cases there is incentive to tell the truth and we can, with caveats, rely on it. Any such incentive assumption in the property rules should be explicated, so that relying parties can examine whether the conditions creating the incentive still hold.Another solution is for property club rules and the registry to originally incorporate rich information about the actual state of property, and modify the actual ownership and transfer on this property based on that state, in a way that leaves few ambiguities so it can be fully audited by club members and third parties. It is most advantageous when this auditing can remain automated, as envisioned above. However the introduction as rule criteria of unrecorded (or unsecurely recorded) transient states common in physical property causes auditing, and thus the titles, to become both less secure and more expensive.My thanks to Gregory Burch, J.D., Eileen O'Connor, J.D., Melora Svoboda, and many others for their helpful comments.Kelly McCollum, \"Using Phone Books, Scholars Build a Data Base for Resettling Kosovars\" \u21a9Hernando de Soto, The Mystery of Capital \u21a9 \u21a9Reasons to buy title insurance \u21a9Bryce \"Zooko\" Wilcox, Names: Decentralized, Secure, Human-Meaningful: Choose Two \u21a9Property on the Internet may take all kinds of new forms. For analysis one recently emerged form, the ownership of open source software projects, see Eric Raymond, \"Homesteading the Noosphere\". \u21a9Malkhi & Reiter, \"Byzantine Quorum Systems\", STOC97 \u21a9 \u21a9Please send your comments to nszabo (at) law (dot) gwu (dot) eduCopyright \u00a9 1998,1999,2002,2005 by Nick Szabo\nPermission to redistribute without alteration hereby granted"}
{"prompt": "Trusted Third Parties are Security Holes", "completion": "Commercial security is a matter of solving the practical problems of business relationships such as privacy, integrity, protecting property, or detecting breach of contract. A security hole is any weakness that increases the risk of violating these goals. In this real world view of security, a problem does not dissapear because a designer assumes it away. The invocation or assumption in a security protocol design of a \"trusted third party\" (TTP) or a \"trusted computing base\" (TCB) controlled by a third party constitutes the introduction of a security hole into that design. The security hole will then need to be plugged by other means.If the risks and costs of TTP institutional alternatives were not accounted for in the protocol design, the resulting protocol will in most cases be too costly or risky to be practical. If the protocol beats these odds and proves practical, it will only succeed after extensive effort has gone into plugging the TTP security hole(s). TTP assumptions cause most of the costs and risks in a security protocol, and plugging TTP security holes produces the most benefit and profit.As a result, we propose a security protocol design methodology whereby the most risky and expensive part(s) of a security protocol, the trusted third partie(s), are designed in parallel with security protocol(s) using those parties. The objectives of cost and risk minimization are focused on the TTPs rather than the security protocols themselves, which should be designed to suit the cost and risk minimized TTPs.We also briefly discuss and reference research and implementation in security mechanisms that radically reduce trusted third party costs and risks by distributing automated TTPs across several parties, only a portion of which need to act in a reliable or trustworthy matter for the protocol to be reliable or trustworthy.This author has professional experience implementing a TTP that was assumed by early advocates of public key cryptography. This TTP has come to be called a \"certificate authority\" (CA). It has been given the responsibility of vouching for the \"identity\" of participants. (Here I focus on the costs imposed by the TTP; alternatives such as PGP's Web of Trust and SPKI have been discussed amply elsewhere).The certificate authority has proved to be by far the most expensive component of this centralized public key infrastructure (PKI). This is exacerbated when the necessity for a TTP deemed by protocol designers is translated, in PKI standards such as SSL and S/MIME, into a requirement for a TTP. A TTP that must be trusted by all users of a protocol becomes an arbiter of who may and may not use the protocol. So that, for example, to run a secure SSL web server, or to participate in S/MIME, one must obtain a certifcate from a mutually trusted certificate authority. The earliest and most popular of these has been Verisign. It has been able to charge several hundred dollars for end user certificates \u2013 far outstripping the few dollars charged (implicitly in the cost of end user software) for the security protocol code itself. The bureaucratic process of applying for and renewing certificates takes up far more time than configuring the SSL options, and the CA's identification process is subject to far greater exposure than the SSL protocol itself. Verisign amassed a stock market valuation in the 10's of billions of U.S. dollars (even before it went into another TTP business, the Internet Domain Name System(DNS) by acquiring Network Solutions). How? By coming up with a solution \u2013 any solution, almost, as its security is quite crude and costly compared to the cryptographic components of a PKI \u2013 to the seemingly innocuous assumption of a \"trusted third party\" made by the designers of public key protocols for e-mail and the Web.Some more problems with CAs are dealt with here.The Internet DNS is another example of the high costs and risks imposed by a TTP. This one tiny part of the TCP/IP protocol stack has accounted for a majority of the disputes and handwringing involving that protocol. Why? Because it is one of the few areas of the TCP/IP stack that depends on a centralized hieararchy of TTPs rather than on protocol negotiations between individual Internet nodes. The DNS is also the single component of the Internet most likely to fail even when its names are not being disputed or spoofed.The high costs of implementing a TTP come about mainly because traditional security solutions, which must be invoked where the protocol itself leaves off, involve high personnel costs. For more information on the necessity and security benefits of these traditional security solutions, especially personnel controls, when implementing TTP organizations, see this author's essay on group controls. The risks and costs borne by protocol users also come to be dominated by the unreliability of the TTP \u2013 the DNS and certificate authorities being two quite commom sources of unreliability and frustration with the Internet and PKIs respectively.Companies like Visa, Dun and Bradstreet, Underwriter's Laboratories, and so forth connect untrusting strangers into a common trust network. Our economy depends on them. Many developing countries lack these trust hubs and would benefit greatly from integrating with developed world hubs like these. While these organizations often have many flaws and weaknesses \u2013 credit card companies, for example, have growing problems with fraud, identity theft, and innacurate reports, and Barings recently went belly up because their control systems had not properly adapted to digital securities trading \u2013 by and large these institutions will be with us for a long time.This doesn't help us get TTPs for new protocols. These institutions have a particular way of doing business that is highly evolved and specialized. They usually cannot \"hill climb\" to a substantially different way of doing business. Substantial innovations in new areas, e.g. e-commerce and digital security, must come from elsewhere. Any new protocol design, especially paradigmatically different areas such as capabilities or cryptographic computations, will be a mismatch to the existing institutions. Since building new TTPs from scratch is so costly, it is far cheaper when introducing protocols from these institutionally novel security technologies to minimize their dependencies on TTPs.Many are the reasons why organizations may come to favor costly TTP based security over more efficient and effective security that minimizes the use of TTPs:Limitations of imagination, effort, knowledge, or time amongst protocol designers \u2013 it is far easier to design security protocols that rely on TTPs than those that do not (i.e. to fob off the problem rather than solve it). Naturally design costs are an important factor limiting progress towards minimizing TTPs in security protocols. A bigger factor is lack of awareness of the importance of the problem among many security architects, especially the corporate architects who draft Internet and wireless security standards.The temptation to claim the \"high ground\" as a TTP of choice are great. The ambition to become the next Visa or Verisign is a power trip that's hard to refuse. The barriers to actually building a successful TTP business are, however, often severe \u2013 the startup costs are substantial, ongoing costs remain high, liability risks are great, and unless there is a substantial \"first mover\" advantage barriers to entry for competitors are few. Still, if nobody solves the TTP problems in the protocol this can be a lucrative business, and it's easy to envy big winners like Verisign rather than remembering all the now obscure companies that tried but lost. It's also easy to imagine oneself as the successful TTP, and come to advocate the security protocol that requires the TTP, rather than trying harder to actually solve the security problem.Entrenched interests. Large numbers of articulate professionals make their living using the skills necessary in TTP organizations. For example, the legions of auditors and lawyers who create and operate traditional control structures and legal protections. They naturally favor security models that assume they must step in and implement the real security. In new areas like e-commerce they favor new business models based on TTPs (e.g. Application Service Providers) rather than taking the time to learn new practices that may threaten their old skills.Mental transaction costs. Trust, like taste, is a subjective judgment. Making such judgement requires mental effort. A third party with a good reputation, and that is actually trustworthy, can save its customers from having to do so much research or bear other costs associated with making these judgments. However, entities that claim to be trusted but end up not being trustworthy impose costs not only of a direct nature, when they breach the trust, but increase the general cost of trying to choose between trustworthy and treacherous trusted third parties.For most of human history the dominant form of property has been personal property. The functionality of personal property has not under normal conditions ever depended on trusted third parties. Security properties of simple goods could be verified at sale or first use, and there was no need for continued interaction with the manufacturer or other third parties (other than on occasion repair personel after exceptional use and on a voluntary and temporary basis). Property rights for many kinds of chattel (portable property) were only minimally dependent on third parties \u2013 the only problem where TTPs were neededwas to defend against the depredations of other third parties. The main security property of personal chattel was often not other TTPs as protectors but rather its portability and intimacy.Here are some examples of the ubiquity of personal property in which there was a reality or at least a strong desire on the part of owners to be free of dependence on TTPs for functionality or security:This desire is instinctive and remains today. It manifests in consumer resistance when they discover unexpected dependence on and vulnerability to third parties in the devices they use. Suggestions that the functionality of personal property be dependent on third parties, even agreed to ones under strict conditions such as creditors until a chattel loan is paid off (a smart lien) are met with strong resistance. Making personal property functionality dependent on trusted third parties (i.e. trusted rather than forced by the protocol to keep to the agreement governing the security protocol and property) is in most cases quite unacceptable.We now propose a security protocol design methodology whereby protocol(s) are designed to minimize these costs and risks of the TTPs. Minimizing the costs and risks of the security protocol(s) themselves is an important but secondary priority.Currently, security designers usually invoke or assume TTPs to suit the most elegant and secure or least computationally costly security protocol. These naive TTPs are then used in a proof of concept of an overall protocol architecture. But this does not discover the important things that need to be discovered. Once a security protocol is implemented the code itself costs very little, and exponential cost functions such as Moore's law keep reducing computational, bandwidth, and many other technological costs. The costs of the security protocol itself (except for the costs of message rounds, limited by the speed of light, and the costs of the user interface, limited by mental transaction costs) approach zero. By far the largest long-term cost of the system (as we learned with PKI) is the cost of implementing the TTPs.It's far more fruitful to estimate from the beginning what the TTPs will cost, rather than try to design the security protocols to minimize the costs of the TTPs. This will likely bring the designer to quite different trust assumptions and thus security protocols than if (s)he assumes pure, unanalyzed TTPs in certain places in order to simplify the security protocol. A natural corrolary is if that there exists a security protocol that can eliminate or greatly reduce the costs of a TTP, then it pays greatly to implement it rather than one which assumes a costly TTP. Even if the latter security protocol is simpler and much more computationally efficient.A corollary of \"trusted third parties are security holes\" is \"all security protocols have security holes\", since no protocol is fully free of such assumptions. The key steps in estimating TTP costs and risk are to (1) examine one's assumptions thoroughly to uncover all TTP assumptions and characterize specifically what each TTP is and is not expected to do, (2) observe that each such specific hole and task has an associated cost and risk.There are several other important considerations, including:If for a new context like e-commerce we can find a security protocol which replaces a TTP organization (a complex set of traditions quite unproven in the new context) with mathematics (which at least in itself is quite clear and provable) it will often be a very big win to do so. More often we will replace a complex costly TTP with one or more much simpler TTPs plus mathematics. That too is a big win. We can only tell if and by how much it is a win by focusing on the trust assumptions and the resulting costs of the TTPs rather than focusing on the efficiency of the security protocol. The key is to focus on the cost of the TTPs and design the security protocol to minimize them, rather than assuming TTPs in order to simplify or optimize the efficiency of the security protocol.A good digital security protocol designer is not only an expert in computer science and cryptography, but also very knowledgeable about the traditional costly techniques of physical security, auditing, law, and the business relationships to be secured. This knowledge is not used to substitute these costly security methods for more cost effective digital security, but in order to minimize hidden dependence on costly methods for the real security. A good protocol designer also designs, rather than merely assumes, TTPs that work with minimal use of costly techniques.We saw above that the keys to minimizing TTPs are to identify them, characterize them, estimate their costs and risks, and then design protocols around TTPs of minimal cost and risk. When the risk is mitigated with techniques like those in this session, it can be very substantially reduced.Three areas of research and implementation show special promise in improving trust. Two of these involve the particularly thorny area of privacy, where breach of trust is often irreversible \u2013 once data gets out it can be impossible to put back.The first protocol family in which trust can be distributed to preserve privacy is the Chaum mixes. Mixes allow communications immune from third party tracing. Only any one out of N proxies in a proxy chain need be trustworthy for the privacy to be preserved. Unfortunately, all N of the proxies need to be reliable or the message will be lost and must be resent. The digital mix protocol's tradeoff is to increase messaging delays (resends) in order to minimizes the risk of irreversible privacy loss.Another protocol family in which trust can be distributed to preserve privacy is the multiparty private computations. Here a virtual computer is distributed across the N parties who provide specially encrypted input to each other rather than to a trusted third party. The distributed computer takes inputs from each of the N parties, computes an agreed to algorithm, then outputs the answer. Each party learns only the answer not the inputs of any other party. The threshold of parties that that must collude to violate privacy or threaten reliability can be traded off and have been studied in detail in the ample literature on this topic. Multiparty private computations can be used for confidential auditing, confidential preference gathering and data mining, auctions and exchanges with confidential bids, and so on.A protocol family that replicates data, and distributes operations on that data, while preserving the integrity of that data, are the Byzantine resilient replicated databases. Implementations of Byzantine resilient replicated databases include Fleet and Phalanx. Fleet implements replicated persistence of general purpose objects. Some open source implementations, which approach but do not achieve Byzantine resilience, general purpose, or complete decentralization include Mojo Nation and Freenet. Applications include secure name registries and property titles as well as securely published content in Mojo Nation and Freenet. The most advace work in this area involves Byzantine fault tolerant quorum systems and other recent advanced in distributed security.It is important to note that these threshold techniques are only meant to enhance the integrity of a single step or run of the protocol. Practical systems, such as Mojo Nation, combine a majority or super-majority within a particular run with failure detection and choice by clients of servers between runs. So we can add back all the reputation systems, auditing, and so on that add robustness in the long term to distributed systems. The majorities or super-majorities within an invocation create a very good short-term robustness that is missing from current systems like Freenet and Mojo Nation. (It's only party missing from Mojo, which has a 4-of-8 voting scheme but this has not been shown to be Byzantine resilient up to 4-of-8).Remote attestation has been proposed for verifying the state of software running on clients to protect intellectual property. A more valuable use for remote attestation is for verifying the behavior of servers. This is also called the transparent server approach. Through remote attestation, clients can verify that the specific desired code is running on a server. Combined with the ability to audit that code as open source, remote attestation of servers can greatly decrease the vulnerability of clients and users to the server. Given the importance of the trusted third party problem we have discussed here, this approach has vast potential to convert trusted third party protocols into secure protocols, and to make possible a wide variety of secure protocols that were heretofore impossible. For example, Hal Finney has implemented a version of bit gold called reusable proofs of work, based on a secure coprrocessor board that allows users to remotely attest the code running on the card. While one still needs to trust the manufacturer of the card, this manufacturer is separated from the installation of server code onto and the operation of the server on the card.Often the protocol designer can't figure out how to fix a vulnerability. If the attack one needs a TTP to protect against is not a serious real-world threat in the context of the application the designer is trying to secure, it is better to simply leave the small hole unplugged than to assign the task to a TTP. In the case of public key cryptography, for example, protocol designers haven't figured out how to prevent a \"man-in-the-middle\" (MITM) attack during the initial key exchange. SSL tried to prevent this by requiring CAs as trusted third parties, as described above, and this solution cost the web community billions of dollars in certificate fees and lost opportunities to secure communications. SSH, on the other hand, decided to simply leave this small hole unplugged. The MITM hole has, to the best of my knowledge, never even once been exploited to compromise the privacy of an SSH user, yet SSH is far more widely used to protect privacy than SSL, at a tiny fraction of the cost. This economical approach to security has been looked at at greater length by Ian Grigg.Alan Karp, Mark Miller, and others have observed the confusion over words like \"trust\" and \"trusted\" as used in the security community, and proposed replacing the verb \"trusts\" with \"is vulnerable to\". This substitution is a great way to radically clarify security protocol designs. \"Trusted third party\" as used in this essay becomes \"vulnerable to a third party\", and the point of this paper, that this is a security hole, becomes obvious.In the context of protocol designs, instead of saying the protocol designer trusts some little-known generic class of parties (referred to in the singular as \"a trusted third party\") with a given authorization (which probably really means the protocol designer just can't figure out how to plug a security hole), an honest protocol designer will admit that there is a vulnerability here \u2013 and that it is up to \"out of band\" mechanisms to plug or minimize, or up to users to knowledgeably ignore, that hole. The class of parties is little-known because security protocol designers typically don't know much about the traditional non-digital security, legal, and institutional solutions needed to make such a party trustworthy. The substitution of \"vulnerable to\" for \"trusted\" works well in protocol design, and in communicating honestly about the security of a protocol.Alas, are security designers and sellers of security systems who invoke \"trusted third parties\", \"trusted computing\", and the like really going to come out and admit that their protocols are \"vulnerable\"? Security designs sound so much more secure when they use the euphemism \"trust\".In the real world, beyond the technical context of security protocol design, \"trust\" has a variety of meanings. One different use of \"trust\" is well-informed trust, for example \"I trust this armor to protect me from normal bullets, because it's been very well tested\", \"I trust this site with this authorization because we're using a strong security protocol to protect me when I grant this authorization\", or \"I trust my wife with the kids\", in which cases translating \"trust\" to \"am vulnerable to\" would be to reverse its meaning. That \"trust\" can take on practically opposite meanings, depending upon the context, is another strong argument for avoiding use of the word when describing the vulnerabilities, or lack thereof, of security protocols. Whether a designer thinks he does or must trust some generic class of parties is one thing. Whether a particular user will actually trust a particular entity in that class when the protocol actually runs is quite another matter. Whether either the user's trust or the designer's trust is well informed is yet another matter still.Traditional security is costly and risky. Digital security when designed well diminishes dramatically in cost over time. When a protocol designer invokes or assumes a TTP, (s)he is creating the need for a novel organization to try to solve an unsolved security problem via traditional security and control methods. Especially in a digital context these methods require continuing high expenditures by the TTP and the TTP creates a bottleneck which imposes continuing high costs and risks on the end user.A far better methodology is to work starting from TTPs that either well known, or easy to characterize, and of minimal cost. The best \"TTP\" of all is one that does not exist, but the necessity for which has been eliminated by the protocol design, or which has been automated and distributed amongst the parties to a protocol. The latter strategy has given rise to the most promising areas of security protocol research including digital mixes, multiparty private computations, and Byzantine resiliant databases. These and similar implementations will be used to radically reduce the cost of current TTPs and to solve the many outstanding problems in privacy, integrity, property rights, and contract enforcement while minimizing the very high costs of creating and operating new TTP institutions.Links in the text.My thanks to Mark Miller who encouraged me to write down these thoughts and provided many good comments. My thanks also to Hal Finney, Marc Stiegler, David Wager, and Ian Grigg for their comments.Please send your comments to nszabo (at) law (dot) gwu (dot) eduCopyright \u00a9 2001, 2004, 2005 by Nick Szabo\nPermission to redistribute without alteration hereby granted"}
{"prompt": "Contracts with Bearer", "completion": "\"Digital bearer certificate\" is a broad term developed by this author[1] incorporating at least two emerging technologies: digital cash and distributed capabilities (secure distributed object references). I will first describe the Chaumian protocol and its innovative privacy feature. I will then discuss how these ideas map to the world of capabilities in the section on generic vs. specific rights. I have altered digital cash terminology from digital cash to bearer certificate or token, from mint to issuer or transfer agent, and so on to reflect the ability of Chaum's protocols to generalize. Chaumian bearer certificates implement standardized rights transferable regardless of the identity of the holder. Each kind of contract (for example, each denomination of \"coin\" in digital cash) corresponds to a digital signature, just as each issue of Federal Reserve Notes or stock certificates corresponds to a particular plate.In the most straightforward Chaumian protocol, the issuer and transfer agent (the same entity, for our purposes, though they can easily be unbundled) create a serial number (really a large unguessable random number, rather than a sequence), and append it to a list of issued certificates. The transfer agent clears a transfer (i.e., redeems the certificate) by checking the signature to identify the class of bearer contract and verify that it was made, then looking on that contract's issued list to make sure the serial number is there, then removing the serial number. Alternatively, the issuer can let the issuee make up the serial number, then, when cleared, check the signature and put the number on the list of cleared certificates. The signature provides the assurance that the certificate is indeed the the particular kind of contract with bearer, while the serial number assures that the same instance of that contract is not cleared or redeemed more than once. In these simple versions, the transfer agent can link the transferee to the transferor for all transfers. To implement the privacy characteristics of coins and physical bearer certificates, we need to add unlinkability features.Meet the greatest simple equation since e=mc2:S is a digital signature. f is the blinding function, and g an unblinding function. The blinding functions are usually based on a secret random number called the \"blinding factor\". m is another random number, a unique identifier which can, for example, refer to an instance of some object.The idea is very clever but very simple. It may be counterintuitive because the simplest physical world metaphor of this highly useful e-commerce primitive sounds worse than useless: Alice can get Carol to sign a blank check! Here's how:The genius behind this discovery: cryptography guru David Chaum. The brilliance lies in step 3: Chaum discovered that some signatures have the property of being \"commutative\" with the blinding functions: Alice can strip off the blinding in the reverse order which the blinding and signature were applied, leaving just Alice's signature of n. It is as if Alice put a piece of carbon paper inside the envelope!In particular for RSA signatures, with public key (pq, e) and private key d, the blind signature functions are the following modulo pq:We can check that the blind signature property holds: gSf(m) = (m(ke))d * k-1 = md * k * k-1 = md, which is the valid RSA signature of private key d on m.Distinguish between either a counter or third party tracing one person's true name, via lack of or weak communications mix, and a third party linking two entities (whether nyms, use-more-than-once-addresses, account numbers, or true names) as being involved in the same transaction. By unlinkability herein we mean the latter. The goal where true names are used (this occurs, for example, when using true name accounts or not using good communications mixes), is to prevent third party linking of two people doing business with each other. Where nyms are used the goal is to minimize the release of traffic information, to prevent the unwanted accumulation of unique behavior patterns, which could be used to link nyms (including to their true names), or could augment other means of breaching privacy. Blinding especially helps where rights holders want to keep third party or public accounts denominated in generic rights. In that case a communications mix doesn't even in principle give us what blinding does.Besides protecting against the transfer agent, Chaum's transferor-, transferee-, and double-blinding protocols protect against collusion of a party with a transfer agent to identify the countparty account or nym.Unlinkability can be provided by combining a list of cleared certificates with blind signatures and a delay-mixing effect. Enough instances of a standardized contract are issued over a period of time to create a mix. Between the issuing and clearing of a certificate, many other certificates with the same signature will be cleared, making it highly improbable that a particular clearing can be linked to a particular issue via the signature. There is a tradeoff between the mixing effect and the exposure to the theft of a \"plate\" for a particular issue: the smaller the issue, the smaller the exposure but the greater the linkability; a larger issue has both greater exposure and greater confidentiality.Blind signatures can be used to make certificate transfers unlinkable via serial number. Privacy from the transfer agent can take the form of transferee-unlinkability, transferor-unlinkability, or \"double blinded\" where both transferor and transferee are unlinkable by the transfer agent or a collusion of a transfer agent and counterparty.A use-once-address communications mix plus foreswearing any reputation gain from keeping accounts, in theory also buys us unlinkability, but a communications mix is weak and very expensive.Bearer certificates come in an \"online\" variety, cleared during every transfer, and thus both verifiable and observable, and an \"offline\" variety, which can be transferred without being cleared, but is only verifiable when finally cleared, by revealing any the clearing name of any intermediate holder who transferred the object multiple times (a breach of contract).This unlinkability is often called \"anonymity\", but the issue of whether accounts are issued to real names or pseudonyms, and whether transferor and transferee identify themselves to each other, is orthogonal to unlinkability by the transfer agent in the online model. In the off-line model, account identification (or at least a highly reputable and/or secured pseudonym) is required: passing an offline certificate a second time reveals this identity. Furthermore, communications channels can allow Eve to link transferor and transferee, unless they take the precaution of using an anonymous remailer. Online clearing does make lack of identification a reasonable option for many kinds of transactions, although common credit and warrantee situations often benefit from or even require identification.When confronting an attempted clearing of a cleared serial number, we face an error-or-fraud dilemma similar to the one we encountered above in double entry bookkeeping. The ecash\u2122 protocol from DigiCash actually takes advantage of on purpose to recover from a network failure. When certificates are lost over the net it is not clear to the transferor whether they have been received and cleared by the transferee or not. Second-transferring directly with the transfer agent resolves the ambiguity. This only works with the online protocol. The issue of distinguishing error from fraud is urgent in the offline protocol, but there is as yet no highly satisfactory solution. This problem is often intractable due to the subjectivity of intent.With ideal two-way anonymous communications between use-once keys, and completely accountless clearing, unlinkability via blind signatures becomes redundant. This ideal case has yet to be even closely approached with implemented technology, and necessarily involves long communications delays which are often intolerable. Real imperfect communications mixes and less expensive blinded tokens complement each other.Issuance and cleared transfer of references to a distributed object conserves the usage of that object. This object becomes \"scarce\" in economic terms, just as use of physical objects is finite. Conserved objects provide the basis for a software economics that more closely resembles economics of scarce physical objects. Conserved objects can be used to selectively exclude not only scarce physical resources (such as CPU time, network bandwidth and response time, etc.), but also fruits of intellectual labor \u2013 as long as one is willing to pay the price to interact with that information over the network rather than locally (cf. content rights management). Conservation immunizes objects and the resources they encapsulate to denial of service attacks. Bearer certificate protocols can be used to transfer references to a particular instance or set of instances of an object, just as they can be used to transfer other kinds of standardized rights.To implement a full transaction of payment for services, we often need need more than just the digital cash protocol; we need a protocol that guarantees that service will be rendered if payment is made, and vice versa. Current commercial systems use a wide variety of techniques to accomplish this, such as certified mail, face to face exchange, reliance on credit history and collection agencies to extend credit, etc. I discuss such issues in my article on smart contracts.To discuss the mapping between Chaumian certificates and distributed capabilities as implemented in for example E I introduce some different, partly overlapping terminology: generic vs. specific, exclusive vs. non-, Transfer Agent vs. Provider, token vs. Swiss number.Rights can be generic or specific. Generic rights correspond to a class of objects, specific rights to an instance. So a specific right is implemented with a Swiss number, a large random number. The signed numbers corresponding to generic rights I will call \"tokens\".Rights can also be exclusive or non-exlusive. Any object which must be conserved, or finally allocated to a specific user, is \"exclusive\".Simple example: the right to an exclusive lock on some 1 MB of memory is generic and exclusive. The right to an exclusive lock on the specific address space 100-101 is specific and exclusive. The right to two dozen particular stock quotes at 12:22 p.m. today is specific and non-exclusive.The main motivation for these distinctions are different mechanisms of unlinkable transfer of these rights, set out below.For simplicity generic rights are all \"use-once\": the life cycle of a token consists of issuance, followed by a series of transfers, followed by consumption. More sophisticated life cycles, such as alternating transfer and consumption, are likely possible with some extra protocol.With a perfect communications mix, including use-once return addresses, and no reputation building, we wouldn't need blinded tokens. However, communications mixes are expensive, and we want the option of having certain public records by which to build reputations, yet do certain rights transfers privately. For these reasons, we should allow clients to blind token transfers in addition to providing a communications mix.For inexpensive, unlinkable, and verifiable transfer of exclusive generic rights, using blinded tokens, there must be a signficant population of interchangable generic rights. Such rights bundled with nonexlusive specific rights can also be cheaply transferred since online clearing is not required for the latter. Unlinkable and verifiable transfer of exclusive specific rights seems to require online clearing via an expensive communications mix.Two kinds of TTPs: a Transfer Agent (TA) and a Provider. The TA operates like an accountless digital cash mint, clearing the transfer of tokens for generic rights. Digital cash is a special case: money is the most generic of rights.The Provider is responsible for actually holding the object, which can contain unique state. The Provider issues a Swiss number, or better a signed description of the specific right and its Swiss number. This signature allows offline verification of the nonexlusive right where the Provider is reputable. The TA issues a token for the corresponding generic rights.Chaum has also developed other means for dealing with unique state[2].I'm assuming the TA and Provider have known reputable signatures. The trust or reputation needed to ensure correctness of transfer between Provider, TA, and users is partly left for later analysis. The two main goals here are to assure that users can verify their rights (including exclusivity from transferors where promised) and retain full privacy from TAs and Providers. Some other trust assumptions are likely made here which need to be explicated and analyzed.To implement exclusive transfers, the TA keeps a list of cleared (cancelled) token numbers. The TA corresponds to a \"mint\" in the Chaumian online digital cash protocol (see above). A class of generic rights corresponds to a \"denomination\" of coin. The Provider may also keep a list of outstanding or used Swiss numbers, like an E Registrar.Here is another example of a generic right, or class of fungible objects: \"A queriable SQL database with up to 10 MB of storage, and certain standard response time guarantees\".The TA sees only classes of fungible objects. The Provider and users see particular instances with unique state, for example a database filled with unique information.The Provider acts analogously to a \"shop\". It is just another token client to the TA, which like other clients can transfer or receive tokens. Its special role is that it is responsible for issuance, where it tells the TA about a new instance, obtains a new token, and transfers it to the client to whom the new generic right is being issued. The TA generates and destroys token supply only at the behest of the Provider; otherwise all its transfers conserve the supply of a particular generic right. The Provider is also responsible for the delivery of service to the client bearing the promised right(s), at which time the Provider \"deposits\" the generic token(s), instructing the TA to decrement the token supply. In digital cash terminology, the Provider is the only entity which has to keep something like a bank account. Rights holders can also keep an account, if they wish to use it to help build reputation, or they can just use the TA for accountless conserved rights transfer.The Provider issues along with the initial generic rights token a signed affadavit, machine or human readable, describing aspects of the object which may be non-exlusive and unique, along with that instance's Swiss number and the public key(s) of the generic right(s) for which it is valid. For example, it might say \"a database containing quotes of these two dozen listed stocks as of 12:22 pm Monday\", without actually containing those quotes. Often such description is worth more when bundled with generic exclusive rights, such as the right to a fast response time. The specific rights can elaborate in unique ways upon the generic rights, as long as these elaborations are not taken to define exclusive rights. The generic rights let the TAs garuntee exclusivity to users and conservation of resources to Providers, while the specific rights describe the unique state to any desired degree of elaboration. The Provider must be prepared to service any specific promise it has issued, as long as it is accompanied by the proper conserved generic tokens.This method of composing specific and generic rights, transferred as a bundle but with exlusive generic atoms cleared by different TAs, allows arbitrarily sophisticated rights bundles, referring to objects with arbitrarily unique state, to be transferred unlinkably. A wide variety of derivatives and combinations are possible. The only restriction is that obtaining rights to specific exclusive resources must either be deferred to the consumption phase, or transferred with online clearing via expensive communications mix.If the Provider wished to guarantee exclusivity to a specific right, transfer seems to require an expensive communications mix between Provider and transferee, rather than a cheap blinded token. For example, \"Deep Space Station 60 from 0500-0900 Sunday\" or \"a lock on autoexec.bat now\" demands exclusivity to a specific right, and thus seems to require a communications mix to unlinkably transfer. On the other hand, \"A one hour block on DSS-60 in May\" and \"the right to lock autoexec.bat at some point\" are generic and can be transferred privately with the much less expensive blinding, given a sufficient population of other tokens for this class of generic right transfered between the issuance and consumption of a given token.Clients can deal with the TA without a communications mix. They deal with the Provider via a communications mix. If both the initial and final holders failed to do this, the Provider could link them. If just the final holder failed to do so, the Provider could identify him as the actual user of the resource. Thus for full privacy generic transfers are cheap, and nonexclusive transfers are cheap, while specific exsclusive transfers and actually using the object seem to require the expensive communications mix.My thanks to David Chaum, Mark Miller, Bill Frantz, Norm Hardy, and many others for taking the time to give me their valuable insights into these issues.The first public references to this idea can be found here, here. I also referred to this idea during this period in many personal communications, using the phrases \"digital bearer instrument\", \"digital bearer certificate\", \"scarce object\", and \"conserved object\". The idea of digital bearer certificates as a serious proposal for the financial industry has been popularized, with many intruiging additional ideas, by Bob Hettinga. \u21a9David Chaum, Online Cash Checks \u21a9\"Blind Signatures for Untraceable Payments,\" D. Chaum,\nAdvances in Cryptology Proceedings of Crypto 82,\nD. Chaum, R.L. Rivest, & A.T. Sherman (Eds.), Plenum, pp. 199-203.The E distributed object languagePlease send your comments to nszabo (at) law (dot) gwu (dot) eduCopyright \u00a9 1997, 1999 by Nick Szabo\nPermission to redistribute without alteration hereby granted"}
{"prompt": "The God Protocols", "completion": "Imagine the ideal protocol. It would have the most trustworthy third party imaginable \u2013 a diety who is on everybody's side. All the parties would send their inputs to God. God would reliably determine the results and return the outputs. God being the ultimate in confessional discretion, no party would learn anything more about the other parties' inputs than they could learn from their own inputs and the output.Alas, in the our temporal world we deal with humans rather than deities. Yet, too often we are forced to treat people in a nearly theological manner, because our infrastructure lacks the security needed to protect ourselves.Network security theorists have recently solved this problem to an astonishing extent. They have developed protocols which create virtual machines between two or more parties. Multiparty secure computation allows any number of parties to share a computation, each learning only what can be inferred from their own inputs and the output of the computation. These virtual machines have the exciting property that each party's input is strongly confidential from the other parties. The program and the output are shared by the parties.For example, we could run a spreadsheet across the Internet on this virtual computer. We would agree on a set of formulas and set up the virtual computer with these formulas. Each participant would have their own input cells, which remain blank on the other participants' computers. The participants share output cell(s). Each input our own private data into our input cells. Alice could only learn only as much about the other participants' input cells as she could infer from her own inputs and the output cells.There are three major limitations. The first is that this virtual computer is very slow: in some cases, one arithmetic calculation per network message. Currently it is at best practical only for small logic or arithmetic calculations used as an adjunct to or component of more efficient computations and protocols.The second is that there is a tradeoff between privacy, fairness, and fault tolerance. Fairness means everybody learning the results in such a way that nobody can gain an advantage by learning first. Fault tolerance can provide robustness against a minority, so that it takes a majority dropping out to halt the protocol, or it can be nonrobust but fail-stop, so that a single participant can terminate the protocol. Many papers have discussed the fraction of parties one must trust in order to be assured of learning the correct output. In traditional results, fairness and privacy could not both be achieved with a faulty majority. Recent papers[3][4][5][6] have produced fair and private protocols even with faulty majorities. They trade robustness for privacy and fairness against any proportion of faulty parties. The advantage of this fail-stop approach is that one can usually find new partners and start over again, but one does not want to suffer irreversible losses such as leaking information, being left holding the bag, or being convinced of an incorrect result.The third limitation is that, far from being omniscient or omnipotent, the protocol will accomplish only what is specified in the algorithm and the inputs. It won't be able to replace human trusted third parties where those parties provide insight or knowledge that cannot be provided by a computer.With these caveats, any algorithmic intermediary can, in principle, be replaced by a trustworthy virtual computer. In practice, because of the three complications, we usually construct more limited protocols out of more efficient elements.Multiparty computation theory, by making possible privy virtual intermediation, has major implications, in theory, for all kinds of contractual relationships. This can be seen most clearly in the area of negotiations. A \"mechanism\" in economics is an abstract model of an institution which communicates with its participants via messages, and whose rules can be specified algorithmically. These institutions can be auctions, exchanges, voting, and so on. They typically implement some kind of negotiation or decision making process.Economists assume a trusted intermediary operates the mechanism. Here's a simple example of using this virtual computer for a mechanism. Alice can submit a bid price, and Bob an ask price, then their shared virtual program which has one instruction, \"A greater than B?\". The computer then returns \"true\" if Alice's bid is greater than Bob's offer. A slightly more sophisticated computer may then decide the settlement price according to a number of different algorithms (Alice's bid, Bob's ask, split the difference, etc.) This implements the mechanism \"blind bargaining\" with no trusted intermediary.In principle, since any computable problem can be solved on this virtual computer (they are \"Turing complete\"), any computable economic mechanism can be implemented without a trusted intermediary. In practice, we face the three limitations discussed above. But the existence proof, that any economic mechanism can be run without a trusted intermediary, is very exciting. This means that, in principle, any contract which can be negotiated through a trusted third party (such as an auction or exchange) can be negotiated directly. So, in some abstract sense, the only remaining \"hard\" problems in smart contract negotiations are (a) problems considered hard even with a trusted intermediary (for the standard economic reasons), and (b) the task of algorithmically specifying the negotiating rules and output contract terms (This includes cases where an intermediary adds knowledge unavailable to the participants, such as a lawyer giving advice on how to draft a contract). In practice, many problems which can be solved in principle with multiparty computation will re-arise when we implement protocols in an efficient, practical manner. The God Protocols give us a target to shoot for.Applying this kind of analysis to the performance phase of contracts is less straightforward. For starters, economic theories of the performance phase are not as well developed or simple as the mechanism theory of negotiations. Indeed, most economic theory simply assumes that all contraccts can be perfectly and costlessly enforced. Some of the \"transaction cost\" literature has started to move beyond this assumption, but there are few compelling results or consensus theories in the area of techniques and costs of contract enforcement.Performance phase analysis with multiparty secure computer theory would seem to apply only to those contracts which can be performed inside the virtual computer. But the use of post-unforgeable auditing logs, combined with running auditing protocols inside the shared virtual computer, allows a wide variety of performances outside the virtual computer to at least be observed and verified by selected arbitrators, albeit not proactively self-enforced.The participants in this mutually confidential auditing protocol can verify that the books match the details of transactions stored in a previously committed transaction log, and that the numbers add up correctly. The participants can compute summary statistics on their confidentially shared transaction logs, including cross-checking of the logs against counterparties to a transaction, without revealing those logs. They only learn what can be inferred from the statistics, can't see the details of the transactions. Another intriguing possibility is that the virtual computer can keep state over long periods of time, allowing sophisticated forms of privy and self-enforcing secured credit.If mutually confidential auditing ever becomes practical, we will be able to gain high confidence in the factuality of counterparties' claims and reports without revealing identifying and other detailed information from the transactions underlying those reports. These would provide the basis for solid reputation systems, and other trusted third party systems, that maintain integrity across time, communications, summarization, and preserve confidentiality for transaction participants. Knowing that mutually confidential auditing can be accomplished in principle will hopefully lead us to practical solutions to these important problems.D. Chaum, C. Cr\u00e9peau, and I. Damgaard, Multiparty unconditionally secure protocols; In 19th Symp. on Theory of Computing, pages 11-19. ACM, 1988.\"The Spymasters Double Agent Problem: Multiparty Computations Secure Unconditionally from Minorities and Cryptographically from Majorities,\" D. Chaum, Advances in Cryptology CRYPTO'89, G. Brassard (Ed.), Springer-Verlag, pp. 591-601.C. Cr\u00e9peau, J. van de Graaf, and A. Tapp, Committed Oblivious Transfer and Private Multi-Party Computations; Advances in Cryptology: Proceedings of Crypto '95, Springer-Verlag, pages 110-123, 1995. \u21a9Complete Characterization of Adversaries Tolerable in Secure Multi-Party Computation, Martin Hirt and Ueli Maurer. Computer Science Department, ETH Z\u00fcrich. 1997. in Proceedings of PODC '97 \u21a9Matthias Fitzi, Martin Hirt, and Ueli Maurer: Trading correctness for privacy in unconditional multi-party computation. In Advances in Cryptology \u2014 CRYPTO '98, volume 1462 of Lecture Notes in Computer Science, 1998. \u21a9R. Cramer, I. Damgaard, S. Dziembowski, M. Hirt, T. Rabin, Efficient Multi-Party Computations with Dishonest Majority, Proceedings of Eurocrypt '99, Springer Verlag LNCS, to appear (May '99). \u21a9Please send your comments to nszabo (at) law (dot) gwu (dot) eduCopyright \u00a9 1997-1999 by Nick Szabo\nPermission to redistribute without alteration hereby granted"}
{"prompt": "Multinational Small Business", "completion": "Currently the vast majority of businesses on the planet are small, but the vast bulk of multinational business is conducted by large corporations.In the future the size distribution of multinationals will approach that of local business. The phase change between these states may be quite rapid as telecomm and transport costs pass through a \"melting point\", creating a wide variety of new multinational small businesses, and industries to support those businesses.Barriers to multinational small business includeBoth transport and telecomm costs have become unprecedentedly low, and with fiber optics telecomm costs will drop orders of magnitude further.Small business can cut through the Gordian knot of jurisdictions with the technologies of jurisdictional independence, including strong encryption for communications and databases, digital cash, firewalls, foiling of traffic analysis with proxy servers and digital mixes, and other system security measures. For use of these capabilities to become routine they must be made seamlessly available in the telecommunications equipment and software used by small business. In their commercial dealings, businesses will increasingly deal with industry specific dispute arbitrators rather than traditional legal jurisdictions, and auditing information from transactions will be shared only between the parties necessary to resolve the dispute. Businesses will learn to share the information needed to attract investment and sales, only to those investors and customers, without jeopardizing their legal status in any major market in the maze of obscure jurisdictions they operate in. The companies that first bring these capabilities to international small business at affordable prices stand to reap large fortunes. The new paradigm of smart contracts may provide the cornerstone for building these tools.Once jurisdictional indepdence is won, small business has nearly endless opportunities to arbitrage between the relative strengths and weaknesses of various localities in various aspects of their business, much like multinationals currently take advantage of relaxed regulatory burdens and low labor costs in Third World countries now. Government intervention probably costs the global economy over $3 trillion U.S. dollars annually; thus vast markets wait to be cracked open by short-circuiting the intervention of governments in both macro and micro markets.Language and culture may remain the largest barriers. Two methods of attack:The rise of virtual nations. Multinational small businesses might speak entirely English, Japanese, Mandarin, etc. Their employees might live primarily within a single cultural milieu, dispersed thru a large number of small ethnic communities around the world, keeping close culture-specific, multimedia communications links between the communities. The worldwide Anglo, Japanese, and Mandarin business networks will be taken up by other cultures, and physically dispersed in most cases.Language-translation software. Crude, specialized versions might soon be reliable, convenient, and inexpensive enough for many kinds of small business uses, such as translating technical manuals.English is becoming increasingly the de facto language for business and technology.One interesting question is what small changes might bring about the phase change faster. Something as simple as a user-friendly voice teleconferencing system, might be enough to tip the penguins into the water. Or it might be widespread Internet access with encrypted, route-mixed TCP/IP connections and virtual whiteboards.Another interesting question in any major new trend is what will be the bottleneck pieces. With the clonable PC, Intel's CPUs and Microsoft's DOS turned out to be the only proprietary elements, with assembly, disk drives, terminals, and the like highly competitive. Wealth will flow to the businesses that provide the bottleneck tools for the coming explosion in multinational small business.The flip side of multinational small business is setting up market processes internal to the large multinational corporation.Please send your comments to nszabo (at) law (dot) gwu (dot) eduCopyright \u00a9 1997, 1999 by Nick Szabo\nPermission to redistribute without alteration hereby granted"}
{"prompt": "Shelling Out: The Origins of Money", "completion": "The precursors of money, along with language, enabled early modern humans to solve problems of cooperation that other animals cannot \u2013 including problems of reciprocal altruism, kin altruism, and the mitigation of aggression. These precursors shared with non-fiat currencies very specific characteristics \u2013 they were not merely symbolic or decorative objects.From the very start, England's 17th century colonies in America had a problem \u2013 a shortage of coins[D94][T01] The British idea was to grow large amounts of tobacco, cut timber for the ships of their global navy and merchant marine, and so forth, sending in return the supplies they felt were needed to keep the Americans working. In effect, early colonists were supposed to both work for the company and shop at the company store. The investors and the Crown much preferred this to paying in coin what the farmers might ask, letting the farmers themselves buy the supplies \u2013 and, heaven forbid, keep some of the profit as well.The colonists' solution was at hand, but it took a few years for them to recognize it. The natives had money, but it was very different from the money Europeans were used to. American Indians had been using money for millenia, and quite useful money it turned out to be for the newly arrived Europeans \u2013 despite the prejudice among some that only metal with the faces of their political leaders stamped on it constituted real money. Worse, the New England natives used neither silver nor gold. Instead, they used the most appropriate money to be found in their environment \u2013 durable skeleton parts of their prey. Specifically, they used wampum, shells of the clam venus mercenaria and its relatives, strung onto pendants.Necklace of wampum. During trade the beads were counted, removed, and re-assembled on new necklaces. Native American shell beads were also sometimes woven into belts or other mnemonic and ceremonial devices that demonstrated the wealth and commitment of a tribe to a treaty.Clams were found only at the ocean, but wampum traded far inland. Sea-shell money of a variety of types could be found in tribes across the American continent. The Iriquois managed to collect the largest wampum treasure of any tribe, without venturing anywhere near the clam's habitat.[D94] Only a handful of tribes, such as the Narragansetts, specialized in manufacturing wampum, while hundreds of other tribes, many of them hunter-gatherers, used it. Wampum pendants came in a variety of lengths, with the number of beads proportional to the length. Pendants could be cut or joined to form a pendant of length equal to the price paid.Once they got over their hangup about what constitutes real money, the colonists went wild trading for and with wampum. Clams entered the American vernacular as another way to say \"money\". The Dutch governor of New Amsterdam (now New York) took out a large loan from an English-American bank \u2013 in wampum. After a while the British authorities were forced to go along. So between 1637 and 1661, wampum became legal tender in New England. Colonists now had a liquid medium of exchange, and trade in the colonies flourished.[D94]The beginning of the end of wampum came when the British started shipping more coin to the Americas, and Europeans started applying their mass-manufacturing techniques. By 1661, British authorities had thrown in the towel, and decided it would pay in coin of the realm \u2013 which being real gold and silver, and its minting audited and branded by the Crown, had even better monetary qualities than shells. In that year wampum ceased to be legal tender in New England. In 1710 briefly became legal tender in North Carolina. It continued to be used as a medium of exchange, in some cases into the 20th century \u2013 but its value had been inflated one hundred fold by Western harvesting and manufacturing techniques, and it gradually went the route that gold and silver jewelry had gone in the West after the invention of coinage \u2013 from well crafted money to decoration. The American language of shell money became a quaint holdover \u2013 \"a hundred clams\" became \"a hundred dollars\". \"Shelling out\" came to mean paying in coins or bills, and eventually by check or credit card.[D94] Little did we know that we had touched the very origins of our species.Native American money took many forms besides shells. Furs, teeth, and a variety of other objects with properties we will discuss below were also commonly used as media of exchange. 12,000 years ago, in what is now Washington state, the Clovis people developed some marvelously long chert blades. The only problem \u2013 they break far too easily. They were useless for cutting. The flints were being made \"for the sheer enjoyment\" \u2013 or for some other purpose that had nothing to do with cutting.[G01] As we shall see, this seeming frivolity was, quite likely, actually very important to their survival.Native Americans had not, however, been the first to make artful but useless blades, nor had they invented shell money. Nor, for that matter, had Europeans, even though they, too, in ages past had widely used shells and teeth for money \u2013 not to mention cattle, gold, silver, weapons, and much else. Asians had used all that and faux axes issued by governments to boot, but they as well imported this institution. For archaeologists have found pendants of shells dating to the early Paleolithic that could easily have substituted for Native American money.Beads made from shells of the pea-sized snail Nassarius kraussianus, that lived in a nearby estuary. Blombos Cave, South Africa, 75,000 B.P.[B04]In the late 1990s archaeologist Stanley Ambrose discovered, in a rock-shelter in the Rift Valley of Kenya, a cache of beads made of ostrich eggshell, blanks, and shell fragments. They are dated using the argon-argon (40Ar/39Ar) ratio to at least 40,000 years old[A98]. Pierced animal teeth have been found in Spain also dating to this time.[W95] Perforated shells have also been recovered from early Paleolithic sites in Lebanon[G95]. Recently regular shells, prepared as strung beads and dating further back still, to 75,000 BP, have been found in Blombos Cave in South Africa.[B04]Ostrich-eggshell beads, Kenya Rift Valley, 40,000 B.P. (Courtesy Stanley Ambrose)Our modern subspecies had migrated to Europe and necklaces of shell and tooth appear there, from 40,000 B.P. onward. Shell and tooth pendants appear in Australia from 30,000 B.P. onward[M93]. In all cases, the work is highly skilled, indicating a practice that probably dates much further back in time. The origin of collecting and decorating is quite likely Africa, the original homeland of the anatomically modern subspecies. Collecting and making necklaces must have had an important selection benefit, since it was costly \u2013 manufacture of these shells took a great deal of both skill and time during an era when humans lived constantly on the brink of starvation[C94].Practically all human cultures, even those that do not engage in substantial trade or that use more modern forms of money, make and enjoy jewelry, and value certain objects more for their artistic or heirloom qualities than for their utility. We humans collect necklaces of shells and other kinds of jewelry \u2013 for the sheer enjoyment of it. For the evolutionary psychologists an explanation that humans do something for \"the sheer enjoyment of it\" is not an explanation at all \u2013 but the posing of a problem. Why do so many people find the collection and wearing of jewelry enjoyable? For the evolutionary psychologist, this question becomes \u2013 what caused this pleasure to evolve?Detail of necklace from a burial at Sungir, Russia, 28,000 BP. Interlocking and interchangeable beads. Each mammoth ivory bead may have required one to two hours of labor to manufacture.[W97]Evolutionary psychology starts with a key mathematical discovery of John Maynard Smith[D89]. Using models of populations of co-evolving genes, from the well-developed area of population genetics, Smith posited genes that can code for strategies, good or bad, used in simple strategic problems (the \"games\" of game theory). Smith proved that these genes, competing to be propagated into future generations, will evolve strategies that are Nash equilibria to the strategic problems presented by the competition. These games include the prisoner's dilemma, a prototypical problem of cooperation, and hawk/dove, a prototypical problem of aggression and its mitigation.Critical to Smith's theory is that these strategic games, while played out between phenotypes proximately, are in fact games between genes at the ultimate level \u2013 the level of competition to be propagated. The genes \u2013 not necessarily the individuals \u2013 influence behavior as if they were boundedly rational (coding for strategies as optimal as possible, within the limits of what phenotypes can express given the biological raw materials and previous evolutionary history) and \"selfish\" (to use Richard Dawkins' metaphor). Genetic influences on behavior are adaptations to the social problems presented by genes competing through their phenotypes. Smith called these evolved Nash equilibria evolutionary stable strategies.The \"epicycles\" built on top of the earlier individual selection theory, such as sexual selection and kin selection, disappear into this more general model which, in a Copernican manner, puts the genes rather than individuals at the center of the theory. Thus Dawkins' metaphorical and often misunderstood phrase, \"selfish gene\", to describe Smith's theory.Few other species cooperate on the order of even Paleolithic humans. In some cases \u2013 brood care, the colonies of ants, termites, and bees, and so forth, animals cooperate because they are kin \u2013 because they can help copies of their \"selfish genes\" found in their kin. In some highly constrained cases, there is also ongoing cooperation between non-kin, which evolutionary psychologists call reciprocal altruism. As Dawkins describes it[D89], unless an exchange of favors is simultaneous (and sometimes even then), one party or the other can cheat. And they usually do. This is the typical result of a game theorists call the Prisoner's Dilemma \u2013 if both parties cooperated, both would be better off, but if one cheats, he gains at the expense of the sucker. In a population of cheaters and suckers, the cheaters always win. However, sometimes animals come to cooperate through repeated interactions and a strategy called Tit-for-Tat: start cooperating and keep cooperating until the other party cheats \u2013 then defect yourself. This threat of retaliation motivates continued cooperation.The situations where such cooperation in fact occurs in the animal world are highly constrained. The main constraint is that such cooperation is restricted to relationships where at least one of the participants is more or less forced to be in the proximity of the other. The most common case is when parasites, and hosts whose bodies they share, evolve into symbiotes. If the interests of the parasite and the host coincide, so that both working together would be more fit than either on their own, (i.e. the parasite is also providing some benefit to the host), then, if they can play a successful game of Tit-for-Tat, they will evolve into symbiosis \u2013 a state where their interests, and especially the exit mechanism of genes from one generation to the next, coincides. They become as a single organism. However, there is much more than cooperation going on here \u2013 there is also exploitation. They occur simultaneously. The situation is analogous to an institution humans would develop \u2013 tribute \u2013 which we will analyze below.Some very special instances occur that do not involve parasite and host sharing the same body and evolving into symbiotes. Rather, they involve non-kin animals and highly constrained territory. A prominent example Dawkins describes are cleaner fish. These fish swim in and out of the mouths of their hosts, eating the bacteria there, benefiting the host fish. The host fish could cheat \u2013 it could wait for the cleaner to finish its job, then eat it. But they don't. Since they are both mobile, they are both potentially free to leave the relationship. However, the cleaner fish have evolved a very strong sense of individual territoriality, and have stripes and dances that are difficult to spoof \u2013 much like a difficult to forge brand logo. So the host fish know where to go to get cleaned \u2013 and they know that if they cheat, they will have to start over again with a new distrustful cleaner fish. The entrance costs, and thus the exit costs, of the relationship are high, so that it works out without cheating. Besides, the cleaner fish are tiny, so the benefit of eating them is not large compared to the benefit of a small number of, or even one, cleaning.One of the most pertinent examples.is the vampire bat. As their name suggests, they suck the blood of prey mammals. The interesting thing is that, on a good night, they bring back a surplus; on a bad night, nothing. Their dark business is highly unpredictable. As a result, the lucky (or skilled) bats often share blood with the less lucky (or skilled) bats in their cave. They vomit up the blood and the grateful recipient eats it.The vast majority of these recipients are kin. Out of 110 such regurgitations witnessed by the strong-stomached biologist G.S. Wilkinson, 77 were cases of mothers feeding their children, and most of the other cases also involved genetic kin. There were, however, a small number that could not be explained by kin altruism. To demonstrate these were cases of reciprocal altruism, Wilkinson combined the populations of bats from two different groups. Bats, with very rare exception, only fed old friends from their original group.[D89] Such cooperation requires building a long-term relationship, where partners interact often, recognize each other, and keep track of each other's behavior. The bat cave helps constrain the bats into long-term relationships where such bonds can form.We will see that some humans, too, chose highly risky and discontinuous prey items, and shared the resulting surpluses with non-kin. Indeed, they accomplished this to a far greater extent than the vampire bat. How they did so is the main subject of our essay. Dawkins suggests, \"money is a formal token of delayed reciprocal altruism\", but then pursues this fascinating idea no further. We will.Among small human groups, public reputation can supercede retaliation by a single individual to motivate cooperation in delayed reciprocation. However, reputational beliefs can suffer from two major kinds of errors \u2013 errors of about which person did what, and errors in appraising the value or damages caused by that act.The need to remember faces and favors is a major cognitive hurdle, but one that most humans find relatively easy to overcome. Recognizing faces is easy, but remembering that a favor took place when such memory needs to be recalled can be harder. Remembering the specifics about a favor that gave it a certain value to the favored is harder still. Avoiding disputes and misunderstandings can be improbable or prohibitively difficult.The appraisal or value measurement problem is very broad. For humans it comes into play in any system of exchange \u2013 reciprocation of favors, barter, money, credit, employment, or purchase in a market. It is important in extortion, taxation, tribute, and the setting of judicial penalties. It is even important in reciprocal altruism in animals. Consider monkeys exchanging favors \u2013 say pieces of fruit for back scratches. Mutual grooming can remove ticks and fleas that an individual can't see or reach. But just how much grooming versus how many pieces of fruit constitutes a reciprocation that both sides will consider to be \"fair\", or in other words not a defection? Is twenty minutes of backscratching worth one piece of fruit or two? And how big a piece?Even the simple case of trading blood for blood is more complicated than it seems. Just how do the bats estimate the value of blood they have received? Do they estimate the value of a favor by weight, by bulk, by taste, by its ability to satiate hunger, or other variables? Just the same, measurement complications arise even in the simple monkey exchange of \"you scratch my back and I'll scratch yours\".For the vast majority of potential exchanges, the measurement problem is intractable for animals. Even more than the easier problem of remembering faces and matching them to favors, the ability of both parties to agree with sufficient accuracy on an estimate of the value of a favor in the first place is probably the main barrier to reciprocal altruism among animals.Just the stone tool-kit of even early Paleolithic man that has survived for us to find was in some ways too complicated for brains of our size. Keeping track of favors involving them \u2013 who manufactured what quality of tool for whom, and therefore who owed whom what, and so on \u2013 would have been too difficult outside the boundaries of the clan. Add onto that, quite likely, a large variety of organic objects, ephemeral services (such as grooming), and so on that have not survived. After even a small fraction of these goods had been transferred and services performed our brains, as inflated as they are, could not possibly keep track of who owed what to whom. Today we often write these things down \u2013 but Paleolithic man had no writing. If cooperation occurred between clans and even tribes, as the archaeological record indicates in fact occured, the problem gets far worse still, since hunter-gatherer tribes were usually highly antagonistic and mutually distrustful.If clams can be money, furs can be money, gold can be money, and so on \u2013 if money is not just coins or notes issued by a government under legal tender laws, but rather can be a wide variety of objects \u2013 then just what is money anyway? And why did humans, often living on the brink of starvation, spend so much time making and enjoying those necklaces when they could have been doing more hunting and gathering? Nineteenth century economist Carl Menger[M1892] first described how money evolves naturally and inevitably from a sufficient volume of commodity barter. In modern economic terms the story is similar to Menger's.Barter requires a coincidence of interests. Alice grows some pecans and wants some apples; Bob grows apples and want some pecans. They just happen to have their orchards near each other, and Alice just happens to trust Bob enough to wait between pecan harvest time and apple harvest time. Assuming all these conditions are met, barter works pretty well. But if Alice was growing oranges, even if Bob wanted oranges as well as pecans, they'd be out of luck \u2013 oranges and apples don 't both grow well in the same climate. If Alice and Bob didn't trust each other, and couldn't find a third party to be a middleman[L94] or enforce a contract, they'd also be out of luck.Further complications could arise. Alice and Bob can't fully articulate a promise to sell pecans or apples in the future, because, among other possibilities, Alice could keep the best pecans to herself (and Bob the best apples), giving the other the dregs. Comparing the qualities as well as the quantities of two different kinds of goods is all the more difficult when the state of one of the goods is only a memory. Furthermore, neither can anticipate events such as a bad harvest. These complications greatly add to the problem of Alice and Bob deciding whether separated reciprocal altruism has truly been reciprocal. These kinds of complications increase the greater the time interval and uncertainty between the original transaction and the reciprocation.A related problem is that, as engineers would say, barter \"doesn't scale\". Barter works well at small volumes but becomes increasingly costly at large volumes, until it becomes too costly to be worth the effort. If there are n goods and services to be traded, a barter market requires n^2 prices. Five products would require twenty-five prices, which is not too bad, but 500 products would require 250,000 prices, which is far beyond what is practical for one person to keep track of. With money, there are only n prices \u2013 500 products, 500 prices. Money for this purpose can work either as a medium of exchange or simply as a standard of value \u2013 as long as the number of money prices themselves do not grow too large to memorize or change too often. (The latter problem, along with an implicit insurance \"contract\", along with the lack of a competitive market may explain why prices were often set by long-evolved custom rather than proximate negotiation).Barter requires, in other words, coincidences of supply or skills, preferences, time, and low transaction costs. Its cost increases far faster than the growth in the number of goods traded. Barter certainly works much better than no trade at all, and has been widely practiced. But it is quite limited compared to trade with money.Primitive money existed long before large scale trade networks. Money had an even earlier and more important use. Money greatly improved the workings of even small barter networks by greatly reducing the need for credit. Simultaneous coincidence of preference was far rarer than coincidences across long spans of time. With money Alice could gather for Bob during the ripening of the blueberries this month, and Bob hunt for Alice during the migration of the mammoth herds six months later, without either having to keep track of who owed who, or trust the other's memory or honesty. A mother's much greater investment in child rearing could be secured by gifts of unforgeable valuables. Money converts the division of labor problem from a prisoner's dilemma into a simple swap.The proto-money used by many hunter-gatherer tribes looks very different from modern money, now serves a different role in our modern culture, and had a function probably limited to small trade networks and other local institutions discussed below. I will thus call such money collectibles instead of money proper. The terms used in the anthropological literature for such objects are usually either \"money\", defined more broadly than just government printed notes and coins but more narrowly than we will use \"collectible\" in this essay, or the vague \"valuable\", which sometimes refers to items that are not collectibles in the sense of this essay. Reasons for choosing the term collectible over other possible names for proto-money will become apparent. Collectibles had very specific attributes. They were not merely symbolic. While the concrete objects and attributes valued as collectible could vary between cultures, they were far from arbitrary. The primary and ultimate evolutionary function of collectibles was as a medium for storing and transferring wealth. Some kinds of collectibles, such as wampum, could be quite functional as money as we moderns know it, where the economic and social conditions encouraged trade. I will occasionally use the terms \"proto-money\" and \"primitive money\" interchangeably with \"collectible\" when discussing pre-coinage media of wealth transfer.People, clans or tribes trade voluntarily because both sides believe they gain something. Their beliefs about the value may change after the trade, for example as they gain experience with the good or service. Their beliefs at the time of the trade, although to some degree inaccurate as to the value, are still usually correct as to the existence of gain. Especially in early intertribal trade, restricted to high value items, there was strong incentive for each party to get their beliefs right. Thus trade almost always did benefit both parties. Trade created value as much as the physical act of making something.Because individuals, clans, and tribes all vary in their preferences, vary in their ability to satisfy these preferences, and vary in the beliefs they have about these skills and preferences and the objects that are consequent of them, there are always gains to be made from trade. Whether the costs of making these trades \u2013 transaction costs \u2013 are low enough to make the trades worthwhile is another matter. In our civilization, far more trades are possible than were through most of human history. Nevertheless, as we shall see some kinds of trades were worth more than the transaction costs, for some cultures, probably back to the beginning of homo sapiens sapiens.Voluntary spot trades are not the only kinds of transactions that benefit from lower transaction costs. This is the key to understanding the origin and evolution of money. Family heirlooms could be used as collateral to remove the credit risk from delayed exchanges. The ability of a victorious tribe to extract tribute from the vanquished was of great benefit to the victor . The victor's ability to collect tribute benefited from some of the same kinds of transaction cost techniques as did trade. So did the plaintiff in assessment of damages for offenses against custom or law, and kin groups arranging a marriage. Kin also benefited from timely and peaceful gifts of wealth by inheritance. The major human life events that modern cultures segregate from the world of trade benefited no less than trade, and sometimes more so, from techniques that lowered transaction costs. None of these techniques was more effective, important, or early than primitive money \u2013 collectibles.When H. sapiens sapiens displaced H. sapiens neanderthalensis, population explosions followed. Evidence from the takeover in Europe, c. 40,000 to 35,000 B.P, indicates that H. sapiens sapiens increased the carrying capacity of its environment by a factor of ten over H. sapiens neanderthalensis \u2013 i.e., the population density increased tenfold[C94]. Not only that, the newcomers had spare time to create the world's first art \u2013 such as the wonderful cave paintings, a wide variety of well crafted figurines \u2013 and of course the wonderful pendants and necklaces of seashells, teeth, and eggshell.These objects were not useless decorations. Newly effective wealth transfers, made possible by collectibles as well as other probable advance of the era, language, created new cultural institutions that quite likely played the leading role in the increase of carrying capacity.The newcomers, H. sapiens sapiens, had the same size brain, weaker bones, and smaller muscles than the Neanderthals. Their hunting tools were more sophisticated, but in 35,000 B.P. they were basically the same tools \u2013 they were probably not even twice as effective, much less ten times more effective. The biggest difference may have been wealth transfers made more effective or even possible by collectibles. H. sapiens sapiens took pleasure from collecting shells, making jewelry out of them, showing them off, and trading them. H. sapiens neanderthalensis did not. The same dynamic would have been at work, tens of thousands of years earlier, on the Serengeti, when H. sapiens sapiens first appeared in that dynamic maelstrom of human evolution, Africa.We shall describe how collectibles lowered transaction costs in each kind of wealth transfer \u2013 in the voluntary free gift of inheritance, in voluntary mutual trade or marriage, and in the involuntary transfers of legal judgments and tribute.All these kinds of value transfer occurred in many cultures of human prehistory, probably from the beginning of Homo sapiens sapiens. The gains to be made, by one or both parties, from these major life event transfers of wealth, were so great that they occurred despite high transaction costs. Compared to modern money, primitive money had a very low velocity \u2013 it might be transferred only a handful of times in an average individual's lifetime. Nevertheless, a durable collectible, what today we would call an heirloom, could persist for many generations and added substantial value at each transfer \u2013 often making the transfer even possible at all. Tribes therefore often spent large amounts of time on the seemingly frivolous tasks of manufacturing and exploring for the raw materials of jewelry and other collectibles.The Kula trading network of pre-colonial Melanesia. The kula valuables doubled as \"high power\" money and mnemonic for stories and gossip. Many of the goods traded, mostly agricultural products, were available in different seasons, and so could not be traded in kind. Kula collectibles solved this double-coincidence problem as an unforgeabaly costly, wearable (for security), and circulated (literally!) money. Necklaces circulated clockwise, and armshells counter-clockwise, in a very regular pattern. By solving the double-coincidence problem an armshell or necklace would prove more valuable than its cost after only a few trades, but could circulate for decades. Gossip and stories that about prior owners of the collectibles further provided information about upstream credit and liquidity. In other Neolithic cultures collectibles, usually shells, circulated in a less regular pattern but had similar purposes and attributes.[L94]Kula armshell (mwali).Kula necklaces (bagi).For any institution in which wealth transfer is an important component, we will ask the following questions:What coincidence in time between the event, the supply for the transferred good, and demand for the transferred good was necessary? How unlikely or how high a barrier to the wealth transfer did the improbability of coincidence represent?Would the wealth transfers formed a closed loop of collectibles just based on that institution, or were other wealth transfer institutions necessary to complete circulation cycles? Taking the actual flow graph of monetary circulation seriously is critical to understanding the emergence of money. General circulation among a wide variety of trades did not and would not exist for most of human prehistory. Without completed and repeated loops collectibles would not circulate and would become worthless. A collectible, to be worth making, had to add value in enough transactions to amortize its cost.We shall first examine the kind of transfer most familiar and economically important to us today \u2013 trade.Bruce Winterhalder[W98] surveys models of how and why food is sometimes transferred between animals: tolerated theft, producing/scrounging/opportunism, risk-sensitive subsistence, by-product mutualism, delayed reciprocity, trade/exchange not in kind, and other selection models (including kin altruism). Here we focus on risk-sensitive subsistence, delayed reciprocity, and trade (exchange not in kind). We argue that substituting trade of food for collectibles for delayed reciprocity can increase food sharing. It does so by mitigating the risks of a variable food supply while avoiding the largely insurmountable problems of delayed reciprocity between bands. We will deal with kin altruism and theft (tolerated or not) in broader contexts below.Food is worth far more to starving people than to well fed ones. If the starving man can save his life by trading his most precious valuables, it may be worth to him months or even years of the labor it might take to replace that value. He will usually consider his life worth more than the sentimental value of the family heirlooms. Like fat itself, collectibles can provide insurance against food shortages. Starvation from local shortages could be staved off with at least two different kinds of trades \u2013 for the food itself, or for foraging or hunting rights.Nevertheless, the transaction costs were usually too high \u2013 bands were far more likely to fight than ever trust each other. The hungry band that couldn't find its own food usually starved. However, if the transaction costs could be lowered, by lowering the need for trust between bands, food that was worth a day's labor to one band might be worth several months' labor to the starving band.Local but extremely valuable trade was, this essay argues, made possible among many cultures by the advent of collectibles, by the time of the Upper Paleolithic. Collectibles substituted for otherwise necessary but non-existent trusting long term relationships. If there had existed a high degree of sustained interaction and trust between tribes, or individuals of different tribes, so that they gave each other unsecured credit, this would have stimulated time-lagged barter trade. However, such a high degree of trust then is highly implausible \u2013 for the reasons stated above regarding reciprocal altruism, confirmed by the empirical evidence that most hunter-gatherer tribal relations have been observed to be quite antagonistic. Hunter-gatherer bands usually broke up into small bands for most of the year and gathered into \"aggregates\", something like medieval European fairs, for a few weeks out of the year. Despite the lack of trust between bands, an important trade in staples, of the kind illustrated in the accompanying figure, almost surely occurred in European and probably elsewhere, such as with the big game hunters of America and Africa.The scenario illustrated by the accompanying figure is hypothetical, but it would be very surprising if it did not occur. While many Europeans even in the Paleolithic enjoyed wearing shell necklaces, many lived farther inland and made necklaces instead out of the teeth of their prey. Flints, axes, furs, and other collectibles were also quite likely used as media of exchange.Reindeer, bison, and other human prey migrated at different times of the year. Different tribes specialized in different prey, to the point where over 90%, and sometimes as much as 99%, of the remains from many sites during the Paleolithic in Europe come from a single species[C94]. This indicates at least seasonal specialization and perhaps full-time specialization by a tribe in a single species. To the extent they specialized, the members of a single tribe would have become experts at the behavior, migration habits, and other patterns surrounding their specific prey species, as well as the specialized tools and techniques for hunting them. Some tribes observed in recent times are known to have specialized. Some North American Indian tribes specialized respectively in hunting bison, antelope, and fishing for salmon. In northern Russia and parts of Finland, many tribes, including the Lapp even today, specialized in herding a single species of reindeer.Such specialization was probably far higher when more large prey (horse, auroch, giant elk, bison, giant sloth, mastodon, mammoth, zebra, elephant, hippopotamus, giraffe, musk oxen, etc.) roamed North America, Europe, and Africa in large herds during the Paleolithic. Large wild animals unafraid of humans no longer exist. During the Paleolithic they were either driven extinct or adapted to be afraid of humans and our projectiles. However, for most of the time span of H. sapiens sapiens these herds were abundant and easy pickings to specialist hunters. According to our theory of trade-based predation, specialization was quite likely far higher when large prey roamed North America, Europe, and Africa in large herds during the Paleolithic. Trade-based division of labor in hunting between tribes is consistent with (although not securely confirmed by) the archaeological evidence from the Paleolithic in Europe.These migrating bands, following their herds, frequently interacted, creating many opportunities for trade. American Indians preserved food by drying, making pemmican, and so on in ways that lasted for a few months but typically not a full year. Such food was commonly traded, along with skins, weapons, and collectibles. Often these trades occurred during annual trading expeditions[T01].Large herd animals migrated through a territory only two times a year, with a window most often of one or two months. Without any other source of protein besides their own prey species, these specialist tribes would have starved. The very high degree of specialization demonstrated in the archaeological record could only have occurred if there was trade.Thus, even if the time-offset barter of meat were the only kind of trade, this is quite sufficient to make the use of collectibles quite worthwhile. The necklaces, flints, and any other objects used as money circulate in a closed loop, back and forth, in roughly equal amounts so long as the value of meat traded remains roughly equal. Note that it is not enough, for the theory of collectibles put forth in this paper to be correct, that single beneficial trades were possible. We must identify closed loops of mutually beneficial trades. With closed loops the collectibles continue to circulate, amortizing their costs.As mentioned, we know from archaeological remains that many tribes specialized in a single large prey species. This specialization was at least seasonal; if there was extensive trade it could have been full-time. Becoming experts in the habits and migration patterns, and best methods of taking down, a tribe reaped enormous productive benefits. These benefits, however, would normally be unattainable, for specializing in a single species meant going without food most of the year. Division of labor between tribes paid off \u2013 and trade made it possible. The supply of food would nearly double from trade just between two complementary tribes. There were, however, rather than two prey species, often up to a dozen that migrated through most hunting territories in areas like the Serengeti and the European steppe. The amount of meat available to a species-specializing tribe would thus likely more than double with such trade among a handful of neighboring tribes. On top of this, the extra meat would be there when needed most \u2013 when the meat from a tribe's own species prey would already have been eaten, and without food the hunters would starve.Thus there were at least four gains, or sources of surplus, from a trade cycle as simple as two prey species and two non-simultaneous but offsetting trades. These gains are distinct but not necessarily independent:Making or saving collectibles to trade for food itself was not the only way to insure against bad times. Perhaps even more common, especially where large prey items were not available, was territoriality combined with trade in foraging rights. This can be observed even in some of the remnants of hunter-gatherer culture that exist today.The !Kung San of southern Africa, like all other modern remnants of hunter-gatherer cultures, live on marginal lands. They have no opportunity to be specialists but must take the meager remnants available. They may thus be rather uncharacteristic of many ancient hunter-gatherer cultures, and uncharacteristic of the original Homo sapien sapiens, which first seized the lushest lands and best game routes from Homo sapiens neanderthalensis and only much later drove the Neanderthals from marginal lands. Yet despite their severe ecological handicap, the !Kung use collectibles as items of trade.Like most hunter-gatherers, the !Kung spend most of the year in small, dispersed bands and a few weeks of the year in an aggregate with several other bands. Aggregation is like a fair with added features \u2013 trade is accomplished, alliances are cemented, partnerships strengthened, and marriages transacted. Preparation for aggregation is filled with the manufacture of tradeable items, partly utilitarian but mostly of a collectible nature. The exchange system, called by the !Kung hxaro, involves a substantial trade in beaded jewelry, including ostrich-shell pendants quite similar to those found in Africa 40,000 years ago.Pattern of hxaro exchanges and kinship relations among neighboring tribes of !Khung San hunter-gatherers.Necklaces used in the hxaro exchange.One of the main things the !Kung buy and sell with their collectibles are abstract rights to enter another band's territory and hunt or gather food there. Trade in these rights is especially brisk during local shortages which can be alleviated by foraging in a neighbor's territory[W77][W82] !Kung bands mark their territories with arrows; trespassing without having purchased the right to enter and forage is tantamount to a declaration of war. Like the inter-band food trade discussed above, the use of collectibles to purchase foraging rights constitutes an \"insurance policy against starvation\", to use the phrase of Stanley Ambrose[A98].Although anatomically modern humans surely had conscious thought, language, and some ability to plan, it would have required little conscious thought or language, and very little planning, to generate trades. It was not necessary that tribe members reasoned out the benefits of anything but a single trade. To create this institution it would have sufficed that people follow their instincts to make obtain collectibles with the characteristics outlined below. (as indicated by proxy observations that make approximate estimations for these characteristics). This is to various extents true of the other institutions we will study \u2013 they evolved, rather than being consciously designed. No one participating in the institution's rituals would have explained their function in terms of ultimate evolutionary function; rather they explained in terms of a wide variety of mythologies that served more as proximate motivators of behavior than as theories of ultimate purpose or origin.Direct evidence for trade in food has long since decayed. We may, in the future, find more direct evidence than is now available for this article, via comparison of hunting remains in one tribe with the consumption patterns in another tribe \u2013 the hardest part of this task likely being to identify the boundaries of different tribes or kin groups. According to our theory, such transfer of meat from one tribe to another was common in many parts of the world during the Paleolithic where large-scale and specialized big game hunting occurred.For now, we do have extensive indirect evidence of trade, via the movement of the collectibles themselves. Fortunately there is a good correlation between the durability desired for collectibles and the conditions under which an artifact has survived to be found by today's archaeologists. In the early Paleolithic, when all human movement was on foot, we have instances of perforated sea shells found up to 500 kilometers away from the nearest source[C94]. There was a similar long-distance movement of flint.Unfortunately, trade was severely restricted by high transaction costs in most times and places. The primary barrier was the antagonism between tribes. The predominant relationship between tribes was one of distrust on good days and outright violence on bad days. Only ties of marriage or kinship could bring tribes into a relationship with trust, albeit only occasionally and of limited scope. The poor ability to protect property, even collectibles worn on the person or buried in well-hidden caches, meant that collectibles had to amortize their costs in a few transactions.Trade was thus not the only kind of wealth transfer, and probably not the most important kind during the long human prehistory where high transaction costs prevented the development of the kinds of markets, firms, and other economic institutions we now take for granted[L94]. Underneath our great economic institutions are far more ancient institutions that also involved wealth transfer \u2013 in prehistoric times, the main kinds of wealth transfer. All of these institutions distinguished Homo sapiens sapiens from previous animals. We now turn to one of the most basic kinds of wealth transfer that we humans take for granted but other animals do not have \u2013 passing wealth onto the next generation.Coincidence in time and locale of supply and demand for trade was rare \u2013 so much so, that most kinds of trades and trade-based economic institutions we now take for granted could not exist. Even more unlikely was the triple coincidence of supply with demand with a major event for a kin group \u2013 the formation of a new family, death, crime, or victory or defeat in war. As we shall see, clans, and individuals greatly benefited from a timely transfer of wealth during these events. Such wealth transfer in turn was much less wasteful when it was the transfer of a store of wealth more durable and general than consumables or tools designed for other purposes. The demand for a durable and general store of wealth for use in these institutions was thus even more urgent than for trade itself. Furthermore, the institutions of marriage, inheritance, dispute resolution, and tribute may predate intertribal trade, and involved for most tribes a greater transfer of wealth than trade. These institutions thus more than trade served as the motivator and incubator of the earliest primitive money.In most hunter-gatherer tribes this wealth came in a form that strikes us preposterously wealthy moderns as trivial \u2013 a collection of wooden utensils, flint and bone tools and weapons, shells on strings, perhaps a hut and in colder climates some mangy furs. Sometimes it could all be carried on the person. Nevertheless, these motley assortments were wealth for a hunter-gatherer no less than real estate, stocks, and bonds are wealth for us. To the hunter-gatherer tools and sometimes warm clothes were necessary for survival. Many of the items were highly valued collectibles that insured against starvation, purchased mates, and could substitute for massacre or starvation in event of war and defeat. The ability to transfer the capital of survival to one's descendants was another advantage Homo sapiens sapiens had over previous animals. Furthermore, the skilled tribesman or clan could accumulate a surplus of wealth from the occasional, but cumulative over a lifetime, trade of surplus consumables for durable wealth, especially collectibles. A temporary fitness advantage could be translated into a more durable fitness advantage for one's descendants.Another form of wealth, hidden from the archaeologist, were titles to offices. Such social positions were more valuable than the tangible forms of wealth in many hunter-gatherer cultures. Examples of such positions included clan leaders, war party leaders, hunting party leaders, membership in a particular long-term trading partnership (with a particular person in a neighboring clan or tribe), midwives, and religious healers. Often collectibles not only embodied wealth, but also served as a mnemonic, representing the title to a clan position of responsibility and privilege. Upon death, to maintain order, the heirs to such positions had to be quickly and clearly determined. Delays could spawn vicious conflicts. Thus, a common event was the mortuary feast, in which the deceased was feted while both his tangible and intangible forms of wealth were distributed to descendants, as determined by custom, clan decision-makers, or the will of the deceased.Other kinds of free gifts were quite rare in pre-modern cultures, as Marcel Mauss[M50] and other anthropologists have pointed out. Seemingly free gifts in fact implicitly invoked an obligation in the recipient. Before contract law, this implicit obligation of the \"gift\", along with community dishonor and punishments ensuing if the implicit obligation was not met, was perhaps the most common motivator of reciprocation in delayed exchange, and is still common in the variety of informal favors we do for each other. Inheritance and other forms of kin altruism were the only widely practiced forms of what we moderns would call gift proper, namely a gift that imposed no obligation on the recipient.Early Western traders and missionaries, who often saw natives as childish primitives, sometimes called their tribute payments \"gifts\" and trades \"gift exchanges\", as if they bore more resemblance to the Christmas and birthday present exchanges of Western children than to the contractual and tax obligations of adults. Partly this may have reflected prejudice, and partly the fact that in the West by that time obligations were usually formalized in writing which the natives lacked. Westerners thus usually translated the rich variety of words natives had for their exchange institutions, rights, and obligations as \"gift\". Seventeenth century French settlers in America were thinly scattered among much larger populations of Indian tribes, and often found themselves paying tribute to these tribes. Calling these payments \"gifts\" was a way for them to save face with other Europeans who faced no such necessity and found it cowardly.Mauss and modern anthropologists have unfortunately kept this terminology. The uncivilized human is still like a child, but now innocent like a child, a creature of moral superiority who would not stoop to our kind of base, cold-blooded economic transactions. However in the West, especially in the official terminology used for our laws covering transactions, a \"gift\" refers to a transfer that imposes no obligation. When coming across anthropological discussions of \"gift exchange\" these caveats should be kept in mind \u2013 modern anthropologists are not at all referring to the free or informal gifts we commonly refer to in our modern use on the term \"gift\". They are rather referring to any of a wide variety of often quite sophisticated systems of rights and obligations involved in wealth transfers. The only major transactions in prehistoric cultures similar to our modern gift, in that it was neither itself a widely recognized obligation nor imposed any obligation on the recipient, were parents or maternal kin caring for their children and inheritance. (An exception was that inheriting title to a position imposed the responsibilities of the position on the heir as well as its privileges).Inheritance of some heirlooms might proceed for several generations uninterrupted, but it did not by itself form a closed loop of collectibles transfers. Heirlooms were only valuable if they eventually got used for something else. They often were used in marriage transactions between clans that could form closed loop cycles of collectibles.An early and important example of a small closed loop trade network made possible by collectibles involves the much higher investment humans make in raising offspring than our primate relatives, and the related human institution of marriage. Combining arrangements of long-term matches for mating and child-raising, negotiated between clans, with wealth transfer, marriage is a human universal and probably dates back to the first Homo sapiens sapiens.Parental investment is a long-term and almost one-shot affair \u2013 there is no time for repeated interactions. Divorce from a negligent father or unfaithful wife usually represented several years of time wasted, in genetic fitness terms, by the jilted party. Fidelity and commitment to the children were primarily enforced by in-laws \u2013 the clan. The marriage was the contract between clans that usually included such promises of fidelity and commitment as well as wealth transfer.The contributions a man and a woman will bring to a marriage are seldom equal. This was even more true in an era when mate choice was largely determined by clans and the population from which clan leaders could choose was quite small. Most commonly, the woman was considered more valuable and the groom's clan paid a bride price to the brides clan. Quite rare in comparison was dowry, a payment by the bride's clan to the new couple. Mostly this was practiced by upper classes of monogamous but highly unequal societies in medieval Europe and India, and was ultimately motivated by the far greater reproductive potential of upper class sons than upper class daughters in those societies. Since literature was mostly written about upper classes, dowry often plays a role in European traditional stories. This does not reflect its actual frequency across human cultures \u2013 it was quite rare.Marriages between clans could form a closed cycle of collectibles. Indeed, two clans exchanging partners would be sufficient to maintain a closed loop, as long as brides tended to alternate. If one clan was wealthier in collectibles from some other kind of transfer, it could marry more of its sons to better brides (in monogamous societies) or a greater number of brides (in polygamous societies). In a loop involving only marriages, primitive money would simply serve to replace the need for memory and trust between clans over a long period of delay between unbalanced transfers of reproductive resources.Like inheritance, lawsuit, and tribute, marriage requires a triple coincidence of the event, in this case the marriage, with supply and demand. Without a transferable and durable store of value, the current ability of a groom's clan to supply the current desires of the bride's clan, to a large enough degree to make up the value mismatch between bride and groom, while also satisfying the political and romantic constraints of the match, were quite unlikely to be well satisfied. One solution is imposing an ongoing service obligation from the groom or his clan to the bride's clan. This occurs in about 15% of known cultures[DW88]. In a much larger number, 67%, the groom or groom's clan pays the brides clan a substantial amount of wealth. Some of this bride price is paid in immediate consumables, in plants to be gathered harvested and animals slaughtered for the marriage feast. In herding or agricultural societies much of the bride price is paid in livestock, a long lasting form of wealth. The balance, and usually the most valuable portion of the bride-price in cultures without livestock, is paid with what are usually the most valuable family heirlooms \u2013 the rarest, costliest, and most durable pendants, rings, and so on. The Western practice of the groom giving the bride a ring \u2013 and a suitor giving a maiden other kinds of jewelry \u2013 was once a substantial transfer of wealth and was common in many other cultures. In about 23% of cultures, mostly modern ones, there is no substantial wealth exchange. In about 6% of cultures there is mutual exchange of substantial wealth between bride and groom clans. In only about 2% of cultures does the bride's clan pay the new couple a dowry.[DW88]Unfortunately, some wealth transfers were a far cry from the altruism of the inheritance gift or the joy of marriage. Quite the opposite, in the case of tribute.Death rates from violence in chimp troops and hunter-gatherer human cultures alike are far higher than in modern civilizations. This probably dates at least as far back as our common ancestor with the chimpanzees \u2013 chimp troops, as well, are constantly fighting.Warfare involved, among other things, killing, maiming, torture, kidnapping, rape, and the extortion of tribute in exchange for avoiding such fates. When two neighboring tribes were not at war, one was usually paying tribute to the other. Tribute could also serve to bind alliances, achieving economies of scale in warfare. Mostly, it was a form of exploitation more lucrative to the victor than further violence against the defeated.Victory in war was sometimes followed by an immediate payment from the losers to the winners. Often this just took the form of looting by the enthusiastic victors, while the losers desperately hid their collectibles. More often, tribute was demanded on a regular basis. In this case, the triple coincidence could and sometimes was avoided by a sophisticated schedule of payments in kind that matched the losing tribe's ability to supply a good or service with the victor's demand for it. However, even with this solution primitive money could provide a better way \u2013 a common medium of value that greatly simplified the terms of payment \u2013 very important in an era when terms of the treaty could not be recorded but had to be memorized. In some cases, as with the wampum as used in the Iriquois Confederacy, the collectibles doubled as a primitive mnemonic device that, while not verbatim, could be used as an aid to recall the terms of the treaty. For the winners, collectibles provided a way to collect tribute at closer to the Laffer optimum. For the losers, collectibles buried in caches provided a way to \"under-report\", leading the victors to believe the losers were less wealthy and thus demand less than they might. Caches of collectibles also provided insurance against overzealous tribute collectors. Much of the wealth in primitive societies escaped the notice of the missionaries and anthropologists due to its highly secretive nature. Only archeology can reveal the existence of this hidden wealth.Hiding and other strategies presented a problem that tribute collectors share with modern tax collectors \u2013 how to estimate the amount of wealth they can extract. Value measurement is a thorny problem in many kinds of transactions, but never more so than in the antagonistic collection of tax or tribute. In making these very difficult and nonintuitive trade-offs, and then executing them in a series of queries, audits, and collection actions, tribute collectors efficiently optimized their revenue, even if the results seemed quite wasteful to the tribute payer.Imagine a tribe collecting tribute from several neighbor tribes it previously defeated in war. It must estimate how much it can extract from each tribe. Bad estimates leave the wealth of some tribes understated, while forcing others to pay tribute based on estimates of wealth they don't actually have. The result: the tribes that are hurt tend to shrink. The tribes that benefit pay less tribute than could be extracted. In both cases, less revenue is generated for the victors than they might be able to get with better rules. This is an application of the Laffer curve to the fortunes of specific tribes. On this curve, applied to income taxes by the brilliant economist Arthur Laffer, as the tax rate increases, the amount of revenue increases, but at an increasingly slower rate than the tax rate, due to increased avoidance, evasion, and most of all disincentive to engage in the taxed activity. At a certain rate due to these reasons tax revenues are optimized. Hiking the tax rate beyond the Laffer optimum results in lower rather than higher revenues for the government. Ironically, the Laffer curve was used by advocates for lower taxes, even though it is a theory of tax collection optimum to government revenue, not a theory of tax collection optimal to social welfare or individual preference satisfaction.On a larger scale, the Laffer curve may be the most important economic law of political history. Charles Adams[A90] uses it to explain the rise and fall of empires. The most successful governments have been implicitly guided by their own incentives \u2013 both their short-term desire for revenue and their long-term success against other governments \u2013 to optimize their revenues according to the Laffer Curve. Governments that overburdened their taxpayers, such as the Soviet Union and later Roman Empire, ended up on the dust-heap of history, while governments that collected below the optimum were often conquered by their better-funded neighbors. Democratic governments may maintain high tax revenues over historical time by more peaceful means than conquering underfunded states. They are the first states in history with tax revenues so high relative to external threats that they have the luxury of spending most of the money in non-military areas. Their tax regimes have operated closer to the Laffer optimum than those of most previous kinds of governments. (Alternatively, this luxury may be made possible by the efficiency of nuclear weapons in deterring attack rather than the increased incentives of democracies to optimize to tax collection). When we apply the Laffer curve to examining the relative impact of treaty tributterms on various tribes, we conclude that the desire to optimize revenues causes victors to want to accurately measure the income and wealth of the vanquished. Measuring value is crucial to determining the tributaries' incentives to avoid or evade the tribute by hiding wealth, fight, or flight. For their part, tributaries can and do spoof these measurements in various ways, for example by burying collectibles in caches. Tribute collection involves a measurement game with unaligned incentives.With collectibles, one can demand tribute at strategically optimal times instead of when items can be supplied by the tributary or is in demand by the victor. The victors can then choose when they will in the future consume the wealth, rather than having to consume it at the time the tribute is extracted. Much later, well into the dawn of history, in 700 BC, though trade was widespread, money still took the form of collectibles \u2013 made out of more precious metals, but in their basic characteristics, such as lack of uniform value, similar to most of the proto-money used since the dawn of Homo sapiens sapiens. This was changed by a Greek-speaking culture in Anatolia (modern Turkey), the Lydians. Specifically, the kings of Lydia were the first major issuers of coins in the archaeological and historical record.From that day to this, government mints with self-granted monopolies, rather than private mints, have been the main issuers of coin. Why wasn't minting dominated by private interests, such as private bankers, which did exist at the time in these semi-market economies? The main explanation for government dominance of coin minting has been that only governments could enforce anti-counterfeiting measures. However, they could have enforced such measures in protection of competing private mints, just as they enforce trademarks today and at that time as well.It was far easier to estimate the value of a coin than that of a collectible \u2013 especially at low transaction values. Far more trades could be made with money instead of barter; indeed many kinds of low-value trades became possible for the first time as the small gains from trade for the first time exceeded transaction costs. Collectibles were low velocity money, involved in a small number of high value transactions. Coins were high velocity money, facilitating a large number of low value trades.Given what we have seen about the benefits of proto-money to tribute and tax collectors, as well as the critical nature of the value measurement problem in optimally coercing such payments, it is not surprising that tax collectors, specifically the kings of Lydia, were the first major issuers of coinage. The king, deriving his revenue from tax collection, had a strong incentive to measure to value of wealth held and exchanged by his subjects more accurately. That the exchange also benefited from cheaper measurement by traders of the medium of exchange, creating something closer to efficient markets, and allowing individuals to enter into the marketplace on a larger scale for the first time, was for the king a fortuitous side effect. The greater wealth flowing through markets, now available to be taxed, boosted the king's revenues even beyond the normal Laffer curve effect of reducing mis-measurement between given tax sources.This combination of more efficient tax collection with more efficient markets meant a vast increase in overall tax revenues. These tax collectors almost literally hit a gold mine, and the wealth of Lydian kings Midas, Croesus, and Giges is famous to this day.A few centuries later, the Greek king Alexander the Great conquered Egypt, Persia and much of India, funding his spectacular conquest by plundering Egyptian and Persian temples, filled with assemblages of low-velocity collectibles, and melting them down into high-velocity coins. More efficient and encompassing market economies as well as more efficient tax collection sprung up in his wake.Tribute payments did not form by themselves a closed loop of collectibles. These were only valuable if they ultimately could be used by the victors for something else, such as marriage, trade, or collateral. However, victors could coerce the vanquished into manufacturing for obtaining collectibles, even if it did not serve the vanquished's voluntary interests.Ancient hunter-gatherers did not have our modern tort or criminal law, but they did have an analogous means of settling disputes, often judged by clan or tribal leaders or vote, that covered what modern law calls crimes and torts. Settling disputes through punishments or payments sanction by the clans of the disputing parties substituted for cycles of revenge or vendetta wars. Most pre-modern cultures, ranging from the Iriquois in America to the pre-Christian Germanic peoples, decided that payment was better than punishment. Prices (e.g. the Germanic \"weregeld\" and Iriquois blood money) were assigned to all actionable offenses, ranging from petty theft to rape to murder. Where money was available, the payment took the form of money. Livestock was used in herding cultures. Otherwise, payment of collectibles were the most commonly used remedy.The payment of remedies for damages in a lawsuit or similar complaint led to the same kind of problem of triple coincidence of event, supply, and demand as occurred in inheritance, marriage, and tribute. The judgment of the case had to coincide with the ability of the plaintiff to pay the damages as well as the opportunity and desire of the defendant to benefit from them. If the remedy was a consumable the plaintiff already had plenty of, the remedy still served as a punishment but would not likely satisfy the defendant \u2013 and thus would not curb the cycle of violence. Thus, we here again the value added by collectibles \u2013 in this case, in making possible the remedy to resolve a dispute or terminate a cycle of revenge.Dispute remedies would not form a closed loop if the payments served to entirely eliminate vendettas. However, if the payments did not completely dampen the vendetta, the payments could form a cycle following the cycle of revenge. For this reason, it is possible that the institution reached an equilibrium when it had reduced but not eliminated cycles of revenge until the advent of more densely connected trading networks.Since humans evolved in small, largely self-sufficient, and mutually antagonistic tribes, the use of collectibles to reduce the need for favor-tracking, and to make possible the other human institutions of wealth transfer we have explored, was far more important than the scale problems of barter for most of the timespan of our species. Indeed, collectibles provided a fundamental improvement to the workings of reciprocal altruism, allowing humans to cooperate in ways unavailable to other species. For them, reciprocal altruism is severely limited by unreliable memory. Some other species have large brains, build their own homes, or make and use tools. No other species has produced such an improvement to the workings of reciprocal altruism. The evidence indicates this new development had matured by 40,000 B.P.Menger called this first money an \"intermediate commodity\" \u2013 what this paper calls collectibles. An artifact useful for other things, such as cutting, could also be used as a collectible. However, once institutions involving wealth transfer became valuable, collectibles would be manufactured just for their collectible properties. What are these properties? For a particular commodity to be chosen as a valuable collectible, it would have had, relative to products less valuable as collectibles, at least the following desirable qualities:Humans the world over are strongly motivated to collect items that better satisfy these properties. Some of this motivation probably includes genetically evolved instincts. Such objects are collected for the sheer pleasure of collecting them (not for any particularly good explicit and proximate reasons), and such pleasure is nearly universal across human cultures. One of the immediate proximate motivations is decoration. According to Dr. Mary C. Stiner, an archaeologist at the University of Arizona, \"Ornamentation is universal among all modern human foragers.\"[W02] For an evolutionary psychologist, such a behavior that has a good ultimate explanation, in terms of natural selection, but has no proximate rationale other than pleasure, is a prime candidate to be a genetically evolved pleasure that motivates the behavior. Such is, if the reasoning in this essay is correct, the human instinct to collect rare items, art, and especially jewelry.Point (2) requires some further explanation. At first, the production of a commodity simply because it is costly seems quite wasteful. However, the unforgeably costly commodity repeatedly adds value by enabling beneficial wealth transfers. More of the cost is recouped every time a transaction is made possible or made less expensive. The cost, initially a complete waste, is amortized over many transactions. The monetary value of precious metals is based on this principle. It also applies to collectibles, which are more prized the rarer they are and the less forgeable this rarity is. It also applies where provably skilled or unique human labor is added to the product, as with art.We have never discovered or made a product that does really well on all three scores. Art and collectibles (in the sense that word is used in modern culture, rather in the technical sense it is used in this paper) optimize (2), but not (1) or (3). Common beads satisfy (1) but not (2) or (3). Jewelry, made at first out of the most beautiful and less common shells but eventually in many cultures out of precious metals, comes closer to satisfying all three properties. It is no coincidence that precious metal jewelry usually came in thin forms such as chains and rings, allowing for inexpensive assaying at randomly chosen locations. Coins were a further improvement \u2013 substituting small standard weights and trademarks for assays greatly reduced the costs of small transactions using precious metals. Money proper was just a further step in the evolution of collectibles.The kind of mobile art also made by Paleolithic man, (small figurines and the like) also matches these characteristics well. Indeed, Paleolithic man made very few objects that were not either utilitarian, or shared characteristics (1)-(3).There are many puzzling instances of useless or at least unused flints with homo sapiens. We have mentioned the unusable flints of the Clovis people. Culiffe[C94] discusses a European Mesolithic era find of hundreds of flints, carefully crafted, but which micrograph analysis reveals were never used for cutting.Flints were quite likely the first collectibles, preceding special-purpose collectibles like jewelry. Indeed, the first flint collectibles would have been made for their cutting utility. Their added value as a medium of wealth transfer was a fortuitous side effect that enabled the institutions described in this article to blossom. These institutions, in turn, would have motivated the manufacture of special-purpose collectibles, at first flints that need have no actual use as cutting tools, then the wide variety of other kinds of collectibles that were developed by Homo sapiens sapiens.Shell money from Sumer, c. 3,000 B.C.During the Neolithic era, in many parts of the Middle East and Europe, some kinds of jewelry became more standardized \u2013 to the point where standard sizes and assayability were often valued over beauty. In commercial areas the quantity of this jewelry sometimes greatly exceeded that of traditional jewelry in hoards. This is an intermediate step between jewelry and coins, when some collectibles increasingly took a fungible form. Around 700 B.C., the Lydian kings started issuing coins, as described above. The unforgeable costliness of standard weights of precious metals could now be \"assayed\" in a marketplace, by wage earners, or by tax collectors via trademark, i.e. trust in the mint's brand, instead of chopping coiled wire at a randomly selected spot.It is no coincidence that the attributes of collectibles are shared with precious metals, coins, and the reserve commodities that have backed most non-fiat currencies. Money proper implemented these properties a purer form than the collectibles used during almost all of human prehistory.Silver ring and coil money from Sumer, c. 2,500 B.C. Note the standard size of cross-sections. Many of the pieces had a standard weight, ranging from one-twelfth of a shekel to sixty shekels. To assay a ring or coil, it could be weighed and cut at random locations. (Courtesy Oriental Institute, University of Chicago)A novelty of the 20th century was the issue of fiat currencies by governments. (\"Fiat\" means not backed by any reserve commodity, as the gold- and silver-based currencies of previous centuries were). While generally excellent as a media of exchange, fiat currencies have proven to be very poor stores of value. Inflation has destroyed many a \"nest egg\". It is no coincidence that markets in rare objects and unique artwork \u2013 usually sharing the attributes of collectibles described above \u2013 have enjoyed a renaissance during the last century. One of our most advanced high-tech marketplaces, EBay, is centered around these objects of primordial economic qualities. The collectibles market is larger than ever, even if the fraction of our wealth invested in them is smaller than when they were crucial to evolutionary success. Collectibles both satisfy our instinctive urges and remain useful in their ancient role as a secure store of value.Many kinds of wealth transfers \u2013 one-way and mutual, voluntary and coerced \u2013 face transaction costs. In voluntary trades both parties gain; a truly free gift is usually an act of kin altruism. These transactions create value for one or both parties as much as the physical act of making something. Tribute benefits the victor and a judgment of damages can prevent further violence as well as benefiting the victim. Inheritance made humans the first animals to pass wealth to their next generation kin. These heirlooms could in turn be used as collateral or payment in trade for goods, for food to stave off starvation, or to pay a marriage bride price. Whether the costs of making these transfers \u2013 transaction costs \u2013 are low enough to make the transfers worthwhile is another matter. Collectibles were crucial in making these kinds of transactions possible for the first time.Collectibles augmented our large brains and language as solutions to the Prisoner's Dilemma that keeps almost all animals from cooperating via delayed reciprocation with nonkin. Reputational beliefs can suffer from two major kinds of errors \u2013 errors of about which person did what, and errors in appraising the value or damages caused by that act. Within clans (the small and immediately local kin group, or extended family, which formed a subset of a tribe), our large brains could minimize these errors, so that public reputation and coercive sanctions superseded the limited motivation provided by the counterparty's ability to cooperate or defect in the future as the main enforcer of delayed reciprocation. In both Homo sapiens neanderthalensis and Homo sapiens sapiens, with the same large brain size, it is quite likely that every local clan member kept track of everybody other local clan member's favors. The use of collectibles for trade within the small local kin group may have been minimal. Between clans within a tribe both favor tracking and collectibles were used. Between tribes, collectibles entirely replaced reputation as the enforcer of reciprocation, although violence still played a major role in enforcing rights as well as being a high transaction cost that prevented most kinds of trade.When costliness becomes forgeable \u2013 Glass trade beads, manufactured in Venice in the 16th or 17th century, excavated from Mali, Africa. Such beads were very popular wherever European colonialists encountered Neolithic or hunter-gatherer cultures.To be useful as a general-purpose store of wealth and means of wealth transfer, a collectible had to be embedded in at least one institution with a closed-loop cycle, so that the cost of discovering and/or manufacturing the object was amortized over multiple transactions. Furthermore, a collectible was not just any kind of beautiful decorative object. It had to have certain functional properties, such as the security of being wearable on the person, compactness for hiding or burial, and unforgeable costliness. That costliness must have been verifiable by the recipient of the transfer \u2013 using many of the same skills that collectors use to appraise collectibles today.The theories presented in this paper can be tested by looking for these characteristics (or the lack of them) in the \"valuables\" often exchanged in these cultures, by examining the economic gains from the cycles through which these valuables move, and by observing preferences for objects with these characteristics in a wide variety of cultures (including modern ones).With its unprecedented technology of cooperation, humans had become the most fearsome predator ever seen on the planet. They adapted to a shifting climate, while dozens of their large herd prey were driven, by hunting and climate change in America, Europe, and Asia, to extinction. Today, most large animals on the planet are afraid of projectiles \u2013 an adaption to only one species of predator [R97]. Cultures based more on gathering than hunting also greatly benefitted. A population explosion followed \u2013 Homo sapiens sapiens was able to populate more parts of the planet and at a density over ten times that of Homo sapiens neanderthalensis [C94], despite weaker bones and no increase in brain size. Much of this increase may be attributed to the social institutions made possible by effective wealth transfer and language \u2013 trade, marriage, inheritance, tribute, collateral, and the ability to assess damages to dampen cycles of vengeance.Primitive money was not modern money as we know it. It took on some of the function modern money now performs, but its form was that of heirlooms, jewelry, and other collectibles. The use of these is so ancient that the desires to explore, collect, make, display, appraise, carefully store, and trade collectibles are human universals \u2013 to some extent instincts. This constellation of human desires might be called the collecting instinct. Searching for the raw materials, such as shells and teeth, and manufacturing of collectibles took up a considerable portion of many ancient humans' time, just as many modern humans expend substantial resources on these activities as hobbies. The results for our ancient forebears were the first secure forms of embodied value very different from concrete utility \u2013 and the forerunner of today's money.[A90] Adams, Charles, For Good and Evil: The Impact of Taxes on Civilization \u21a9[A98] Tim Appenzeller, \"Art: Evolution or Revolution?\", Science 282(Nov 20, 1998), p. 1452. See also the home page of Stanley Ambrose \u21a9 \u21a9[B04] The Blombos Cave Project \u21a9 \u21a9[C94] Culiffe, Barry, ed., The Oxford Illustrated History of Prehistoric Europe, Oxford University Press 1994. \u21a9 \u21a9 \u21a9 \u21a9 \u21a9[D89] Dawkins, Richard, The Selfish Gene, Oxford University Press 1989. \u21a9 \u21a9 \u21a9[D94] Davies, Glyn, A History of Money, From Ancient Times to the Present Day, University of Wales Press 1994. \u21a9 \u21a9 \u21a9 \u21a9[DW88] Daly, Martin and Wilson, Margo, Homicide, New York: Aldine (1998). \u21a9 \u21a9[G95] Gilead, I. 1995. \"The Foragers of the Upper Paleolithic Period,\" in Archaeology and Society in the Holy Land. Ed. by T. E. Levy. New York, Facts on File. \u21a9[G01] [ref: http://www-geology.ucdavis.edu/~GEL115/115CH1.html] \u21a9[Gr01] Graeber, David, Towards an Anthropological Theory of Value, Palgrave 2001.[I98] Ifrah, Georges, The Universal History of Numbers, John Wiley & Sons 1998, pg. 73.[K99] Kohn, M. and Mithen, S. \"Handaxes: Products of sexual selection?\", Antiquity, 73, 518-526.[K99] Kohn, M. and Mithen, S. \"Handaxes: Products of sexual selection?\", Antiquity, 73, 518-526.[L94] Landa, Janet, Trust, Ethnicity, and Identity: Beyond the New Institutional Economics of Ethnic Trading Networks, Contract Law, and Gift-Exchange, The University of Michigan Press, second edition, 1998. \u21a9 \u21a9 \u21a9[M1892] Menger, Carl, \"On the Origins of Money\" Economic Journal, volume 2,(1892) p. 239-55. translated by C.A. Foley, at http://www.socsci.mcmaster.ca/~econ/ugcm/3ll3/menger/money.txt \u21a9[M50] Mauss, Marcel, The Gift, 1950, English translation by W.D. Halls, W.W. Norton 1990. \u21a9[M93] (Morse 1993) via http://www.wac.uct.ac.za/wac4/symposia/papers/s095wht1.pdf \u21a9[R96] Riddley, Matt, The Origins of Virtue, Viking 1996.[T01] Taylor, Alan, American Colonies \u2013 The Settling of North America, Penguin 2001. \u21a9 \u21a9[P89] Plattner, Stuart, Economic Anthropology, Stanford University Press 1989.[W77] Wiessner, P. 1977. Hxaro: a regional system at reciprocity for reducing risk among the !Kung San. Unpublished PhD thesis: University of Michigan. \u21a9[W82] Wiessner, P. 1982. Risk, reciprocity and social influences on !Kung San economies. In: Leacock, H. R. & Lee, R.B. (eds) Politics and history in band societies: 61-84. London: Cambridge University Press.[W95] White, Randall, \"Ivory Personal Ornaments of Aurignacian Age: Technological, Social and Symbolic Perspectives\", Institute For Ice Age Studies, http://www.insticeagestudies.com/library/Ivory/Ivorypersonal.html \u21a9[W97] White, Randall, \"From Materials To Meaning\", Institute For Ice Age Studies, http://www.insticeagestudies.com/library/materialstomeaning/index.html \u21a9[W98] Winterhalder, Bruce, \"Intra-Group Resource Transfers: Comparative Evidence, Models, and Implications for Human Evolution\", http://www.unc.edu/depts/ecology/winterweb/intra_group.html \u21a9[W02] Wilford, John, \"Debate is Fueled on When Humans Became Human\", New York Times, February 26th, 2002  \u21a9My thanks to Jerome Barkow, Andrew Odlyzko, Bruce Smith, K. Eric Drexler, Markus Krummenacker, Mark Wiley, Norm Hardy, and others for their insightful comments.Please send your comments to nszabo (at) law (dot) gwu (dot) eduCopyright \u00a9 2002, 2005 by Nick Szabo\nPermission to redistribute without alteration hereby grantedEditor's note: Some links may be broken."}
{"prompt": "The Ricardian Contract", "completion": "Describing digital value for payment systems is not a trivial task. Simplistic methods of using numbers or country codes to describe currencies, and ticker tape symbols to issue bonds, shares, and other financial instruments soon run into shortcomings in their ability to handle dynamic and divergent demands. The seemingly arbitrary variations in the meanings of different instruments are best captured as contracts between issuers and holders. Thus, the digital issuance of instruments can be viewed as the issuance of contracts.This paper proposes that the contract is the issue. A document form is described that encompasses the inherent contractual nature of the financial instrument yet copes with the requirements of being an integral part of a payment system.Little work has been done on classification and description of value in the field of financial cryptography. This paper presents the Ricardian Contract, a method to identify and describe issues of financial instruments as contracts[1]. It was originally developed by Ian Grigg and Gary Howland as part of the Ricardo payment system.The original application was a bond trading system[2]. For trading, a basic component is a transfer or payment system which receives and acts on transfer instructions to move instruments (cash, bonds) from one account to another. Each instruction therefore must identify the instrument.A means was required to capture, identify, and describe the traded instruments. There are thousands of bonds, and potentially millions of other instruments that could be issued and traded, and each has unique characteristics that are not amenable to compression into databases. To such a system, cash is no different to bonds, and requires the same description.When someone issues a currency (or bond or share) over the Internet, what is it? What does the recipient have?Few systems for issuance of value (payment systems) treat these questions adequately. They generally refer to existing external units of currency and tidy up loose edges in a user agreement. For example, Paypal, an issuer of dollars, relies on the familiarity of the US dollar to define much of its service offering. Gold issuers lean more heavily on their user agreements as the metal unit is not so familiar.For trading, it is not sufficient to refer to well-known familiar references, as each instrument is different in finicky ways and these differences matter to traders. Even with currencies, however, the user has difficulty in determining the security and safety of one dollar with respect to another.Classification by numbers or symbols is a starting point. Almost all systems of digital issuance identify their basic issue by allocating numbers or letters as currencies (for example, 840, \"USD\", \"AUG\" [3]). These systems runs into trouble quickly.An issuer with many currencies or many issuers with the same nominal currency raises difficult questions. Can an issuer have two or more dollar units? For example, within ISO3166-1, there are three different US dollars: 840/USD (cash), 998/USS (same day), and 997/USN (next day). Similarly, how does one Digital Gold Currency (\"DGC\") differentiate his gold over that of another issuer, when all are known as \"AUG\"?As bonds are, at their essence, contracts between issuers and users, our problem reduces to one of issuing contracts. Whereas other issues have contracts, our issues are contracts.Our innovation is to express an issued instrument as a contract, and to link that contract into every aspect of the payment system. By this process, a document of some broad utility (readable by user and program) is drafted and digitally signed by the issuer of the instrument. This document, the Ricardian Contract, forms the basis for understanding an issue and every transaction within that issue.By extension, all issues of value, such as currencies, shares, derivatives, loyalty systems and vouchers, can benefit from this approach.This paper is structured as follows. In Section 2, we discuss conventional approaches to identifying and describing issuance, and explore questions and doubts surrounding these approaches. Then, in Section 3, a design to express issuance as a contract is presented. Finally, in Section 4, concluding remarks are added.Consider the case of the pioneering digital cash scheme, eCash, as originally fielded by DigiCash BV. The first valuable currency, issued by Mark Twain Bank of the USA, was identified with the number 4. Lore has it that the early system allocated a small sequential number to each currency. Test systems had already acquired 0,1,2,3 and thus 4 was the next. DigiCash's marketing assumptions then changed to assume one issue per country. In time, this scheme was adjusted to issue currencies numbered after international dialling codes (e.g., 49 for Germany, 61 for Australia). The shortfalls of this scheme became apparent, so a new design was created [4]. One 32 bit number to describe the issue was used, on the pragmatic assumption that this would be large enough to cover foreseeable eventualities.Yet the strains of one issuer, one currency were obvious almost immediately. A more advanced scheme could use a tuple of (issuer, currency) to describe a system whereby each issuer is empowered in some sense to issue multiple competing currencies[5]. It is easy to generalise this system by adding additional elements to the tuple: (issuer, type, identifier) tuple[6]. For example, a zero coupon bond issued by the Joint Universal and Nationwide Keiretsu that pays out in January of 2100 might have a tuple of (JUNK, zero, Jan_2100).Numbers as a space for identifying digital instruments are limiting, and having tuples as an extension is not really an answer.Firstly, what do they describe? In the case of electronic cash systems, they can describe currencies and issuers. Is it one or both, and how do we generalise to other aspects? Secondly, what surety do we have that what is described is accurate? Whilst a lot can be achieved by simply relying on the reputation of the issuer, financial insiders know that the real value is expressed in the detail and the reliability of the claim. Thirdly, how are the numbers derived? Is a central registry required, or can any issuer of digital value acquire a number as per local requirements? Finally, is there a limit to the space? Integer numbers as expressed in packets are generally limited to some quantity of bits, such as 32. For practical software engineering, there need to be limits, but do these limits need to limit the business possibilities?Any successful system will be used in ways that make it appear to be broken. As software engineers, we need to present our inventions with the humility of toolmakers for future generations of builders, not as bureaucrats planning the zoning of the digital commerce space.What happens when we have gone through the early adopters, dominated the moms and pops, and competition is fiercely turning onto our elderly retired set? Imagine mints in the pockets of billions of idle game-playing senior citizens. Or, imagine a world with an issuer of digital loyalty points on every parking meter, or where students must pay for tuition with shares of future earnings. Already we have seen popular musicians selling bonds backed by their music[7], and proposals for software bug fixes financed by securitized issues to anonymous users[8].Consider the zero coupon bond, an instrument that pays a face value of a currency on a given date. The zero is perhaps the simplest general financial instrument in common use, and it formed the benchmark for our design.To describe the face value, the currency of the face value, and the expiry date of this bond, we would add additional elements to the above tuple. But this is only a beginning. In his description of Eurobonds, Noel Clarke expects dozens or hundreds of fields[9]. If we examine just one of these characteristics, for example Event-Related Put Options, we find that a bond needs to describe what happens in the event of:These items bind tightly to the instrument in question, but they represent difficulties to the software architect. We can make a number of observations.Firstly, each event is not simple. Today, one may be able to shoehorn the notion of \"a hostile or friendly takeover\" into a single name-value pair, but this would not survive the evolving scene of regulation and litigation that applies to such events.Secondly, there is no reason to believe that the above list is complete.Thirdly, not only is it going to be hard to design a single field of any sort to cope with these, they are mostly going to be full of legal text.Consider a data layout point of view. To describe the document that forms the basis of a bond we will need a tree-structured database of tuples, as a minimum. More, that layout is only going to work for one instrument, or one extremely tight, nearly fungible set of instruments.Currencies, or cash, might be that tight set. After all, a dollar is a dollar is a dollar. Can we describe money with some simple set of tuples? Even for cash, we argue that a layout of tuples is not sufficient.Take the case of a digital dollar issued by a bank. The digital dollars would be derivatives, often backed by deposits in the same amount. This may be sufficient for marketing purposes but it would not survive a serious financial analysis.Compare such derivative dollars to those issued by the US Federal Reserve Board. The Fed has yet to deny acceptance of its notes if presented with same, if only as a claim on another bunch of the same instrument, or for taxation liabilities. Radical interpretations aside, the Fed has never filed for bankruptcy and remains a pretty solid bet.The same cannot be said of just any bank issuer of derivative dollars. Its digital dollars would be backed by deposits with ... the very same institution. Such a bank can close its doors at any time, and, given the history of the banking sector in the 20th Century, an analyst should take this risk seriously. Further, in the USA at least, the FDIC has already ruled that funds so held on a user's PC are considered to be uninsured deposits[10].This is not to suggest that any given bank is about to close doors, but to ask what happens when an issuer does indeed default on its promise?Any holder of any asset will carry a risk. A holder of electronic dollars will carry the risk that the issuer fails, and the holder of another issuer's dollars carries a similar, comparable, but distinct risk. Each of those risks result in a cost, which should be subtracted from the face value of the dollar to calculate a comparative value. In this risk distinction lies the inescapable fact that any given dollar is not of constant value, even when measured against some well-known dollar such as that issued by the Federal Reserve.If there is no such thing as a single dollar, what is left? Clearly, we must describe each and every dollar for what it is. This would seem to be a task of fine print and detail, and, indeed, every distinct issued currency is a distinct contract between the issuer and the holder.A contract can encapsulate the detail. Consider the original sovereign currency contracts, in which the issuer promised to pay the bearer in ounces of precious metal. That is four datum in the contract already: which sovereign, \"pay to bearer,\" what to pay, and how much of it.So it is with every bond, every currency, and any financial instrument of any complexity. In fact, within the digital domain, the question of how to treat a financial instrument reduces in great part to how to treat a contract.Or, an issue is a contract. Issues within other payment systems have contracts but only as adjunct documents such as user agreements. Often, their role and importance is subject to battles; marketing wants them hidden, while Legal asks for them to be thrust in the user's face at all times.Once we accept that the issue is a contract, the task becomes simple: create a contract that can be linked into the payment system as the centerpiece. That is the subject of the next section.Almost all aspects of Ricardian Contracts are best seen by examining examples, and this section only briefly covers the salient details, before discussing the ramifications. Examples can be found at webfunds.org/ricardo/contracts/ .A Ricardian Contract can be defined as a single document that is a) a contract offered by an issuer to holders, b) for a valuable right held by holders, and managed by the issuer, c) easily readable by people (like a contract on paper), d) readable by programs (parsable like a database), e) digitally signed, f) carries the keys and server information, and g) allied with a unique and secure identifier.In the simplest possible terms, a Ricardian Contract is a document defining a type of value for issuance over the Internet[11]. It identifies the Issuer, being the signatory, and any terms and clauses the Issuer sees fit to add in to make the document stand as a contract.The same document has to be both readable by people and parsable by programs. The Ricardian Contract is formatted as a text file that can be easily read (displayed or printed), and programs can convert it into internal forms for searching for name-value pairs. It includes a special section for each type of contract, such as bond, share, currency, etc. Further sections within describe, in program-parsable terms, usage of decimal points, titles, and symbols.As legal signatory, the Issuer signs the document in the OpenPGP cleartext form with his contract signing key[12]. He includes the full chain of OpenPGP keys within the document to permit programs to directly verify and authenticate.To uniquely identify the contract, any user can calculate a canonical message digest over the clearsigned document. This message digest is included in all records of transactions, and provides a secure (unforgeable) link from the document to the accounting of the issue.E.g., e3b445c2a6d82df81ef46b54d386da23ce8f3775 is the full message digest for Systemics Inc's issue of prepaid services dollars. Commonly called a hash, the message digest is a cryptographic technique to create a relatively small number that is one to one with the document. That is, for each document, there is only one hash, and the hash refers uniquely to that document. The algorithm is the well-known standard, SHA1.The following observations highlight how strong the result is.Hash Limits Frog-Boiling. A gradual change in contract by the stronger party over time is known as frog-boiling. The stronger party is generally the issuer, and can be expected to change the contract if there is a benefit. This is a frequent attack. One result of the use of the hash identifier is that neither party can change the contract arbitrarily or surreptitiously.To see this is true, we need to examine the records that refer to the hash. An application can sign all important records (e.g., payments, tokens, receipts, balances), and these signed records include the hash of a Ricardian Contract. The hash within the record cannot be changed without losing its ability to pass a test of signature validity. Likewise, the contract cannot be changed without losing its relationship to records already signed and delivered. In other words, every record, held by every user, incorporates an unalterable copy of that hash. Any change to the contract creates a new hash, and that new hash is not the one which the users have or value.This crystallises the contract for both parties, stopping the stronger party from modifying the contract subtly at some later stage. To some extent, this redresses the imbalance of power between provider and customer in the offering of a form contract. The lesser party has no option to negotiate, but neither has the greater party the option to claim a distinct contract at a later time. The limitation comes at some cost as it can be a nuisance for the support team of that financial instrument.The Ricardian PKI Delivers Clarity. Ricardian Contracts carry their own Public Key Infrastructure (\"PKI\") with them. The Issuer's top level public key is included in the contract, and it signs his contract-signing key, also included. The contract-signing key signs the contract itself.This achieves several things. Firstly, client software can check the entire digital signature chain in one automated sequence.Secondly, there is no need for a complex multi-party PKI. All the keys are present, and there is no need to go looking for them on the net. This eliminates substitution attacks, whereby a key that might pass some checks could be inserted in some key lookup phase. It also reduces costs dramatically.Thirdly, the canonical hash of the contract also represents a signature on the contract. It is recorded in all relevant records, and thus entangles the contract with those activities[13]. Once the contract has been in play for a while, it establishes its provenance through presence and reliance by the user public. This provides far more persuasive evidence than the issuer's signature itself; once the issuer and the public have spent time and money relying on the contract, via the hash, it is hard for the issuer to renege on the nature of the contract or his signature.The result is a PKI that delivers strong end-to-end reliability, based on a single document. This is simply not present in other designs for PKIs[14]. This reliability pays off in the dispute resolution phase, where, we suggest, the Ricardian Contract can stand alone on its merits and requires no complex descriptions of PKI, digital signatures, or references to uncertain third parties to bolster its provenance. By including the keys, we can draw a couple of simple lines within the contract, asserting \"this key signs that key, and that latter signs the contract. The first key is the top-level key of the individual that signed this contract. That's the whole story, mi'lud.\"Validating the Issuer's Key. All good crypto protocols divide into two parts, the first of which says to the second, \"trust this key completely.\"The top-level key of the Issuer ultimately authenticates the contract. The keys and other information in the contract also permit a protocol such as SOX to bootstrap a strongly secured connection to the server[15].How then to verify that this ultimate key is really the Issuer's? This is not difficult. The business process of digital issuance involves a great deal of relationship-building between Issuers and Users. Many different interactions involve chances to establish trust. For example, from his web site, the Issuer can publish the contract, keys and hashes, and have other sites mirror them. The value so issued will be distributed via payments that include the hash. An already trusted party usually delivers these payments. The payments validly identify the contract, and derive their own validity, via the hash.Contrast this to assumptions in the x.509 PKI behind SSL/HTTPS browsing (the following is highly debatable, but is presented for comparison only). In that PKI, it was originally claimed that a user would present her credit card to sites with which she had no prior relationship and no way for her to establish the provenance of the site's key. Thus, a trusted third party, the Certificate Authority, was put in place to confirm the key.Payments, trading and matters of finance are fundamentally relationship-rich. The nature of money and finance is that participants always conduct their own due diligence, they prefer to listen to peers they already trust, and do not readily accept the word of an independent party. Thus, there is no place for a central third party to stand in and authenticate players. Before the user desires to place any value on a given payment, she has almost certainly been made aware of the contract via other means.Presumption of Possession. The use of the hash as an identifier is a compromise as it is unintelligible to humans[16]. Yet this very compromise delivers an unexpected benefit: Use of the issue leads to a presumption that the user has the contract. To use an issue of value, such as a currency, the user must have the hash in the applicable records. That is, if the user receives a payment, that payment record will include the hash. As the hash is not descriptive, this implies that the user has the contract in order to interpret the issue.To see that this is true, imagine having a record with the hash but without having the contract. The first thing the user will need is a database of parameters telling her what the hash refers to. Unlike a payment in 10 of \"GBP\", a payment of 1000 in \"972097bb...\" is not intelligible.Yet how could software predict what the user needs to know about the hash? Very quickly it becomes apparent that the software is better off storing the source of the information \u2013 the full contract itself \u2013 as it removes an unlimited degree of complexity in storing intermediate or secondary information.Software can still function with only the hash. However, it would be entirely blind to the semantics of the instrument. Such a cavalier approach might be acceptable for communications and storage, but for user software, it is equivalent to a traumatic failure. To cope with this, the client-side software takes especial care to acquire and keep contracts. Hence, we can state the presumption with some degree of confidence: in a functioning system, the user has available the full Ricardian Contract (albeit under software control).This is only a small step for the client software, but is a giant leap forward for the relationship between the issuer and the holder. Specifically, having a strong presumption that the user has the full contract available will simplify many legal aspects about the issuer's responsibilities. (We suggest and thus acknowledge the legal ramifications of the term presumption, but neither space nor expertise permits more in this paper.)The Ricardian Contract delivers a rich source of primary, complete information. The full story is right there in textual form, in parsable parameters, and in the signature chain. Thus, within a dispute, a hostile legal attack has less room to manoeuvre, and can only confirm the facts as laid out in the contract.Our intent is that the contract is the beginning and the end of the discussion; we call this principle the rule of one contract. The legal fraternity refers to \"the contract being bounded by the four corners of the page.\" By showing how we have carefully laid out a readable document, with a verifiable digital signature, and an unforgeable identifier linking to every record, we can more readily ask the judiciary to accept that the single document which is being presented is indeed the valid contract agreed to by the parties.The contract is the keystone of issuance[17]. Our innovation is to express all the salient details of an issuance as an unforgeable contract, unforgeably linked into every action within a payment system. In this way, financial innovation can develop along the lines it always has done \u2013 by means of innovation within contracts. By translating the institution of the contract into the digital domain, we build upon centuries' and even millenia' worth of experience in documenting, sharing and disputing the meaning of agreements between parties.To capture complexity, we can put documents such as contracts into electronic form and sign them using digital signature technologies such as OpenPGP. The result is a reasonable analogue of the paper and ink contracts that most people and businesses are familiar with, bolstered with cryptographic integrity.With the hash as the identifier, software can now uniquely identify a given financial arrangement and can confirm a strong chain of signatures. The hash strongly implies the user has the contract available at all times, and it cannot be changed without being noticed.The Ricardian Contract delivers one huge benefit to the issuer \u2013 clarity in many legal and customer support questions. The user benefits from lower overall costs, and better presentation of information, within a more consistent framework.The form has been in successful use since 1996. Since that time, it has delivered about 20 financial instruments without failure.Disputes. The Ricardian Contract has appeared in two distinct forums of dispute resolution to resolve claims[18]. Anecdotally, each claim was resolved directly and efficiently, and without undue fuss, simply by referring to the applicable Ricardian Contract.Automation. Relatively little has needed to be automated. In practice, fields have been inserted and standardised so that programs can extract decimalisation (dollars versus cents), labels for units (USD versus $), and titles for the issuer and the issue. In contrast to expectations, there has been no demand to parse every field.Cost. The cost of the concept has compared favourably with that incurred with other payment systems. The preparation of the contract text carries some costs, but no more so than a user agreement. OpenPGP infrastructure requirements (keys and signing) add some minor costs to issuers but they are easily offset by the benefits of risk reduction from contract distribution. Custom signing editors have helped to reduce those costs[19].Layering. Layering of contracts is an impending need. Many businesses can take a standard and defined set of terms and draw on them directly. Other contracts result from earlier contracts and need to reference them.XML. Initial efforts suggested that XML would break the rule of one contract, but it seems that we will need something better than the archaic INI format[20]. One recent proposal, the XML Voucher, stops short of presenting itself as a contract[21].Law of Contract. The treatment of the Ricardian Contract as a contract may raise more legal questions than it answers. For example, is this form indeed a contract? How do distinct jurisidictions view the concept (common law, civil law, UCC, Koranic code)? Is this a negotiated or a form contract? When did the user accept the contract? How strong, or rebuttable, is the presumption that the user has the contract?Smart Contracts. By unifying all information in a program-readable file, there is the enhanced potential of smart contracts[22]. We have not gone further in this direction than methods to handle decimals. This is partly for lack of demand, and partly because it is not clear how a court would treat a computer program presented as a contract.Originally introduced in Ian Grigg, \"Financial Cryptography in 7 Layers,\" 4th Conference on Financial Cryptography, Anguilla, 2000, Springer-Verlag LNCS 1962. All papers are at http://iang.org/papers/ \u21a9Ian Grigg, \"Digital Trading,\" Virtual Finance Report, November 1997. \u21a9Country and Currency Codes, ISO3166-1. \u21a9Bryce Wilcox, open design review, DigiCash's developer list, <ecash-dev@digicash.com>, August 1997. \u21a9Ibid, Rachel Willmer, 14 August 1997. \u21a9Robert Hettinga, \"What's a Digital Bearer Bond?\" e$ rants, 19th November, 1995 \u21a9Alex Tajirian, \"David Bowie Bonds,\" \u21a9Ian Grigg and C. Petro, \"Using Electronic Markets Achieve Efficient Task Distribution,\" 1st Conference on Financial Cryptography, Anguilla, 1997, Springer-Verlag LNCS 1318. \u21a9Noel Clarke, Guide to Eurobonds, The Economist Intelligence Unit, 1993. \u21a9FDIC General Counsel's Opinion No. 8; Stored Value Cards, Federal Register, August 2, 1996. Also see the (readable) Press Release entitled FDIC will Continue to rely on General Counsel Opinion rather than issue rules on Stored-Value Cards, 24 June 97. \u21a9Ian Grigg, Guide to Ricardian Contracts, WebFunds project. \u21a9Jon Callas, et al, \"OpenPGP Message Format,\" Internet Draft, RFC2440bis (-10 draft). \u21a9Petros Maniatis, Mary Baker \"Secure History Preservation through Timeline Entanglement\", 11th USENIX Security Symposium, San Francisco, USA. August 2002. \u21a9Jane K. Winn, \"Couriers without Luggage\" 49 South Carolina Law Review 739 (1998) \u21a9Gary Howland, \"Development of an Open and Flexible Payment System\" 1996. \u21a9Bryce Wilcox, \"Names: Decentralized, Secure, Human-Meaningful: Choose Two\", 2003 \u21a9Metaphor by Martin (Hasan) Bramwell. See \"The Contract is the Keystone of Issuance,\" Financial Cryptography blog, 19th September 2003. \u21a9DigiGold v. Systemics, before the Supreme Court of Anguilla (2001), and thereafter referred to the American Arbitration Association (2002). \u21a9Edwin Woudt, ContractSignWizard, WebFunds project. \u21a9Erwin van der Koogh, \"Ricardian Contracts in XML,\" (presented at) Edinburgh Financial Cryptography Engineering (EFCE-2), 2001. \u21a9Ko Fujimura and Masayuki Terada, XML Voucher: Generic Voucher Language, Internet Draft. \u21a9Nick Szabo, \"The Idea of Smart Contracts,\" 1997. \u21a9Ian Grigg\nSystemics, Inc.\niang@iang.org"}
{"prompt": "Triple Entry Accounting", "completion": "The digitally signed receipt, an innovation from financial cryptography, presents a challenge to classical double entry bookkeeping. Rather than compete, the two melded together form a stronger system. Expanding the usage of accounting into the wider domain of digital cash gives 3 local entries for each of 3 roles, the result of which I call triple entry accounting.This system creates bullet proof accounting systems for aggressive uses and users. It not only lowers costs by delivering reliable and supported accounting, it makes much stronger governance possible in a way that positively impacts on the future needs of corporate and public accounting.This paper brings together financial cryptography innovations such as the Signed Receipt with the standard accountancy techniques of double entry bookkeeping.The first section presents a brief backgrounder to explain the importance of double entry bookkeeping. It is aimed at the technologist, and accountancy professionals may skip this. The second section presents how the Signed Receipt arises and why it challenges double entry bookkeeping.The third section integrates the two together and the Conclusion attempts to predict wider ramifications into Governance issues.This paper benefitted from comments by Graeme Burnett and Todd Boyle[1].Accounting or accountancy is these days thought to go back to the genesis of writing; the earliest discovered texts have been deciphered as simple lists of the counts of animal and food stock. The Sumerians of Mesopotamia, around 5000 years ago, used Cuneiform or wedge shaped markings as a base-60 number form, which we still remember as seconds and minutes, and squared, as the degrees in a circle. Mathematics and writing themselves may well have been derived from the need to add, subtract and indeed account for the basic assets and stocks of early society.Single entry bookkeeping is how 'everyone' would do accounting: start a list, and add in entries that describe each asset. A more advanced arrangement would be to create many lists. Each list or 'book' would represent a category, and each entry would record a date, an amount, and perhaps a comment. To move an asset around, one would cross it off from one list and enter it onto another list.Very simple, but it was a method that was fraught with the potential for errors. Worse, the errors could be either accidental, and difficult to track down and repair, or they could be fraudulent. As each entry or each list stood alone, there was nothing to stop a bad employee from simply adding more to the list; even when discovered there was nothing to say whether it was an honest mistake, or a fraud.Accounting based on single entry bookkeeping places an important limitation on the trust of the books. Likely, only the owner's family or in times long past, his slaves could be trusted with the enterprise's books, leading to a supportive influence on extended families or slavery as economic enterprises.Double Entry bookkeeping adds an additional important property to the accounting system; that of a clear strategy to identify errors and to remove them. Even better, it has a side effect of clearly firewalling errors as either accident or fraud.This property is enabled by means of three features, being the separation of all books into two groups or sides, called assets and liabilities, the redundancy of the duplicative double entries with each entry having a match on the other side, and the balance sheet equation, which says that the sum of all entries on the asset side must equal the sum of all entries on the liabilities side.A correct entry must refer to its counterparty, and its counterpart entry must exist on the other side. An entry in error might have been created for perhaps fraudulent reasons, but to be correct at the local level, it must refer to its counterparty book. If not, it can simply be eliminated as an incomplete entry. If it does refer, the existence of the other entry can be easily confirmed, or indeed recreated depending on the sense of it, and the loop is thus closed.Previously, in single entry books, the fraudster simply added his amount to a column of choice. In double entry books, that amount has to come from somewhere. If it comes from nowhere, it is eliminated above as an accidental error, and if it comes from somewhere in particular, that place is identified. In this way, fraud leaves a trail; and its purpose is revealed in the other book because the value taken from that book must also have come from somewhere.This then leads to an audit strategy. First, ensure that all entries are complete, in that they refer to their counterpart. Second, ensure that all movements of value make sense. This simple strategy created a record of transactions that permitted an accountancy of a business, without easily hiding frauds in the books themselves.Double Entry bookkeeping is one of the greatest discoveries of commerce, and its significance is difficult to overstate. Historians think it to have been invented around the 1300s AD, although there are suggestions that it existed in some form or other as far back as the Greek empire. The earliest strong evidence is a 1494 treatise on mathematics by the Venetian Friar Luca Pacioli[2]. In his treatise, Pacioli documented many standard techniques, including a chapter on accounting. It was to become the basic text in double entry bookkeeping for many a year.Double Entry bookkeeping arose in concert with the arisal of modern forms of enterprise as pioneered by the Venetian merchants. Historians have debated whether Double Entry was invented to support the dramatically expanded demands of the newer ventures then taking place surrounding the expansion of city states such as Venice or whether Double Entry was an enabler of this expansion.Our experiences weigh in on the side of enablement. I refer to the experiences of digital money issuers. Our own first deployment of a system was with a single entry bookkeeping system. Its failure rate even though coding was tight was such that it could not sustain more than 20 accounts before errors in accounting crept in and the system lost cohesion. This occurred within weeks of initial testing and was never capable of being fielded. The replacement double entry system was fielded in early 1996 and has never lost a transaction (although there have been some close shaves[3]).Likewise, the company DigiCash BV of the Netherlands fielded an early digital cash system into a bank in the USA. During its testing period, the original single entry accounting system had to be field replaced with a double entry system for the same reason \u2013 errors crept in and rendered the accounting underneath the digital cash system unreliable.Another major digital money system lasted for many years on a single entry accounting system. Yet, the company knew it was running on luck. When a cracker managed to find a flaw in the system, an overnight attack allowed the creation of many millions of dollars worth of value. As this was more than the contractual issue of value to date, it caused dramatic contortions to the balance sheet, including putting it in breach of its user contract and at dire risk of a 'bank run'. Luckily, the cracker deposited the created value into the account of an online game that failed shortly afterwards, so the value was able to be neutralised and monetarily cleansed, without disclosure, and without scandal.In the opinion of this author at least, single entry bookkeeping is incapable of supporting any enterprise more sophisticated than a household. Given this, I suggest that evolution of complex enterprises required double entry as an enabler.Double Entry has always been the foundation of accounting systems for computers. The capability to detect, classify and correct errors is even more important to computers than it is to humans, as there is no luxury of human intervention; the distance between the user and the bits and bytes is far greater than the distance between the bookkeeper and the ink marks on his ledgers.How Double Entry is implemented is a subject in and of itself. Computer science introduces concepts such as transactions, which are defined as units of work that are atomic, consistent, isolated, and durable (or ACID for short). The core question for computer scientists is how to add an entry to the assets side, then add an entry to the liabilities side, and not crash half way through this sequence. Or even worse, have another transaction start half way through. This makes more sense when considered in the context of the millions of entries that a computer might manage, and a very small chance that something goes wrong; eventually something does, and computers cannot handle errors of that nature very well.For the most part, these concepts simply reduce to \"how do we implement double entry bookkeeping?\" As this question is well answered in the literature, we do no more than mention it here.Recent advances in financial cryptography have provided a challenge to the concept of double entry bookkeeping. The digital signature is capable of creating a record with some strong degree of reliabilty, at least in the senses expressed by ACID, above. A digital signature can be relied upon to keep a record safe, as it will fail to verify if any details in the record are changed.If we can assume that the the record was originally created correctly, then later errors are revealed, both of an accidental nature and of fraudulent intent. (Computers very rarely make accidental errors, and when they do, they are most normally done in a clumsy fashion more akin to the inkpot being spilt than a few numbers.) In this way, any change to a record that makes some sort of accounting or semantic sense is almost certainly an attempt at fraud, and a digital signature makes this obvious.A digital signature gives us a particular property, to whit:There are several variants, with softer and harder claims to that property. For example, message digests with entanglement form one simple and effective form of signature, and public key cryptosystems provide another form where signers hold a private key and verifiers hold a public key[4]. There are also many ways to attack the basic property. In this essay I avoid comparisons, and assume the basic property as a reliable mark of having been seen by a computer at some point in time.Digital signatures then represent a new way to create reliable and trustworthy entries, which can be constructed into accounting systems. At first it was suggested that a variant known as the blinded signature would enable digital cash[5]. Then, certificates would circulate as rights or contracts, in much the same way as the share certificates of old and thus replace centralised accounting systems[6]. These ideas took financial cryptography part of the way there. Although they showed how to strongly verify each transaction, they stopped short of placing the the digital signature in an overall framework of accountancy and governance. A needed step was to add in the redundancy implied in double entry bookkeeping in order to protect both the transacting agents and the system operators from fraud.Designs that derived from the characteristics of the Internet, the capabilities of cryptography and the needs of governance led to the development of the signed receipt[7]. In order to develop this concept, let us assume a simple three party payment system, wherein each party holds an authorising key which can be used to sign their instructions. We call these players Alice, Bob (two users) and Ivan (the Issuer) for convenience.When Alice wishes to transfer value to Bob in some unit or contract managed by Ivan, she writes out the payment instruction and signs it digitally, much like a cheque is dealt with in the physical world. She sends this to the server, Ivan, and he presumably agrees and does the transfer in his internal set of books. He then issues a receipt and signs it with his signing key. As an important part of the protocol, Ivan then reliably delivers the signed receipt to both Alice and Bob, and they can update their internal books accordingly.Our concept of digital value sought to eliminate as many risks as possible. This was derived simply from one of the high level requirements, that of being extremely efficient at issuance of value. Efficiency in digital issuance is primarily a function of support costs, and a major determinant of support costs is the costs of fraud and theft.One risk that consistently blew away any design for efficient digital value at reasonable cost was the risk of insider fraud. In our model of many users and a single centralised server, the issuers of the unit of digital value (as signatory to the contract) and any governance partners such as the server operators are powerful candidates for insider fraud. Events over the last few years such as the mutual funds and stockgate scandals are canonical cases of risks that we decided to address.In order to address the risk of insider fraud, the written receipt was historically introduced as being a primary source of evidence. Mostly forgotten to the buying public these days, the purpose of a written receipt in normal retail trade is not to permit returns and complaints by the customer, but rather to engage her in a protocol of documentation that binds the shop attendant into safekeeping of the monies. A good customer will notice fraud by the shop attendant and warn the owner to look out for the monies identified by the receipt; the same story applies to the invention of the cash till or register, which was originally just a box separating the owner's takings from the monies in the shop attendant's pockets. We extend this primary motive into the digital world by using a signed receipt to bind the Issuer into a governance protocol with the users.We also go several steps further forward. Firstly, to achieve a complete binding, Alice's original authorisation is also included within the record. The receipt then includes all the evidence of both the user's intention and the server's action in response, and it now becomes a dominating record of the event. This then means that the most efficient record keeping strategy is to drop all prior records and keep safe the signed receipt.This domination affects both the Issuer and the user, and allows us to state the following principle:As the signed receipt is delivered from Issuer to both users, all three parties hold the same dominating record for each event. This reduces support costs by dramatically reducing problems caused by differences in information.Secondly, we bind a signed contract of issuance known as a Ricardian Contract into the receipt[8]. This invention relates a digitally signed document securely to the signed receipt by means of a unique identifier called a message digest, again provided by cryptography. It provides strong binding for the unit of account, the nature of the issue, the terms, conditions and promises being made by the Issuer, and of course the identity of the Issuer.Finally, with these enabling steps in place, we can now introduce the principle:Within the full record of the signed receipt, the user's intention is expressed, and is fully confirmed by the server's response. Both of these are covered by digital signatures, locking these data down. A reviewer such as an auditor can confirm the two sets of data, and can verify the signatures.The principle of the Receipt as the Transaction has become sacrosact over time. In our client software, the principle has been hammered into the design consistently, resulting in a simplified accounting regime, and delivering a high reliability. Issues still remain, such as the loss of receipts and the counting of balances by the client side software, but these become reasonably tractable once the goal of receipts as transactions is placed paramount in the designer's mind.In order to calculate balances on a related set of receipts, or to present a transaction history, a book would be constructed on the fly from the set. This amounts to using the Signed Receipt as a basis for single entry bookkeeping. In effect, the bookkeeping is derived from the raw receipts, and this raises the question as to whether to keep the books in place.The principles of Relational Databases provide guidance here. The fourth normal form directs that we store the primary records, in this case the set of receipts, and we construct derivative records, the accounting books, on the fly[9].Similar issues arise for Ivan the Issuer. The server has to accept each new transaction on the basis of the available balance in the effected books; for this reason Ivan needs those books to be available efficiently. Due to the greater number of receipts and books (one for each user account), both receipts and books will tend to exist, in direct contrast to fourth normal form. A meld between relationally sound sets of receipts and double entry books comes to assist here.Alice and Bob both are granted a book each within the server's architecture. As is customary, we place those books on the liabilities side. Receipts then can be placed in a separate single book and this could be logically placed on the assets side. Each transaction from Alice to Bob now has a logical contra entry, and is then represented in 3 places within the accounts of the server. Yet, the assets side remains in fourth normal form terms as the liabilities entries are derived, each pair from one entry on the assets side.By extension, a more sophisticated client-side software agent, working for Alice or Bob, could employ the same techniques. At this extreme, entries are now in place in three separate locations, and each holding potentially three records.The digitally signed receipt, with the entire authorisation for a transaction, represents a dramatic challenge to double entry bookkeeping at least at the conceptual level. The cryptographic invention of the digital signature gives powerful evidentiary force to the receipt, and in practice reduces the accounting problem to one of the receipt's presence or its absence. This problem is solved by sharing the records \u2013 each of the agents has a good copy.In some strict sense of relational database theory, double entry book keeping is now redundant; it is normalised away by the fourth normal form. Yet this is more a statement of theory than practice, and in the software systems that we have built, the two remain together, working mostly hand in hand.Which leads to the pairs of double entries connected by the central list of receipts; three entries for each transaction. Not only is each accounting agent led to keep three entries, the natural roles of a transaction are of three parties, leading to three by three entries.We term this triple entry bookkeeping. Although the digitally signed receipt dominates in information terms, in processing terms it falls short. Double entry book keeping fills in the processing gap, and thus the two will work better together than apart. In this sense, our term of triple entry bookkeeping recommends an advance in accounting, rather than a revolution.The precise layout of the entries in software and data terms is not settled, and may ultimately become one of those ephemeral implementation issues. The signed receipts may form a natural asset-side contra account, or they may be a separate non-book list underlying the bookkeeping system and its two sides.Auditing issues arise where construction of the books derives from the receipts, and normalisation issues arise when a receipt is lost. These are issues for future research.Likewise, it is worth stating that the technique of signing receipts works both with private key signatures and also with entanglement message digest signatures; whether the security aspects of these techniques is adequate to task is dependent on the business environment.It will be noted that the above design of triple entry bookkeeping assumed that Alice and Bob were agents of some independence. This was made possible, and reflected the usage of the system as a digital cash system, and not as a classical accounting system.Far from reducing the relevance of this work to the accounting profession, it introduces digital cash as an alternate to corporate bookkeeping. If an accounting system for a corporation or other administrative entity is recast as a system of digital cash, or internal money, then experience shows that benefits accrue to the organisation.Although the core of the system looks exactly like an accounting system, each department's books are pushed out as digital cash accounts. Departments no longer work so much with budgets as have control over their own corporate money. Fundamental governance control is still held within the accounting department by dint of their operation of the system, and by the limited scope of the money as only being usable within the organisation; the accounting department might step in as a market maker, exchanging payments in internal money for payments in external money to outside suppliers.We have operated this system on a small scale. Rather than be inefficient on such a small scale, the system has generated dramatic savings in coordination. No longer are bills and salaries paid using conventional monies; many transactions are dealt with by internal money transfers and at the edges of the corporation, formal and informal agents work to exchange between internal money and external money. Paperwork reduces dramatically, as the records of the money system are reliable enough to quickly resolve questions even years after the event.The innovations present in internal money go beyond the present paper, but suffice to say that they answer the obvious question of why this design of triple entry accounting sprung from the world of digital cash, and has relevence back to the corporate world.Todd Boyle looked at a similar problem from the point of view of small business needs in an Internet age, and reached the same conclusion \u2013 triple entry accounting[10]. His starting premises were that:From those foundations, Boyle concluded that therefore what is needed is a shared access repository that provides arms-length access. Fundamentally, this repository is akin to the classic double-entry accounting ledger of transaction rows (\"GLT\" for General Ledger - Transactions), yet its entries are dynamic and shared.Simple examples will help. When Alice forms a transaction, she enters it into her software. Every GLT transaction requires naming her external counterparty, Bob. When she posts the transaction, her software stores it in her local GLT and also submits it to the shared repository service's GLT.The Shared Transaction Repository (\"STR\") then forwards the transaction on to Bob. Both Bob and Alice are now expected to store the handle to the transaction as an index or stub, and the STR then stores the entire transaction.Boyle's ideas are logically comparable to Grigg and Howland's, although they arive from different directions (the STR is Grigg's Ivan, above) and are not totally equivalent. Where the latter limited themselves to payments, the accuracy of amounts, and protection with hard cryptographic shells, Boyle looked at wider patterns of transactions, and showed that the STR could mediate these transactions, if the core shared data could be extracted and made into a single shared record. Boyle's focus was on the economic substance of the transaction.Imagine a simple invoicing procedure. Alice creates an invoice and posts it to her software (GLT). As she has named Bob, the GLT automatically posts it to Ivan, the STR, and he forwards it to Bob. At this point Bob has a decision to make, accept or reject. Assuming acceptance, his software can then respond by sending an acceptance message to Ivan. The STR now assembles an accepted invoice record to replace the earlier speculative invoice record and posts that threeways. At some related time (to do with payment policy) Bob also posts a separate transaction to pay for the invoice. This could operate in much the same way as a separate transaction, linking directly to the original invoice.Now, as the payment links back, and the invoice is a live transaction within the three entries in the three accounting systems, it is possible for a new updated invoice record to refer back to the payment activity. When the payment clears, the new record can again replace the older unpaid copy and promulgate to all three parties.Software could be written to facilitate and monitor this flow and similar flows. If the payments system is sufficiently flexible, and integrated with the needs of the users, if might be possible to merge the above invoice with the payment itself, at the Receipts level. Seen in this light, the Signed receipt of Ricardo is simply the smallest and simplest pattern within the more general set of patterns. We could then suggest that the narrow principle of the Receipt is the Transaction could be extended into The Invoice is the Transaction.A particular transaction in business almost never stands alone. They come in patterns. For example offers and acceptances form a wider transaction but seldom encapsulate the entire fulfillment and payment cycle. Even if there has been a payment accompanying a PO message, the customer then waits for fulfillment.There is a large body of science and literature built around these patterns of transactions. These have been adopted by the Business Process workgroup of ebXML and other standards bodies, where they are called \"Commercial Transactions.\" Where however the present work distinguishes itself is in breaking down these transactions into the atomic elements. It is to that we now turn.The implementation of Triple Entry Accounting will in time evolve to support patterns of transactions. What has become clear is that double entry does not sufficiently support these patterns, as it is a framework that breaks down as soon as the number of parties exceeds one. Yet, even as double entry is \"broken\" on the net and unable to support commercial demands, triple entry is not widely understood, nor are the infrastructure requirements that it imposes well recognised.Below are the list of requirements that we believed to be important[11][12].1. Strong Psuedonymity, At Least. As there are many cycles in the patterns, the system must support a clear relationship of participants. At the minimum this requires a nymous architecture of the nature of Ricardo or AADS. (This requirement is very clear, but space prevents any discussion of it.)2. Entry Signing. In order to neutralise the threats to and by the parties, a mechanism that freezes and confirms the basic data is needed. This is signing, and we require that all entries are capable of carrying digital signatures (see 1, above, which suggests public key signatures).3. Message Passing. The system is fundamentally one of message passing, in contrast to much of the net's connection based architecture. Boyle recognised early on that a critical component was the generic message passing nature, and Systemics proposed and built this into Ricardo over the period 2001-2004[13].4. Entry Enlargement and Migration. Each new version of a message coming in represents an entry that is either to be updated or added. As each message adds to a prior conversation, the stored entry needs to enlarge and absorb the new information, while preserving the other properties.5. Local Entry Storage and Reports. The persistent saving and responsive availability of entries. In practice, this is the classical accounting general ledger, at least in storage terms. It needs to bend somewhat to handle much more flexible entries, and its report capabilities become more key as they conduct instrinsic reconciliation on a demand or live basis.6. Integrated Hard Payments. Trade can only be as efficient as the payment. That means that the payment must be at least as efficient as every other part; which in practice means that a payment system should be built-in at the infrastructure level. C.f., Ricardo.7. Integrated Application-Level Messaging. As distinct to the messaging at the lower protocol levels (1 above), there is a requirement for Alice and Bob to be able to communicate. That is because the vast majority of the patterns turns around the basic communications of the agents. There is no point in establishing a better payment and invoice mechanism than the means of communication and negotiation. This concept is perhaps best seen in the SWIFT system which is a messaging system, first and foremost, to deliver instructions for payments.Double Entry bookkeeping provides evidence of intent and origin, leading to strategies for dealing with errors of accident and fraud. The financial cryptography invention of the signed receipt provides the same benefits, and thus challenges the 800 year reign of double entry. Indeed, in evidentiary terms, the signed receipt is more powerful than double entry records due to the technical qualities of its signature.There remain some weaknesses in strict comparison with double entry bookkeeping. Firstly, in the Ricardo instantiation of triple entry accounting, the receipts themselves may be lost or removed, and for this reason we stress as a principle that the entry is the transaction. This results in three active agents who are charged with securing the signed entry as their most important record of transaction.Secondly, the software ramifications of the triple entry system that are less convenient than that offered by double entry bookkeeping. For this reason, we expand the information held in the receipt into a set of double entry books; in this way we have the best of both worlds on each node: the evidentiary power of the signed entries and the convenience and local crosschecking power of the double entry concept.Both of these imperitives meld signed receipts in with double entry bookkeeping. As we end up with a logical arrangement of three by three entries, we feel the term triple entry bookkeeping is useful to describe the advance on the older form.To fully benefit from triple entry bookkeeping, we have to expand accounting systems out to agents and offer them direct capabilities to do transactions. That is, we make the agents stakeholders by giving them internal money[14]. Use of digital cash to do company accounts empowers the use of this concept as a general replacement for accounting using books and departmental budgets, and is an enabler for verifying and auditing the centralised accounts system by way of signed receipts.Once there, governance receives substantial benefits. Accounts are now much more difficult to change, and much more transparent. It is our opinion that various scandals and failures of governance would have been impossible given these techniques: the mutual funds scandal would have shown a clear audit trail of transactions and thus late timing and otherwise perverted or dropped transactions would have been clearly identified or eliminated completely[15]. The emerging scandal in the USA known as Stockgate would have been impossible as forgery of shares and value for manipulative trading purposes is revealed by signed receipts. Likewise, Barings would still be a force in investment banking if accounts had been organised around easily transparent digital cash with open and irreducible signed receipts that evidence invisible accounts (88888). Enron style scandals would have permitted more direct \"follow the money\" governance lifting the veil on various innovative but economically meaningless swaps.A draft form of this paper credited Todd Boyle as an author, but this was later withdrawn at his request due to wider differences between the views. \u21a9Friar Luca Pacioli, Summa de Arithmetica, Geometria, Proportioni et Proportionalita 1494, Venice. \u21a9Ian Grigg \"The Twilight Zone,\" Financial Cryptography blog 16th April 2005 \u21a9Entanglement is discussed in: Petros Maniatis and Mary Baker, \"Secure History Preservation through Timeline Entanglement,\" Proc. 11th USENIX Security Symposium, August 2002. \u21a9David Chaum, \"Achieving Electronic Privacy,\" Scientific American, v. 267, n. 2 Aug 1992. \u21a9Robert A. Hettinga \"The Book-Entry/Certificate Distinction\" 1995, Cypherpunks \u21a9Gary Howland \"Development of an Open and Flexible Payment System\" 1996, Amsterdam, NL. \u21a9Ian Grigg \"The Ricardian Contract,\" First IEEE International Workshop on Electronic Contracting (WEC) 6th July 2004 \u21a9E.F. Codd, \"A Relational Model of Data for Large Shared Data Banks,\" Comm. ACM 13 (6), June 1970, pp. 377-387. \u21a9Todd Boyle, \"GLT and GLR: conceptual architecture for general ledgers,\" Ledgerism.net, 1997-2005. \u21a9Todd Boyle, \"STR software specification,\" Goals, 1-5. This section adopts that numbering convention. \u21a9Ian Grigg, various design and requirements documents, Systemics, unpublished. \u21a9A substantial part of the programming and design was conducted by Edwin Woudt (first demo, SOX layers, UI) and Jeroen van Gelderen (message passing client architecture). \u21a9Using internal money instead of an accounting system is not a new idea but has only been recently experienced: Ian Grigg, How we raised capital at 0%, saved our creditors from an accounting nightmare, gave our suppliers a discount and got to bed before midnight. Informal essay (rant), 7 Jul 2003. \u21a9James Nesfield and Ian Grigg \"Mutual Funds and Financial Flaws,\" U.S. Senate Finance Subcommittee 27th January, 2004 \u21a9"}
{"prompt": "Truledger in Plain English", "completion": "Truledger is an anonymous, digitally-signed vault and trading system. Like Loom, it allows anyone to issue assets (digital currencies). Unlike Loom, which relies entirely on (very good) obscurity for security, Truledger's digital signatures allow the server and the customer to prove to each other that they agreed at a particular time on their balances. It does this while allowing destruction of transaction history for closed trades. Truledger will initially provide server-based trading. Eventually, it will provide digital checks and bearer certificates. These, however, WILL require permanent storage of transaction history (unless they expire).doc/db.txt gives a terse description of the Truledger server database and protocol. This page attempts to render the protocol in plain English.Truledger uses public key cryptography to sign all messages passed back and forth between its web interface and the Truledger server. Digital signatures are a virtually unforgeable way to ensure that a message was written by its purported author. Truledger uses OpenSSL for its public key cryptography. You probably use OpenSSL every time you visit a secure web site, https://somewhere.com/, as does the web server. I didn't roll my own. Just used the same tried and true technology that secures the web. You can read more about public key cryptography, digital signatures, and hashing here and here.I'm going to use four actors in the scenarios that follow. \"Server\" is the name of the Truledger server. \"Bob\" and \"Sue\" are two customers, who will trade with each other. \"Spammer\" is a third customer, unknown to Bob or Sue.Sue (via email or IM): Hey, Bob. Check out Truledger. Go to Truledger.com, download the client, and install it on your computer. Then create a private key, and send me your ID, and I'll give you some usage tokens so that you can create an account.Bob (via email or IM): Thanks, Sue! I installed the Truledger client and created a private key. Here's my ID.Sue (via her Truledger client): Hey server, Here's a new request number. Give me a transaction number please.\nSigned: SueServer: Here's a new transaction number.\nSigned: ServerSue: Hey server, here's that transaction number you gave me. Please spend 50 usage tokens to Bob's ID, with a message of \"Hey Bob. Welcome to Truledger!\" I'm paying 2 usage tokens as a transaction fee, which I'll get back when Bob accepts the spend. My balance after this transaction will be 1025 usage tokens. My outbox hash after this transaction will be X.\nSigned: SueServer: I processed your spend of 50 usage tokens to Bob's ID. I agree that the transaction fee at the time of this transaction is 2 usage tokens, and that your balance after this transaction is 1025 usage tokens. I agree with you on your outbox hash.\nSigned: ServerSue (via email or IM): OK, Bob. I've given you 50 usage tokens. You should now be able to create an account at Truledger.com. Send me a message via Truledger when you've registered.Bob (via his Truledger client): Hello server. Here's my ID and my public key. What's your ID and public key?\nSigned: BobServer: Here's my ID and public key.\nSigned: ServerBob: Here's my ID and my public key, please create an account for me.\nSigned: BobServer: I've registered your ID and public key. Somebody gave you enough tokens to register. Welcome to Truledger.\nSigned: ServerIn order to sign a message, you need to have a private key. In order to verify the signature on a message, you need to have the corresponding public key. Truledger identifies customers by the hash of their public key, their ID. The ID is a 40-character string of numbers and the letters A to F, the hexadecimal representation of a 160-bit number. You identify your account to the Truledger client with a passphrase, which is used to encrypt your private key on your disk. You'll only need to copy and paste your ID when you want to tell a trading partner how to send you money for the first time, or to seed your account with usage tokens, as Sue did for Bob.Usage tokens are an idea from Patrick Chkoreff's Loom system. They are a way to charge for the server's resources. You have to buy storage for your account balances, and lease temporary storage for transactions. Usage tokens are the \"currency\" used to do this. Truledger also supports fees in other asset types, for server management that wants to make more than the sale of usage tokens. Truledger uses the file system as a database. One file in the Truledger database costs one usage token. Files vary in size, but are usually about 8K, mostly signatures.Note that Bob had to send his public key to the server twice, once when he requested the server's public key, and again when he registered. Every message going to and from Truledger is digitally signed. It's only possible to verify a digital signature if you know the public key of the signer. A new customer's public key isn't in the database until after he's registered, so the first two messages, in which the new customer gets the server's public key, so that he can verify the server's signatures, and the registration request, both need to include the customers's public key, so that the signatures on those two messages can themselves be verified. After registration is complete, subsequent messages need to carry only the ID; the public key can then be looked up in the database.Actual messages sent (with the signature that goes with each parenthesized item omitted):Bob: Hello server. Here's my ID and a new request number. What's in my inbox?\nSigned: BobServer: Your inbox contains a 50 usage token spend from Sue with a message of \"Hey Bob. Welcome to Truledger!\" It also contains a 10 usage token charge from the server with a message of \"Registration Fee\". Here are two transaction numbers you can use to accept these spends and do a spend yourself.\nSigned: ServerBob: Here's my ID and the first of the transaction numbers you gave me. Accept the spend from Sue with a message of, \"Thanks, Sue. I'm excited about Truledger!\" Accept the server charge. My balance after this transaction will be 39 usage tokens.\nSigned: BobServer: I've processed the spend from Sue and the server charge. I agree that your balance after this transaction is 39 usage tokens.\nSigned: ServerOne possible attack on an electronic server can be for someone to replay an intercepted message. Unless the protocol protects against that, this can cause problems. Except for the serverid request, the registration request, and a request for a customer's last request number, every information request must be accompanied by a request number that is larger than the customer's last used request number, and every transaction must be accompanied by a transaction number that is given out by the server. The server maintains a counter, which it increments each time someone asks for a transaction number. This makes requests that reveal information or initiate transactions impossible to replay without a customer's passphrase and private key. In the Truledger world, your passphrase and your private key are your identity. Guard them well.Another possible replay attack is to intercept a message for one server and send it to another. Customers could protect against this by having different IDs, hence different public/private key pairs, for different servers. But it will be very convenient to use the same ID. Your friends will recognize you, and you'll have only one passphrase to remember. So the server's ID is included in almost every request. Requests meant for another server will not work.You're probably wondering why Bob's balance after the transaction is 39, instead of 40, usage tokens. He got 50 usage tokens from Sue, and paid the server 10 usage tokens for his registration fee. The additional usage token is the price of the new file used to store the usage token balance. Storage costs usage tokens. Loom charges 1 usage token for each 16 bytes of storage. I considered charging per byte, but decided that charging per file was easier to handle, though not quite as fair. It only makes sense if message sizes are limited, of course. If you were allowed megabyte messages, then Truledger would have to charge per byte, or per kilobyte.Actual messages sent:Sue: Hello server. Here's my ID and a new request number. What's in my inbox?\nSigned: SueServer: Your inbox contains an acceptance from Bob of your 50 usage token spend with a message of, \"Thanks Sue. I'm excited about Truledger!\" Here are two transaction numbers you can use to close that transaction and do a new spend.\nSigned: ServerSue: Here's my ID and the first of the transaction numbers you gave me. Clear the spend to Bob. My balance after this transaction will be 1027 usage tokens. My outbox hash after this transaction will be Y.\nSigned: SueServer: I've cleared the spend to Bob (and refunded the usage tokens that were leasing the outbox and inbox locations). I agree that your balance after this transaction is 1027 usage tokens. And I agree that your outbox hash after this transaction is Y.\nSigned: ServerThere are three main parts of a Truledger account: the balances, the outbox, and the inbox. Value is stored in all three places. When you do a spend, your balance for the spent asset is debited, and the spend request is stored in your outbox and in the recipients inbox. You are charged two usage tokens to lease the new outbox and inbox files. When the recipient accepts the spend, his balance for the spent asset is credited, the spend notice is removed from his inbox, and a spend acceptance notice is added to your inbox. When you acknowledge his acceptance of the spend, the spend request is removed from your outbox, the acceptance notice is removed from your inbox, and the two usage tokens you paid to lease those files is credited to your balance. This three step process is necessary, because the server can't modify your balances without your signed permission, and it can't modify the recipient's balances without his signed permission.You may be wondering what an \"outbox hash\" is. Your balances plus your outbox represent the part of your account that you and the server have agreed upon. Your inbox is changed without your knowledge, but the server needs your signed permission to change your outbox (do a spend) or your balances. Since your outbox might get large, instead of sending the entire contents back and forth every time you do a spend, or acknowledge the acceptance (or rejection) of a spend by a recipient, you compute a hash of your outbox, and send that instead, and the server responds with an acknowledgement of that outbox hash (thank you to Patrick Chkoreff for this idea).Actual messages sent:Spammer (likely via an automated client): Hey server. Here's a new request number. Give me a transaction number please.\nSigned: SpammerServer: Here's a new transaction number.\nSigned: ServerSpammer: Hey server. Here's that transaction number you gave me. Please spend 0 usage tokens to Bob's ID, with a message of, \"Go all night. Visit BuyViagra.com.\" I'm paying 2 usage tokens as a transaction fee, which I'll get back when Bob accepts the spend. My balance after this transaction will be 2425 usage tokens. My outbox hash after this transaction will be Z.\nSigned: SpammerServer: I processed your spend of 0 usage tokens to Bob's ID. I agree that the transaction fee at the time of this transaction is 2 usage tokens, and that your balance after this transaction is 2425 usage tokens. I agree with you on your outbox hash.\nSigned: ServerBob: Hello server. Here's my ID and a new request number. What's in my inbox?\nSigned: BobServer: Your inbox contains a 0 usage token spend from Spammer with a message of, \"Go all night. Visit BuyViagra.com.\" Here are two transaction numbers you can use to accept these spends and do a spend yourself.\nSigned: ServerBob: Here's my ID and the first of the transaction numbers you gave me. Reject the spend from Spammer with a message of, \"Thanks for the tokens\", and give me the two usage tokens he paid to send that spam. My balance after this transaction will be 41 usage tokens.\nSigned: BobServer: I've rejected the spend from Spammer. I agree that your balance after this transaction is 41 usage tokens.\nSigned: ServerSpends can be rejected. The amount spent goes back to the spender, but the recipient pockets the transaction fee. Zero spends use Truledger as a simple messaging service. But not a free one, unless the recipient wants the message. IMHO, spam exists largely because it is nearly free to send email. In a system where each spam message costs 2 usage tokens, cheap but not free, I doubt it will be much of a problem. Time will tell.Actual messages sent:Bob: Hey server. Here's a new request number. Give me a transaction number please.\nSigned: BobServer: Here's a new transaction number.\nSigned: ServerBob: Hey server. Here's that transaction number you gave me. Please register a new asset named \"Bob GoldGrams\". It has a scale of 7 and a precision of 3. Its ID is <bobggid>. My balance after this transaction will be 39 usage tokens and -1 <bobggid>.Server: I have registered the new \"Bob GoldGrams\" asset. I agree that your balance after this transaction is 39 usage tokens and -1 <bobggid>.Like Loom, Truledger allows customers to create their own asset types. Then, if they can convince them to do so, other customers can trade in that asset type. The ID of a Truledger asset is the sha1 hash of the creator's ID, its scale, its precision, and its name. But the message the customer signs to create the asset, and that the server signs to acknowledge creation, also contains the serverid. This allows the asset to be registered at multiple servers, with the same ID, but makes each particular registration specific to a specific server. Hence, it makes sense for an asset issuer to provide a service of transferring his holdings of his asset between servers at which he's registered; it's self-evident that Bob GoldGrams at Server A are the same asset as Bob GoldGrams at server B.I plan to support transfer of asset issuance, but I haven't figured out the intricacies yet.Like Loom, all amounts in Truledger are stored as integers. The scale value controls where the decimal point goes in the real-world representation of that value: move it left by scale places. The precision controls the minimum number of decimal places that are printed. So with a scale of 7 and a precision of 3, the value 12000000 will be printed by Truledger clients as 1.200, and the minimum value for Bob's new currency is 0.0000001, one ten-millionth of a gram of gold, or $0.000003 at $30/gram: 3 ten-thousandths of a cent. Hello micropayments.Also like Loom, the sum of all the amounts, in accounts and outboxes, for one asset type is -1. There is one negative balance, owned by the issuer, who can spend as much as he wants, and a bunch of positive balances, and outbox entries. A -1 balance in the issuer's account means there are no outstanding balances or outbox entries in that asset, so that's where Bob's Bob GoldGrams balance begins. Users of an asset have to trust the issuer when he tells them, outside of Truledger, that his asset is backed by something of real value, and that he'll never issue more of the virtual asset than he has in the backing commodity. Well, unless he wants to act like a country, and issue fiat currency that is backed by his Full Faith and Credit and nothing else. Good luck getting people to go for that.Actual messages sent:Bob: Hey server. Here's a new request number. Give me a transaction number please.\nSigned: BobServer: Here's a new transaction number.\nSigned: ServerBob: Hey server. Here's that transaction number you gave me. Make a zero spend to myself. My balance after the transaction will be 38 usage tokens, -311.0347681 Bob GoldGrams in my default sub-account, and 311.034768 Bob GoldGrams in my \"Gun Safe\" sub-account.Server: I did that spend. I agree with you that after the transaction, your balance is 38 usages tokens, -311.0347681 Bob GoldGrams in your default account, and 311.034768 Bob GoldGrams in your \"Gun Safe\" sub-account.Bob: Hey server. Here's a new request number. Give me a transaction number please.\nSigned: BobServer: Here's a new transaction number.\nSigned: ServerBob: Hey server. Here's that transaction number you gave me. Please spend 2.4056304 Bob GoldGrams to Sue, with a message of, \"Well, I finally issued my new currency, backed by Krugerands in my gun safe. I'm giving you a gram in thanks for turning me on to Truledger, and 1.4056304 grams for 36 Capulin Coffee Units, which you said you'd sell me, so I can buy more of Daniel Fourwinds' fine coffee that we relished at your house the other day. I used a gold price of $796.60/ounce, Kitco's bid price this morning.\" My transaction fee will be 2 usage tokens. My balance after this transaction will be 36 usage tokens, and 309.6291376 Bob GoldGrams in my \"Gun Safe\" sub-account. My outbox hash after this transaction will be A.\nSigned: BobServer: I have done your spend of 2.4056304 Bob GoldGrams to Sue, with your message, and a transaction fee of 2 usage tokens. I agree that your balance after this transaction is 36 usage tokens, and 309.6291376 Bob GoldGrams in your \"Gun Safe\" sub-account. I agree on the outbox hash.\nSigned: ServerTruledger supports splitting up your balances into multiple \"sub-accounts\". Much like a conventional server gives you a checking account and a savings account, you can use these sub-accounts to help manage your assets. You can have as many of them as you wish, limited only by having usage tokens to pay for the files.Bob has decided to keep track of his Bob GoldGrams assets with a \"Gun Safe\" sub-account, with a balance recording how many grams of the gold in his safe have not yet been put into circulation. He seeds it with 10 ounces of gold, the part of his holdings that he's willing to sell. Then he spends some of it to Sue, asking for enough Capulin Coffee Units for two pounds of Capulin Coffee ($17.95 per pound, shipped).Note that you don't have to mention all of your balances with every spend. You only mention the balances that change. Also notice that there's no transaction fee for spends to yourself. Moving assets between your sub-accounts costs only tokens for new files. No need for the outbox and inbox stuff.Actual messages sent:To be doneTo be doneCopyright \u00a9 2008 Bill St. Clair, All Rights Reserved."}
{"prompt": "A Cypherpunk's Manifesto", "completion": "Privacy is necessary for an open society in the electronic age. Privacy is not secrecy. A private matter is something one doesn't want the whole world to know, but a secret matter is something one doesn't want anybody to know. Privacy is the power to selectively reveal oneself to the world.If two parties have some sort of dealings, then each has a memory of their interaction. Each party can speak about their own memory of this; how could anyone prevent it? One could pass laws against it, but the freedom of speech, even more than privacy, is fundamental to an open society; we seek not to restrict any speech at all. If many parties speak together in the same forum, each can speak to all the others and aggregate together knowledge about individuals and other parties. The power of electronic communications has enabled such group speech, and it will not go away merely because we might want it to.Since we desire privacy, we must ensure that each party to a transaction have knowledge only of that which is directly necessary for that transaction. Since any information can be spoken of, we must ensure that we reveal as little as possible. In most cases personal identity is not salient. When I purchase a magazine at a store and hand cash to the clerk, there is no need to know who I am. When I ask my electronic mail provider to send and receive messages, my provider need not know to whom I am speaking or what I am saying or what others are saying to me; my provider only need know how to get the message there and how much I owe them in fees. When my identity is revealed by the underlying mechanism of the transaction, I have no privacy. I cannot here selectively reveal myself; I must _always_ reveal myself.Therefore, privacy in an open society requires anonymous transaction systems. Until now, cash has been the primary such system. An anonymous transaction system is not a secret transaction system. An anonymous system empowers individuals to reveal their identity when desired and only when desired; this is the essence of privacy.Privacy in an open society also requires cryptography. If I say something, I want it heard only by those for whom I intend it. If the content of my speech is available to the world, I have no privacy. To encrypt is to indicate the desire for privacy, and to encrypt with weak cryptography is to indicate not too much desire for privacy. Furthermore, to reveal one's identity with assurance when the default is anonymity requires the cryptographic signature.We cannot expect governments, corporations, or other large, faceless organizations to grant us privacy out of their beneficence. It is to their advantage to speak of us, and we should expect that they will speak. To try to prevent their speech is to fight against the realities of information. Information does not just want to be free, it longs to be free. Information expands to fill the available storage space. Information is Rumor's younger, stronger cousin; Information is fleeter of foot, has more eyes, knows more, and understands less than Rumor.We must defend our own privacy if we expect to have any. We must come together and create systems which allow anonymous transactions to take place. People have been defending their own privacy for centuries with whispers, darkness, envelopes, closed doors, secret handshakes, and couriers. The technologies of the past did not allow for strong privacy, but electronic technologies do.We the Cypherpunks are dedicated to building anonymous systems. We are defending our privacy with cryptography, with anonymous mail forwarding systems, with digital signatures, and with electronic money.Cypherpunks write code. We know that someone has to write software to defend privacy, and since we can't get privacy unless we all do, we're going to write it. We publish our code so that our fellow Cypherpunks may practice and play with it. Our code is free for all to use, worldwide. We don't much care if you don't approve of the software we write. We know that software can't be destroyed and that a widely dispersed system can't be shut down.Cypherpunks deplore regulations on cryptography, for encryption is fundamentally a private act. The act of encryption, in fact, removes information from the public realm. Even laws against cryptography reach only so far as a nation's border and the arm of its violence. Cryptography will ineluctably spread over the whole globe, and with it the anonymous transactions systems that it makes possible.For privacy to be widespread it must be part of a social contract. People must come and together deploy these systems for the common good. Privacy only extends so far as the cooperation of one's fellows in society. We the Cypherpunks seek your questions and your concerns and hope we may engage you so that we do not deceive ourselves. We will not, however, be moved out of our course because some may disagree with our goals.The Cypherpunks are actively engaged in making the networks safer for privacy. Let us proceed together apace.Onward.Eric Hughes"}
{"prompt": "The Right to Read: A Dystopian Short Story", "completion": "From The Road to Tycho, a collection of articles about the antecedents of the Lunarian Revolution, published in Luna City in 2096.For Dan Halbert, the road to Tycho began in college\u2014when Lissa Lenz asked to borrow his computer. Hers had broken down, and unless she could borrow another, she would fail her midterm project. There was no one she dared ask, except Dan.This put Dan in a dilemma. He had to help her\u2014but if he lent her his computer, she might read his books. Aside from the fact that you could go to prison for many years for letting someone else read your books, the very idea shocked him at first. Like everyone, he had been taught since elementary school that sharing books was nasty and wrong\u2014something that only pirates would do.And there wasn't much chance that the SPA\u2014the Software Protection Authority\u2014would fail to catch him. In his software class, Dan had learned that each book had a copyright monitor that reported when and where it was read, and by whom, to Central Licensing. (They used this information to catch reading pirates, but also to sell personal interest profiles to retailers.) The next time his computer was networked, Central Licensing would find out. He, as computer owner, would receive the harshest punishment\u2014for not taking pains to prevent the crime.Of course, Lissa did not necessarily intend to read his books. She might want the computer only to write her midterm. But Dan knew she came from a middle-class family and could hardly afford the tuition, let alone her reading fees. Reading his books might be the only way she could graduate. He understood this situation; he himself had had to borrow to pay for all the research papers he read. (Ten percent of those fees went to the researchers who wrote the papers; since Dan aimed for an academic career, he could hope that his own research papers, if frequently referenced, would bring in enough to repay this loan.)Later on, Dan would learn there was a time when anyone could go to the library and read journal articles, and even books, without having to pay. There were independent scholars who read thousands of pages without government library grants. But in the 1990s, both commercial and nonprofit journal publishers had begun charging fees for access. By 2047, libraries offering free public access to scholarly literature were a dim memory.There were ways, of course, to get around the SPA and Central Licensing. They were themselves illegal. Dan had had a classmate in software, Frank Martucci, who had obtained an illicit debugging tool, and used it to skip over the copyright monitor code when reading books. But he had told too many friends about it, and one of them turned him in to the SPA for a reward (students deep in debt were easily tempted into betrayal). In 2047, Frank was in prison, not for pirate reading, but for possessing a debugger.Dan would later learn that there was a time when anyone could have debugging tools. There were even free debugging tools available on CD or downloadable over the net. But ordinary users started using them to bypass copyright monitors, and eventually a judge ruled that this had become their principal use in actual practice. This meant they were illegal; the debuggers' developers were sent to prison.Programmers still needed debugging tools, of course, but debugger vendors in 2047 distributed numbered copies only, and only to officially licensed and bonded programmers. The debugger Dan used in software class was kept behind a special firewall so that it could be used only for class exercises.It was also possible to bypass the copyright monitors by installing a modified system kernel. Dan would eventually find out about the free kernels, even entire free operating systems, that had existed around the turn of the century. But not only were they illegal, like debuggers\u2014you could not install one if you had one, without knowing your computer's root password. And neither the FBI nor Microsoft Support would tell you that.Dan concluded that he couldn't simply lend Lissa his computer. But he couldn't refuse to help her, because he loved her. Every chance to speak with her filled him with delight. And that she chose him to ask for help, that could mean she loved him too.Dan resolved the dilemma by doing something even more unthinkable\u2014he lent her the computer, and told her his password. This way, if Lissa read his books, Central Licensing would think he was reading them. It was still a crime, but the SPA would not automatically find out about it. They would only find out if Lissa reported him.Of course, if the school ever found out that he had given Lissa his own password, it would be curtains for both of them as students, regardless of what she had used it for. School policy was that any interference with their means of monitoring students' computer use was grounds for disciplinary action. It didn't matter whether you did anything harmful\u2014the offense was making it hard for the administrators to check on you. They assumed this meant you were doing something else forbidden, and they did not need to know what it was.Students were not usually expelled for this\u2014not directly. Instead they were banned from the school computer systems, and would inevitably fail all their classes.Later, Dan would learn that this kind of university policy started only in the 1980s, when university students in large numbers began using computers. Previously, universities maintained a different approach to student discipline; they punished activities that were harmful, not those that merely raised suspicion.Lissa did not report Dan to the SPA. His decision to help her led to their marriage, and also led them to question what they had been taught about piracy as children. The couple began reading about the history of copyright, about the Soviet Union and its restrictions on copying, and even the original United States Constitution. They moved to Luna, where they found others who had likewise gravitated away from the long arm of the SPA. When the Tycho Uprising began in 2062, the universal right to read soon became one of its central aims.This note has been updated several times since the first publication of the story.The right to read is a battle being fought today. Although it may take 50 years for our present way of life to fade into obscurity, most of the specific laws and practices described above have already been proposed; many have been enacted into law in the US and elsewhere. In the US, the 1998 Digital Millennium Copyright Act (DMCA) established the legal basis to restrict the reading and lending of computerized books (and other works as well). The European Union imposed similar restrictions in a 2001 copyright directive. In France, under the DADVSI law adopted in 2006, mere possession of a copy of DeCSS, the free program to decrypt video on a DVD, is a crime.In 2001, Disney-funded Senator Hollings proposed a bill called the SSSCA that would require every new computer to have mandatory copy-restriction facilities that the user cannot bypass. Following the Clipper chip and similar US government key-escrow proposals, this shows a long-term trend: computer systems are increasingly set up to give absentees with clout control over the people actually using the computer system. The SSSCA was later renamed to the unpronounceable CBDTPA, which was glossed as the \"Consume But Don't Try Programming Act.\"The Republicans took control of the US senate shortly thereafter. They are less tied to Hollywood than the Democrats, so they did not press these proposals. Now that the Democrats are back in control, the danger is once again higher.In 2001 the US began attempting to use the proposed Free Trade Area of the Americas (FTAA) treaty to impose the same rules on all the countries in the Western Hemisphere. The FTAA is one of the so-called free trade treaties, which are actually designed to give business increased power over democratic governments; imposing laws like the DMCA is typical of this spirit. The FTAA was effectively killed by Lula, President of Brazil, who rejected the DMCA requirement and others.Since then, the US has imposed similar requirements on countries such as Australia and Mexico through bilateral \"free trade\" agreements, and on countries such as Costa Rica through another treaty, CAFTA. Ecuador's President Correa refused to sign a \"free trade\" agreement with the US, but I've heard Ecuador had adopted something like the DMCA in 2003.One of the ideas in the story was not proposed in reality until 2002. This is the idea that the FBI and Microsoft will keep the root passwords for your personal computers, and not let you have them.The proponents of this scheme have given it names such as \"trusted computing\" and \"Palladium.\" We call it treacherous computing\" because the effect is to make your computer obey companies even to the extent of disobeying and defying you. This was implemented in 2007 as part of Windows Vista; we expect Apple to do something similar. In this scheme, it is the manufacturer that keeps the secret code, but the FBI would have little trouble getting it.What Microsoft keeps is not exactly a password in the traditional sense; no person ever types it on a terminal. Rather, it is a signature and encryption key that corresponds to a second key stored in your computer. This enables Microsoft, and potentially any web sites that cooperate with Microsoft, the ultimate control over what the user can do on his own computer.Vista also gives Microsoft additional powers; for instance, Microsoft can forcibly install upgrades, and it can order all machines running Vista to refuse to run a certain device driver. The main purpose of Vista's many restrictions is to impose DRM (Digital Restrictions Management) that users can't overcome. The threat of DRM is why we have established the Defective by Design campaign.When this story was first written, the SPA was threatening small Internet service providers, demanding they permit the SPA to monitor all users. Most ISPs surrendered when threatened, because they cannot afford to fight back in court. One ISP, Community ConneXion in Oakland, California, refused the demand and was actually sued. The SPA later dropped the suit, but obtained the DMCA, which gave them the power they sought.The SPA, which actually stands for Software Publishers Association, has been replaced in its police-like role by the Business Software Alliance. The BSA is not, today, an official police force; unofficially, it acts like one. Using methods reminiscent of the erstwhile Soviet Union, it invites people to inform on their coworkers and friends. A BSA terror campaign in Argentina in 2001 made slightly veiled threats that people sharing software would be raped.The university security policies described above are not imaginary. For example, a computer at one Chicago-area university displayed this message upon login:This is an interesting approach to the Fourth Amendment: pressure most everyone to agree, in advance, to waive their rights under it.The battle for the right to read is already in progress. The enemy is organized, while we are not, so it is going against us. Here are articles about bad things that have happened since the original publication of this article.If we want to stop the bad news and create some good news, we need to organize and fight. The FSF's Defective by Design campaign has made a start \u2014 subscribe to the campaign's mailing list to lend a hand. And join the FSF to help fund our work.The Free Software Foundation is the principal organizational sponsor of the GNU Operating System. Their mission is to preserve, protect and promote the freedom to use, study, copy, modify, and redistribute computer software, and to defend the rights of Free Software users.Copyright \u00a9 1996, 2002, 2007, 2009, 2010 Richard Stallman\nThis essay was written in 1996 and was published in Communications of the ACM, vol. 40, n. 2, February 1997."}
{"prompt": "Areopagitica;\nA Speech of Mr. John Milton\nFor the Liberty of Unlicens'd Printing,\nto the Parliament of England", "completion": "This is true liberty, when free-born men,\nHaving to advise the public, may speak free,\nWhich he who can, and will, deserves high praise;\nWho neither can, nor will, may hold his peace:\nWhat can be juster in a state than this?They, who to states and governors of the Commonwealth direct their speech, High Court of Parliament, or, wanting such accesse in a private condition, write that which they foresee may advance the publick good; I suppose them, as at the beginning of no mean endeavour, not a little alter'd and mov'd inwardly in their mindes: some with doubt of what will be the successe, others with fear of what will be the censure; some with hope, others with confidence of what they have to speake. And me perhaps each of these dispositions, as the subject was whereon I enter'd, may have at other times variously affected; and likely might in these foremost expressions now also disclose which of them sway'd most, but that the very attempt of this address thus made, and the thought of whom it hath recourse to, hath got the power within me to a passion, farre more welcome than incidental to a preface.Which though I stay not to confesse ere any aske, I shall be blamelesse, if it be no other than the joy and gratulation which it brings to all who wish and promote their country's liberty; whereof this whole discourse proposed will be a certain testimony, if not a trophy. For this is not the liberty which we can hope, that no grievance ever should arise in the Commonwealth--that let no man in this world expect; but when complaints are freely heard, deeply considered and speedily reformed, then is the utmost bound of civil liberty attained that wise men look for. To which if I now manifest by the very sound of this which I shall utter, that we are already in good part arrived, and yet from such a steep disadvantage of tyranny and superstition grounded into our principles as was beyond the manhood of a Roman recovery, it will be attributed first, as is most due, to the strong assistance of God our deliverer, next to your faithful guidance and undaunted wisdom, Lords and Commons of England. Neither is it in God's esteem the diminution of his glory, when honourable things are spoken of good men and worthy magistrates; which if I now first should begin to do, after so fair a progress of your laudable deeds, and such a long obligement upon the whole realm to your indefatigable virtues, I might be justly reckoned among the tardiest, and the unwillingest of them that praise ye.Nevertheless there being three principal things, without which all praising is but courtship and flattery: First, when that only is praised which is solidly worth praise: next, when greatest likelihoods are brought that such things are truly and really in those persons to whom they are ascribed: the other, when he who praises, by showing that such his actual persuasion is of whom he writes, can demonstrate that he flatters not; the former two of these I have heretofore endeavour'd, rescuing the employment from him who went about to impair your merits with a trivial and malignant encomium; the latter as belonging chiefly to mine own acquittal, that whom I so extolled I did not flatter, hath been reserved opportunely to this occasion.For he who freely magnifies what hath been nobly done, and fears not to declare as freely what might be done better, gives ye the best covenant of his fidelity; and that his loyalest affection and his hope waits on your proceedings. His highest praising is not flattery, and his plainest advice is a kind of praising. For though I should affirm and hold by argument, that it would fare better with truth, with learning and the Commonwealth, if one of your published Orders, which I should name, were called in; yet at the same time it could not but much redound to the lustre of your mild and equal government, whenas private persons are hereby animated to think ye better pleased with public advice, than other statists have been delighted heretofore with public flattery. And men will then see what difference there is between the magnanimity of a triennial Parliament, and that jealous haughtiness of prelates and cabin counsellors that usurped of late, whenas they shall observe ye in the midst of your victories and successes more gently brooking written exceptions against a voted Order than other courts, which had produced nothing worth memory but the weak ostentation of wealth, would have endured the least signified dislike at any sudden proclamation.If I should thus far presume upon the meek demeanour of your civil and gentle greatness, Lords and Commons, as what your published Order hath directly said, that to gainsay, I might defend myself with ease, if any should accuse me of being new or insolent, did they but know how much better I find ye esteem it to imitate the old and elegant humanity of Greece, than the barbaric pride of a Hunnish and Norwegian stateliness. And out of those ages, to whose polite wisdom and letters we owe that we are not yet Goths and Jutlanders, I could name him who from his private house wrote that discourse to the Parliament of Athens, that persuades them to change the form of democracy which was then established. Such honour was done in those days to men who professed the study of wisdom and eloquence, not only in their own country, but in other lands, that cities and signiories heard them gladly, and with great respect, if they had aught in public to admonish the state. Thus did Dion Prusaeus, a stranger and a private orator, counsel the Rhodians against a former edict; and I abound with other like examples, which to set here would be superfluous.But if from the industry of a life wholly dedicated to studious labours, and those natural endowments haply not the worst for two and fifty degrees of northern latitude, so much must be derogated, as to count me not equal to any of those who had this privilege, I would obtain to be thought not so inferior, as yourselves are superior to the most of them who received their counsel: and how far you excel them, be assured, Lords and Commons, there can no greater testimony appear, than when your prudent spirit acknowledges and obeys the voice of reason from what quarter soever it be heard speaking; and renders ye as willing to repeal any Act of your own setting forth, as any set forth by your predecessors.If ye be thus resolved, as it were injury to think ye were not, I know not what should withhold me from presenting ye with a fit instance wherein to show both that love of truth which ye eminently profess, and that uprightness of your judgment which is not wont to be partial to yourselves; by judging over again that Order which ye have ordained to regulate printing:--that no book, pamphlet, or paper shall be henceforth printed, unless the same be first approved and licensed by such, or at least one of such, as shall be thereto appointed. For that part which preserves justly every man's copy to himself, or provides for the poor, I touch not, only wish they be not made pretences to abuse and persecute honest and painful men, who offend not in either of these particulars. But that other clause of licensing books, which we thought had died with his brother quadragesimal and matrimonial when the prelates expired, I shall now attend with such a homily, as shall lay before ye, first the inventors of it to be those whom ye will be loath to own; next what is to be thought in general of reading, whatever sort the books be; and that this Order avails nothing to the suppressing of scandalous, seditious, and libellous books, which were mainly intended to be suppressed. Last, that it will be primely to the discouragement of all learning, and the stop of truth, not only by disexercising and blunting our abilities in what we know already, but by hindering and cropping the discovery that might be yet further made both in religious and civil wisdom.I deny not, but that it is of greatest concernment in the Church and Commonwealth, to have a vigilant eye how books demean themselves as well as men; and thereafter to confine, imprison, and do sharpest justice on them as malefactors. For books are not absolutely dead things, but do contain a potency of life in them to be as active as that soul was whose progeny they are; nay, they do preserve as in a vial the purest efficacy and extraction of that living intellect that bred them. I know they are as lively, and as vigorously productive, as those fabulous dragon's teeth; and being sown up and down, may chance to spring up armed men. And yet, on the other hand, unless wariness be used, as good almost kill a man as kill a good book. Who kills a man kills a reasonable creature, God's image; but he who destroys a good book, kills reason itself, kills the image of God, as it were in the eye. Many a man lives a burden to the earth; but a good book is the precious life-blood of a master spirit, embalmed and treasured up on purpose to a life beyond life. 'Tis true, no age can restore a life, whereof perhaps there is no great loss; and revolutions of ages do not oft recover the loss of a rejected truth, for the want of which whole nations fare the worse.We should be wary therefore what persecution we raise against the living labours of public men, how we spill that seasoned life of man, preserved and stored up in books; since we see a kind of homicide may be thus committed, sometimes a martyrdom, and if it extend to the whole impression, a kind of massacre; whereof the execution ends not in the slaying of an elemental life, but strikes at that ethereal and fifth essence, the breath of reason itself, slays an immortality rather than a life. But lest I should be condemned of introducing license, while I oppose licensing, I refuse not the pains to be so much historical, as will serve to show what hath been done by ancient and famous commonwealths against this disorder, till the very time that this project of licensing crept out of the Inquisition, was catched up by our prelates, and hath caught some of our presbyters.In Athens, where books and wits were ever busier than in any other part of Greece, I find but only two sorts of writings which the magistrate cared to take notice of; those either blasphemous and atheistical, or libellous. Thus the books of Protagoras were by the judges of Areopagus commanded to be burnt, and himself banished the territory for a discourse begun with his confessing not to know WHETHER THERE WERE GODS, OR WHETHER NOT. And against defaming, it was decreed that none should be traduced by name, as was the manner of Vetus Comoedia, whereby we may guess how they censured libelling. And this course was quick enough, as Cicero writes, to quell both the desperate wits of other atheists, and the open way of defaming, as the event showed. Of other sects and opinions, though tending to voluptuousness, and the denying of divine Providence, they took no heed.Therefore we do not read that either Epicurus, or that libertine school of Cyrene, or what the Cynic impudence uttered, was ever questioned by the laws. Neither is it recorded that the writings of those old comedians were suppressed, though the acting of them were forbid; and that Plato commended the reading of Aristophanes, the loosest of them all, to his royal scholar Dionysius, is commonly known, and may be excused, if holy Chrysostom, as is reported, nightly studied so much the same author and had the art to cleanse a scurrilous vehemence into the style of a rousing sermon.That other leading city of Greece, Lacedaemon, considering that Lycurgus their lawgiver was so addicted to elegant learning, as to have been the first that brought out of Ionia the scattered works of Homer, and sent the poet Thales from Crete to prepare and mollify the Spartan surliness with his smooth songs and odes, the better to plant among them law and civility, it is to be wondered how museless and unbookish they were, minding nought but the feats of war. There needed no licensing of books among them, for they disliked all but their own laconic apophthegms, and took a slight occasion to chase Archilochus out of their city, perhaps for composing in a higher strain than their own soldierly ballads and roundels could reach to. Or if it were for his broad verses, they were not therein so cautious but they were as dissolute in their promiscuous conversing; whence Euripides affirms in Andromache, that their women were all unchaste. Thus much may give us light after what sort of books were prohibited among the Greeks.The Romans also, for many ages trained up only to a military roughness resembling most the Lacedaemonian guise, knew of learning little but what their twelve Tables, and the Pontific College with their augurs and flamens taught them in religion and law; so unacquainted with other learning, that when Carneades and Critolaus, with the Stoic Diogenes, coming ambassadors to Rome, took thereby occasion to give the city a taste of their philosophy, they were suspected for seducers by no less a man than Cato the Censor, who moved it in the Senate to dismiss them speedily, and to banish all such Attic babblers out of Italy. But Scipio and others of the noblest senators withstood him and his old Sabine austerity; honoured and admired the men; and the censor himself at last, in his old age, fell to the study of that whereof before he was so scrupulous. And yet at the same time Naevius and Plautus, the first Latin comedians, had filled the city with all the borrowed scenes of Menander and Philemon. Then began to be considered there also what was to be done to libellous books and authors; for Naevius was quickly cast into prison for his unbridled pen, and released by the tribunes upon his recantation; we read also that libels were burnt, and the makers punished by Augustus. The like severity, no doubt, was used, if aught were impiously written against their esteemed gods. Except in these two points, how the world went in books, the magistrate kept no reckoning.And therefore Lucretius without impeachment versifies his Epicurism to Memmius, and had the honour to be set forth the second time by Cicero, so great a father of the Commonwealth; although himself disputes against that opinion in his own writings. Nor was the satirical sharpness or naked plainness of Lucilius, or Catullus, or Flaccus, by any order prohibited. And for matters of state, the story of Titus Livius, though it extolled that part which Pompey held, was not therefore suppressed by Octavius Caesar of the other faction. But that Naso was by him banished in his old age, for the wanton poems of his youth, was but a mere covert of state over some secret cause: and besides, the books were neither banished nor called in. From hence we shall meet with little else but tyranny in the Roman empire, that we may not marvel, if not so often bad as good books were silenced. I shall therefore deem to have been large enough, in producing what among the ancients was punishable to write; save only which, all other arguments were free to treat on.By this time the emperors were become Christians, whose discipline in this point I do not find to have been more severe than what was formerly in practice. The books of those whom they took to be grand heretics were examined, refuted, and condemned in the general Councils; and not till then were prohibited, or burnt, by authority of the emperor. As for the writings of heathen authors, unless they were plain invectives against Christianity, as those of Porphyrius and Proclus, they met with no interdict that can be cited, till about the year 400, in a Carthaginian Council, wherein bishops themselves were forbid to read the books of Gentiles, but heresies they might read: while others long before them, on the contrary, scrupled more the books of heretics than of Gentiles. And that the primitive Councils and bishops were wont only to declare what books were not commendable, passing no further, but leaving it to each one's conscience to read or to lay by, till after the year 800, is observed already by Padre Paolo, the great unmasker of the Trentine Council.After which time the Popes of Rome, engrossing what they pleased of political rule into their own hands, extended their dominion over men's eyes, as they had before over their judgments, burning and prohibiting to be read what they fancied not; yet sparing in their censures, and the books not many which they so dealt with: till Martin V., by his bull, not only prohibited, but was the first that excommunicated the reading of heretical books; for about that time Wickliffe and Huss, growing terrible, were they who first drove the Papal Court to a stricter policy of prohibiting. Which course Leo X. and his successors followed, until the Council of Trent and the Spanish Inquisition engendering together brought forth, or perfected, those Catalogues and expurging Indexes, that rake through the entrails of many an old good author, with a violation worse than any could be offered to his tomb. Nor did they stay in matters heretical, but any subject that was not to their palate, they either condemned in a Prohibition, or had it straight into the new purgatory of an index.To fill up the measure of encroachment, their last invention was to ordain that no book, pamphlet, or paper should be printed (as if St. Peter had bequeathed them the keys of the press also out of Paradise) unless it were approved and licensed under the hands of two or three glutton friars. For example:Let the Chancellor Cini be pleased to see if in this present work be contained aught that may withstand the printing.I have seen this present work, and find nothing athwart the Catholic faith and good manners: in witness whereof I have given, etc.Attending the precedent relation, it is allowed that this present work of Davanzati may be printed.It may be printed, July 15.Sure they have a conceit, if he of the bottomless pit had not long since broke prison, that this quadruple exorcism would bar him down. I fear their next design will be to get into their custody the licensing of that which they say Claudius intended, but went not through with. Vouchsafe to see another of their forms, the Roman stamp:Imprimatur, If it seem good to the reverend Master of the Holy Palace.ImprimaturasdfasdfSometimes five Imprimaturs are seen together dialogue-wise in the piazza of one title-page, complimenting and ducking each to other with their shaven reverences, whether the author, who stands by in perplexity at the foot of his epistle, shall to the press or to the sponge. These are the pretty responsories, these are the dear antiphonies, that so bewitched of late our prelates and their chaplains with the goodly echo they made; and besotted us to the gay imitation of a lordly Imprimatur, one from Lambeth House, another from the west end of Paul's; so apishly Romanizing, that the word of command still was set down in Latin; as if the learned grammatical pen that wrote it would cast no ink without Latin; or perhaps, as they thought, because no vulgar tongue was worthy to express the pure conceit of an Imprimatur, but rather, as I hope, for that our English, the language of men ever famous and foremost in the achievements of liberty, will not easily find servile letters enow to spell such a dictatory presumption English.And thus ye have the inventors and the original of book-licensing ripped up and drawn as lineally as any pedigree. We have it not, that can be heard of, from any ancient state, or polity or church; nor by any statute left us by our ancestors elder or later; nor from the modern custom of any reformed city or church abroad, but from the most anti-christian council and the most tyrannous inquisition that ever inquired. Till then books were ever as freely admitted into the world as any other birth; the issue of the brain was no more stifled than the issue of the womb: no envious Juno sat cross-legged over the nativity of any man's intellectual offspring; but if it proved a monster, who denies, but that it was justly burnt, or sunk into the sea? But that a book, in worse condition than a peccant soul, should be to stand before a jury ere it be born to the world, and undergo yet in darkness the judgment of Radamanth and his colleagues, ere it can pass the ferry backward into light, was never heard before, till that mysterious iniquity, provoked and troubled at the first entrance of Reformation, sought out new limbos and new hells wherein they might include our books also within the number of their damned. And this was the rare morsel so officiously snatched up, and so ill-favouredly imitated by our inquisiturient bishops, and the attendant minorites their chaplains. That ye like not now these most certain authors of this licensing order, and that all sinister intention was far distant from your thoughts, when ye were importuned the passing it, all men who know the integrity of your actions, and how ye honour truth, will clear ye readily.But some will say, what though the inventors were bad, the thing for all that may be good? It may so; yet if that thing be no such deep invention, but obvious, and easy for any man to light on, and yet best and wisest commonwealths through all ages and occasions have forborne to use it, and falsest seducers and oppressors of men were the first who took it up, and to no other purpose but to obstruct and hinder the first approach of Reformation; I am of those who believe it will be a harder alchemy than Lullius ever knew, to sublimate any good use out of such an invention. Yet this only is what I request to gain from this reason, that it may be held a dangerous and suspicious fruit, as certainly it deserves, for the tree that bore it, until I can dissect one by one the properties it has. But I have first to finish, as was propounded, what is to be thought in general of reading books, whatever sort they be, and whether be more the benefit or the harm that thence proceeds.Not to insist upon the examples of Moses, Daniel, and Paul, who were skilful in all the learning of the Egyptians, Chaldeans, and Greeks, which could not probably be without reading their books of all sorts; in Paul especially, who thought it no defilement to insert into Holy Scripture the sentences of three Greek poets, and one of them a tragedian; the question was notwithstanding sometimes controverted among the primitive doctors, but with great odds on that side which affirmed it both lawful and profitable; as was then evidently perceived, when Julian the Apostate and subtlest enemy to our faith made a decree forbidding Christians the study of heathen learning: for, said he, they wound us with our own weapons, and with our own arts and sciences they overcome us. And indeed the Christians were put so to their shifts by this crafty means, and so much in danger to decline into all ignorance, that the two Apollinarii were fain, as a man may say, to coin all the seven liberal sciences out of the Bible, reducing it into divers forms of orations, poems, dialogues, even to the calculating of a new Christian grammar. But, saith the historian Socrates, the providence of God provided better than the industry of Apollinarius and his son, by taking away that illiterate law with the life of him who devised it. So great an injury they then held it to be deprived of Hellenic learning; and thought it a persecution more undermining, and secretly decaying the Church, than the open cruelty of Decius or Diocletian.And perhaps it was the same politic drift that the devil whipped St. Jerome in a lenten dream, for reading Cicero; or else it was a phantasm bred by the fever which had then seized him. For had an angel been his discipliner, unless it were for dwelling too much upon Ciceronianisms, and had chastised the reading, not the vanity, it had been plainly partial; first to correct him for grave Cicero, and not for scurril Plautus, whom he confesses to have been reading, not long before; next to correct him only, and let so many more ancient fathers wax old in those pleasant and florid studies without the lash of such a tutoring apparition; insomuch that Basil teaches how some good use may be made of Margites, a sportful poem, not now extant, writ by Homer; and why not then of Morgante, an Italian romance much to the same purpose?But if it be agreed we shall be tried by visions, there is a vision recorded by Eusebius, far ancienter than this tale of Jerome, to the nun Eustochium, and, besides, has nothing of a fever in it. Dionysius Alexandrinus was about the year 240 a person of great name in the Church for piety and learning, who had wont to avail himself much against heretics by being conversant in their books; until a certain presbyter laid it scrupulously to his conscience, how he durst venture himself among those defiling volumes. The worthy man, loath to give offence, fell into a new debate with himself what was to be thought; when suddenly a vision sent from God (it is his own epistle that so avers it) confirmed him in these words: READ ANY BOOKS WHATEVER COME TO THY HANDS, FOR THOU ART SUFFICIENT BOTH TO JUDGE ARIGHT AND TO EXAMINE EACH MATTER. To this revelation he assented the sooner, as he confesses, because it was answerable to that of the Apostle to the Thessalonians, PROVE ALL THINGS, HOLD FAST THAT WHICH IS GOOD. And he might have added another remarkable saying of the same author: TO THE PURE, ALL THINGS ARE PURE; not only meats and drinks, but all kind of knowledge whether of good or evil; the knowledge cannot defile, nor consequently the books, if the will and conscience be not defiled.For books are as meats and viands are; some of good, some of evil substance; and yet God, in that unapocryphal vision, said without exception, RISE, PETER, KILL AND EAT, leaving the choice to each man's discretion. Wholesome meats to a vitiated stomach differ little or nothing from unwholesome; and best books to a naughty mind are not unappliable to occasions of evil. Bad meats will scarce breed good nourishment in the healthiest concoction; but herein the difference is of bad books, that they to a discreet and judicious reader serve in many respects to discover, to confute, to forewarn, and to illustrate. Whereof what better witness can ye expect I should produce, than one of your own now sitting in Parliament, the chief of learned men reputed in this land, Mr. Selden; whose volume of natural and national laws proves, not only by great authorities brought together, but by exquisite reasons and theorems almost mathematically demonstrative, that all opinions, yea errors, known, read, and collated, are of main service and assistance toward the speedy attainment of what is truest. I conceive, therefore, that when God did enlarge the universal diet of man's body, saving ever the rules of temperance, he then also, as before, left arbitrary the dieting and repasting of our minds; as wherein every mature man might have to exercise his own leading capacity.How great a virtue is temperance, how much of moment through the whole life of man! Yet God commits the managing so great a trust, without particular law or prescription, wholly to the demeanour of every grown man. And therefore when he himself tabled the Jews from heaven, that omer, which was every man's daily portion of manna, is computed to have been more than might have well sufficed the heartiest feeder thrice as many meals. For those actions which enter into a man, rather than issue out of him, and therefore defile not, God uses not to captivate under a perpetual childhood of prescription, but trusts him with the gift of reason to be his own chooser; there were but little work left for preaching, if law and compulsion should grow so fast upon those things which heretofore were governed only by exhortation. Solomon informs us, that much reading is a weariness to the flesh; but neither he nor other inspired author tells us that such or such reading is unlawful: yet certainly had God thought good to limit us herein, it had been much more expedient to have told us what was unlawful than what was wearisome. As for the burning of those Ephesian books by St. Paul's converts; 'tis replied the books were magic, the Syriac so renders them. It was a private act, a voluntary act, and leaves us to a voluntary imitation: the men in remorse burnt those books which were their own; the magistrate by this example is not appointed; these men practised the books, another might perhaps have read them in some sort usefully.Good and evil we know in the field of this world grow up together almost inseparably; and the knowledge of good is so involved and interwoven with the knowledge of evil, and in so many cunning resemblances hardly to be discerned, that those confused seeds which were imposed upon Psyche as an incessant labour to cull out, and sort asunder, were not more intermixed. It was from out the rind of one apple tasted, that the knowledge of good and evil, as two twins cleaving together, leaped forth into the world. And perhaps this is that doom which Adam fell into of knowing good and evil, that is to say of knowing good by evil. As therefore the state of man now is; what wisdom can there be to choose, what continence to forbear without the knowledge of evil? He that can apprehend and consider vice with all her baits and seeming pleasures, and yet abstain, and yet distinguish, and yet prefer that which is truly better, he is the true warfaring Christian.I cannot praise a fugitive and cloistered virtue, unexercised and unbreathed, that never sallies out and sees her adversary but slinks out of the race, where that immortal garland is to be run for, not without dust and heat. Assuredly we bring not innocence into the world, we bring impurity much rather; that which purifies us is trial, and trial is by what is contrary. That virtue therefore which is but a youngling in the contemplation of evil, and knows not the utmost that vice promises to her followers, and rejects it, is but a blank virtue, not a pure; her whiteness is but an excremental whiteness. Which was the reason why our sage and serious poet Spenser, whom I dare be known to think a better teacher than Scotus or Aquinas, describing true temperance under the person of Guion, brings him in with his palmer through the cave of Mammon, and the bower of earthly bliss, that he might see and know, and yet abstain. Since therefore the knowledge and survey of vice is in this world so necessary to the constituting of human virtue, and the scanning of error to the confirmation of truth, how can we more safely, and with less danger, scout into the regions of sin and falsity than by reading all manner of tractates and hearing all manner of reason? And this is the benefit which may be had of books promiscuously read.But of the harm that may result hence three kinds are usually reckoned. First, is feared the infection that may spread; but then all human learning and controversy in religious points must remove out of the world, yea the Bible itself; for that ofttimes relates blasphemy not nicely, it describes the carnal sense of wicked men not unelegantly, it brings in holiest men passionately murmuring against Providence through all the arguments of Epicurus: in other great disputes it answers dubiously and darkly to the common reader. And ask a Talmudist what ails the modesty of his marginal Keri, that Moses and all the prophets cannot persuade him to pronounce the textual Chetiv. For these causes we all know the Bible itself put by the Papist must be next removed, as Clement of Alexandria, and that Eusebian book of Evangelic preparation, transmitting our ears through a hoard of heathenish obscenities to receive the Gospel. Who finds not that Irenaeus, Epiphanius, Jerome, and others discover more heresies than they well confute, and that oft for heresy which is the truer opinion?Nor boots it to say for these, and all the heathen writers of greatest infection, if it must be thought so, with whom is bound up the life of human learning, that they writ in an unknown tongue, so long as we are sure those languages are known as well to the worst of men, who are both most able and most diligent to instil the poison they suck, first into the courts of princes, acquainting them with the choicest delights and criticisms of sin. As perhaps did that Petronius whom Nero called his Arbiter, the master of his revels; and the notorious ribald of Arezzo, dreaded and yet dear to the Italian courtiers. I name not him for posterity's sake, whom Henry VIII. named in merriment his vicar of hell. By which compendious way all the contagion that foreign books can infuse will find a passage to the people far easier and shorter than an Indian voyage, though it could be sailed either by the north of Cataio eastward, or of Canada westward, while our Spanish licensing gags the English press never so severely.But on the other side that infection which is from books of controversy in religion is more doubtful and dangerous to the learned than to the ignorant; and yet those books must be permitted untouched by the licenser. It will be hard to instance where any ignorant man hath been ever seduced by papistical book in English, unless it were commended and expounded to him by some of that clergy: and indeed all such tractates, whether false or true, are as the prophecy of Isaiah was to the eunuch, not to be UNDERSTOOD WITHOUT A GUIDE. But of our priests and doctors how many have been corrupted by studying the comments of Jesuits and Sorbonists, and how fast they could transfuse that corruption into the people, our experience is both late and sad. It is not forgot, since the acute and distinct Arminius was perverted merely by the perusing of a nameless discourse written at Delft, which at first he took in hand to confute.Seeing, therefore, that those books, and those in great abundance, which are likeliest to taint both life and doctrine, cannot be suppressed without the fall of learning and of all ability in disputation, and that these books of either sort are most and soonest catching to the learned, from whom to the common people whatever is heretical or dissolute may quickly be conveyed, and that evil manners are as perfectly learnt without books a thousand other ways which cannot be stopped, and evil doctrine not with books can propagate, except a teacher guide, which he might also do without writing, and so beyond prohibiting, I am not able to unfold, how this cautelous enterprise of licensing can be exempted from the number of vain and impossible attempts. And he who were pleasantly disposed could not well avoid to liken it to the exploit of that gallant man who thought to pound up the crows by shutting his park gate.Besides another inconvenience, if learned men be the first receivers out of books and dispreaders both of vice and error, how shall the licensers themselves be confided in, unless we can confer upon them, or they assume to themselves above all others in the land, the grace of infallibility and uncorruptedness? And again, if it be true that a wise man, like a good refiner, can gather gold out of the drossiest volume, and that a fool will be a fool with the best book, yea or without book; there is no reason that we should deprive a wise man of any advantage to his wisdom, while we seek to restrain from a fool, that which being restrained will be no hindrance to his folly. For if there should be so much exactness always used to keep that from him which is unfit for his reading, we should in the judgment of Aristotle not only, but of Solomon and of our Saviour, not vouchsafe him good precepts, and by consequence not willingly admit him to good books; as being certain that a wise man will make better use of an idle pamphlet, than a fool will do of sacred Scripture.'Tis next alleged we must not expose ourselves to temptations without necessity, and next to that, not employ our time in vain things. To both these objections one answer will serve, out of the grounds already laid, that to all men such books are not temptations, nor vanities, but useful drugs and materials wherewith to temper and compose effective and strong medicines, which man's life cannot want. The rest, as children and childish men, who have not the art to qualify and prepare these working minerals, well may be exhorted to forbear, but hindered forcibly they cannot be by all the licensing that Sainted Inquisition could ever yet contrive. Which is what I promised to deliver next: that this order of licensing conduces nothing to the end for which it was framed; and hath almost prevented me by being clear already while thus much hath been explaining. See the ingenuity of Truth, who, when she gets a free and willing hand, opens herself faster than the pace of method and discourse can overtake her.It was the task which I began with, to show that no nation, or well-instituted state, if they valued books at all, did ever use this way of licensing; and it might be answered, that this is a piece of prudence lately discovered. To which I return, that as it was a thing slight and obvious to think on, so if it had been difficult to find out, there wanted not among them long since who suggested such a course; which they not following, leave us a pattern of their judgment that it was not the rest knowing, but the not approving, which was the cause of their not using it.Plato, a man of high authority, indeed, but least of all for his Commonwealth, in the book of his Laws, which no city ever yet received, fed his fancy by making many edicts to his airy burgomasters, which they who otherwise admire him wish had been rather buried and excused in the genial cups of an Academic night sitting. By which laws he seems to tolerate no kind of learning but by unalterable decree, consisting most of practical traditions, to the attainment whereof a library of smaller bulk than his own Dialogues would be abundant. And there also enacts, that no poet should so much as read to any private man what he had written, until the judges and law-keepers had seen it, and allowed it. But that Plato meant this law peculiarly to that commonwealth which he had imagined, and to no other, is evident. Why was he not else a lawgiver to himself, but a transgressor, and to be expelled by his own magistrates; both for the wanton epigrams and dialogues which he made, and his perpetual reading of Sophron Mimus and Aristophanes, books of grossest infamy, and also for commending the latter of them, though he were the malicious libeller of his chief friends, to be read by the tyrant Dionysius, who had little need of such trash to spend his time on? But that he knew this licensing of poems had reference and dependence to many other provisos there set down in his fancied republic, which in this world could have no place: and so neither he himself, nor any magistrate or city, ever imitated that course, which, taken apart from those other collateral injunctions, must needs be vain and fruitless. For if they fell upon one kind of strictness, unless their care were equal to regulate all other things of like aptness to corrupt the mind, that single endeavour they knew would be but a fond labour; to shut and fortify one gate against corruption, and be necessitated to leave others round about wide open.If we think to regulate printing, thereby to rectify manners, we must regulate all recreation and pastimes, all that is delightful to man. No music must be heard, no song be set or sung, but what is grave and Doric. There must be licensing dancers, that no gesture, motion, or deportment be taught our youth but what by their allowance shall be thought honest; for such Plato was provided of. It will ask more than the work of twenty licensers to examine all the lutes, the violins, and the guitars in every house; they must not be suffered to prattle as they do, but must be licensed what they may say. And who shall silence all the airs and madrigals that whisper softness in chambers? The windows also, and the balconies must be thought on; there are shrewd books, with dangerous frontispieces, set to sale; who shall prohibit them, shall twenty licensers? The villages also must have their visitors to inquire what lectures the bagpipe and the rebeck reads, even to the ballatry and the gamut of every municipal fiddler, for these are the countryman's Arcadias, and his Monte Mayors.Next, what more national corruption, for which England hears ill abroad, than household gluttony: who shall be the rectors of our daily rioting? And what shall be done to inhibit the multitudes that frequent those houses where drunkenness is sold and harboured? Our garments also should be referred to the licensing of some more sober workmasters to see them cut into a less wanton garb. Who shall regulate all the mixed conversation of our youth, male and female together, as is the fashion of this country? Who shall still appoint what shall be discoursed, what presumed, and no further? Lastly, who shall forbid and separate all idle resort, all evil company? These things will be, and must be; but how they shall be least hurtful, how least enticing, herein consists the grave and governing wisdom of a state.To sequester out of the world into Atlantic and Utopian polities, which never can be drawn into use, will not mend our condition; but to ordain wisely as in this world of evil, in the midst whereof God hath placed us unavoidably. Nor is it Plato's licensing of books will do this, which necessarily pulls along with it so many other kinds of licensing, as will make us all both ridiculous and weary, and yet frustrate; but those unwritten, or at least unconstraining, laws of virtuous education, religious and civil nurture, which Plato there mentions as the bonds and ligaments of the commonwealth, the pillars and the sustainers of every written statute; these they be which will bear chief sway in such matters as these, when all licensing will be easily eluded. Impunity and remissness, for certain, are the bane of a commonwealth; but here the great art lies, to discern in what the law is to bid restraint and punishment, and in what things persuasion only is to work.If every action, which is good or evil in man at ripe years, were to be under pittance and prescription and compulsion, what were virtue but a name, what praise could be then due to well-doing, what gramercy to be sober, just, or continent? Many there be that complain of divine Providence for suffering Adam to transgress; foolish tongues! When God gave him reason, he gave him freedom to choose, for reason is but choosing; he had been else a mere artificial Adam, such an Adam as he is in the motions. We ourselves esteem not of that obedience, or love, or gift, which is of force: God therefore left him free, set before him a provoking object, ever almost in his eyes; herein consisted his merit, herein the right of his reward, the praise of his abstinence. Wherefore did he create passions within us, pleasures round about us, but that these rightly tempered are the very ingredients of virtue?They are not skilful considerers of human things, who imagine to remove sin by removing the matter of sin; for, besides that it is a huge heap increasing under the very act of diminishing, though some part of it may for a time be withdrawn from some persons, it cannot from all, in such a universal thing as books are; and when this is done, yet the sin remains entire. Though ye take from a covetous man all his treasure, he has yet one jewel left, ye cannot bereave him of his covetousness. Banish all objects of lust, shut up all youth into the severest discipline that can be exercised in any hermitage, ye cannot make them chaste, that came not hither so; such great care and wisdom is required to the right managing of this point. Suppose we could expel sin by this means; look how much we thus expel of sin, so much we expel of virtue: for the matter of them both is the same; remove that, and ye remove them both alike.This justifies the high providence of God, who, though he command us temperance, justice, continence, yet pours out before us, even to a profuseness, all desirable things, and gives us minds that can wander beyond all limit and satiety. Why should we then affect a rigour contrary to the manner of God and of nature, by abridging or scanting those means, which books freely permitted are, both to the trial of virtue and the exercise of truth? It would be better done, to learn that the law must needs be frivolous, which goes to restrain things, uncertainly and yet equally working to good and to evil. And were I the chooser, a dream of well-doing should be preferred before many times as much the forcible hindrance of evil-doing. For God sure esteems the growth and completing of one virtuous person more than the restraint of ten vicious.And albeit whatever thing we hear or see, sitting, walking, travelling, or conversing, may be fitly called our book, and is of the same effect that writings are, yet grant the thing to be prohibited were only books, it appears that this Order hitherto is far insufficient to the end which it intends. Do we not see, not once or oftener, but weekly, that continued court-libel against the Parliament and City, printed, as the wet sheets can witness, and dispersed among us, for all that licensing can do? Yet this is the prime service a man would think, wherein this Order should give proof of itself. If it were executed, you'll say. But certain, if execution be remiss or blindfold now, and in this particular, what will it be hereafter and in other books? If then the Order shall not be vain and frustrate, behold a new labour, Lords and Commons, ye must repeal and proscribe all scandalous and unlicensed books already printed and divulged; after ye have drawn them up into a list, that all may know which are condemned, and which not; and ordain that no foreign books be delivered out of custody, till they have been read over. This office will require the whole time of not a few overseers, and those no vulgar men. There be also books which are partly useful and excellent, partly culpable and pernicious; this work will ask as many more officials, to make expurgations and expunctions, that the commonwealth of learning be not damnified. In fine, when the multitude of books increase upon their hands, ye must be fain to catalogue all those printers who are found frequently offending, and forbid the importation of their whole suspected typography. In a word, that this your Order may be exact and not deficient, ye must reform it perfectly according to the model of Trent and Seville, which I know ye abhor to do.Yet though ye should condescend to this, which God forbid, the Order still would be but fruitless and defective to that end whereto ye meant it. If to prevent sects and schisms, who is so unread or so uncatechized in story, that hath not heard of many sects refusing books as a hindrance, and preserving their doctrine unmixed for many ages, only by unwritten traditions? The Christian faith, for that was once a schism, is not unknown to have spread all over Asia, ere any Gospel or Epistle was seen in writing. If the amendment of manners be aimed at, look into Italy and Spain, whether those places be one scruple the better, the honester, the wiser, the chaster, since all the inquisitional rigour that hath been executed upon books.Another reason, whereby to make it plain that this Order will miss the end it seeks, consider by the quality which ought to be in every licenser. It cannot be denied but that he who is made judge to sit upon the birth or death of books, whether they may be wafted into this world or not, had need to be a man above the common measure, both studious, learned, and judicious; there may be else no mean mistakes in the censure of what is passable or not; which is also no mean injury. If he be of such worth as behooves him, there cannot be a more tedious and unpleasing journey-work, a greater loss of time levied upon his head, than to be made the perpetual reader of unchosen books and pamphlets, ofttimes huge volumes. There is no book that is acceptable unless at certain seasons; but to be enjoined the reading of that at all times, and in a hand scarce legible, whereof three pages would not down at any time in the fairest print, is an imposition which I cannot believe how he that values time and his own studies, or is but of a sensible nostril, should be able to endure. In this one thing I crave leave of the present licensers to be pardoned for so thinking; who doubtless took this office up, looking on it through their obedience to the Parliament, whose command perhaps made all things seem easy and unlaborious to them; but that this short trial hath wearied them out already, their own expressions and excuses to them who make so many journeys to solicit their licence are testimony enough. Seeing therefore those who now possess the employment by all evident signs wish themselves well rid of it; and that no man of worth, none that is not a plain unthrift of his own hours, is ever likely to succeed them, except he mean to put himself to the salary of a press corrector; we may easily foresee what kind of licensers we are to expect hereafter, either ignorant, imperious, and remiss, or basely pecuniary. This is what I had to show, wherein this Order cannot conduce to that end whereof it bears the intention.I lastly proceed from the no good it can do, to the manifest hurt it causes, in being first the greatest discouragement and affront that can be offered to learning, and to learned men.It was the complaint and lamentation of prelates, upon every least breath of a motion to remove pluralities, and distribute more equally Church revenues, that then all learning would be for ever dashed and discouraged. But as for that opinion, I never found cause to think that the tenth part of learning stood or fell with the clergy: nor could I ever but hold it for a sordid and unworthy speech of any churchman who had a competency left him. If therefore ye be loath to dishearten utterly and discontent, not the mercenary crew of false pretenders to learning, but the free and ingenuous sort of such as evidently were born to study, and love learning for itself, not for lucre or any other end but the service of God and of truth, and perhaps that lasting fame and perpetuity of praise which God and good men have consented shall be the reward of those whose published labours advance the good of mankind; then know that, so far to distrust the judgment and the honesty of one who hath but a common repute in learning, and never yet offended, as not to count him fit to print his mind without a tutor and examiner, lest he should drop a schism, or something of corruption, is the greatest displeasure and indignity to a free and knowing spirit that can be put upon him.What advantage is it to be a man, over it is to be a boy at school, if we have only escaped the ferula to come under the fescue of an Imprimatur; if serious and elaborate writings, as if they were no more than the theme of a grammar-lad under his pedagogue, must not be uttered without the cursory eyes of a temporizing and extemporizing licenser? He who is not trusted with his own actions, his drift not being known to be evil, and standing to the hazard of law and penalty, has no great argument to think himself reputed in the Commonwealth wherein he was born for other than a fool or a foreigner. When a man writes to the world, he summons up all his reason and deliberation to assist him; he searches, meditates, is industrious, and likely consults and confers with his judicious friends; after all which done he takes himself to be informed in what he writes, as well as any that writ before him. If, in this the most consummate act of his fidelity and ripeness, no years, no industry, no former proof of his abilities can bring him to that state of maturity, as not to be still mistrusted and suspected, unless he carry all his considerate diligence, all his midnight watchings and expense of Palladian oil, to the hasty view of an unleisured licenser, perhaps much his younger, perhaps his inferior in judgment, perhaps one who never knew the labour of bookwriting, and if he be not repulsed or slighted, must appear in print like a puny with his guardian, and his censor's hand on the back of his title to be his bail and surety that he is no idiot or seducer, it cannot be but a dishonour and derogation to the author, to the book, to the privilege and dignity of learning.And what if the author shall be one so copious of fancy, as to have many things well worth the adding come into his mind after licensing, while the book is yet under the press, which not seldom happens to the best and diligentest writers; and that perhaps a dozen times in one book? The printer dares not go beyond his licensed copy; so often then must the author trudge to his leave-giver, that those his new insertions may be viewed; and many a jaunt will be made, ere that licenser, for it must be the same man, can either be found, or found at leisure; meanwhile either the press must stand still, which is no small damage, or the author lose his accuratest thoughts, and send the book forth worse than he had made it, which to a diligent writer is the greatest melancholy and vexation that can befall.And how can a man teach with authority, which is the life of teaching; how can he be a doctor in his book as he ought to be, or else had better be silent, whenas all he teaches, all he delivers, is but under the tuition, under the correction of his patriarchal licenser to blot or alter what precisely accords not with the hidebound humour which he calls his judgment? When every acute reader, upon the first sight of a pedantic licence, will be ready with these like words to ding the book a quoit's distance from him: I hate a pupil teacher, I endure not an instructor that comes to me under the wardship of an overseeing fist. I know nothing of the licenser, but that I have his own hand here for his arrogance; who shall warrant me his judgment? The State, sir, replies the stationer, but has a quick return: The State shall be my governors, but not my critics; they may be mistaken in the choice of a licenser, as easily as this licenser may be mistaken in an author; this is some common stuff; and he might add from Sir Francis Bacon, THAT SUCH AUTHORIZED BOOKS ARE BUT THE LANGUAGE OF THE TIMES. For though a licenser should happen to be judicious more than ordinary, which will be a great jeopardy of the next succession, yet his very office and his commission enjoins him to let pass nothing but what is vulgarly received already.Nay, which is more lamentable, if the work of any deceased author, though never so famous in his lifetime and even to this day, come to their hands for licence to be printed, or reprinted, if there be found in his book one sentence of a venturous edge, uttered in the height of zeal (and who knows whether it might not be the dictate of a divine spirit?) yet not suiting with every low decrepit humour of their own, though it were Knox himself, the reformer of a kingdom, that spake it, they will not pardon him their dash: the sense of that great man shall to all posterity be lost, for the fearfulness or the presumptuous rashness of a perfunctory licenser. And to what an author this violence hath been lately done, and in what book of greatest consequence to be faithfully published, I could now instance, but shall forbear till a more convenient season.Yet if these things be not resented seriously and timely by them who have the remedy in their power, but that such iron-moulds as these shall have authority to gnaw out the choicest periods of exquisitest books, and to commit such a treacherous fraud against the orphan remainders of worthiest men after death, the more sorrow will belong to that hapless race of men, whose misfortune it is to have understanding. Henceforth let no man care to learn, or care to be more than worldly-wise; for certainly in higher matters to be ignorant and slothful, to be a common steadfast dunce, will be the only pleasant life, and only in request.And it is a particular disesteem of every knowing person alive, and most injurious to the written labours and monuments of the dead, so to me it seems an undervaluing and vilifying of the whole nation. I cannot set so light by all the invention, the art, the wit, the grave and solid judgment which is in England, as that it can be comprehended in any twenty capacities how good soever, much less that it should not pass except their superintendence be over it, except it be sifted and strained with their strainers, that it should be uncurrent without their manual stamp. Truth and understanding are not such wares as to be monopolized and traded in by tickets and statutes and standards. We must not think to make a staple commodity of all the knowledge in the land, to mark and licence it like our broadcloth and our woolpacks. What is it but a servitude like that imposed by the Philistines, not to be allowed the sharpening of our own axes and coulters, but we must repair from all quarters to twenty licensing forges? Had anyone written and divulged erroneous things and scandalous to honest life, misusing and forfeiting the esteem had of his reason among men, if after conviction this only censure were adjudged him that he should never henceforth write but what were first examined by an appointed officer, whose hand should be annexed to pass his credit for him that now he might be safely read; it could not be apprehended less than a disgraceful punishment. Whence to include the whole nation, and those that never yet thus offended, under such a diffident and suspectful prohibition, may plainly be understood what a disparagement it is. So much the more, whenas debtors and delinquents may walk abroad without a keeper, but unoffensive books must not stir forth without a visible jailer in their title.Nor is it to the common people less than a reproach; for if we be so jealous over them, as that we dare not trust them with an English pamphlet, what do we but censure them for a giddy, vicious, and ungrounded people; in such a sick and weak state of faith and discretion, as to be able to take nothing down but through the pipe of a licenser? That this is care or love of them, we cannot pretend, whenas, in those popish places where the laity are most hated and despised, the same strictness is used over them. Wisdom we cannot call it, because it stops but one breach of licence, nor that neither: whenas those corruptions, which it seeks to prevent, break in faster at other doors which cannot be shut.And in conclusion it reflects to the disrepute of our ministers also, of whose labours we should hope better, and of the proficiency which their flock reaps by them, than that after all this light of the Gospel which is, and is to be, and all this continual preaching, they should still be frequented with such an unprincipled, unedified and laic rabble, as that the whiff of every new pamphlet should stagger them out of their catechism and Christian walking. This may have much reason to discourage the ministers when such a low conceit is had of all their exhortations, and the benefiting of their hearers, as that they are not thought fit to be turned loose to three sheets of paper without a licenser; that all the sermons, all the lectures preached, printed, vented in such numbers, and such volumes, as have now well nigh made all other books unsaleable, should not be armour enough against one single Enchiridion, without the castle of St. Angelo of an Imprimatur.And lest some should persuade ye, Lords and Commons, that these arguments of learned men's discouragement at this your Order are mere flourishes, and not real, I could recount what I have seen and heard in other countries, where this kind of inquisition tyrannizes; when I have sat among their learned men, for that honour I had, and been counted happy to be born in such a place of philosophic freedom, as they supposed England was, while themselves did nothing but bemoan the servile condition into which learning amongst them was brought; that this was it which had damped the glory of Italian wits; that nothing had been there written now these many years but flattery and fustian. There it was that I found and visited the famous Galileo, grown old, a prisoner to the Inquisition, for thinking in astronomy otherwise than the Franciscan and Dominican licensers thought. And though I knew that England then was groaning loudest under the prelatical yoke, nevertheless I took it as a pledge of future happiness, that other nations were so persuaded of her liberty. Yet was it beyond my hope that those worthies were then breathing in her air, who should be her leaders to such a deliverance, as shall never be forgotten by any revolution of time that this world hath to finish. When that was once begun, it was as little in my fear that what words of complaint I heard among learned men of other parts uttered against the Inquisition, the same I should hear by as learned men at home, uttered in time of Parliament against an order of licensing; and that so generally that, when I had disclosed myself a companion of their discontent, I might say, if without envy, that he whom an honest quaestorship had endeared to the Sicilians was not more by them importuned against Verres, than the favourable opinion which I had among many who honour ye, and are known and respected by ye, loaded me with entreaties and persuasions, that I would not despair to lay together that which just reason should bring into my mind, toward the removal of an undeserved thraldom upon learning. That this is not therefore the disburdening of a particular fancy, but the common grievance of all those who had prepared their minds and studies above the vulgar pitch to advance truth in others, and from others to entertain it, thus much may satisfy.And in their name I shall for neither friend nor foe conceal what the general murmur is; that if it come to inquisitioning again and licensing, and that we are so timorous of ourselves, and so suspicious of all men, as to fear each book and the shaking of every leaf, before we know what the contents are; if some who but of late were little better than silenced from preaching shall come now to silence us from reading, except what they please, it cannot be guessed what is intended by some but a second tyranny over learning: and will soon put it out of controversy, that bishops and presbyters are the same to us, both name and thing. That those evils of prelaty, which before from five or six and twenty sees were distributively charged upon the whole people, will now light wholly upon learning, is not obscure to us: whenas now the pastor of a small unlearned parish on the sudden shall be exalted archbishop over a large diocese of books, and yet not remove, but keep his other cure too, a mystical pluralist. He who but of late cried down the sole ordination of every novice Bachelor of Art, and denied sole jurisdiction over the simplest parishioner, shall now at home in his private chair assume both these over worthiest and excellentest books and ablest authors that write them.This is not, ye Covenants and Protestations that we have made! this is not to put down prelaty; this is but to chop an episcopacy; this is but to translate the Palace Metropolitan from one kind of dominion into another; this is but an old canonical sleight of commuting our penance. To startle thus betimes at a mere unlicensed pamphlet will after a while be afraid of every conventicle, and a while after will make a conventicle of every Christian meeting. But I am certain that a State governed by the rules of justice and fortitude, or a Church built and founded upon the rock of faith and true knowledge, cannot be so pusillanimous. While things are yet not constituted in religion, that freedom of writing should be restrained by a discipline imitated from the prelates and learnt by them from the Inquisition, to shut us up all again into the breast of a licenser, must needs give cause of doubt and discouragement to all learned and religious men.Who cannot but discern the fineness of this politic drift, and who are the contrivers; that while bishops were to be baited down, then all presses might be open; it was the people's birthright and privilege in time of Parliament, it was the breaking forth of light. But now, the bishops abrogated and voided out of the Church, as if our Reformation sought no more but to make room for others into their seats under another name, the episcopal arts begin to bud again, the cruse of truth must run no more oil, liberty of printing must be enthralled again under a prelatical commission of twenty, the privilege of the people nullified, and, which is worse, the freedom of learning must groan again, and to her old fetters: all this the Parliament yet sitting. Although their own late arguments and defences against the prelates might remember them, that this obstructing violence meets for the most part with an event utterly opposite to the end which it drives at: instead of suppressing sects and schisms, it raises them and invests them with a reputation. The punishing of wits enhances their authority, saith the Viscount St. Albans; and a forbidden writing is thought to be a certain spark of truth that flies up in the faces of them who seek to tread it out. This Order, therefore, may prove a nursing-mother to sects, but I shall easily show how it will be a step-dame to Truth: and first by disenabling us to the maintenance of what is known already.Well knows he who uses to consider, that our faith and knowledge thrives by exercise, as well as our limbs and complexion. Truth is compared in Scripture to a streaming fountain; if her waters flow not in a perpetual progression, they sicken into a muddy pool of conformity and tradition. A man may be a heretic in the truth; and if he believe things only because his pastor says so, or the Assembly so determines, without knowing other reason, though his belief be true, yet the very truth he holds becomes his heresy.There is not any burden that some would gladlier post off to another than the charge and care of their religion. There be--who knows not that there be?--of Protestants and professors who live and die in as arrant an implicit faith as any lay Papist of Loretto. A wealthy man, addicted to his pleasure and to his profits, finds religion to be a traffic so entangled, and of so many piddling accounts, that of all mysteries he cannot skill to keep a stock going upon that trade. What should he do? fain he would have the name to be religious, fain he would bear up with his neighbours in that. What does he therefore, but resolves to give over toiling, and to find himself out some factor, to whose care and credit he may commit the whole managing of his religious affairs; some divine of note and estimation that must be. To him he adheres, resigns the whole warehouse of his religion, with all the locks and keys, into his custody; and indeed makes the very person of that man his religion; esteems his associating with him a sufficient evidence and commendatory of his own piety. So that a man may say his religion is now no more within himself, but is become a dividual movable, and goes and comes near him, according as that good man frequents the house. He entertains him, gives him gifts, feasts him, lodges him; his religion comes home at night, prays, is liberally supped, and sumptuously laid to sleep; rises, is saluted, and after the malmsey, or some well-spiced brewage, and better breakfasted than he whose morning appetite would have gladly fed on green figs between Bethany and Jerusalem, his religion walks abroad at eight, and leaves his kind entertainer in the shop trading all day without his religion.Another sort there be who, when they hear that all things shall be ordered, all things regulated and settled, nothing written but what passes through the custom-house of certain publicans that have the tonnaging and poundaging of all free-spoken truth, will straight give themselves up into your hands, make 'em and cut 'em out what religion ye please: there be delights, there be recreations and jolly pastimes that will fetch the day about from sun to sun, and rock the tedious year as in a delightful dream. What need they torture their heads with that which others have taken so strictly and so unalterably into their own purveying? These are the fruits which a dull ease and cessation of our knowledge will bring forth among the people. How goodly and how to be wished were such an obedient unanimity as this, what a fine conformity would it starch us all into! Doubtless a staunch and solid piece of framework, as any January could freeze together.Nor much better will be the consequence even among the clergy themselves. It is no new thing never heard of before, for a parochial minister, who has his reward and is at his Hercules' pillars in a warm benefice, to be easily inclinable, if he have nothing else that may rouse up his studies, to finish his circuit in an English Concordance and a topic folio, the gatherings and savings of a sober graduateship, a Harmony and a Catena; treading the constant round of certain common doctrinal heads, attended with their uses, motives, marks, and means, out of which, as out of an alphabet, or sol-fa, by forming and transforming, joining and disjoining variously, a little bookcraft, and two hours' meditation, might furnish him unspeakably to the performance of more than a weekly charge of sermoning: not to reckon up the infinite helps of interlinearies, breviaries, synopses, and other loitering gear. But as for the multitude of sermons ready printed and piled up, on every text that is not difficult, our London trading St. Thomas in his vestry, and add to boot St. Martin and St. Hugh, have not within their hallowed limits more vendible ware of all sorts ready made: so that penury he never need fear of pulpit provision, having where so plenteously to refresh his magazine. But if his rear and flanks be not impaled, if his back door be not secured by the rigid licenser, but that a bold book may now and then issue forth and give the assault to some of his old collections in their trenches, it will concern him then to keep waking, to stand in watch, to set good guards and sentinels about his received opinions, to walk the round and counter-round with his fellow inspectors, fearing lest any of his flock be seduced, who also then would be better instructed, better exercised and disciplined. And God send that the fear of this diligence, which must then be used, do not make us affect the laziness of a licensing Church.For if we be sure we are in the right, and do not hold the truth guiltily, which becomes not, if we ourselves condemn not our own weak and frivolous teaching, and the people for an untaught and irreligious gadding rout, what can be more fair than when a man judicious, learned, and of a conscience, for aught we know, as good as theirs that taught us what we know, shall not privily from house to house, which is more dangerous, but openly by writing publish to the world what his opinion is, what his reasons, and wherefore that which is now thought cannot be sound? Christ urged it as wherewith to justify himself, that he preached in public; yet writing is more public than preaching; and more easy to refutation, if need be, there being so many whose business and profession merely it is to be the champions of truth; which if they neglect, what can be imputed but their sloth, or unability?Thus much we are hindered and disinured by this course of licensing, toward the true knowledge of what we seem to know. For how much it hurts and hinders the licensers themselves in the calling of their ministry, more than any secular employment, if they will discharge that office as they ought, so that of necessity they must neglect either the one duty or the other, I insist not, because it is a particular, but leave it to their own conscience, how they will decide it there.There is yet behind of what I purposed to lay open, the incredible loss and detriment that this plot of licensing puts us to; more than if some enemy at sea should stop up all our havens and ports and creeks, it hinders and retards the importation of our richest merchandise, truth; nay, it was first established and put in practice by Antichristian malice and mystery on set purpose to extinguish, if it were possible, the light of Reformation, and to settle falsehood; little differing from that policy wherewith the Turk upholds his Alcoran, by the prohibition of printing. 'Tis not denied, but gladly confessed, we are to send our thanks and vows to Heaven louder than most of nations, for that great measure of truth which we enjoy, especially in those main points between us and the Pope, with his appurtenances the prelates: but he who thinks we are to pitch our tent here, and have attained the utmost prospect of reformation that the mortal glass wherein we contemplate can show us, till we come to beatific vision, that man by this very opinion declares that he is yet far short of truth.Truth indeed came once into the world with her divine Master, and was a perfect shape most glorious to look on: but when he ascended, and his Apostles after him were laid asleep, then straight arose a wicked race of deceivers, who, as that story goes of the Egyptian Typhon with his conspirators, how they dealt with the good Osiris, took the virgin Truth, hewed her lovely form into a thousand pieces, and scattered them to the four winds. From that time ever since, the sad friends of Truth, such as durst appear, imitating the careful search that Isis made for the mangled body of Osiris, went up and down gathering up limb by limb, still as they could find them. We have not yet found them all, Lords and Commons, nor ever shall do, till her Master's second coming; he shall bring together every joint and member, and shall mould them into an immortal feature of loveliness and perfection. Suffer not these licensing prohibitions to stand at every place of opportunity, forbidding and disturbing them that continue seeking, that continue to do our obsequies to the torn body of our martyred saint.We boast our light; but if we look not wisely on the sun itself, it smites us into darkness. Who can discern those planets that are oft combust, and those stars of brightest magnitude that rise and set with the sun, until the opposite motion of their orbs bring them to such a place in the firmament, where they may be seen evening or morning? The light which we have gained was given us, not to be ever staring on, but by it to discover onward things more remote from our knowledge. It is not the unfrocking of a priest, the unmitring of a bishop, and the removing him from off the presbyterian shoulders, that will make us a happy nation. No, if other things as great in the Church, and in the rule of life both economical and political, be not looked into and reformed, we have looked so long upon the blaze that Zuinglius and Calvin hath beaconed up to us, that we are stark blind. There be who perpetually complain of schisms and sects, and make it such a calamity that any man dissents from their maxims. 'Tis their own pride and ignorance which causes the disturbing, who neither will hear with meekness, nor can convince; yet all must be suppressed which is not found in their Syntagma. They are the troublers, they are the dividers of unity, who neglect and permit not others to unite those dissevered pieces which are yet wanting to the body of Truth. To be still searching what we know not by what we know, still closing up truth to truth as we find it (for all her body is homogeneal and proportional), this is the golden rule in theology as well as in arithmetic, and makes up the best harmony in a Church; not the forced and outward union of cold, and neutral, and inwardly divided minds.Lords and Commons of England! consider what nation it is whereof ye are, and whereof ye are the governors: a nation not slow and dull, but of a quick, ingenious and piercing spirit, acute to invent, subtle and sinewy to discourse, not beneath the reach of any point the highest that human capacity can soar to. Therefore the studies of learning in her deepest sciences have been so ancient and so eminent among us, that writers of good antiquity and ablest judgment have been persuaded that even the school of Pythagoras and the Persian wisdom took beginning from the old philosophy of this island. And that wise and civil Roman, Julius Agricola, who governed once here for Caesar, preferred the natural wits of Britain before the laboured studies of the French. Nor is it for nothing that the grave and frugal Transylvanian sends out yearly from as far as the mountainous borders of Russia, and beyond the Hercynian wilderness, not their youth, but their staid men, to learn our language and our theologic arts.Yet that which is above all this, the favour and the love of Heaven, we have great argument to think in a peculiar manner propitious and propending towards us. Why else was this nation chosen before any other, that out of her, as out of Sion, should be proclaimed and sounded forth the first tidings and trumpet of Reformation to all Europe? And had it not been the obstinate perverseness of our prelates against the divine and admirable spirit of Wickliff, to suppress him as a schismatic and innovator, perhaps neither the Bohemian Huns and Jerome, no nor the name of Luther or of Calvin, had been ever known: the glory of reforming all our neighbours had been completely ours. But now, as our obdurate clergy have with violence demeaned the matter, we are become hitherto the latest and the backwardest scholars, of whom God offered to have made us the teachers. Now once again by all concurrence of signs, and by the general instinct of holy and devout men, as they daily and solemnly express their thoughts, God is decreeing to begin some new and great period in his Church, even to the reforming of Reformation itself: what does he then but reveal himself to his servants, and as his manner is, first to his Englishmen? I say, as his manner is, first to us, though we mark not the method of his counsels, and are unworthy.Behold now this vast city: a city of refuge, the mansion house of liberty, encompassed and surrounded with his protection; the shop of war hath not there more anvils and hammers waking, to fashion out the plates and instruments of armed justice in defence of beleaguered truth, than there be pens and heads there, sitting by their studious lamps, musing, searching, revolving new notions and ideas wherewith to present, as with their homage and their fealty, the approaching Reformation: others as fast reading, trying all things, assenting to the force of reason and convincement. What could a man require more from a nation so pliant and so prone to seek after knowledge? What wants there to such a towardly and pregnant soil, but wise and faithful labourers, to make a knowing people, a nation of prophets, of sages, and of worthies? We reckon more than five months yet to harvest; there need not be five weeks; had we but eyes to lift up, the fields are white already.Where there is much desire to learn, there of necessity will be much arguing, much writing, many opinions; for opinion in good men is but knowledge in the making. Under these fantastic terrors of sect and schism, we wrong the earnest and zealous thirst after knowledge and understanding which God hath stirred up in this city. What some lament of, we rather should rejoice at, should rather praise this pious forwardness among men, to reassume the ill-deputed care of their religion into their own hands again. A little generous prudence, a little forbearance of one another, and some grain of charity might win all these diligences to join, and unite in one general and brotherly search after truth; could we but forgo this prelatical tradition of crowding free consciences and Christian liberties into canons and precepts of men. I doubt not, if some great and worthy stranger should come among us, wise to discern the mould and temper of a people, and how to govern it, observing the high hopes and aims, the diligent alacrity of our extended thoughts and reasonings in the pursuance of truth and freedom, but that he would cry out as Pyrrhus did, admiring the Roman docility and courage: If such were my Epirots, I would not despair the greatest design that could be attempted, to make a Church or kingdom happy.Yet these are the men cried out against for schismatics and sectaries; as if, while the temple of the Lord was building, some cutting, some squaring the marble, others hewing the cedars, there should be a sort of irrational men who could not consider there must be many schisms and many dissections made in the quarry and in the timber, ere the house of God can be built. And when every stone is laid artfully together, it cannot be united into a continuity, it can but be contiguous in this world; neither can every piece of the building be of one form; nay rather the perfection consists in this, that, out of many moderate varieties and brotherly dissimilitudes that are not vastly disproportional, arises the goodly and the graceful symmetry that commends the whole pile and structure.Let us therefore be more considerate builders, more wise in spiritual architecture, when great reformation is expected. For now the time seems come, wherein Moses the great prophet may sit in heaven rejoicing to see that memorable and glorious wish of his fulfilled, when not only our seventy elders, but all the Lord's people, are become prophets. No marvel then though some men, and some good men too perhaps, but young in goodness, as Joshua then was, envy them. They fret, and out of their own weakness are in agony, lest these divisions and subdivisions will undo us. The adversary again applauds, and waits the hour: when they have branched themselves out, saith he, small enough into parties and partitions, then will be our time. Fool! he sees not the firm root, out of which we all grow, though into branches: nor will beware until he see our small divided maniples cutting through at every angle of his ill-united and unwieldy brigade. And that we are to hope better of all these supposed sects and schisms, and that we shall not need that solicitude, honest perhaps, though over-timorous, of them that vex in this behalf, but shall laugh in the end at those malicious applauders of our differences, I have these reasons to persuade me.First, when a city shall be as it were besieged and blocked about, her navigable river infested, inroads and incursions round, defiance and battle oft rumoured to be marching up even to her walls and suburb trenches, that then the people, or the greater part, more than at other times, wholly taken up with the study of highest and most important matters to be reformed, should be disputing, reasoning, reading, inventing, discoursing, even to a rarity and admiration, things not before discoursed or written of, argues first a singular goodwill, contentedness and confidence in your prudent foresight and safe government, Lords and Commons; and from thence derives itself to a gallant bravery and well-grounded contempt of their enemies, as if there were no small number of as great spirits among us, as his was, who when Rome was nigh besieged by Hannibal, being in the city, bought that piece of ground at no cheap rate, whereon Hannibal himself encamped his own regiment.Next, it is a lively and cheerful presage of our happy success and victory. For as in a body, when the blood is fresh, the spirits pure and vigorous, not only to vital but to rational faculties, and those in the acutest and the pertest operations of wit and subtlety, it argues in what good plight and constitution the body is; so when the cheerfulness of the people is so sprightly up, as that it has not only wherewith to guard well its own freedom and safety, but to spare, and to bestow upon the solidest and sublimest points of controversy and new invention, it betokens us not degenerated, nor drooping to a fatal decay, but casting off the old and wrinkled skin of corruption to outlive these pangs and wax young again, entering the glorious ways of truth and prosperous virtue, destined to become great and honourable in these latter ages. Methinks I see in my mind a noble and puissant nation rousing herself like a strong man after sleep, and shaking her invincible locks: methinks I see her as an eagle mewing her mighty youth, and kindling her undazzled eyes at the full midday beam; purging and unscaling her long-abused sight at the fountain itself of heavenly radiance; while the whole noise of timorous and flocking birds, with those also that love the twilight, flutter about, amazed at what she means, and in their envious gabble would prognosticate a year of sects and schisms.What would ye do then? should ye suppress all this flowery crop of knowledge and new light sprung up and yet springing daily in this city? Should ye set an oligarchy of twenty engrossers over it, to bring a famine upon our minds again, when we shall know nothing but what is measured to us by their bushel? Believe it, Lords and Commons, they who counsel ye to such a suppressing do as good as bid ye suppress yourselves; and I will soon show how. If it be desired to know the immediate cause of all this free writing and free speaking, there cannot be assigned a truer than your own mild and free and humane government. It is the liberty, Lords and Commons, which your own valorous and happy counsels have purchased us, liberty which is the nurse of all great wits; this is that which hath rarefied and enlightened our spirits like the influence of heaven; this is that which hath enfranchised, enlarged and lifted up our apprehensions, degrees above themselves.Ye cannot make us now less capable, less knowing, less eagerly pursuing of the truth, unless ye first make yourselves, that made us so, less the lovers, less the founders of our true liberty. We can grow ignorant again, brutish, formal and slavish, as ye found us; but you then must first become that which ye cannot be, oppressive, arbitrary and tyrannous, as they were from whom ye have freed us. That our hearts are now more capacious, our thoughts more erected to the search and expectation of greatest and exactest things, is the issue of your own virtue propagated in us; ye cannot suppress that, unless ye reinforce an abrogated and merciless law, that fathers may dispatch at will their own children. And who shall then stick closest to ye, and excite others? not he who takes up arms for coat and conduct, and his four nobles of Danegelt. Although I dispraise not the defence of just immunities, yet love my peace better, if that were all. Give me the liberty to know, to utter, and to argue freely according to conscience, above all liberties.What would be best advised, then, if it be found so hurtful and so unequal to suppress opinions for the newness or the unsuitableness to a customary acceptance, will not be my task to say. I only shall repeat what I have learned from one of your own honourable number, a right noble and pious lord, who, had he not sacrificed his life and fortunes to the Church and Commonwealth, we had not now missed and bewailed a worthy and undoubted patron of this argument. Ye know him, I am sure; yet I for honour's sake, and may it be eternal to him, shall name him, the Lord Brook. He writing of episcopacy, and by the way treating of sects and schisms, left ye his vote, or rather now the last words of his dying charge, which I know will ever be of dear and honoured regard with ye, so full of meekness and breathing charity, that next to his last testament, who bequeathed love and peace to his disciples, I cannot call to mind where I have read or heard words more mild and peaceful. He there exhorts us to hear with patience and humility those, however they be miscalled, that desire to live purely, in such a use of God's ordinances, as the best guidance of their conscience gives them, and to tolerate them, though in some disconformity to ourselves. The book itself will tell us more at large, being published to the world, and dedicated to the Parliament by him who, both for his life and for his death, deserves that what advice he left be not laid by without perusal.And now the time in special is, by privilege to write and speak what may help to the further discussing of matters in agitation. The temple of Janus with his two controversial faces might now not unsignificantly be set open. And though all the winds of doctrine were let loose to play upon the earth, so Truth be in the field, we do injuriously, by licensing and prohibiting, to misdoubt her strength. Let her and Falsehood grapple; who ever knew Truth put to the worse, in a free and open encounter? Her confuting is the best and surest suppressing. He who hears what praying there is for light and clearer knowledge to be sent down among us, would think of other matters to be constituted beyond the discipline of Geneva, framed and fabricked already to our hands. Yet when the new light which we beg for shines in upon us, there be who envy and oppose, if it come not first in at their casements. What a collusion is this, whenas we are exhorted by the wise man to use diligence, to seek for wisdom as for hidden treasures early and late, that another order shall enjoin us to know nothing but by statute? When a man hath been labouring the hardest labour in the deep mines of knowledge, hath furnished out his findings in all their equipage: drawn forth his reasons as it were a battle ranged: scattered and defeated all objections in his way; calls out his adversary into the plain, offers him the advantage of wind and sun, if he please, only that he may try the matter by dint of argument: for his opponents then to skulk, to lay ambushments, to keep a narrow bridge of licensing where the challenger should pass, though it be valour enough in soldiership, is but weakness and cowardice in the wars of Truth.For who knows not that Truth is strong, next to the Almighty? She needs no policies, nor stratagems, nor licensings to make her victorious; those are the shifts and the defences that error uses against her power. Give her but room, and do not bind her when she sleeps, for then she speaks not true, as the old Proteus did, who spake oracles only when he was caught and bound, but then rather she turns herself into all shapes, except her own, and perhaps tunes her voice according to the time, as Micaiah did before Ahab, until she be adjured into her own likeness. Yet is it not impossible that she may have more shapes than one. What else is all that rank of things indifferent, wherein Truth may be on this side or on the other, without being unlike herself? What but a vain shadow else is the abolition of those ordinances, that hand-writing nailed to the cross? What great purchase is this Christian liberty which Paul so often boasts of? His doctrine is, that he who eats or eats not, regards a day or regards it not, may do either to the Lord. How many other things might be tolerated in peace, and left to conscience, had we but charity, and were it not the chief stronghold of our hypocrisy to be ever judging one another?I fear yet this iron yoke of outward conformity hath left a slavish print upon our necks; the ghost of a linen decency yet haunts us. We stumble and are impatient at the least dividing of one visible congregation from another, though it be not in fundamentals; and through our forwardness to suppress, and our backwardness to recover any enthralled piece of truth out of the gripe of custom, we care not to keep truth separated from truth, which is the fiercest rent and disunion of all. We do not see that, while we still affect by all means a rigid external formality, we may as soon fall again into a gross conforming stupidity, a stark and dead congealment of wood and hay and stubble, forced and frozen together, which is more to the sudden degenerating of a Church than many subdichotomies of petty schisms.Not that I can think well of every light separation, or that all in a Church is to be expected gold and silver and precious stones: it is not possible for man to sever the wheat from the tares, the good fish from the other fry; that must be the Angels' ministry at the end of mortal things. Yet if all cannot be of one mind--as who looks they should be?--this doubtless is more wholesome, more prudent, and more Christian, that many be tolerated, rather than all compelled. I mean not tolerated popery, and open superstition, which, as it extirpates all religions and civil supremacies, so itself should be extirpate, provided first that all charitable and compassionate means be used to win and regain the weak and the misled: that also which is impious or evil absolutely either against faith or manners no law can possibly permit, that intends not to unlaw itself: but those neighbouring differences, or rather indifferences, are what I speak of, whether in some point of doctrine or of discipline, which, though they may be many, yet need not interrupt THE UNITY OF SPIRIT, if we could but find among us THE BOND OF PEACE.In the meanwhile if any one would write, and bring his helpful hand to the slow-moving Reformation which we labour under, if Truth have spoken to him before others, or but seemed at least to speak, who hath so bejesuited us that we should trouble that man with asking license to do so worthy a deed? and not consider this, that if it come to prohibiting, there is not aught more likely to be prohibited than truth itself; whose first appearance to our eyes, bleared and dimmed with prejudice and custom, is more unsightly and unplausible than many errors, even as the person is of many a great man slight and contemptuous to see to. And what do they tell us vainly of new opinions, when this very opinion of theirs, that none must be heard but whom they like, is the worst and newest opinion of all others; and is the chief cause why sects and schisms do so much abound, and true knowledge is kept at distance from us; besides yet a greater danger which is in it.For when God shakes a kingdom with strong and healthful commotions to a general reforming, 'tis not untrue that many sectaries and false teachers are then busiest in seducing; but yet more true it is, that God then raises to his own work men of rare abilities, and more than common industry, not only to look back and revise what hath been taught heretofore, but to gain further and go on some new enlightened steps in the discovery of truth. For such is the order of God's enlightening his Church, to dispense and deal out by degrees his beam, so as our earthly eyes may best sustain it.Neither is God appointed and confined, where and out of what place these his chosen shall be first heard to speak; for he sees not as man sees, chooses not as man chooses, lest we should devote ourselves again to set places, and assemblies, and outward callings of men; planting our faith one while in the old Convocation house, and another while in the Chapel at Westminster; when all the faith and religion that shall be there canonized is not sufficient without plain convincement, and the charity of patient instruction to supple the least bruise of conscience, to edify the meanest Christian, who desires to walk in the Spirit, and not in the letter of human trust, for all the number of voices that can be there made; no, though Harry VII himself there, with all his liege tombs about him, should lend them voices from the dead, to swell their number.And if the men be erroneous who appear to be the leading schismatics, what withholds us but our sloth, our self-will, and distrust in the right cause, that we do not give them gentle meetings and gentle dismissions, that we debate not and examine the matter thoroughly with liberal and frequent audience; if not for their sakes, yet for our own? seeing no man who hath tasted learning, but will confess the many ways of profiting by those who, not contented with stale receipts, are able to manage and set forth new positions to the world. And were they but as the dust and cinders of our feet, so long as in that notion they may yet serve to polish and brighten the armoury of Truth, even for that respect they were not utterly to be cast away. But if they be of those whom God hath fitted for the special use of these times with eminent and ample gifts, and those perhaps neither among the priests nor among the Pharisees, and we in the haste of a precipitant zeal shall make no distinction, but resolve to stop their mouths, because we fear they come with new and dangerous opinions, as we commonly forejudge them ere we understand them; no less than woe to us, while, thinking thus to defend the Gospel, we are found the persecutors.There have been not a few since the beginning of this Parliament, both of the presbytery and others, who by their unlicensed books, to the contempt of an Imprimatur, first broke that triple ice clung about our hearts, and taught the people to see day: I hope that none of those were the persuaders to renew upon us this bondage which they themselves have wrought so much good by contemning. But if neither the check that Moses gave to young Joshua, nor the countermand which our Saviour gave to young John, who was so ready to prohibit those whom he thought unlicensed, be not enough to admonish our elders how unacceptable to God their testy mood of prohibiting is; if neither their own remembrance what evil hath abounded in the Church by this set of licensing, and what good they themselves have begun by transgressing it, be not enough, but that they will persuade and execute the most Dominican part of the Inquisition over us, and are already with one foot in the stirrup so active at suppressing, it would be no unequal distribution in the first place to suppress the suppressors themselves: whom the change of their condition hath puffed up, more than their late experience of harder times hath made wise.And as for regulating the press, let no man think to have the honour of advising ye better than yourselves have done in that Order published next before this, \"that no book be printed, unless the printer's and the author's name, or at least the printer's, be registered.\" Those which otherwise come forth, if they be found mischievous and libellous, the fire and the executioner will be the timeliest and the most effectual remedy that man's prevention can use. For this authentic Spanish policy of licensing books, if I have said aught, will prove the most unlicensed book itself within a short while; and was the immediate image of a Star Chamber decree to that purpose made in those very times when that Court did the rest of those her pious works, for which she is now fallen from the stars with Lucifer. Whereby ye may guess what kind of state prudence, what love of the people, what care of religion or good manners there was at the contriving, although with singular hypocrisy it pretended to bind books to their good behaviour. And how it got the upper hand of your precedent Order so well constituted before, if we may believe those men whose profession gives them cause to inquire most, it may be doubted there was in it the fraud of some old patentees and monopolizers in the trade of bookselling; who under pretence of the poor in their Company not to be defrauded, and the just retaining of each man his several copy, which God forbid should be gainsaid, brought divers glossing colours to the House, which were indeed but colours, and serving to no end except it be to exercise a superiority over their neighbours; men who do not therefore labour in an honest profession to which learning is indebted, that they should be made other men's vassals. Another end is thought was aimed at by some of them in procuring by petition this Order, that, having power in their hands, malignant books might the easier scape abroad, as the event shows.But of these sophisms and elenchs of merchandise I skill not. This I know, that errors in a good government and in a bad are equally almost incident; for what magistrate may not be misinformed, and much the sooner, if liberty of printing be reduced into the power of a few? But to redress willingly and speedily what hath been erred, and in highest authority to esteem a plain advertisement more than others have done a sumptuous bride, is a virtue (honoured Lords and Commons) answerable to your highest actions, and whereof none can participate but greatest and wisest men.Text is available under the Creative Commons Attribution-ShareAlike License; additional terms may apply. See original source at Wikisource."}
{"prompt": "The libbitcoin Manifesto", "completion": "\u201cTools for The People\u201dAs humans, we share little in common. But that little we do share is the deep core of our being. We search for purpose. We are curious. And we thrive on new information. Our self-awareness, rationality and sapience are the high level features that make up a person. They are our capacity for good or evil.As people, we need to ask ourselves whether we act with purpose, intent and ambition, ask how are we defining ourselves, and what are the values that our lives are promoting.Are you taking concrete steps now to achieve your objective?It's important we ask ourselves these questions, and decide which end of the spectrum between liberty and security we fixate on. A safe life of luxury, and comfort closed in by 4 walls. Or a life of freedom. Freedom to make love, play loud music, create art, wrestle naked, and raise confident kids that think.In criticising the world we're born into, it's easy to point the finger at this or that politician or resign problems to circumstance. And with the perceived lack of power to concede the situation is unfixable and utterly broken. But if we want to know who to blame, we need only to look into a mirror. We support the situation. It is people, not rulers, who create the world of today.Some of us conclude that the situation is just a normal state of affairs, and simply human nature. As if there were one human nature! And disregarding that we all evolve and grow as people in different directions during our lives.Think of the values we are taught as children. How we are taught to behave as civic citizens. The phrases we are told by our parents, teachers and friends. The system is not just the state and corporations, it is a machine encompassing all spheres of life.You might hear for example:I was told all of these sentences in my life. That learning to accept authority is an inevitable part of growing up. That my character is defined by how I look, not how I act. That my single purpose is to be a work-slave. To avoid interaction with random unknowns outside my circle. And that responsibility starts and stops with myself.All of them are bad values.We are not born with these values. They are hard-wired into us from a young age. Luckily knowledge feeds the unlearning process and the internet is an unlearning tool.Have you ever questioned the 15 years of our precious childhood from kindergarten to highschool. We attend a prison with fixed schedules and dinner at an allocated time. We're forced to wear uniforms. If you want to speak, you need to raise your hand. If you need the toilet, you must ask permission. And the lessons amount to little more than drilling information with the given promise of honours and qualifications.The reward for faithfully jumping through all these hoops for 15 years is a worthless piece of paper that isn't even required for a job at McDonalds. And the workers still need training. Our children aren't taught how to cook a healthy meal, grow a garden or even a rudimentary concept of how to organise or lead groups of people without even a glimmer of understanding on how to resolve conflicts without violence. Or the principles of logic, and how to question an ideology. Kids are taught to sit at a desk and listen obediently as the world is packaged into neat boxes.School is little more than a training camp for salaried drones designed to format young minds for a life of subservience, too stupid to question the system itself or the authority of those running it. We are not born with bad values. They are wired into us from a young age.Lets talk about good values.Responsibility is about fulfilling your needs to have a dignified existence, and then expanding that circle to the people around you. To help bring up and out the potential of other free people so that together we thrive. Community and collective action is absolutely essential if we want to rise up. The system thrives by separating people into isolated pockets who get their information from TV and their culture from corporations. United together, we are stronger.\u201cVires in numeris\u201dIndependence and autonomy is the ability to act. If we always need third parties and central organisations to resolve disputes, solve our problems and coordinate us then we are doomed as a species. Central authorities are always a magnet for corruption and that will never change. Learn to be self reliant and make things happen.Understanding is not an easy skill to develop, but it is very powerful. Being able to get into people's minds, to listen and be able to meet their needs is leadership. A leader serves and inspires people into action, whereas a ruler uses coercion. For all their grandeur and force, rulers cannot harness the real potential of people. Nobody thinks under duress.We need assertive individuals who stand unyielding for what they believe in. If you know something is right, then fight for your vision. It will happen. The system feeds off passivity, and giving consent to its exclusive hold of force feeds the machine.Lastly lets approach the world as artists, and bring creativity to our work. The world is diverse, colourful and vibrant. Humans are not meant to live in little boxes and grey concrete jungles. Live art and be creative. Your work is art. Good art makes people think and feel.The role of good people is the vanguard of tomorrow.The penalty good men pay for indifference to public affairs is to be ruled by evil men.It's an old story. David vs Goliath. Starfleet rebels vs galactic deathstar. Anarchist revolutionaries vs the fascist empire. Both sides have existed for centuries and the struggle continues. However in recent decades with the unique political situation, the internet and a dawning awareness among people, the balance of power is shifting in our favour this time around.Humans can look to a future less dominated by the command hierarchies of the past, and more by thriving marketplaces of knowledge and merit.I remember an amateur blue webpage in the summer of 2010 describing a p2p currency that \u201ccannot be controlled by governments or central banks\u201d. Extremely skeptical, I dived into the code and discovered an idea which burnt itself in my memory. My mind latched onto Bitcoin. I realised this unknown project is the future of money.Bitcoin is a tool of resistance gifted to us by Satoshi. The idea has escaped and the idea of cryptocurrency will not be stopped. Bitcoin or some other cryptocurrency will succeed.Bitcoin is about direct trade from peer to peer. The purest value transfer possible between 2 or more people. A direct and personal interaction over digital infrastructure. Welcome to the future of the black market. Real values, real people and uncorrupted markets.The internet is a tool of freedom and self-determination. Meddling in its mechanics is destructive. Whenever a website is blocked, a protocol is corrupted at some low level or undesirable traffic shaping occurs then seismic ripples of censorship and destruction lead to degradation of the network. The internet is fundamental to humanity, and must be protected at all costs.Bitcoin is no different, and must be kept pure. There are real risks to Bitcoin.The protocol is not an axiomatic system fixed by Satoshi. It's been constantly changing, rapidly evolving and the pace is accelerating. The risks are more subtle and probable than a government demanding changes to the fundamentals of Bitcoin's protocol. The chilling effect of self censorship.We don't even need to touch the protocol.As Bitcoin grows, the inevitable specialisation is kicking in. The blockchain is moving towards specialised services, and the future of full Bitcoin nodes is on the server, not personal computers. We have to wake up, adapt and work with the reality rather than persisting in self denial.If development is too centralised, with a small core infrastructure, then businesses will put real pressure to have features that destroy the integrity of the Bitcoin network. The excuse will be to protect themselves from liability. Self-censorship.And what they demand does not have to be protocol changes. They will demand features in the software they use. Software which remains compatible with the network, but works against the interests of individuals, small businesses and the black market.The possible malicious scenarios are endless. Stuff like p2p blacklists to create a 'legitimate' walled garden, or tracking technologies like large databases of IP addresses to triangulate where transactions came from. At the other end of the spectrum, is putting development effort into diversifying the ecosystem to protect against censorship and proxy relay nodes, anonymising mixers, small privacy tweaks and other technologies. That's where developers who believe in Bitcoin should devote time to. Corporations are powerful enough. To developers: serve your community.A diversified Bitcoin of many wallets and implementations is a strong and pure Bitcoin. To protect the integrity of the network, we need to eliminate single points of failure. An inbred Bitcoin with the same software code everywhere shares the same weaknesses, and is susceptible to the same attacks. A single pathogen can wipe out a genetically homogenous population. And centralised software is vulnerable to the dictates of whoever controls development of that software code, and any dictates pressured onto them.The implications of a diversified Bitcoin is a Bitcoin difficult to control. It also sets the protocol in stone, as nobody has sole power over the standard. Consensus from many parties is the way forwards.The proper way to develop a standard is by having many different competing parties that require mutual interest and agreement to pass through changes. History is rife with abuse like when Internet Explorer dominated the browser market, and constantly broke the web standard by introducing proprietary extensions. Their motive was to swallow the market and lock users into Internet Explorer. The result was a broken web. A monopoly likes to dominate the market, shut out competitors and erect high barriers to entry.A diversified ecosystem protects against feature-creep or bloat of the standard. Extra features go beyond the basic function of Bitcoin and so can result in over-complication rather than simple design. Viewed over a longer time period, extra or unnecessary features seem to creep into the system beyond the initial goals and the small code of 15,000 lines set by Satoshi. The result will be a Bitcoin that becomes increasingly difficult to understand or implement without a huge initial investment of resources, time and people. No single person will fully understand Bitcoin anymore, and development monopolies will be further enforced.Linux is the most secure operating system because of its diversity. There is no single exploit that is universal across all versions of Linux. Bitcoin must evolve in the same way to become a resilient and tough system able to serve a global audience.A massive standard is difficult to reimplement. Satoshi Nakamoto gifted us a small, focused and pure Bitcoin.There is no need for compromise. Lets push for our complete vision. Bitcoin is here. We have the initiative and we make our stand now. We have the power and now is the time. Not later. Now.Within a century of the printing press being invented, wars, social strife and revolutions erupted across Europe. Old kings, revered religious leaders and tyrannical rulers were removed from power. People could now read what was being written in their bibles. Mass printing of the bible was subversive. And what was written in their bibles, is not what they were being fed. In the face of hard evidence, people dispelled old notions of what their religion was saying.Our economy will change. Bitcoin will rise as a fundamental technology. Seeking approval from the halls of Washington, and consent from the status quo is mere pandering as lapdogs at the feet of the system. Why would you willingly give your power away? Are you stupid?Some people make the argument that throwing Bitcoin under the bus and corrupting the core of this technology is needed to help businesses which specialise in the exchange of failing government fiat paper-money with Bitcoins. Are we willing to sacrifice the purity of this tool for a few short term gains that primarily benefit US corporations? Do they serve the need of Bitcoin?Others even go further, arguing we need the masses. That being a majority protects people from assaults. Typical herd mentality.And that regulation (and the measures to implement them) are a typical process of acceptance. I have news for you: majorities have been slaughtered like pigs all throughout history. Being \u201cpragmatic\u201d is code speak for obedience and cowardice.Bitcoin is the future. Act like you believe it. Act to prevent corruption of the system. Act to prevent Bitcoin becoming coopted in any way. We must preserve the principles of Satoshi Nakamoto.We have the initiative and the power. You know the truth of the world. Stop supporting your own enemies. We don't need them. They need us. You are the one empowering them. Withdraw your consent. Withdraw your support. Don't accept their terms or try to win a game where they set the rules. Don't try to win your ruler's favour. Don't bother to beg for welfare or good treatment. Worst of all, don't help them hunt down your neighbour.Time we stick our flag in the ground, and make our stand.Our task force will offer balanced, effective solutions for policy makers, law enforcement, regulators and the public.[...]The Task Force, which launched in August, is not solely focussed on child exploitation.[...]The report detailed how criminal and terrorist organisations have turned to digital currency to reap profits from drug trafficking, prostitution and the dissemination of child abuse images.One day master told slave: \u201cDo this small thing and everything is fine. Keep up the good work.\u201d. The slave was happy because not much was asked so he started to create something cool. The master walked in a week later, and said \u201cdo this as well\u201d. The slave was shocked. \u201cBut master, we had an agreement, you said I only needed to do this?\u201d. Master responded \u201cI changed my mind. You need to do this as well.\u201d. The slave reluctantly agreed. At least it wasn't that bad.Over time, the master more and more increased his demands on the slave. By now the slave had created something totally wonderful and was dependant on it, but the master controlled his work and owned him.The task of an activist is not to negotiate systems of power with as much personal integrity as possible- it's to dismantle those systems.The road is long, and real work is needed. Less talk, more action. There are too few people in this world working on worthwhile things for the people. But eventhough the work-load is immense and daunting, there are concrete steps to achieve the global objective.Truth happens. We will succeed. Don't wait around for others to take action. We must dive head first without regard for consequences, and break the inertia of passivity. When enough people do this, the real change will occur.Fight for what you believe in. If you believe, and uphold a truth, then all your energy should be devoted to your objectives. Anytime you are accepting compromise, you are acting against your objective. None of us are pure. We are flawed and imperfect. But as good people we must strive for uncomplicated directness in our actions. Our actions must be transparent in motive and pure in reasoning.The power is within us. It always has been."}
{"prompt": "Bit Gold", "completion": "A long time ago I hit upon the idea of bit gold. The problem, in a nutshell, is that our money currently depends on trust in a third party for its value. As many inflationary and hyperinflationary episodes during the 20th century demonstrated, this is not an ideal state of affairs. Similarly, private bank note issue, while it had various advantages as well as disadvantages, similarly depended on a trusted third party.Precious metals and collectibles have an unforgeable scarcity due to the costliness of their creation. This once provided money the value of which was largely independent of any trusted third party. Precious metals have problems, however. It's too costly to assay metals repeatedly for common transactions. Thus a trusted third party (usually associated with a tax collector who accepted the coins as payment) was invoked to stamp a standard amount of the metal into a coin. Transporting large values of metal can be a rather insecure affair, as the British found when transporting gold across a U-boat infested Atlantic to Canada during World War I to support their gold standard. What's worse, you can't pay online with metal.Thus, it would be very nice if there were a protocol whereby unforgeably costly bits could be created online with minimal dependence on trusted third parties, and then securely stored, transferred, and assayed with similar minimal trust. Bit gold.My proposal for bit gold is based on computing a string of bits from a string of challenge bits, using functions called variously \"client puzzle function,\" \"proof of work function,\" or \"secure benchmark function.\" The resulting string of bits is the proof of work. Where a one-way function is prohibitively difficult to compute backwards, a secure benchmark function ideally comes with a specific cost, measured in compute cycles, to compute backwards.Here are the main steps of the bit gold system that I envision:Note that Alice's control over her bit gold does not depend on her sole possession of the bits, but rather on her lead position in the unforgeable chain of title (chain of digital signatures) in the title registry.All of this can be automated by software. The main limits to the security of the scheme are how well trust can be distributed in steps (3) and (4), and the problem of machine architecture which will be discussed below.Hal Finney has implemented a variant of bit gold called RPOW (Reusable Proofs of Work). This relies on publishing the computer code for the \"mint,\" which runs on a remote tamper-evident computer. The purchaser of of bit gold can then use remote attestation, which Finney calls the transparent server technique, to verify that a particular number of cycles were actually performed.The main problem with all these schemes is that proof of work schemes depend on computer architecture, not just an abstract mathematics based on an abstract \"compute cycle.\" (I wrote about this obscurely several years ago.) Thus, it might be possible to be a very low cost producer (by several orders of magnitude) and swamp the market with bit gold. However, since bit gold is timestamped, the time created as well as the mathematical difficulty of the work can be automatically proven. From this, it can usually be inferred what the cost of producing during that time period was.Unlike fungible atoms of gold, but as with collector's items, a large supply during a given time period will drive down the value of those particular items. In this respect \"bit gold\" acts more like collector's items than like gold. However, the match between this ex post market and the auction determining the initial value might create a very substantial profit for the \"bit gold miner\" who invents and deploys an optimized computer architecture.Thus, bit gold will not be fungible based on a simple function of, for example, the length of the string. Instead, to create fungible units dealers will have to combine different-valued pieces of bit gold into larger units of approximately equal value. This is analogous to what many commodity dealers do today to make commodity markets possible. Trust is still distributed because the estimated values of such bundles can be independently verified by many other parties in a largely or entirely automated fashion.In summary, all money mankind has ever used has been insecure in one way or another. This insecurity has been manifested in a wide variety of ways, from counterfeiting to theft, but the most pernicious of which has probably been inflation. Bit gold may provide us with a money of unprecedented security from these dangers. The potential for initially hidden supply gluts due to hidden innovations in machine architecture is a potential flaw in bit gold, or at least an imperfection which the initial auctions and ex post exchanges of bit gold will have to address."}
{"prompt": "Libertaria in Cyberspace", "completion": "Here are a few points about why \"cyberspace,\" or a computer-mediated network, is more hospitable than physical locations for the kind of \"crypto anarchy\" libertarian system I've been describing.Several folks have commented recently about ocean-going libertarian havens, supertankers used as data havens, and so forth. In the 1970s, especially, there were several unsuccessful attempts to acquire islands in the Pacific for the site of what some called \"Libertaria.\" (Some keywords: Vanuatu, Minerva, Mike Oliver, Tonga)Obtaining an entire island is problematic. Getting the consent of the residents is one issue (familiar to those on the this list who weathered the Hurrican Andrew diversion debate). Being allowed to operate by the leading world powers is another....the U.S. has enforced trade embargoes and blockades against many nations in the past several decades, including Cuba, North Korea, Libya, Iran, Iraq, andothers. Further, the U.S. has invaded some countries---Panama is a good example---whose government it disliked. How long would a supertanker \"data haven\" or libertarian regime last in such an environment? (Stephenson's fascinating Snow Crash didn't address tthe issue of why the \"Raft\" wasn't simply sunk by the remaining military forces.)I should note that the recent splintering of countries may provide opportunities for libertarian (or PPL, if your prefer to think of it in this way) regions. Some have speculated that Russia itself is a candidate, given that it has little vested in the previous system and may be willing to abandon statism. If several dozen new countries are formed, some opportunities exist.The basic problem is that physical space is too small, too exposed to the view of others. \"Libertaria\" in the form of, say, an island, is too exposed to the retaliatation of world powers. (I won't go into the \"private nukes\" strategy, which I need to think about further.)A floating private nation (or whatever it's called) is too vulnerable to a single well-placed torpedo. Even if it serves as a kind of Swiss bank, and thus gets some of the same protection Switzerland got (to wit, many leaders kept their loot there), it is too vulnerable to a single attacker or invader. Piracy will be just one of the problems.Finally, how many of us want to move to a South Pacific island? Or a North Sea oil rig? Or even to Russia?Cyberspace looks more promising. There is more \"space\" in cyberspace, thus allowing more security and more colonizable space. And this space is coterminous with our physical space, accessible with proper terminals from any place in the world (though there may be attempts in physical space to block access, to restrict access to necessay cryptographic methods, etc.).I won't go into the various cryptographic methods here (see my earlier posting on the \"Dining Cryptographers\" protocol and various other postings on public key systems, digital mixes, electronic cash, etc.). Interested readers have many sources. (I have just read a superb survey of these new techniques, the 1992 Ph.D. thesis of Jurgen Bos, \"Practical Privacy,\" which deals with these various protocols in a nice little book.)Alice and Bob, our favorite cryptographic stand-ins, can communicate and transact business without ever meeting or even knowing who the other is. This can be extended to create virtual communities subject only to rules they themselves reach agreement on, much like this very Extropians list. Private law is the only law, as there is no appeal to some higher authority like the Pope or police. (This is why I said in several of my postings on the Hurricane Andrew debate that I am sympathetic to the PPL view.)And this is the most compelling advantage of \"Crypto Libertaria\": an arbitrarily large number of separate \"nations\" can simultaneously exist. This allows for rapid experimentation, self-selection, and evolution. If folks get tired of some virtual community, they can leave. The cryptographic aspects mean their membership in some community is unknown to others (vis-a-vis the physical or outside world, i.e., their \"true names\") and physical coercion is reduced.Communalists are free to create a communal environment, Creative Anachronists are free to create their own idea of a space, and so on. I'm not even getting into the virtual reality-photorealistic images-Jaron Lanier sort of thing, as even current text-based systems are demonstrably enough to allow the kind of virtual communities I'm describing here (and described in Vinge's \"True Names,\" in Gibson's Neuromancer, in Sterling's Islands in the Net, and in Stephenson's Snow Crash...though all of them missed out on some of the most exciting aspects...perhaps my novel will hit the mark?).But will the government allow these sorts of things? Won't they just torpedo it, just as they'd torpedo an offshore ooirig data haven?The key is that distributed systems have no nexus which can be knocked out. Neither Usenet norFidoNet can be disabled by any single government, as they are worldwide. Shutting them down would mean banning computer-to-computer communication. And despite the talk of mandatory \"trap doors\" in encryption systems, encryption is fundamentally easy to do and hard to detect. (For those who doubt this, let me describe a simple system I posted to sci.crypt several years ago. An ordinary digital audio tape (DAT) carries more than a gigabyte of data. This means that thhe least significant bit (LSB) of an audio DAT recordingng carries about 8megabytes of data! So Alice is stopped by the Data Police. They ask if she's carrying illegal data. She smiles inocently and say \"No. I know you'll search me.\" They find her Sony DATman and ask about her collection of tapes and live recordings. Alice is carrying 80 MB of data---about 3 entire days worth of Usenet feeds!---on each and every tape. The data are stored in the LSBs, completely indistinguishable from microphone and quantization noise...unless you know the key. Similar methods allow data to be undetectably packed into LSBs of the PICT and GIF pictures now flooding the Net, into sampled sounds, and even into messages like this...the \"whitespace\" on the right margin of this message carries a hidden message readable only to a few chosen Extropians.)I've already described using religions and role-playing games as a kind of legal cover for the development and deployment of these techniques. If a church decides to offer \"digital confessionals\" for its far-flung members, by what argument will the U.S. government justify insisting that encryption not be used? (I should note that psychiatrists and similar professionals have a responsibility to their clients and to their licensing agencies to ensure the privacy of patient records. Friends of mine are using encryption to protect patient records. This is just one little example of how encryption is getting woven into the fabric of our electronic society. There are many other examples.)In future discussions, I hope we can hit on some of the many approaches to deploying these methods. I've spent several years thinking about this, but I've surely missed some good ideas. The \"crypto anarchy game\" being planned is an attempt to get some of the best hackers in the Bay Area thinking along these lines and thinking of new wrinkles. Several have already offered to help further.Some have commented that this list is not an appropriate place to discuss these ideas. I think it is. We are not discussing anything that is actually illegal, even under the broad powers of RICO (Racketeer-Influenced and Corrupt Organizations Act, used to go after \"conspiracies\" of porn dealers and gun dealers, amongst others). What we are discussing are long-range implications of these ideas.In conclusion, it will be easier to form certain types of libertarian societies in cyberspace than in the real world of nations and physical locations. The electronic world is by no means complete, as we will still live much of our lives in the physical world. But economic activity is sharply increasing in the Net domain and these \"crypto anarchy\" ideas will further erode the power of physical states to tax and coerce residents.-- Tim May"}
{"prompt": "Crypto Glossary", "completion": "From: tcmay@netcom.com (Timothy C. May)\nSubject: Crypto Glossary\nDate: Sun, 22 Nov 92 11:50:55 PSTHere's the glossary of crypto terms we passed out in printed form at the first Cypherpunks meeting in September 1992. Some compromises had to be made in going from the printed form to the ASCII of this transmission, so I hope you'll bear with me.I'm sending it to the entire list because nearly everyone who hears about it says \"Is it online?\" and wants a copy. If you don't want it, discard it.I'm not going to be maintaining the \"Cypherpunks FAQ,\" so don't send me corrections or additions.EnjoyTim May(these sections will introduce the terms in context, though complete definitions will not be given)privacy of messages\nusing ciphers and codes to protect the secrecy of messages\nDES is the most common symmetric cipher (same key for encryption and decryption)\nRSA is the most common asymmetric cipher (different keys for encryption and decryption)proving who you are\nproving you signed a document (and not someone else)untraceable sending and receiving of mail and messages\nfocus: defeating eavesdroppers and traffic analysis\nDC protocol (dining cryptographers)focus: ballot box anonymity\ncredentials for voting\nissues of double voting, security, robustness, efficiencyfocus: privacy in transactions, purchases\nunlinkable credentials\nblinded notes\n\"digital coins\" may not be possibleusing the above to evade government, to bypass tax collection, etc.\na technological solution to the problem of too much governmentopen, free market systems in which voluntary transactions are central.cryptographic protocols are often made clearer by considering parties A and B, or Alice and Bob, performing some protocol. Eve the eavesdropper, Paul the prover, and Vic the verifier are other common stand-in names.all or nothing disclosure of secrets.a credential which asserts some right or privilege or fact without revealing the identity of the holder. This is unlike CA driver's licenses.same as public key cryptosystem.the process of verifying an identity or credential, to ensure you are who you said you were.a type of authentication using fingerprints, retinal scans, palm prints, or other physical/biological signatures of an individual.e.g., tossing a coin and then committing to the value without being able to change the outcome. The blob is a cryptographic primitive for this.A signature that the signer does not remember having made. A blind signature is always a cooperative protocol and the receiver of the signature provides the signer with the blinding information.the crypto equivalent of a locked box. A cryptographic primitive for bit commitment, with the properties that a blobs can represent a 0 or a 1, that others cannot tell be looking whether itUs a 0 or a 1, that the creator of the blob can \"open\" the blob to reveal the contents, and that no blob can be both a 1 and a 0. An example of this is a flipped coin covered by a hand.the path over which messages are transmitted. Channels may be secure or insecure, and may have eavesdroppers (or enemies, or disrupters, etc.) who alter messages, insert and delete messages, etc. Cryptography is the means by which communications over insecure channels are protected.an attack where the cryptanalyst gets to choose the plaintext to be enciphered, e.g., when possession of an enciphering machine or algorithm is in the possession of the cryptanalyst.a secret form of writing, using substitution or transposition of characters or symbols.the plaintext after it has been encrypted.a restricted cryptosystem where words or letters of a message are replaced by other words chosen from a codebook. Not part of modern cryptology, but still useful.an important crypto primitive, or protocol, in which the equivalent of flipping a fair coin is possible. Implemented with blobs.wherein several participants cooperate to deduce the identity of a sender or receiver, or to break a cipher. Most cryptosystems are sensitive to some forms of collusion. Much of the work on implementing DC Nets, for example, involves ensuring that colluders cannot isolate message senders and thereby trace origins and destinations of mail.where a cipher cannot be broken with available computer resources, but in theory can be broken with enough computer resources. Contrast with unconditionally secure.something you do to thwart an attacker.facts or assertions about some entity. For example, credit ratings, passports, reputations, tax status, insurance records, etc. Under the current system, these credentials are increasingly being cross-linked. Blind signatures may be used to create anonymous credentials.banks, credit agencies, insurance companies, police departments, etc., that correlate records and decide the status of records.methods for attacking and breaking ciphers and related cryptographic systems. Ciphers may be broken, traffic may be analyzed, and passwords may be cracked. Computers are of course essential.the economic and political system after the deployment of encryption, untraceable e-mail, digital pseudonyms, cryptographic voting, and digital cash. A pun on \"crypto,\" meaning \"hipen,\" and as when Gore Vidal called William F. Buckley a \"crypto fascist.\"another name for cryptology.the science and study of writing, sending, receiving, and deciphering secret messages. Includes authentication, digital signatures, the hiding of messages (steganography), cryptanalysis, and several other fields.the electronic domain, the Nets, and computer-generated spaces. Some say it is the \"consensual reality\" described in \"Neuromancer.\" Others say it is the phone system. Others have work to do.the dining cryptographers protocol. DC-Nets use multiple participants communicating with the DC protocol.the Data Encryption Standard, proposed in 1977 by the National Bureau of Standards (now NIST), with assistance from the National Security Agency. Based on the \"Lucifer\" cipher developed by Horst Feistel at IBM, DES is a secret key cryptosystem that cycles 64-bit blocks of data through multiple permutations with a 56-bit key controlling the routing. \"Diffusion\" and \"confusion\" are combined to form a cipher that has not yet been cryptanalyzed (see \"DES, Security of\"). DES is in use for interbank transfers, as a cipher inside of several RSA-based systems, and is available for PCs.many have speculated that the NSA placed a trapdoor (or back door) in DES to allow it to read DES-encrypted messages. This has not been proved. It is known that the original Lucifer algorithm used a 128-bit key and that this key length was shortened to 64 bits (56 bits plus 8 parity bits), thus making exhaustive search much easier (so far as is known, brute-force search has not been done, though it should be feasible today). Shamir and Bihan have used a technique called \"differential cryptanalysis\" to reduce the exhaustive search needed for chosen plaintext attacks (but with no import for ordinary DES).technique for cryptanalyzing DES. With a chosen plaintext attack, they've reduced the number of DES keys that must be tried from about 2^56 to about 2^47 or less. Note, however, that rarely can an attacker mount a chosen plaintext attack on DES systems.Protocols for transferring value, monetary or otherwise, electronically. Digital cash usually refers to systems that are anonymous. Digital money systems can be used to implement any quantity that is conserved, such as points, mass, dollars, etc. There are many variations of digital money systems, ranging from VISA numbers to blinded signed digital coins. A topic too large for a single glossary entry.basically, a \"crypto identity.\" A way for individuals to set up accounts with various organizations without revealing more information than they wish. Users may have several digital pseudonyms, some used only once, some used over the course of many years. Ideally, the pseudonyms can be linked only at the will of the holder. In the simplest form, a public key can serve as a digital pseudonym and need not be linked to a physical identity.Analogous to a written signature on a document. A modification to a message that only the signer can make but that everyone can recognize. Can be used legally to contract at a distance.one function of a digital notary public, in which some message (a song, screenplay, lab notebook, contract, etc.) is stamped with a time that cannot (easily) be forged.the untraceable message sending system invented by David Chaum. Named after the \"dining philosophers\" problem in computer science, participants form circuits and pass messages in such a way that the origin cannot be deduced, barring collusion. At the simplest level, two participants share a key between them. One of them sends some actual message by bitwise exclusive-ORing the message with the key, while the other one just sends the key itself. The actual message from this pair of participants is obtained by XORing the two outputs. However, since nobody but the pair knows the original key, the actual message cannot be traced to either one of the participants.given integers a, n, and x, find some integer m such that a^m mod n = x, if m exists. Modular exponentiation, the a^m mod n part, is straightforward (and special purpose chips are available), but the inverse problem is believed to be very hard, in general. Thus it is conjectured that modular exponentiation is a one-way function.the latest NIST (National Institute of Standards and Technology, successor to NBS) standard for digital signatures. Based on the El Gamal cipher, some consider it weak and poor substitute for RSA-based signature schemes.intercepting messages without detection. Radio waves may be intercepted, phone lines may be tapped, and computers may have RF emissions detected. Even fiber optic lines can be tapped.Some large numbers are difficult to factor. It is conjectured that there are no feasible--i.e.\"easy,\" less than exponential in size of number-- factoring methods. It is also an open problem whether RSA may be broken more easily than by factoring the modulus (e.g., the public key might reveal information which simplifies the problem). Interestingly, though factoring is believed to be \"hard\", it is not known to be in the class of NP-hard problems. Professor Janek invented a factoring device, but he is believed to be fictional.security, in which no amount of cryptanalysis can break a cipher or system. One time pads are an example (providing the pads are not lost nor stolen nor used more than once, of course). Same as unconditionally secure.a piece of information needed to encipher or decipher a message. Keys may be stolen, bought, lost, etc., just as with physical keys.the process of sharing a key with some other party, in the case of symmetric ciphers, or of distributing a public key in an asymmetric cipher. A major issue is that the keys be exchanged reliably and without compromise. Diffie and Hellman devised one such scheme, based on the discrete logarithm problem.a cryptanalysis of a cipher where plaintext-ciphertext pairs are known. This attack searches for an unknown key. Contrast with the chosen plaintext attack, where the cryptanalyst can also choose the plaintext to be enciphered.a system for sending and receiving mail without traceability or observability. Receiving mail anonymously can be done with broadcast of the mail in encrypted form. Only the intended recipient (whose identity, or true name, may be unknown to the sender) may able to decipher the message. Sending mail anonymously apparently requires mixes or use of the dining cryptographers (DC) protocol.another name for zero knowledge proofs, favored by Chaum.David Chaum's term for a box which performs the function of mixing, or decorrelating, incoming and outgoing electronic mail messages. The box also strips off the outer envelope (i.e., decrypts with its private key) and remails the message to the apress on the inner envelope. Tamper-resistant modules may be used to prevent cheating and forced disclosure of the mapping between incoming and outgoing mail. A sequence of many remailings effectively makes tracing sending and receiving impossible. Contrast this with the software version, the DC protocol.raising an integer to the power of another integer, modulo some integer. For integers a, n, and m, a^m mod n. For example, 5^3 mod 100 = 25. Modular exponentiation can be done fairly quickly with a sequence of bit shifts and aps, and special purpose chips have been designed. See also discrete logarithm.the largest intelligence agency, responsible for making and breaking ciphers, for intercepting communications, and for ensuring the security of U.S. computers. Headquartered in Fort Meade, Maryland, with many listening posts around the world. The NSA funds cryptographic research and advises other agencies about cryptographic matters. The NSA once obviously had the world's leading cryptologists, but this may no longer be the case.a credential that you possess that you don't want any one else to know, for example, a bankruptcy filing. A formal version of a negative reputation.a large class of difficult problems. \"NP\" stands for nondeterministic polynomial time, a class of problems thought in general not to have feasible algorithms for their solution. A problem is \"complete\" if any other NP problem may be reduced to that problem. Many important combinatorial and algebraic problems are NP-complete: the traveling salesman problem, the Hamiltonian cycle problem, the word problem, and on and on.a cryptographic primitive that involves the probabilistic transmission of bits. The sender does not know if the bits were received.a string of randomly-selected bits or symbols which is combined with a plaintext message to produce the ciphertext. This combination may be shifting letters some amount, bitwise exclusive-ORed, etc.). The recipient, who also has a copy of the one time pad, can easily recover the plaintext. Provided the pad is only used once and then destroyed, and is not available to an eavesdropper, the system is perfectly secure, i.e., it is information-theoretically secure. Key distribution (the pad) is obviously a practical concern, but consider CD-ROM's.a function which is easy to compute in one direction but hard to find any inverse for, e.g. modular exponentiation, where the inverse problem is known as the discrete logarithm problem. Compare the special case of trap door one-way functions. An example of a one-way operation is multiplication: it is easy to multiply two prime numbers of 100 digits to produce a 200-digit number, but hard to factor that 200-digit number.Certainly the most important unsolved problem in complexity theory. If P = NP, then cryptography as we know it today does not exist. If P = NP, all NP problems are \"easy.\"sending extra messages to confuse eavesdroppers and to defeat traffic analysis. Also aping random bits to a message to be enciphered.also called cleartext, the text that is to be enciphered.Phillip Zimmerman's implementation of RSA, recently upgraded to version 2.0, with more robust components and several new features. RSA Data Security has threatened PZ so he no longer works on it. Version 2.0 was written by a consortium of non-U.S. hackers.integers with no factors other than themselves and 1. The number of primes is unbounded. About 1% of the 100 decimal digit numbers are prime. Since there are about 10^70 particles in the universe, there are about 10^23 100 digit primes for each and every particle in the universe!a scheme by Goldwasser, Micali, and Blum that allows multiple ciphertexts for the same plaintext, i.e., any given plaintext may have many ciphertexts if the ciphering is repeated. This protects against certain types of known ciphertext attacks on RSA.proving who you are, either your true name, or your digital identity. Generally, possession of the right key is sufficient proof (guard your key!). Some work has been done on \"is-a-person\" credentialling agencies, using the so-called Fiat-Shamir protocol...think of this as a way to issue unforgeable digital passports. Physical proof of identity may be done with biometric security methods. Zero knowledge proofs of identity reveal nothing beyond the fact that the identity is as claimed. This has obvious uses for computer access, passwords, etc.a formal procedure for solving some problem. Modern cryptology is mostly about the study of protocols for many problems, such as coin-flipping, bit commitment (blobs), zero knowledge proofs, dining cryptographers, and so on.the key distributed publicly to potential message-senders. It may be published in a phonebook-like directory or otherwise sent. A major concern is the validity of this public key to guard against spoofing or impersonation.the modern breakthrough in cryptology, designed by Diffie and Hellman, with contributions from several others. Uses trap door one-way functions so that encryption may be done by anyone with access to the \"public key\" but decryption may be done only by the holder of the \"private key.\" Encompasses public key encryption, digital signatures, digital cash, and many other protocols and applications.the use of modern cryptologic methods to provided message security and authentication. The RSA algorithm is the most widely used form of public key encryption, although other systems exist. A public key may be freely published, e.g., in phonebook-like directories, while the corresponding private key is closely guarded.M.I.T. and Stanford, due to the work of Rivest, Shamir, Adleman, Diffie, Hellman, and Merkle, formed Public Key Partners to license the various public key, digital signature, and RSA patents. These patents, granted in the early 1980s, expire in the between 1998 and 2002. PKP has licensed RSA Data Security Inc., of Redwood City, CA, which handles the sales, etc.a system based on quantum-mechanical principles. Eavesdroppers alter the quantum state of the system and so are detected. Developed by Brassard and Bennett, only small laboratory demonstrations have been made.the trail of positive and negative associations and judgments that some entity accrues. Credit ratings, academic credentials, and trustworthiness are all examples. A digital pseudonym will accrue these reputation credentials based on actions, opinions of others, etc. In crypto anarchy, reputations and agoric systems will be of paramount importance. There are many fascinating issues of how reputation-based systems work, how credentials can be bought and sold, and so forth.the main public key encryption algorithm, developed by Ron Rivest, Adi Shamir, and Kenneth Adleman. It exploits the difficulty of factoring large numbers to create a private key and public key. First invented in 1978, it remains the core of modern public key systems. It is usually much slower than DES, but special-purpose modular exponentiation chips will likely speed it up. A popular scheme for speed is to use RSA to transmit session keys and then a high-speed cipher like DES for the actual message text.Let p and q be large primes, typically with more than 100 digits. Let n = pq and find some e such that e is relatively prime to (p - 1)(q - 1). The set of numbers p, q, and e is the private key for RSA. The set of numbers n and e forms the public key (recall that knowing n is not sufficient to easily find p and q...the factoring problem). A message M is encrypted by computing M^e mod n. The owner of the private key can decrypt the encrypted message by exploiting number theory results, as follows. An integer d is computed such that ed =1 (mod (p - 1)(q - 1)). Euler proved a theorem that M^(ed) = M mod n and so M^(ed) mod n = M. This means that in some sense the integers e and d are \"inverses\" of each other. [If this is unclear, please see one of the many texts and articles on public key encryption.]A system which uses the same key to encrypt and decrypt traffic at each end of a communication link. Also called a symmetric or one-key system. Contrast with public key cryptosystem.a computer chip embeped in credit card. They can hold cash, credentials, cryptographic keys, etc. Usually these are built with some degree of tamper-resistance. Smart cards may perform part of a crypto transaction, or all of it. Performing part of it may mean checking the computations of a more powerful computer, e.g., one in an ATM.posing as another user. Used for stealing passwords, modifying files, and stealing cash. Digital signatures and other authentication methods are useful to prevent this. Public keys must be validated and protected to ensure that others don't substitute their own public keys which users may then unwittingly use.a part of cryptology dealing with hiding messages and obscuring who is sending and receiving messages. Message traffic is often paped to reduce the signals that would otherwise come from a supen beginning of messages.same as private key cryptosystem.sealed boxes or modules which are hard to open, requiring extensive probing and usually leaving ample evidence that the tampering has occurred. Various protective techniques are used, such as special metal or oxide layers on chips, armored coatings, embeped optical fibers, and other measures to thwart analysis. Popularly called \"tamper-proof boxes.\" Uses include: smart cards, nuclear weapon initiators, cryptographic key holders, ATMs, etc.interfering with messages and possibly modifying them. This may compromise data security, help to break ciphers, etc. See also spoofing.some representation, such as ID cards, subway tokens, money, etc., that indicates possession of some property or value.determining who is sending or receiving messages by analyzing packets, frequency of packets, etc. A part of steganography. Usually handled with traffic paping.the protocols for determining who can send messages in a DC protocol, and when. These rules are needed to prevent collision and deliberate jamming of the channels.dummy messages in DC Nets which are used to catch jammers and disrupters. The messages contain no private information and are published in a blob beforehand so that the trap message can later be opened to reveal the disrupter. (There are many strategies to explore here.)In cryptography, a piece of secret information that allows the holder of a private key to invert a normally hard to invert function.functions which are easy to compute in both the forward and reverse direction but for which the disclosure of an algorithm to compute the function in the forward direction does not provide information on how to compute the function in the reverse direction. More simply put, trap-door one way functions are one way for all but the holder of the secret information. The RSA algorithm is the best-known example of such a function.same as information-theoretic security, that is, unbreakable except by loss or theft of the key.where no amount of intercepted ciphertext is enough to allow the cipher to be broken, as with the use of a one-time pad cipher. Contrast with computationally secure.Various schemes have been devised for anonymous, untraceable voting. Voting schemes should have several properties: privacy of the vote, security of the vote (no multiple votes), robustness against disruption by jammers or disrupters, verifiability (voter has confidence in the results), and efficiency.proofs in which no knowledge of the actual proof is conveyed. Peggy the Prover demonstrates to Sid the Skeptic that she is indeed in possession of some piece of knowledge without actually revealing any of that knowledge. This is useful for access to computers, because eavesdroppers or dishonest sysops cannot steal the knowledge given. Also called minimum disclosure proofs. Useful for proving possession of some property, or credential, such as age or voting status, without revealing personal information."}
{"prompt": "Detecting Double Spending", "completion": "Here is an attempt to describe Chaum's digital cash from his paper, Untraceable Electronic Cash, by Chaum, Fiat, and Naor, from the Crypto 88 proceedings. This cash has the property that the user of the cash can remain anonymous so long as she does not spend it more than once, but if she does double-spend then her identity is revealed.This is how it works in general terms: Alice opens an account with a bank non-anonymously. She shows ID so that the bank knows who she is; both she and the bank know her account number. When she withdraws cash, she goes to the bank or contacts them electronically and presents some proof of who she is and what her account number is, and the bank gives her some digital cash. The digital cash is an information pattern, perhaps stored in a computer file on a smart card or magnetic disk. Later, she spends the digital cash by sending or giving it to Bob, a merchant. Bob can check and verify that the cash must have come from the bank. He accepts the cash if it is valid, giving Alice the merchandise. Later, he sends the cash to the bank to be added to his own account.Note that this much could basically be done with a simple RSA signature. The bank could give Alice a statement saying, \"this is worth $1\", signed by the bank's secret key. Bob could verify that the statement was in fact signed by the bank, and know therefore that no one else than the bank could have created that statement. He accepts it and sends it to the bank, which honors it since it recognizes its own signature.One problem with this trivial money is that double-spending can not be detected or prevented since all the cash looks alike. This can be remedied by having the cash include a unique serial number. Now when Bob goes to accept the cash from Alice, he can call the bank and say, has anyone else deposited serial number 123456? If not, he accepts the cash and deposits it. This is called on-line electronic money; the merchant must check with the bank for each transaction.This improved simple system does not deserve to be called cash, though, because it lacks the distinguishing characteristic of digital cash: it is not anonymous. When the bank sees money with serial number 123456 being deposited, the bank recognizes that this was the same bill that Alice withdrew. The bank can therefore deduce that Alice spent the money at Bob's, and from this kind of information a dossier could be built up with all kinds of privacy-destroying information about her.To allow anonymity, we have to get into the mathematics. What we want is for Alice and the bank collectively to create an RSA signature from the bank that could not be forged, but one which the bank will not recognize as coming from Alice. This is the first thing Chaum's paper discusses.The money in this system is of the form (x, f(x)^(1/3)) mod n, where n is the bank's public modulus. f() (and, below, g()) is a one-way function, one which can be calculated easily but for which it is infeasible to calculate the inverse. It should also be infeasible to come up with two different y,z such that f(y) = f(z). Today there are several suitable choices for one-way functions, the most common being the MD5 algorithm from RSA, and the US government's Secure Hash Algorithm (SHA).The reason the expression above would be accepted as cash is two-fold. First, only the bank can calculate anything ^ (1/3) mod n. This is basically the RSA signing operation for the exponent of 3. Nobody else can find cube roots. The reason f(x) is used is this. Suppose we proposed that (x, x^(1/3)) should be the cash, for some random x, reasoning that only the bank could find the cube root of x. Can you see how to forge cash like this? (Take a few moments and try to see how you could construct a pair like this even if you can't take cube roots.)The answer is that it is easy to forge this by first choosing a random y, and exhibiting the pair (y^3, y). Now we have a number and then its cube root. Yet we didn't have to take any cube roots to find it. That's why this kind of money would be no good.Chaum's system avoids this by taking the cube root of a one-way function of x. To forge it without taking a cube root you'd have to produce (finv(y^3), y), which would match the above pattern, but you can't invert the one-way function like that. So only the bank can create money of the proper form. This can be thought of as the formal, mathematical form of my informal \"money\" above which was a digitally signed note with a serial number. Here, x is the serial number, and it's digitally signed in this special way. Nothing more is needed.The nice thing about this money is that it allows for blinding, a method of having the bank sign the value without knowing what value it is signing. It works like this. Alice chooses x, which will be the x in the cash. She calculates f(x), but instead of sending it to the bank to be signed (raised to the 1/3 power) she first chooses a random number r, and sends f(x)*r^3 to the bank. The bank takes this number to the 1/3 power, getting r * f(x)^(1/3). Remember, though, that the bank doesn't see r or f(x) separately, but just their product. It doesn't know what r or f(x) is. They could each be anything, actually.The bank sends this r * f(x)^(1/3) back to Alice, and she divides it by r, which she knows. This gives her f(x)^(1/3), and she puts that together with x to get her digital cash: (x, f(x)^(1/3)). She has a piece of money which could only have been signed by the bank, yet the bank won't recognize it when it is deposited.Other, non-mathematical, things take place as this withdrawal goes on. Alice must prove her identity to the bank, as mentioned above. And the bank will debit her account by the value of the cash. In this system, we are assuming for simplicity that all cash has the same value. In a real system, different values might be encoded by different exponents than 3.When Alice deposits the money, Bob must call the bank to make sure that it hasn't been deposited before, this being an \"on-line\" system. Although the bank won't recognize x (it's never heard of it) it will remember all the x's which have been deposited and so can alert Bob if the money has been spent before. Both Bob and the bank can verify the digital signature on the money and so will honor it.All the material above takes up less than one page of Chaum's nine-page paper. For Chaum, this much is trivial. Now we get to the interesting part. Now we will see the scheme that allows double-spenders to lose their anonymity. This will allow for \"off-line\" electronic cash; Bob will no longer have to check with the bank to see if the money has already been spent. He accepts it from Alice knowing that if she does cheat, the bank will honor the cash and sue Alice to make up the loss.(To make this explanation easier to follow, I will describe a slightly simplified version of Chaum's off-line cash. The version I describe requires the use of a non-invertable one-way function as in the f() used above. Chaum's version does not require as strong an assumption and provides \"unconditional\" untraceability even if the one-way function is broken.)Let's start with the form of the cash itself. It is the product of k/2 numbers, where k is a \"security parameter\" that affects the chance of a cheater succeeding. Each number is of the form g(xi,yi)^(1/3), where g is a two-argument one-way function similar to the f above. (The \"xi\", \"yi\", \"ai\", etc. here are separate values for each i from 0 to k/2.)xi and yi are like this: xi = f(ai), where ai is a random number, and f is another one-way function. yi is kind of complicated. It is f(ai xor <info>), where <info>, the key to this whole operation, is identifying information about Alice's account! It is her account number concatenated with a serial number for the cash.Now, why go through all this? Here's why. If you could find out both ai and (ai xor <info>), for some i, you would know Alice's identity. (Xor'ing them would produce <info>.) When Alice double-spends, both ai and ai xor <info>will be revealed.What happens when Alice spends the coin is this. For each i from 0 to k/2 Bob chooses 0 or 1 at random. If he chooses 1 he gets told ai and yi. If he chooses 0 he gets told (ai xor <info>) and xi. This will let him check the signature on the money, as described in more detail below.Notice that when Bob gets this information, he'll know a bunch of ai's, and he'll know a bunch of (ai xor <info>)'s, but they are for different i's. He doesn't know both ai and (ai xor <info>) for any one i. So he can't break Alice's anonymity.When Bob deposits the money at the bank, he passes along the information he got from Alice regarding the ai's and such.Now, suppose Alice cheats. She spends the money again somewhere else, at Charlie's. Charlie goes through the same procedure as Bob, choosing 0 or 1 at random for each value of i. Here is the catch. Since he is choosing at random, it would be very unlikely that he will choose exactly the same 0's and 1's that Bob chose. (Here is where the size of k matters \u2013 making it bigger makes it less likely that Charlie and Bob will choose the same pattern of 0's and 1's. But it makes the calculations take longer.) That means for one or more values of i, Charlie will probably choose a 0 where Bob chose a 1, or vice versa.Because of this, if Bob got ai for that i, Charlie will get ai xor <info>. Or if Bob got ai xor <info>, Charlie will get ai. Either way, when Charlie sends his record of this information to the bank, the bank will put Bob's and Charlie's information together and get both ai and ai xor <info>. Xor'ing these together reveals <info>, and Alice is caught! This is the main idea.(Chaum suggests not just relying on random chance to make sure Bob and Charlie use different sets of 1's and 0's. At least some of the bits might be assigned to Bob and Charlie by the bank in such a way that everybody gets a different number. This way it would be guaranteed that Bob and Charlie would choose opposite values for some i.)The reason for the money to have the form it does is so that Bob can check that it is signed by the bank. For each value of i Alice has to give him enough information to calculate xi and yi. If Bob choses a 1, she gives him ai and yi. Given ai Bob can calculate xi (=f(ai)), and with this and yi he can calculate g(xi,yi). If Bob chooses a 0, she gives him (ai xor <info>), as described before, and also xi. Given (ai xor <info>), Bob calculates yi (=f(ai xor <info>)), and with this and xi he can calculate g(xi,yi).So for each i, whether Bob gives a 0 or a 1 he gets enough information to calculate g(xi,yi). He multiplies these all together and confirms that they are equal to Alice's original \"money\" value when it is taken to the 3rd power (recall the money was product of g(xi,yi)^(1/3) for all i). Only the bank could have produced a signature on this one-way function f whose arguments take this special form.One more complication exists. (Well, actually, an almost infinite number of complications exist if you look hard enough. But we'll just focus on one more.) Alice needs to get this special form of money from the bank in such a way that the bank won't recognize it. That means she has to blind it. But in this case the bank wants to be sure that the money is of the proper form when it signs it; in particular, it wants to make darned sure that Alice's <info> which is buried deep in all of those f's of g's is actually the right one for her. But since the bank can't see what it is signing, this is hard to do.Chaum uses cut-and-choose for this. He has Alice prepare all these f's and g's according to the form above, carefully embedding her own incriminating <info> in each one. Then she multiplies each g(xi,yi) by a blinding factor ri^3 just like in the first cash. These are what she sends to the bank to be signed.The trick, though, is that she sends twice as many as will be used. She sends k of them, but only k/2 will be used. (That's why the loop above used k/2 as the limit.) The bank chooses k/2 at random out of the k she sent as the ones which will actually be used. Alice then has to send the blinding ri values for the ones which the bank didn't pick.The idea is that if Alice tries to cheat, embedding \"Bozo\" instead of \"Alice\" in that <info> field, she's taking a chance. First, to be useful, she's going to have to embed it in a lot of <info> fields for different values of i. When Bob and Charlie compare notes after she double-spends, every value of i for which they chose different 0's and 1's, which will be on the average half of them, will reveal an <info> field. If she only fakes a few, chances are her real identity will still be revealed.But if she falsifies a great many of them, then when the bank chooses half, chances are at least some of the fake ones will be in the set the bank didn't choose. Then when Alice has to reveal her blinding r's, the jig will be up. The bank will un-blind all those g(xi,yi)'s which aren't being used, and see the fake <info> fields.This cut-and-choose methodology has the disadvantage that Alice has to do twice as much work in preparing the money, half of which will just be thrown away. But it is a simple, \"brute force\" way to make sure that blinding signatures are actually being done on properly-formed data.So, there you have it. Anonymity as long as you don't cheat, and double-spenders get caught. It's a little complicated but that's what computers are for; Bob and Alice wouldn't do all this stuff by hand. Alice would push the \"generate a money candidate\" button and get something to be sent to the bank (lots of the new PDA's have infrared wireless communications that would be perfect for face-to-face transactions). Bob would push the \"check money\" button when Alice spent it and it would flash red or green. As long as the calculations don't actually take too much time, which they really wouldn't in this case despite this long-winded explanation, the people involved can ignore the details.Hal Finney\nhal@rain.orgHal Finney Home Page"}
{"prompt": "The Cathedral and the Bazaar", "completion": "I anatomize a successful open-source project, fetchmail, that was run as a deliberate test of the surprising theories about software engineering suggested by the history of Linux. I discuss these theories in terms of two fundamentally different development styles, the \"cathedral\" model of most of the commercial world versus the \"bazaar\" model of the Linux world. I show that these models derive from opposing assumptions about the nature of the software-debugging task. I then make a sustained argument from the Linux experience for the proposition that \"Given enough eyeballs, all bugs are shallow\", suggest productive analogies with other self-correcting systems of selfish agents, and conclude with some exploration of the implications of this insight for the future of software.Linux is subversive. Who would have thought even five years ago (1991) that a world-class operating system could coalesce as if by magic out of part-time hacking by several thousand developers scattered all over the planet, connected only by the tenuous strands of the Internet?Certainly not I. By the time Linux swam onto my radar screen in early 1993, I had already been involved in Unix and open-source development for ten years. I was one of the first GNU contributors in the mid-1980s. I had released a good deal of open-source software onto the net, developing or co-developing several programs (nethack, Emacs's VC and GUD modes, xlife, and others) that are still in wide use today. I thought I knew how it was done.Linux overturned much of what I thought I knew. I had been preaching the Unix gospel of small tools, rapid prototyping and evolutionary programming for years. But I also believed there was a certain critical complexity above which a more centralized, a priori approach was required. I believed that the most important software (operating systems and really large tools like the Emacs programming editor) needed to be built like cathedrals, carefully crafted by individual wizards or small bands of mages working in splendid isolation, with no beta to be released before its time.Linus Torvalds's style of development\u2014release early and often, delegate everything you can, be open to the point of promiscuity\u2014came as a surprise. No quiet, reverent cathedral-building here\u2014rather, the Linux community seemed to resemble a great babbling bazaar of differing agendas and approaches (aptly symbolized by the Linux archive sites, who'd take submissions from anyone) out of which a coherent and stable system could seemingly emerge only by a succession of miracles.The fact that this bazaar style seemed to work, and work well, came as a distinct shock. As I learned my way around, I worked hard not just at individual projects, but also at trying to understand why the Linux world not only didn't fly apart in confusion but seemed to go from strength to strength at a speed barely imaginable to cathedral-builders.By mid-1996 I thought I was beginning to understand. Chance handed me a perfect way to test my theory, in the form of an open-source project that I could consciously try to run in the bazaar style. So I did\u2014and it was a significant success.This is the story of that project. I'll use it to propose some aphorisms about effective open-source development. Not all of these are things I first learned in the Linux world, but we'll see how the Linux world gives them particular point. If I'm correct, they'll help you understand exactly what it is that makes the Linux community such a fountain of good software\u2014and, perhaps, they will help you become more productive yourself.Since 1993 I'd been running the technical side of a small free-access Internet service provider called Chester County InterLink (CCIL) in West Chester, Pennsylvania. I co-founded CCIL and wrote our unique multiuser bulletin-board software\u2014you can check it out by telnetting to locke.ccil.org. Today it supports almost three thousand users on thirty lines. The job allowed me 24-hour-a-day access to the net through CCIL's 56K line\u2014in fact, the job practically demanded it!I had gotten quite used to instant Internet email. I found having to periodically telnet over to locke to check my mail annoying. What I wanted was for my mail to be delivered on snark (my home system) so that I would be notified when it arrived and could handle it using all my local tools.The Internet's native mail forwarding protocol, SMTP (Simple Mail Transfer Protocol), wouldn't suit, because it works best when machines are connected full-time, while my personal machine isn't always on the Internet, and doesn't have a static IP address. What I needed was a program that would reach out over my intermittent dialup connection and pull across my mail to be delivered locally. I knew such things existed, and that most of them used a simple application protocol called POP (Post Office Protocol). POP is now widely supported by most common mail clients, but at the time, it wasn't built in to the mail reader I was using.I needed a POP3 client. So I went out on the Internet and found one. Actually, I found three or four. I used one of them for a while, but it was missing what seemed an obvious feature, the ability to hack the addresses on fetched mail so replies would work properly.The problem was this: suppose someone named 'joe' on locke sent me mail. If I fetched the mail to snark and then tried to reply to it, my mailer would cheerfully try to ship it to a nonexistent 'joe' on snark. Hand-editing reply addresses to tack on <@ccil.org> quickly got to be a serious pain.This was clearly something the computer ought to be doing for me. But none of the existing POP clients knew how! And this brings us to the first lesson:Perhaps this should have been obvious (it's long been proverbial that \"Necessity is the mother of invention\") but too often software developers spend their days grinding away for pay at programs they neither need nor love. But not in the Linux world\u2014which may explain why the average quality of software originated in the Linux community is so high.So, did I immediately launch into a furious whirl of coding up a brand-new POP3 client to compete with the existing ones? Not on your life! I looked carefully at the POP utilities I had in hand, asking myself \"Which one is closest to what I want?\" Because:While I don't claim to be a great programmer, I try to imitate one. An important trait of the great ones is constructive laziness. They know that you get an A not for effort but for results, and that it's almost always easier to start from a good partial solution than from nothing at all.Linus Torvalds, for example, didn't actually try to write Linux from scratch. Instead, he started by reusing code and ideas from Minix, a tiny Unix-like operating system for PC clones. Eventually all the Minix code went away or was completely rewritten\u2014but while it was there, it provided scaffolding for the infant that would eventually become Linux.In the same spirit, I went looking for an existing POP utility that was reasonably well coded, to use as a development base.The source-sharing tradition of the Unix world has always been friendly to code reuse (this is why the GNU project chose Unix as a base OS, in spite of serious reservations about the OS itself). The Linux world has taken this tradition nearly to its technological limit; it has terabytes of open sources generally available. So spending time looking for some else's almost-good-enough is more likely to give you good results in the Linux world than anywhere else.And it did for me. With those I'd found earlier, my second search made up a total of nine candidates\u2014fetchpop, PopTart, get-mail, gwpop, pimp, pop-perl, popc, popmail and upop. The one I first settled on was 'fetchpop' by Seung-Hong Oh. I put my header-rewrite feature in it, and made various other improvements which the author accepted into his 1.9 release.A few weeks later, though, I stumbled across the code for popclient by Carl Harris, and found I had a problem. Though fetchpop had some good original ideas in it (such as its background-daemon mode), it could only handle POP3 and was rather amateurishly coded (Seung-Hong was at that time a bright but inexperienced programmer, and both traits showed). Carl's code was better, quite professional and solid, but his program lacked several important and rather tricky-to-implement fetchpop features (including those I'd coded myself).Stay or switch? If I switched, I'd be throwing away the coding I'd already done in exchange for a better development base.A practical motive to switch was the presence of multiple-protocol support. POP3 is the most commonly used of the post-office server protocols, but not the only one. Fetchpop and the other competition didn't do POP2, RPOP, or APOP, and I was already having vague thoughts of perhaps adding IMAP (Internet Message Access Protocol, the most recently designed and most powerful post-office protocol) just for fun.But I had a more theoretical reason to think switching might be as good an idea as well, something I learned long before Linux.Or, to put it another way, you often don't really understand the problem until after the first time you implement a solution. The second time, maybe you know enough to do it right. So if you want to get it right, be ready to start over at least once[JB].Well (I told myself) the changes to fetchpop had been my first try. So I switched.After I sent my first set of popclient patches to Carl Harris on 25 June 1996, I found out that he had basically lost interest in popclient some time before. The code was a bit dusty, with minor bugs hanging out. I had many changes to make, and we quickly agreed that the logical thing for me to do was take over the program.Without my actually noticing, the project had escalated. No longer was I just contemplating minor patches to an existing POP client. I took on maintaining an entire one, and there were ideas bubbling in my head that I knew would probably lead to major changes.In a software culture that encourages code-sharing, this is a natural way for a project to evolve. I was acting out this principle:But Carl Harris's attitude was even more important. He understood thatWithout ever having to discuss it, Carl and I knew we had a common goal of having the best solution out there. The only question for either of us was whether I could establish that I was a safe pair of hands. Once I did that, he acted with grace and dispatch. I hope I will do as well when it comes my turn.And so I inherited popclient. Just as importantly, I inherited popclient's user base. Users are wonderful things to have, and not just because they demonstrate that you're serving a need, that you've done something right. Properly cultivated, they can become co-developers.Another strength of the Unix tradition, one that Linux pushes to a happy extreme, is that a lot of users are hackers too. Because source code is available, they can be effective hackers. This can be tremendously useful for shortening debugging time. Given a bit of encouragement, your users will diagnose problems, suggest fixes, and help improve the code far more quickly than you could unaided.The power of this effect is easy to underestimate. In fact, pretty well all of us in the open-source world drastically underestimated how well it would scale up with number of users and against system complexity, until Linus Torvalds showed us differently.In fact, I think Linus's cleverest and most consequential hack was not the construction of the Linux kernel itself, but rather his invention of the Linux development model. When I expressed this opinion in his presence once, he smiled and quietly repeated something he has often said: \"I'm basically a very lazy person who likes to get credit for things other people actually do.\" Lazy like a fox. Or, as Robert Heinlein famously wrote of one of his characters, too lazy to fail.In retrospect, one precedent for the methods and success of Linux can be seen in the development of the GNU Emacs Lisp library and Lisp code archives. In contrast to the cathedral-building style of the Emacs C core and most other GNU tools, the evolution of the Lisp code pool was fluid and very user-driven. Ideas and prototype modes were often rewritten three or four times before reaching a stable final form. And loosely-coupled collaborations enabled by the Internet, a la Linux, were frequent.Indeed, my own most successful single hack previous to fetchmail was probably Emacs VC (version control) mode, a Linux-like collaboration by email with three other people, only one of whom (Richard Stallman, the author of Emacs and founder of the Free Software Foundation) I have met to this day. It was a front-end for SCCS, RCS and later CVS from within Emacs that offered \"one-touch\" version control operations. It evolved from a tiny, crude sccs.el mode somebody else had written. And the development of VC succeeded because, unlike Emacs itself, Emacs Lisp code could go through release/test/improve generations very quickly.The Emacs story is not unique. There have been other software products with a two-level architecture and a two-tier user community that combined a cathedral-mode core and a bazaar-mode toolbox. One such is MATLAB, a commercial data-analysis and visualization tool. Users of MATLAB and other products with a similar structure invariably report that the action, the ferment, the innovation mostly takes place in the open part of the tool where a large and varied community can tinker with it.Early and frequent releases are a critical part of the Linux development model. Most developers (including me) used to believe this was bad policy for larger than trivial projects, because early versions are almost by definition buggy versions and you don't want to wear out the patience of your users.This belief reinforced the general commitment to a cathedral-building style of development. If the overriding objective was for users to see as few bugs as possible, why then you'd only release a version every six months (or less often), and work like a dog on debugging between releases. The Emacs C core was developed this way. The Lisp library, in effect, was not\u2014because there were active Lisp archives outside the FSF's control, where you could go to find new and development code versions independently of Emacs's release cycle[QR].The most important of these, the Ohio State Emacs Lisp archive, anticipated the spirit and many of the features of today's big Linux archives. But few of us really thought very hard about what we were doing, or about what the very existence of that archive suggested about problems in the FSF's cathedral-building development model. I made one serious attempt around 1992 to get a lot of the Ohio code formally merged into the official Emacs Lisp library. I ran into political trouble and was largely unsuccessful.But by a year later, as Linux became widely visible, it was clear that something different and much healthier was going on there. Linus's open development policy was the very opposite of cathedral-building. Linux's Internet archives were burgeoning, multiple distributions were being floated. And all of this was driven by an unheard-of frequency of core system releases.Linus was treating his users as co-developers in the most effective possible way:Linus's innovation wasn't so much in doing quick-turnaround releases incorporating lots of user feedback (something like this had been Unix-world tradition for a long time), but in scaling it up to a level of intensity that matched the complexity of what he was developing. In those early times (around 1991) it wasn't unknown for him to release a new kernel more than once a day! Because he cultivated his base of co-developers and leveraged the Internet for collaboration harder than anyone else, this worked.But how did it work? And was it something I could duplicate, or did it rely on some unique genius of Linus Torvalds?I didn't think so. Granted, Linus is a damn fine hacker. How many of us could engineer an entire production-quality operating system kernel from scratch? But Linux didn't represent any awesome conceptual leap forward. Linus is not (or at least, not yet) an innovative genius of design in the way that, say, Richard Stallman or James Gosling (of NeWS and Java) are. Rather, Linus seems to me to be a genius of engineering and implementation, with a sixth sense for avoiding bugs and development dead-ends and a true knack for finding the minimum-effort path from point A to point B. Indeed, the whole design of Linux breathes this quality and mirrors Linus's essentially conservative and simplifying design approach.So, if rapid releases and leveraging the Internet medium to the hilt were not accidents but integral parts of Linus's engineering-genius insight into the minimum-effort path, what was he maximizing? What was he cranking out of the machinery?Put that way, the question answers itself. Linus was keeping his hacker/users constantly stimulated and rewarded\u2014stimulated by the prospect of having an ego-satisfying piece of the action, rewarded by the sight of constant (even daily) improvement in their work.Linus was directly aiming to maximize the number of person-hours thrown at debugging and development, even at the possible cost of instability in the code and user-base burnout if any serious bug proved intractable. Linus was behaving as though he believed something like this:Or, less formally, \"Given enough eyeballs, all bugs are shallow.\" I dub this: \"Linus's Law\".My original formulation was that every problem \"will be transparent to somebody\". Linus demurred that the person who understands and fixes the problem is not necessarily or even usually the person who first characterizes it. \"Somebody finds the problem,\" he says, \"and somebody else understands it. And I'll go on record as saying that finding it is the bigger challenge.\" That correction is important; we'll see how in the next section, when we examine the practice of debugging in more detail. But the key point is that both parts of the process (finding and fixing) tend to happen rapidly.In Linus's Law, I think, lies the core difference underlying the cathedral-builder and bazaar styles. In the cathedral-builder view of programming, bugs and development problems are tricky, insidious, deep phenomena. It takes months of scrutiny by a dedicated few to develop confidence that you've winkled them all out. Thus the long release intervals, and the inevitable disappointment when long-awaited releases are not perfect.In the bazaar view, on the other hand, you assume that bugs are generally shallow phenomena\u2014or, at least, that they turn shallow pretty quickly when exposed to a thousand eager co-developers pounding on every single new release. Accordingly you release often in order to get more corrections, and as a beneficial side effect you have less to lose if an occasional botch gets out the door.And that's it. That's enough. If \"Linus's Law\" is false, then any system as complex as the Linux kernel, being hacked over by as many hands as the that kernel was, should at some point have collapsed under the weight of unforseen bad interactions and undiscovered \"deep\" bugs. If it's true, on the other hand, it is sufficient to explain Linux's relative lack of bugginess and its continuous uptimes spanning months or even years.Maybe it shouldn't have been such a surprise, at that. Sociologists years ago discovered that the averaged opinion of a mass of equally expert (or equally ignorant) observers is quite a bit more reliable a predictor than the opinion of a single randomly-chosen one of the observers. They called this the Delphi effect. It appears that what Linus has shown is that this applies even to debugging an operating system\u2014that the Delphi effect can tame development complexity even at the complexity level of an OS kernel.[CV]One special feature of the Linux situation that clearly helps along the Delphi effect is the fact that the contributors for any given project are self-selected. An early respondent pointed out that contributions are received not from a random sample, but from people who are interested enough to use the software, learn about how it works, attempt to find solutions to problems they encounter, and actually produce an apparently reasonable fix. Anyone who passes all these filters is highly likely to have something useful to contribute.Linus's Law can be rephrased as \"Debugging is parallelizable\". Although debugging requires debuggers to communicate with some coordinating developer, it doesn't require significant coordination between debuggers. Thus it doesn't fall prey to the same quadratic complexity and management costs that make adding developers problematic.In practice, the theoretical loss of efficiency due to duplication of work by debuggers almost never seems to be an issue in the Linux world. One effect of a \"release early and often\" policy is to minimize such duplication by propagating fed-back fixes quickly[JH].Brooks (the author of The Mythical Man-Month) even made an off-hand observation related to this: \"The total cost of maintaining a widely used program is typically 40 percent or more of the cost of developing it. Surprisingly this cost is strongly affected by the number of users. More users find more bugs.\" [emphasis added].More users find more bugs because adding more users adds more different ways of stressing the program. This effect is amplified when the users are co-developers. Each one approaches the task of bug characterization with a slightly different perceptual set and analytical toolkit, a different angle on the problem. The \"Delphi effect\" seems to work precisely because of this variation. In the specific context of debugging, the variation also tends to reduce duplication of effort.So adding more beta-testers may not reduce the complexity of the current \"deepest\" bug from the developer's point of view, but it increases the probability that someone's toolkit will be matched to the problem in such a way that the bug is shallow to that person.Linus coppers his bets, too. In case there are serious bugs, Linux kernel version are numbered in such a way that potential users can make a choice either to run the last version designated \"stable\" or to ride the cutting edge and risk bugs in order to get new features. This tactic is not yet systematically imitated by most Linux hackers, but perhaps it should be; the fact that either choice is available makes both more attractive.[HBS]It's one thing to observe in the large that the bazaar style greatly accelerates debugging and code evolution. It's another to understand exactly how and why it does so at the micro-level of day-to-day developer and tester behavior. In this section (written three years after the original paper, using insights by developers who read it and re-examined their own behavior) we'll take a hard look at the actual mechanisms. Non-technically inclined readers can safely skip to the next section.One key to understanding is to realize exactly why it is that the kind of bug report non\u2013source-aware users normally turn in tends not to be very useful. Non\u2013source-aware users tend to report only surface symptoms; they take their environment for granted, so they (a) omit critical background data, and (b) seldom include a reliable recipe for reproducing the bug.The underlying problem here is a mismatch between the tester's and the developer's mental models of the program; the tester, on the outside looking in, and the developer on the inside looking out. In closed-source development they're both stuck in these roles, and tend to talk past each other and find each other deeply frustrating.Open-source development breaks this bind, making it far easier for tester and developer to develop a shared representation grounded in the actual source code and to communicate effectively about it. Practically, there is a huge difference in leverage for the developer between the kind of bug report that just reports externally-visible symptoms and the kind that hooks directly to the developer's source-code\u2013based mental representation of the program.Most bugs, most of the time, are easily nailed given even an incomplete but suggestive characterization of their error conditions at source-code level. When someone among your beta-testers can point out, \"there's a boundary problem in line nnn\", or even just \"under conditions X, Y, and Z, this variable rolls over\", a quick look at the offending code often suffices to pin down the exact mode of failure and generate a fix.Thus, source-code awareness by both parties greatly enhances both good communication and the synergy between what a beta-tester reports and what the core developer(s) know. In turn, this means that the core developers' time tends to be well conserved, even with many collaborators.Another characteristic of the open-source method that conserves developer time is the communication structure of typical open-source projects. Above I used the term \"core developer\"; this reflects a distinction between the project core (typically quite small; a single core developer is common, and one to three is typical) and the project halo of beta-testers and available contributors (which often numbers in the hundreds).The fundamental problem that traditional software-development organization addresses is Brook's Law: \"Adding more programmers to a late project makes it later.\" More generally, Brooks's Law predicts that the complexity and communication costs of a project rise with the square of the number of developers, while work done only rises linearly.Brooks's Law is founded on experience that bugs tend strongly to cluster at the interfaces between code written by different people, and that communications/coordination overhead on a project tends to rise with the number of interfaces between human beings. Thus, problems scale with the number of communications paths between developers, which scales as the square of the humber of developers (more precisely, according to the formula N*(N - 1)/2 where N is the number of developers).The Brooks's Law analysis (and the resulting fear of large numbers in development groups) rests on a hidden assummption: that the communications structure of the project is necessarily a complete graph, that everybody talks to everybody else. But on open-source projects, the halo developers work on what are in effect separable parallel subtasks and interact with each other very little; code changes and bug reports stream through the core group, and only within that small core group do we pay the full Brooksian overhead.[SU]There are are still more reasons that source-code\u2013level bug reporting tends to be very efficient. They center around the fact that a single error can often have multiple possible symptoms, manifesting differently depending on details of the user's usage pattern and environment. Such errors tend to be exactly the sort of complex and subtle bugs (such as dynamic-memory-management errors or nondeterministic interrupt-window artifacts) that are hardest to reproduce at will or to pin down by static analysis, and which do the most to create long-term problems in software.A tester who sends in a tentative source-code\u2013level characterization of such a multi-symptom bug (e.g. \"It looks to me like there's a window in the signal handling near line 1250\" or \"Where are you zeroing that buffer?\") may give a developer, otherwise too close to the code to see it, the critical clue to a half-dozen disparate symptoms. In cases like this, it may be hard or even impossible to know which externally-visible misbehaviour was caused by precisely which bug\u2014but with frequent releases, it's unnecessary to know. Other collaborators will be likely to find out quickly whether their bug has been fixed or not. In many cases, source-level bug reports will cause misbehaviours to drop out without ever having been attributed to any specific fix.Complex multi-symptom errors also tend to have multiple trace paths from surface symptoms back to the actual bug. Which of the trace paths a given developer or tester can chase may depend on subtleties of that person's environment, and may well change in a not obviously deterministic way over time. In effect, each developer and tester samples a semi-random set of the program's state space when looking for the etiology of a symptom. The more subtle and complex the bug, the less likely that skill will be able to guarantee the relevance of that sample.For simple and easily reproducible bugs, then, the accent will be on the \"semi\" rather than the \"random\"; debugging skill and intimacy with the code and its architecture will matter a lot. But for complex bugs, the accent will be on the \"random\". Under these circumstances many people running traces will be much more effective than a few people running traces sequentially\u2014even if the few have a much higher average skill level.This effect will be greatly amplified if the difficulty of following trace paths from different surface symptoms back to a bug varies significantly in a way that can't be predicted by looking at the symptoms. A single developer sampling those paths sequentially will be as likely to pick a difficult trace path on the first try as an easy one. On the other hand, suppose many people are trying trace paths in parallel while doing rapid releases. Then it is likely one of them will find the easiest path immediately, and nail the bug in a much shorter time. The project maintainer will see that, ship a new release, and the other people running traces on the same bug will be able to stop before having spent too much time on their more difficult traces[RJ].Having studied Linus's behavior and formed a theory about why it was successful, I made a conscious decision to test this theory on my new (admittedly much less complex and ambitious) project.But the first thing I did was reorganize and simplify popclient a lot. Carl Harris's implementation was very sound, but exhibited a kind of unnecessary complexity common to many C programmers. He treated the code as central and the data structures as support for the code. As a result, the code was beautiful but the data structure design ad-hoc and rather ugly (at least by the high standards of this veteran LISP hacker).I had another purpose for rewriting besides improving the code and the data structure design, however. That was to evolve it into something I understood completely. It's no fun to be responsible for fixing bugs in a program you don't understand.For the first month or so, then, I was simply following out the implications of Carl's basic design. The first serious change I made was to add IMAP support. I did this by reorganizing the protocol machines into a generic driver and three method tables (for POP2, POP3, and IMAP). This and the previous changes illustrate a general principle that's good for programmers to keep in mind, especially in languages like C that don't naturally do dynamic typing:Brooks, Chapter 9: \"Show me your flowchart and conceal your tables, and I shall continue to be mystified. Show me your tables, and I won't usually need your flowchart; it'll be obvious.\"\" Allowing for thirty years of terminological/cultural shift, it's the same point.At this point (early September 1996, about six weeks from zero) I started thinking that a name change might be in order\u2014after all, it wasn't just a POP client any more. But I hesitated, because there was as yet nothing genuinely new in the design. My version of popclient had yet to develop an identity of its own.That changed, radically, when popclient learned how to forward fetched mail to the SMTP port. I'll get to that in a moment. But first: I said earlier that I'd decided to use this project to test my theory about what Linus Torvalds had done right. How (you may well ask) did I do that? In these ways:The payoff from these simple measures was immediate. From the beginning of the project, I got bug reports of a quality most developers would kill for, often with good fixes attached. I got thoughtful criticism, I got fan mail, I got intelligent feature suggestions. Which leads to:One interesting measure of fetchmail's success is the sheer size of the project beta list, fetchmail-friends. At the time of latest revision of this paper (November 2000) it has 287 members and is adding two or three a week.Actually, when I revised in late May 1997 I found the list was beginning to lose members from its high of close to 300 for an interesting reason. Several people have asked me to unsubscribe them because fetchmail is working so well for them that they no longer need to see the list traffic! Perhaps this is part of the normal life-cycle of a mature bazaar-style project.The real turning point in the project was when Harry Hochheiser sent me his scratch code for forwarding mail to the client machine's SMTP port. I realized almost immediately that a reliable implementation of this feature would make all the other mail delivery modes next to obsolete.For many weeks I had been tweaking fetchmail rather incrementally while feeling like the interface design was serviceable but grubby\u2014inelegant and with too many exiguous options hanging out all over. The options to dump fetched mail to a mailbox file or standard output particularly bothered me, but I couldn't figure out why.(If you don't care about the technicalia of Internet mail, the next two paragraphs can be safely skipped.)What I saw when I thought about SMTP forwarding was that popclient had been trying to do too many things. It had been designed to be both a mail transport agent (MTA) and a local delivery agent (MDA). With SMTP forwarding, it could get out of the MDA business and be a pure MTA, handing off mail to other programs for local delivery just as sendmail does.Why mess with all the complexity of configuring a mail delivery agent or setting up lock-and-append on a mailbox when port 25 is almost guaranteed to be there on any platform with TCP/IP support in the first place? Especially when this means retrieved mail is guaranteed to look like normal sender-initiated SMTP mail, which is really what we want anyway.(Back to a higher level....)Even if you didn't follow the preceding technical jargon, there are several important lessons here. First, this SMTP-forwarding concept was the biggest single payoff I got from consciously trying to emulate Linus's methods. A user gave me this terrific idea\u2014all I had to do was understand the implications.Interestingly enough, you will quickly find that if you are completely and self-deprecatingly truthful about how much you owe other people, the world at large will treat you as though you did every bit of the invention yourself and are just being becomingly modest about your innate genius. We can all see how well this worked for Linus!(When I gave my talk at the first Perl Conference in August 1997, hacker extraordinaire Larry Wall was in the front row. As I got to the last line above he called out, religious-revival style, \"Tell it, tell it, brother!\". The whole audience laughed, because they knew this had worked for the inventor of Perl, too.)After a very few weeks of running the project in the same spirit, I began to get similar praise not just from my users but from other people to whom the word leaked out. I stashed away some of that email; I'll look at it again sometime if I ever start wondering whether my life has been worthwhile :-).But there are two more fundamental, non-political lessons here that are general to all kinds of design.I had been trying to solve the wrong problem by continuing to develop popclient as a combined MTA/MDA with all kinds of funky local delivery modes. Fetchmail's design needed to be rethought from the ground up as a pure MTA, a part of the normal SMTP-speaking Internet mail path.When you hit a wall in development\u2014when you find yourself hard put to think past the next patch\u2014it's often time to ask not whether you've got the right answer, but whether you're asking the right question. Perhaps the problem needs to be reframed.Well, I had reframed my problem. Clearly, the right thing to do was (1) hack SMTP forwarding support into the generic driver, (2) make it the default mode, and (3) eventually throw out all the other delivery modes, especially the deliver-to-file and deliver-to-standard-output options.I hesitated over step 3 for some time, fearing to upset long-time popclient users dependent on the alternate delivery mechanisms. In theory, they could immediately switch to .forward files or their non-sendmail equivalents to get the same effects. In practice the transition might have been messy.But when I did it, the benefits proved huge. The cruftiest parts of the driver code vanished. Configuration got radically simpler\u2014no more grovelling around for the system MDA and user's mailbox, no more worries about whether the underlying OS supports file locking.Also, the only way to lose mail vanished. If you specified delivery to a file and the disk got full, your mail got lost. This can't happen with SMTP forwarding because your SMTP listener won't return OK unless the message can be delivered or at least spooled for later delivery.Also, performance improved (though not so you'd notice it in a single run). Another not insignificant benefit of this change was that the manual page got a lot simpler.Later, I had to bring delivery via a user-specified local MDA back in order to allow handling of some obscure situations involving dynamic SLIP. But I found a much simpler way to do it.The moral? Don't hesitate to throw away superannuated features when you can do it without loss of effectiveness. Antoine de Saint-Exup\u00e9ry (who was an aviator and aircraft designer when he wasn't authoring classic children's books) said:When your code is getting both better and simpler, that is when you know it's right. And in the process, the fetchmail design acquired an identity of its own, different from the ancestral popclient.It was time for the name change. The new design looked much more like a dual of sendmail than the old popclient had; both are MTAs, but where sendmail pushes then delivers, the new popclient pulls then delivers. So, two months off the blocks, I renamed it fetchmail.There is a more general lesson in this story about how SMTP delivery came to fetchmail. It is not only debugging that is parallelizable; development and (to a perhaps surprising extent) exploration of design space is, too. When your development mode is rapidly iterative, development and enhancement may become special cases of debugging\u2014fixing 'bugs of omission' in the original capabilities or concept of the software.Even at a higher level of design, it can be very valuable to have lots of co-developers random-walking through the design space near your product. Consider the way a puddle of water finds a drain, or better yet how ants find food: exploration essentially by diffusion, followed by exploitation mediated by a scalable communication mechanism. This works very well; as with Harry Hochheiser and me, one of your outriders may well find a huge win nearby that you were just a little too close-focused to see.There I was with a neat and innovative design, code that I knew worked well because I used it every day, and a burgeoning beta list. It gradually dawned on me that I was no longer engaged in a trivial personal hack that might happen to be useful to few other people. I had my hands on a program that every hacker with a Unix box and a SLIP/PPP mail connection really needs.With the SMTP forwarding feature, it pulled far enough in front of the competition to potentially become a \"category killer\", one of those classic programs that fills its niche so competently that the alternatives are not just discarded but almost forgotten.I think you can't really aim or plan for a result like this. You have to get pulled into it by design ideas so powerful that afterward the results just seem inevitable, natural, even foreordained. The only way to try for ideas like that is by having lots of ideas\u2014or by having the engineering judgment to take other peoples' good ideas beyond where the originators thought they could go.Andy Tanenbaum had the original idea to build a simple native Unix for IBM PCs, for use as a teaching tool (he called it Minix). Linus Torvalds pushed the Minix concept further than Andrew probably thought it could go\u2014and it grew into something wonderful. In the same way (though on a smaller scale), I took some ideas by Carl Harris and Harry Hochheiser and pushed them hard. Neither of us was 'original' in the romantic way people think is genius. But then, most science and engineering and software development isn't done by original genius, hacker mythology to the contrary.The results were pretty heady stuff all the same\u2014in fact, just the kind of success every hacker lives for! And they meant I would have to set my standards even higher. To make fetchmail as good as I now saw it could be, I'd have to write not just for my own needs, but also include and support features necessary to others but outside my orbit. And do that while keeping the program simple and robust.The first and overwhelmingly most important feature I wrote after realizing this was multidrop support\u2014the ability to fetch mail from mailboxes that had accumulated all mail for a group of users, and then route each piece of mail to its individual recipients.I decided to add the multidrop support partly because some users were clamoring for it, but mostly because I thought it would shake bugs out of the single-drop code by forcing me to deal with addressing in full generality. And so it proved. Getting RFC 822 address parsing right took me a remarkably long time, not because any individual piece of it is hard but because it involved a pile of interdependent and fussy details.But multidrop addressing turned out to be an excellent design decision as well. Here's how I knew:The unexpected use for multidrop fetchmail is to run mailing lists with the list kept, and alias expansion done, on the client side of the Internet connection. This means someone running a personal machine through an ISP account can manage a mailing list without continuing access to the ISP's alias files.Another important change demanded by my beta-testers was support for 8-bit MIME (Multipurpose Internet Mail Extensions) operation. This was pretty easy to do, because I had been careful to keep the code 8-bit clean (that is, to not press the 8th bit, unused in the ASCII character set, into service to carry information within the program). Not because I anticipated the demand for this feature, but rather in obedience to another rule:Had I not obeyed this rule, 8-bit MIME support would have been difficult and buggy. As it was, all I had to do is read the MIME standard (RFC 1652) and add a trivial bit of header-generation logic.Some European users bugged me into adding an option to limit the number of messages retrieved per session (so they can control costs from their expensive phone networks). I resisted this for a long time, and I'm still not entirely happy about it. But if you're writing for the world, you have to listen to your customers\u2014this doesn't change just because they're not paying you in money.Before we go back to general software-engineering issues, there are a couple more specific lessons from the fetchmail experience to ponder. Nontechnical readers can safely skip this section.The rc (control) file syntax includes optional 'noise' keywords that are entirely ignored by the parser. The English-like syntax they allow is considerably more readable than the traditional terse keyword-value pairs you get when you strip them all out.These started out as a late-night experiment when I noticed how much the rc file declarations were beginning to resemble an imperative minilanguage. (This is also why I changed the original popclient \"server\" keyword to \"poll\").It seemed to me that trying to make that imperative minilanguage more like English might make it easier to use. Now, although I'm a convinced partisan of the \"make it a language\" school of design as exemplified by Emacs and HTML and many database engines, I am not normally a big fan of \"English-like\" syntaxes.Traditionally programmers have tended to favor control syntaxes that are very precise and compact and have no redundancy at all. This is a cultural legacy from when computing resources were expensive, so parsing stages had to be as cheap and simple as possible. English, with about 50% redundancy, looked like a very inappropriate model then.This is not my reason for normally avoiding English-like syntaxes; I mention it here only to demolish it. With cheap cycles and core, terseness should not be an end in itself. Nowadays it's more important for a language to be convenient for humans than to be cheap for the computer.There remain, however, good reasons to be wary. One is the complexity cost of the parsing stage\u2014you don't want to raise that to the point where it's a significant source of bugs and user confusion in itself. Another is that trying to make a language syntax English-like often demands that the \"English\" it speaks be bent seriously out of shape, so much so that the superficial resemblance to natural language is as confusing as a traditional syntax would have been. (You see this bad effect in a lot of so-called \"fourth generation\" and commercial database-query languages.)The fetchmail control syntax seems to avoid these problems because the language domain is extremely restricted. It's nowhere near a general-purpose language; the things it says simply are not very complicated, so there's little potential for confusion in moving mentally between a tiny subset of English and the actual control language. I think there may be a broader lesson here:Another lesson is about security by obscurity. Some fetchmail users asked me to change the software to store passwords encrypted in the rc file, so snoopers wouldn't be able to casually see them.I didn't do it, because this doesn't actually add protection. Anyone who's acquired permissions to read your rc file will be able to run fetchmail as you anyway\u2014and if it's your password they're after, they'd be able to rip the necessary decoder out of the fetchmail code itself to get it.All .fetchmailrc password encryption would have done is give a false sense of security to people who don't think very hard. The general rule here is:Early reviewers and test audiences for this essay consistently raised questions about the preconditions for successful bazaar-style development, including both the qualifications of the project leader and the state of code at the time one goes public and starts to try to build a co-developer community.It's fairly clear that one cannot code from the ground up in bazaar style[IN]. One can test, debug and improve in bazaar style, but it would be very hard to originate a project in bazaar mode. Linus didn't try it. I didn't either. Your nascent developer community needs to have something runnable and testable to play with.When you start community-building, what you need to be able to present is a plausible promise. Your program doesn't have to work particularly well. It can be crude, buggy, incomplete, and poorly documented. What it must not fail to do is (a) run, and (b) convince potential co-developers that it can be evolved into something really neat in the foreseeable future.Linux and fetchmail both went public with strong, attractive basic designs. Many people thinking about the bazaar model as I have presented it have correctly considered this critical, then jumped from that to the conclusion that a high degree of design intuition and cleverness in the project leader is indispensable.But Linus got his design from Unix. I got mine initially from the ancestral popclient (though it would later change a great deal, much more proportionately speaking than has Linux). So does the leader/coordinator for a bazaar-style effort really have to have exceptional design talent, or can he get by through leveraging the design talent of others?I think it is not critical that the coordinator be able to originate designs of exceptional brilliance, but it is absolutely critical that the coordinator be able to recognize good design ideas from others.Both the Linux and fetchmail projects show evidence of this. Linus, while not (as previously discussed) a spectacularly original designer, has displayed a powerful knack for recognizing good design and integrating it into the Linux kernel. And I have already described how the single most powerful design idea in fetchmail (SMTP forwarding) came from somebody else.Early audiences of this essay complimented me by suggesting that I am prone to undervalue design originality in bazaar projects because I have a lot of it myself, and therefore take it for granted. There may be some truth to this; design (as opposed to coding or debugging) is certainly my strongest skill.But the problem with being clever and original in software design is that it gets to be a habit\u2014you start reflexively making things cute and complicated when you should be keeping them robust and simple. I have had projects crash on me because I made this mistake, but I managed to avoid this with fetchmail.So I believe the fetchmail project succeeded partly because I restrained my tendency to be clever; this argues (at least) against design originality being essential for successful bazaar projects. And consider Linux. Suppose Linus Torvalds had been trying to pull off fundamental innovations in operating system design during the development; does it seem at all likely that the resulting kernel would be as stable and successful as what we have?A certain base level of design and coding skill is required, of course, but I expect almost anybody seriously thinking of launching a bazaar effort will already be above that minimum. The open-source community's internal market in reputation exerts subtle pressure on people not to launch development efforts they're not competent to follow through on. So far this seems to have worked pretty well.There is another kind of skill not normally associated with software development which I think is as important as design cleverness to bazaar projects\u2014and it may be more important. A bazaar project coordinator or leader must have good people and communications skills.This should be obvious. In order to build a development community, you need to attract people, interest them in what you're doing, and keep them happy about the amount of work they're doing. Technical sizzle will go a long way towards accomplishing this, but it's far from the whole story. The personality you project matters, too.It is not a coincidence that Linus is a nice guy who makes people like him and want to help him. It's not a coincidence that I'm an energetic extrovert who enjoys working a crowd and has some of the delivery and instincts of a stand-up comic. To make the bazaar model work, it helps enormously if you have at least a little skill at charming people.It is truly written: the best hacks start out as personal solutions to the author's everyday problems, and spread because the problem turns out to be typical for a large class of users. This takes us back to the matter of rule 1, restated in a perhaps more useful way:So it was with Carl Harris and the ancestral popclient, and so with me and fetchmail. But this has been understood for a long time. The interesting point, the point that the histories of Linux and fetchmail seem to demand we focus on, is the next stage\u2014the evolution of software in the presence of a large and active community of users and co-developers.In The Mythical Man-Month, Fred Brooks observed that programmer time is not fungible; adding developers to a late software project makes it later. As we've seen previously, he argued that the complexity and communication costs of a project rise with the square of the number of developers, while work done only rises linearly. Brooks's Law has been widely regarded as a truism. But we've examined in this essay an number of ways in which the process of open-source development falsifies the assumptionms behind it\u2014and, empirically, if Brooks's Law were the whole picture Linux would be impossible.Gerald Weinberg's classic The Psychology of Computer Programming supplied what, in hindsight, we can see as a vital correction to Brooks. In his discussion of \"egoless programming\", Weinberg observed that in shops where developers are not territorial about their code, and encourage other people to look for bugs and potential improvements in it, improvement happens dramatically faster than elsewhere. (Recently, Kent Beck's 'extreme programming' technique of deploying coders in pairs looking over one anothers' shoulders might be seen as an attempt to force this effect.)Weinberg's choice of terminology has perhaps prevented his analysis from gaining the acceptance it deserved\u2014one has to smile at the thought of describing Internet hackers as \"egoless\". But I think his argument looks more compelling today than ever.The bazaar method, by harnessing the full power of the \"egoless programming\" effect, strongly mitigates the effect of Brooks's Law. The principle behind Brooks's Law is not repealed, but given a large developer population and cheap communications its effects can be swamped by competing nonlinearities that are not otherwise visible. This resembles the relationship between Newtonian and Einsteinian physics\u2014the older system is still valid at low energies, but if you push mass and velocity high enough you get surprises like nuclear explosions or Linux.The history of Unix should have prepared us for what we're learning from Linux (and what I've verified experimentally on a smaller scale by deliberately copying Linus's methods[EGCS]). That is, while coding remains an essentially solitary activity, the really great hacks come from harnessing the attention and brainpower of entire communities. The developer who uses only his or her own brain in a closed project is going to fall behind the developer who knows how to create an open, evolutionary context in which feedback exploring the design space, code contributions, bug-spotting, and other improvements come from from hundreds (perhaps thousands) of people.But the traditional Unix world was prevented from pushing this approach to the ultimate by several factors. One was the legal contraints of various licenses, trade secrets, and commercial interests. Another (in hindsight) was that the Internet wasn't yet good enough.Before cheap Internet, there were some geographically compact communities where the culture encouraged Weinberg's \"egoless\" programming, and a developer could easily attract a lot of skilled kibitzers and co-developers. Bell Labs, the MIT AI and LCS labs, UC Berkeley\u2014these became the home of innovations that are legendary and still potent.Linux was the first project for which a conscious and successful effort to use the entire world as its talent pool was made. I don't think it's a coincidence that the gestation period of Linux coincided with the birth of the World Wide Web, and that Linux left its infancy during the same period in 1993\u20141994 that saw the takeoff of the ISP industry and the explosion of mainstream interest in the Internet. Linus was the first person who learned how to play by the new rules that pervasive Internet access made possible.While cheap Internet was a necessary condition for the Linux model to evolve, I think it was not by itself a sufficient condition. Another vital factor was the development of a leadership style and set of cooperative customs that could allow developers to attract co-developers and get maximum leverage out of the medium.But what is this leadership style and what are these customs? They cannot be based on power relationships\u2014and even if they could be, leadership by coercion would not produce the results we see. Weinberg quotes the autobiography of the 19th-century Russian anarchist Pyotr Alexeyvich Kropotkin's Memoirs of a Revolutionist to good effect on this subject:Having been brought up in a serf-owner's family, I entered active life, like all young men of my time, with a great deal of confidence in the necessity of commanding, ordering, scolding, punishing and the like. But when, at an early stage, I had to manage serious enterprises and to deal with [free] men, and when each mistake would lead at once to heavy consequences, I began to appreciate the difference between acting on the principle of command and discipline and acting on the principle of common understanding. The former works admirably in a military parade, but it is worth nothing where real life is concerned, and the aim can be achieved only through the severe effort of many converging wills.The \"severe effort of many converging wills\" is precisely what a project like Linux requires\u2014and the \"principle of command\" is effectively impossible to apply among volunteers in the anarchist's paradise we call the Internet. To operate and compete effectively, hackers who want to lead collaborative projects have to learn how to recruit and energize effective communities of interest in the mode vaguely suggested by Kropotkin's \"principle of understanding\". They must learn to use Linus's Law.[SP]Earlier I referred to the \"Delphi effect\" as a possible explanation for Linus's Law. But more powerful analogies to adaptive systems in biology and economics also irresistably suggest themselves. The Linux world behaves in many respects like a free market or an ecology, a collection of selfish agents attempting to maximize utility which in the process produces a self-correcting spontaneous order more elaborate and efficient than any amount of central planning could have achieved. Here, then, is the place to seek the \"principle of understanding\".The \"utility function\" Linux hackers are maximizing is not classically economic, but is the intangible of their own ego satisfaction and reputation among other hackers. (One may call their motivation \"altruistic\", but this ignores the fact that altruism is itself a form of ego satisfaction for the altruist). Voluntary cultures that work this way are not actually uncommon; one other in which I have long participated is science fiction fandom, which unlike hackerdom has long explicitly recognized \"egoboo\" (ego-boosting, or the enhancement of one's reputation among other fans) as the basic drive behind volunteer activity.Linus, by successfully positioning himself as the gatekeeper of a project in which the development is mostly done by others, and nurturing interest in the project until it became self-sustaining, has shown an acute grasp of Kropotkin's \"principle of shared understanding\". This quasi-economic view of the Linux world enables us to see how that understanding is applied.We may view Linus's method as a way to create an efficient market in \"egoboo\"\u2014to connect the selfishness of individual hackers as firmly as possible to difficult ends that can only be achieved by sustained cooperation. With the fetchmail project I have shown (albeit on a smaller scale) that his methods can be duplicated with good results. Perhaps I have even done it a bit more consciously and systematically than he.Many people (especially those who politically distrust free markets) would expect a culture of self-directed egoists to be fragmented, territorial, wasteful, secretive, and hostile. But this expectation is clearly falsified by (to give just one example) the stunning variety, quality, and depth of Linux documentation. It is a hallowed given that programmers hate documenting; how is it, then, that Linux hackers generate so much documentation? Evidently Linux's free market in egoboo works better to produce virtuous, other-directed behavior than the massively-funded documentation shops of commercial software producers.Both the fetchmail and Linux kernel projects show that by properly rewarding the egos of many other hackers, a strong developer/coordinator can use the Internet to capture the benefits of having lots of co-developers without having a project collapse into a chaotic mess. So to Brooks's Law I counter-propose the following:I think the future of open-source software will increasingly belong to people who know how to play Linus's game, people who leave behind the cathedral and embrace the bazaar. This is not to say that individual vision and brilliance will no longer matter; rather, I think that the cutting edge of open-source software will belong to people who start from individual vision and brilliance, then amplify it through the effective construction of voluntary communities of interest.Perhaps this is not only the future of open-source software. No closed-source developer can match the pool of talent the Linux community can bring to bear on a problem. Very few could afford even to hire the more than 200 (1999: 600, 2000: 800) people who have contributed to fetchmail!Perhaps in the end the open-source culture will triumph not because cooperation is morally right or software \"hoarding\" is morally wrong (assuming you believe the latter, which neither Linus nor I do), but simply because the closed-source world cannot win an evolutionary arms race with open-source communities that can put orders of magnitude more skilled time into a problem.The original Cathedral and Bazaar paper of 1997 ended with the vision above\u2014that of happy networked hordes of programmer/anarchists outcompeting and overwhelming the hierarchical world of conventional closed software.A good many skeptics weren't convinced, however; and the questions they raise deserve a fair engagement. Most of the objections to the bazaar argument come down to the claim that its proponents have underestimated the productivity-multiplying effect of conventional management.Traditionally-minded software-development managers often object that the casualness with which project groups form and change and dissolve in the open-source world negates a significant part of the apparent advantage of numbers that the open-source community has over any single closed-source developer. They would observe that in software development it is really sustained effort over time and the degree to which customers can expect continuing investment in the product that matters, not just how many people have thrown a bone in the pot and left it to simmer.There is something to this argument, to be sure; in fact, I have developed the idea that expected future service value is the key to the economics of software production in the essay The Magic Cauldron.But this argument also has a major hidden problem; its implicit assumption that open-source development cannot deliver such sustained effort. In fact, there have been open-source projects that maintained a coherent direction and an effective maintainer community over quite long periods of time without the kinds of incentive structures or institutional controls that conventional management finds essential. The development of the GNU Emacs editor is an extreme and instructive example; it has absorbed the efforts of hundreds of contributors over 15 years into a unified architectural vision, despite high turnover and the fact that only one person (its author) has been continuously active during all that time. No closed-source editor has ever matched this longevity record.This suggests a reason for questioning the advantages of conventionally-managed software development that is independent of the rest of the arguments over cathedral vs. bazaar mode. If it's possible for GNU Emacs to express a consistent architectural vision over 15 years, or for an operating system like Linux to do the same over 8 years of rapidly changing hardware and platform technology; and if (as is indeed the case) there have been many well-architected open-source projects of more than 5 years duration\u2014then we are entitled to wonder what, if anything, the tremendous overhead of conventionally-managed development is actually buying us.Whatever it is certainly doesn't include reliable execution by deadline, or on budget, or to all features of the specification; it's a rare 'managed' project that meets even one of these goals, let alone all three. It also does not appear to be ability to adapt to changes in technology and economic context during the project lifetime, either; the open-source community has proven far more effective on that score (as one can readily verify, for example, by comparing the 30-year history of the Internet with the short half-lives of proprietary networking technologies\u2014or the cost of the 16-bit to 32-bit transition in Microsoft Windows with the nearly effortless upward migration of Linux during the same period, not only along the Intel line of development but to more than a dozen other hardware platforms, including the 64-bit Alpha as well).One thing many people think the traditional mode buys you is somebody to hold legally liable and potentially recover compensation from if the project goes wrong. But this is an illusion; most software licenses are written to disclaim even warranty of merchantability, let alone performance\u2014and cases of successful recovery for software nonperformance are vanishingly rare. Even if they were common, feeling comforted by having somebody to sue would be missing the point. You didn't want to be in a lawsuit; you wanted working software.So what is all that management overhead buying?In order to understand that, we need to understand what software development managers believe they do. A woman I know who seems to be very good at this job says software project management has five functions:Apparently worthy goals, all of these; but under the open-source model, and in its surrounding social context, they can begin to seem strangely irrelevant. We'll take them in reverse order.My friend reports that a lot of resource marshalling is basically defensive; once you have your people and machines and office space, you have to defend them from peer managers competing for the same resources, and from higher-ups trying to allocate the most efficient use of a limited pool.But open-source developers are volunteers, self-selected for both interest and ability to contribute to the projects they work on (and this remains generally true even when they are being paid a salary to hack open source.) The volunteer ethos tends to take care of the 'attack' side of resource-marshalling automatically; people bring their own resources to the table. And there is little or no need for a manager to 'play defense' in the conventional sense.Anyway, in a world of cheap PCs and fast Internet links, we find pretty consistently that the only really limiting resource is skilled attention. Open-source projects, when they founder, essentially never do so for want of machines or links or office space; they die only when the developers themselves lose interest.That being the case, it's doubly important that open-source hackers organize themselves for maximum productivity by self-selection\u2014and the social milieu selects ruthlessly for competence. My friend, familiar with both the open-source world and large closed projects, believes that open source has been successful partly because its culture only accepts the most talented 5% or so of the programming population. She spends most of her time organizing the deployment of the other 95%, and has thus observed first-hand the well-known variance of a factor of one hundred in productivity between the most able programmers and the merely competent.The size of that variance has always raised an awkward question: would individual projects, and the field as a whole, be better off without more than 50% of the least able in it? Thoughtful managers have understood for a long time that if conventional software management's only function were to convert the least able from a net loss to a marginal win, the game might not be worth the candle.The success of the open-source community sharpens this question considerably, by providing hard evidence that it is often cheaper and more effective to recruit self-selected volunteers from the Internet than it is to manage buildings full of people who would rather be doing something else.Which brings us neatly to the question of motivation. An equivalent and often-heard way to state my friend's point is that traditional development management is a necessary compensation for poorly motivated programmers who would not otherwise turn out good work.This answer usually travels with a claim that the open-source community can only be relied on only to do work that is `sexy' or technically sweet; anything else will be left undone (or done only poorly) unless it's churned out by money-motivated cubicle peons with managers cracking whips over them. I address the psychological and social reasons for being skeptical of this claim in Homesteading the Noosphere. For present purposes, however, I think it's more interesting to point out the implications of accepting it as true.If the conventional, closed-source, heavily-managed style of software development is really defended only by a sort of Maginot Line of problems conducive to boredom, then it's going to remain viable in each individual application area for only so long as nobody finds those problems really interesting and nobody else finds any way to route around them. Because the moment there is open-source competition for a 'boring' piece of software, customers are going to know that it was finally tackled by someone who chose that problem to solve because of a fascination with the problem itself\u2014which, in software as in other kinds of creative work, is a far more effective motivator than money alone.Having a conventional management structure solely in order to motivate, then, is probably good tactics but bad strategy; a short-term win, but in the longer term a surer loss.So far, conventional development management looks like a bad bet now against open source on two points (resource marshalling, organization), and like it's living on borrowed time with respect to a third (motivation). And the poor beleaguered conventional manager is not going to get any succour from the monitoring issue; the strongest argument the open-source community has is that decentralized peer review trumps all the conventional methods for trying to ensure that details don't get slipped.Can we save defining goals as a justification for the overhead of conventional software project management? Perhaps; but to do so, we'll need good reason to believe that management committees and corporate roadmaps are more successful at defining worthy and widely shared goals than the project leaders and tribal elders who fill the analogous role in the open-source world.That is on the face of it a pretty hard case to make. And it's not so much the open-source side of the balance (the longevity of Emacs, or Linus Torvalds's ability to mobilize hordes of developers with talk of \"world domination\") that makes it tough. Rather, it's the demonstrated awfulness of conventional mechanisms for defining the goals of software projects.One of the best-known folk theorems of software engineering is that 60% to 75% of conventional software projects either are never completed or are rejected by their intended users. If that range is anywhere near true (and I've never met a manager of any experience who disputes it) then more projects than not are being aimed at goals that are either (a) not realistically attainable, or (b) just plain wrong.This, more than any other problem, is the reason that in today's software engineering world the very phrase \"management committee\" is likely to send chills down the hearer's spine\u2014even (or perhaps especially) if the hearer is a manager. The days when only programmers griped about this pattern are long past; Dilbert cartoons hang over executives' desks now.Our reply, then, to the traditional software development manager, is simple\u2014if the open-source community has really underestimated the value of conventional management, why do so many of you display contempt for your own process?Once again the example of the open-source community sharpens this question considerably\u2014because we have fun doing what we do. Our creative play has been racking up technical, market-share, and mind-share successes at an astounding rate. We're proving not only that we can do better software, but that joy is an asset.Two and a half years after the first version of this essay, the most radical thought I can offer to close with is no longer a vision of an open-source\u2013dominated software world; that, after all, looks plausible to a lot of sober people in suits these days.Rather, I want to suggest what may be a wider lesson about software, (and probably about every kind of creative or professional work). Human beings generally take pleasure in a task when it falls in a sort of optimal-challenge zone; not so easy as to be boring, not too hard to achieve. A happy programmer is one who is neither underutilized nor weighed down with ill-formulated goals and stressful process friction. Enjoyment predicts efficiency.Relating to your own work process with fear and loathing (even in the displaced, ironic way suggested by hanging up Dilbert cartoons) should therefore be regarded in itself as a sign that the process has failed. Joy, humor, and playfulness are indeed assets; it was not mainly for the alliteration that I wrote of \"happy hordes\" above, and it is no mere joke that the Linux mascot is a cuddly, neotenous penguin.It may well turn out that one of the most important effects of open source's success will be to teach us that play is the most economically efficient mode of creative work.It's a strange feeling to realize you're helping make history....On January 22 1998, approximately seven months after I first published The Cathedral and the Bazaar, Netscape Communications, Inc. announced plans to give away the source for Netscape Communicator. I had had no clue this was going to happen before the day of the announcement.Eric Hahn, executive vice president and chief technology officer at Netscape, emailed me shortly afterwards as follows: \"On behalf of everyone at Netscape, I want to thank you for helping us get to this point in the first place. Your thinking and writings were fundamental inspirations to our decision.\"\"The following week I flew out to Silicon Valley at Netscape's invitation for a day-long strategy conference (on 4 Feb 1998) with some of their top executives and technical people. We designed Netscape's source-release strategy and license together.A few days later I wrote the following:Netscape is about to provide us with a large-scale, real-world test of the bazaar model in the commercial world. The open-source culture now faces a danger; if Netscape's execution doesn't work, the open-source concept may be so discredited that the commercial world won't touch it again for another decade.On the other hand, this is also a spectacular opportunity. Initial reaction to the move on Wall Street and elsewhere has been cautiously positive. We're being given a chance to prove ourselves, too. If Netscape regains substantial market share through this move, it just may set off a long-overdue revolution in the software industry.The next year should be a very instructive and interesting time.And indeed it was. As I write in mid-2000, the development of what was later named Mozilla has been only a qualified success. It achieved Netscape's original goal, which was to deny Microsoft a monopoly lock on the browser market. It has also achieved some dramatic successes (notably the release of the next-generation Gecko rendering engine).However, it has not yet garnered the massive development effort from outside Netscape that the Mozilla founders had originally hoped for. The problem here seems to be that for a long time the Mozilla distribution actually broke one of the basic rules of the bazaar model; it didn't ship with something potential contributors could easily run and see working. (Until more than a year after release, building Mozilla from source required a license for the proprietary Motif library.)Most negatively (from the point of view of the outside world) the Mozilla group didn't ship a production-quality browser for two and a half years after the project launch\u2014and in 1999 one of the project's principals caused a bit of a sensation by resigning, complaining of poor management and missed opportunities. \"Open source,\" he correctly observed, \"is not magic pixie dust.\"And indeed it is not. The long-term prognosis for Mozilla looks dramatically better now (in November 2000) than it did at the time of Jamie Zawinski's resignation letter\u2014in the last few weeks the nightly releases have finally passed the critical threshold to production usability. But Jamie was right to point out that going open will not necessarily save an existing project that suffers from ill-defined goals or spaghetti code or any of the software engineering's other chronic ills. Mozilla has managed to provide an example simultaneously of how open source can succeed and how it could fail.In the mean time, however, the open-source idea has scored successes and found backers elsewhere. Since the Netscape release we've seen a tremendous explosion of interest in the open-source development model, a trend both driven by and driving the continuing success of the Linux operating system. The trend Mozilla touched off is continuing at an accelerating rate.[JB] In Programing Pearls, the noted computer-science aphorist Jon Bentley comments on Brooks's observation with \"If you plan to throw one away, you will throw away two.\" He is almost certainly right. The point of Brooks's observation, and Bentley's, isn't merely that you should expect first attempt to be wrong, it's that starting over with the right idea is usually more effective than trying to salvage a mess. \u21a9[QR] Examples of successful open-source, bazaar development predating the Internet explosion and unrelated to the Unix and Internet traditions have existed. The development of the info-Zip compression utility during 1990\u2013x1992, primarily for DOS machines, was one such example. Another was the RBBS bulletin board system (again for DOS), which began in 1983 and developed a sufficiently strong community that there have been fairly regular releases up to the present (mid-1999) despite the huge technical advantages of Internet mail and file-sharing over local BBSs. While the info-Zip community relied to some extent on Internet mail, the RBBS developer culture was actually able to base a substantial on-line community on RBBS that was completely independent of the TCP/IP infrastructure. \u21a9[CV] That transparency and peer review are valuable for taming the complexity of OS development turns out, after all, not to be a new concept. In 1965, very early in the history of time-sharing operating systems, Corbat\u00f3 and Vyssotsky, co-designers of the Multics operating system, wroteIt is expected that the Multics system will be published when it is operating substantially... Such publication is desirable for two reasons: First, the system should withstand public scrutiny and criticism volunteered by interested readers; second, in an age of increasing complexity, it is an obligation to present and future system designers to make the inner operating system as lucid as possible so as to reveal the basic system issues. \u21a9[JH] John Hasler has suggested an interesting explanation for the fact that duplication of effort doesn't seem to be a net drag on open-source development. He proposes what I'll dub \"Hasler's Law\": the costs of duplicated work tend to scale sub-qadratically with team size\u2014that is, more slowly than the planning and management overhead that would be needed to eliminate them.This claim actually does not contradict Brooks's Law. It may be the case that total complexity overhead and vulnerability to bugs scales with the square of team size, but that the costs from duplicated work are nevertheless a special case that scales more slowly. It's not hard to develop plausible reasons for this, starting with the undoubted fact that it is much easier to agree on functional boundaries between different developers' code that will prevent duplication of effort than it is to prevent the kinds of unplanned bad interactions across the whole system that underly most bugs.The combination of Linus's Law and Hasler's Law suggests that there are actually three critical size regimes in software projects. On small projects (I would say one to at most three developers) no management structure more elaborate than picking a lead programmer is needed. And there is some intermediate range above that in which the cost of traditional management is relatively low, so its benefits from avoiding duplication of effort, bug-tracking, and pushing to see that details are not overlooked actually net out positive.Above that, however, the combination of Linus's Law and Hasler's Law suggests there is a large-project range in which the costs and problems of traditional management rise much faster than the expected cost from duplication of effort. Not the least of these costs is a structural inability to harness the many-eyeballs effect, which (as we've seen) seems to do a much better job than traditional management at making sure bugs and details are not overlooked. Thus, in the large-project case, the combination of these laws effectively drives the net payoff of traditional management to zero. \u21a9[HBS] The split between Linux's experimental and stable versions has another function related to, but distinct from, hedging risk. The split attacks another problem: the deadliness of deadlines. When programmers are held both to an immutable feature list and a fixed drop-dead date, quality goes out the window and there is likely a colossal mess in the making. I am indebted to Marco Iansiti and Alan MacCormack of the Harvard Business School for showing me me evidence that relaxing either one of these constraints can make scheduling workable.One way to do this is to fix the deadline but leave the feature list flexible, allowing features to drop off if not completed by deadline. This is essentially the strategy of the \"stable\" kernel branch; Alan Cox (the stable-kernel maintainer) puts out releases at fairly regular intervals, but makes no guarantees about when particular bugs will be fixed or what features will beback-ported from the experimental branch.The other way to do this is to set a desired feature list and deliver only when it is done. This is essentially the strategy of the \"experimental\" kernel branch. De Marco and Lister cited research showing that this scheduling policy (\"wake me up when it's done\") produces not only the highest quality but, on average, shorter delivery times than either \"realistic\" or \"aggressive\" scheduling.I have come to suspect (as of early 2000) that in earlier versions of this essay I severely underestimated the importance of the \"wake me up when it's done\" anti-deadline policy to the open-source community's productivity and quality. General experience with the rushed GNOME 1.0 release in 1999 suggests that pressure for a premature release can neutralize many of the quality benefits open source normally confers.It may well turn out to be that the process transparency of open source is one of three co-equal drivers of its quality, along with \"wake me up when it's done\" scheduling and developer self-selection. \u21a9[SU] It's tempting, and not entirely inaccurate, to see the core-plus-halo organization characteristic of open-source projects as an Internet-enabled spin on Brooks's own recommendation for solving the N-squared complexity problem, the \"surgical-team\" organization\u2014but the differences are significant. The constellation of specialist roles such as \"code librarian\" that Brooks envisioned around the team leader doesn't really exist; those roles are executed instead by generalists aided by toolsets quite a bit more powerful than those of Brooks's day. Also, the open-source culture leans heavily on strong Unix traditions of modularity, APIs, and information hiding\u2014none of which were elements of Brooks's prescription. \u21a9[RJ] The respondent who pointed out to me the effect of widely varying trace path lengths on the difficulty of characterizing a bug speculated that trace-path difficulty for multiple symptoms of the same bug varies \"exponentially\" (which I take to mean on a Gaussian or Poisson distribution, and agree seems very plausible). If it is experimentally possible to get a handle on the shape of this distribution, that would be extremely valuable data. Large departures from a flat equal-probability distribution of trace difficulty would suggest that even solo developers should emulate the bazaar strategy by bounding the time they spend on tracing a given symptom before they switch to another. Persistence may not always be a virtue... \u21a9[IN] An issue related to whether one can start projects from zero in the bazaar style is whether the bazaar style is capable of supporting truly innovative work. Some claim that, lacking strong leadership, the bazaar can only handle the cloning and improvement of ideas already present at the engineering state of the art, but is unable to push the state of the art. This argument was perhaps most infamously made by the Halloween Documents, two embarrassing internal Microsoft memoranda written about the open-source phenomenon. The authors compared Linux's development of a Unix-like operating system to \"chasing taillights\", and opined \"(once a project has achieved \"parity\" with the state-of-the-art), the level of management necessary to push towards new frontiers becomes massive.\"There are serious errors of fact implied in this argument. One is exposed when the Halloween authors themseselves later observe that \"often [...] new research ideas are first implemented and available on Linux before they are available / incorporated into other platforms.\"If we read \"open source\" for \"Linux\", we see that this is far from a new phenomenon. Historically, the open-source community did not invent Emacs or the World Wide Web or the Internet itself by chasing taillights or being massively managed\u2014and in the present, there is so much innovative work going on in open source that one is spoiled for choice. The GNOME project (to pick one of many) is pushing the state of the art in GUIs and object technology hard enough to have attracted considerable notice in the computer trade press well outside the Linux community. Other examples are legion, as a visit to Freshmeat on any given day will quickly prove.But there is a more fundamental error in the implicit assumption that the cathedral model (or the bazaar model, or any other kind of management structure) can somehow make innovation happen reliably. This is nonsense. Gangs don't have breakthrough insights\u2014even volunteer groups of bazaar anarchists are usually incapable of genuine originality, let alone corporate committees of people with a survival stake in some status quo ante. Insight comes from individuals. The most their surrounding social machinery can ever hope to do is to be responsive to breakthrough insights\u2014to nourish and reward and rigorously test them instead of squashing them.Some will characterize this as a romantic view, a reversion to outmoded lone-inventor stereotypes. Not so; I am not asserting that groups are incapable of developing breakthrough insights once they have been hatched; indeed, we learn from the peer-review process that such development groups are essential to producing a high-quality result. Rather I am pointing out that every such group development starts from\u2014is necessarily sparked by\u2014one good idea in one person's head. Cathedrals and bazaars and other social structures can catch that lightning and refine it, but they cannot make it on demand.Therefore the root problem of innovation (in software, or anywhere else) is indeed how not to squash it\u2014but, even more fundamentally, it is how to grow lots of people who can have insights in the first place.To suppose that cathedral-style development could manage this trick but the low entry barriers and process fluidity of the bazaar cannot would be absurd. If what it takes is one person with one good idea, then a social milieu in which one person can rapidly attract the cooperation of hundreds or thousands of others with that good idea is going inevitably to out-innovate any in which the person has to do a political sales job to a hierarchy before he can work on his idea without risk of getting fired.And, indeed, if we look at the history of software innovation by organizations using the cathedral model, we quickly find it is rather rare. Large corporations rely on university research for new ideas (thus the Halloween Documents authors' unease about Linux's facility at coopting that research more rapidly). Or they buy out small companies built around some innovator's brain. In neither case is the innovation native to the cathedral culture; indeed, many innovations so imported end up being quietly suffocated under the \"massive level of management\" the Halloween Documents' authors so extol.That, however, is a negative point. The reader would be better served by a positive one. I suggest, as an experiment, the following:Pick a criterion for originality that you believe you can apply consistently. If your definition is \"I know it when I see it\", that's not a problem for purposes of this test.Pick any closed-source operating system competing with Linux, and a best source for accounts of current development work on it.Watch that source and Freshmeat for one month. Every day, count the number of release announcements on Freshmeat that you consider 'original' work. Apply the same definition of 'original' to announcements for that other OS and count them.Thirty days later, total up both figures.The day I wrote this, Freshmeat carried twenty-two release announcements, of which three appear they might push state of the art in some respect, This was a slow day for Freshmeat, but I will be astonished if any reader reports as many as three likely innovations a month in any closed-source channel. \u21a9[EGCS] We now have history on a project that, in several ways, may provide a more indicative test of the bazaar premise than fetchmail; EGCS, the Experimental GNU Compiler System.This project was announced in mid-August of 1997 as a conscious attempt to apply the ideas in the early public versions of The Cathedral and the Bazaar. The project founders felt that the development of GCC, the Gnu C Compiler, had been stagnating. For about twenty months afterwards, GCC and EGCS continued as parallel products\u2014both drawing from the same Internet developer population, both starting from the same GCC source base, both using pretty much the same Unix toolsets and development environment. The projects differed only in that EGCS consciously tried to apply the bazaar tactics I have previously described, while GCC retained a more cathedral-like organization with a closed developer group and infrequent releases.This was about as close to a controlled experiment as one could ask for, and the results were dramatic. Within months, the EGCS versions had pulled substantially ahead in features; better optimization, better support for FORTRAN and C++. Many people found the EGCS development snapshots to be more reliable than the most recent stable version of GCC, and major Linux distributions began to switch to EGCS.In April of 1999, the Free Software Foundation (the official sponsors of GCC) dissolved the original GCC development group and officially handed control of the project to the the EGCS steering team. \u21a9[SP] Of course, Kropotkin's critique and Linus's Law raise some wider issues about the cybernetics of social organizations. Another folk theorem of software engineering suggests one of them; Conway's Law\u2014commonly stated as \"If you have four groups working on a compiler, you'll get a 4-pass compiler\". The original statement was more general: \"Organizations which design systems are constrained to produce designs which are copies of the communication structures of these organizations.\" We might put it more succinctly as \"The means determine the ends\", or even \"Process becomes product\".It is accordingly worth noting that in the open-source community organizational form and function match on many levels. The network is everything and everywhere: not just the Internet, but the people doing the work form a distributed, loosely coupled, peer-to-peer network that provides multiple redundancy and degrades very gracefully. In both networks, each node is important only to the extent that other nodes want to cooperate with it.The peer-to-peer part is essential to the community's astonishing productivity. The point Kropotkin was trying to make about power relationships is developed further by the 'SNAFU Principle': \"True communication is possible only between equals, because inferiors are more consistently rewarded for telling their superiors pleasant lies than for telling the truth.\" Creative teamwork utterly depends on true communication and is thus very seriously hindered by the presence of power relationships. The open-source community, effectively free of such power relationships, is teaching us by contrast how dreadfully much they cost in bugs, in lowered productivity, and in lost opportunities.Further, the SNAFU principle predicts in authoritarian organizations a progressive disconnect between decision-makers and reality, as more and more of the input to those who decide tends to become pleasant lies. The way this plays out in conventional software development is easy to see; there are strong incentives for the inferiors to hide, ignore, and minimize problems. When this process becomes product, software is a disaster. \u21a9I quoted several bits from Frederick P. Brooks's classic The Mythical Man-Month because, in many respects, his insights have yet to be improved upon. I heartily recommend the 25th Anniversary edition from Addison-Wesley (ISBN 0-201-83595-9), which adds his 1986 \"No Silver Bullet\" paper.The new edition is wrapped up by an invaluable 20-years-later retrospective in which Brooks forthrightly admits to the few judgements in the original text which have not stood the test of time. I first read the retrospective after the first public version of this essay was substantially complete, and was surprised to discover that Brooks attributed bazaar-like practices to Microsoft! (In fact, however, this attribution turned out to be mistaken. In 1998 we learned from the Halloween Documents that Microsoft's internal developer community is heavily balkanized, with the kind of general source access needed to support a bazaar not even truly possible.)Gerald M. Weinberg's The Psychology Of Computer Programming (New York, Van Nostrand Reinhold 1971) introduced the rather unfortunately-labeled concept of \"egoless programming\". While he was nowhere near the first person to realize the futility of the \"principle of command\", he was probably the first to recognize and argue the point in particular connection with software development.Richard P. Gabriel, contemplating the Unix culture of the pre-Linux era, reluctantly argued for the superiority of a primitive bazaar-like model in his 1989 paper \"LISP: Good News, Bad News, and How To Win Big\". Though dated in some respects, this essay is still rightly celebrated among LISP fans (including me). A correspondent reminded me that the section titled \"Worse Is Better\" reads almost as an anticipation of Linux. The paper is accessible on the World Wide Web at http://www.naggum.no/worse-is-better.html.De Marco and Lister's Peopleware: Productive Projects and Teams (New York; Dorset House, 1987; ISBN 0-932633-05-6) is an underappreciated gem which I was delighted to see Fred Brooks cite in his retrospective. While little of what the authors have to say is directly applicable to the Linux or open-source communities, the authors' insight into the conditions necessary for creative work is acute and worthwhile for anyone attempting to import some of the bazaar model's virtues into a commercial context.Finally, I must admit that I very nearly called this essay \"The Cathedral and the Agora\", the latter term being the Greek for an open market or public meeting place. The seminal \"agoric systems\" papers by Mark Miller and Eric Drexler, by describing the emergent properties of market-like computational ecologies, helped prepare me to think clearly about analogous phenomena in the open-source culture when Linux rubbed my nose in them five years later. These papers are available on the Web at http://www.agorics.com/agorpapers.html.This essay was improved by conversations with a large number of people who helped debug it. Particular thanks to Jeff Dutky <dutky@wam.umd.edu>, who suggested the \"debugging is parallelizable\" formulation, and helped develop the analysis that proceeds from it. Also to Nancy Lebovitz <nancyl@universe.digex.net> for her suggestion that I emulate Weinberg by quoting Kropotkin. Perceptive criticisms also came from Joan Eslinger <wombat@kilimanjaro.engr.sgi.com> and Marty Franz <marty@net-link.net> of the General Technics list. Glen Vandenburg <glv@vanderburg.org> pointeed out the importance of self-selection in contributor populations and suggested the fruitful idea that much development rectifies 'bugs of omission'; Daniel Upper <upper@peak.org> suggested the natural analogies for this. I'm grateful to the members of PLUG, the Philadelphia Linux User's group, for providing the first test audience for the first public version of this essay. Paula Matuszek <matusp00@mh.us.sbphrd.com> enlightened me about the practice of software management. Phil Hudson <phil.hudson@iname.com> reminded me that the social organization of the hacker culture mirrors the organization of its software, and vice-versa. John Buck <johnbuck@sea.ece.umassd.edu> pointed out that MATLAB makes an instructive parallel to Emacs. Russell Johnston <russjj@mail.com> brought me to consciousness about some of the mechanisms discussed in \"How Many Eyeballs Tame Complexity.\" Finally, Linus Torvalds's comments were helpful and his early endorsement very encouraging."}
{"prompt": "Advances in Distributed Security", "completion": "The last decade has witnessed a revolution in distributed security. Old, pessimistic proofs that security and fault tolerance were \"impossible\", based on assumptions that protocols had to be deterministic and security and fault tolerance properties had to be absolutely certain, have given way to new proofs and implementations of provable security based on the assumption of cryptography and other randomized protocols that achieving security with very high probability is sufficient. The old view \"proved\" that the integrity properties of a wide variety of services on which civilization depends, whether synchronized clocks, public directories, censorship-proof file sharing and publication, or issuing money or securities were \"impossible\" on asynchronous networks like the Internet unless we put unlimited faith in a third party to enforce many of the rules of the service. We now know how to provide such services with a high degree of integrity and availability, yet far more resilient to the possibility that any party might act in a malicious manner.As a result of these new possibilities, we are witnessing a shift in the way we view trust. The old view in computer and network security was that trust was all-or-nothing \u2013 either we must place an essentially blind faith in a third party (for example a certificate authority or an issuer of digital cash) or we must protect against a particular mode of attack completely (as, for example, encryption protects against wiretappers). The old view could not handle most real-life situations which don't fall into either of these extremes. Among knowledgeable distributed security designers, unconditionally trusted third parties are now viewed as a cheat \u2013 \"here we pray for heavenly benevolence\", analogous to the comic-strip mathematician whose proof contains the crucial step, \"here a miracle occurs\". A third party fully trusted with a security property means that property in fact remains fully insecure \u2013 it means the protocol designer has fobbed off security on somebody else rather than actually solved a security problem.The new view reiterates the desirability of complete protection against attack where it is available, but it adds protection against vast new classes of attacks, and protection of a wide variety of other desirable properties of distributed system, that are impossible to protect without at least some trust assumptions. The new trust assumptions are that participants in a critical public service are partially, usually, or more often than not trustworthy, and often only under certain conditions. The set of parties that make up a critical distributed service is never either completely trustworthy nor all malicious.Modern protocols for critical services such as public directories construct, out of all possible subsets of all participants, attack structures consisting of the worst combination of malicious parties that be tolerated, and their complement, access structures, the minimal set of parties that need to act correctly during this operation to perform the function. (Note that access structures have nothing to do with access control lists, a traditional security method that assumes a fully trusted third party and consists of a static list of persons or classes of persons and the resources or classes of resources they have access to).One particular simple example of such an attack and access structure is a threshold structure where the malicious behavior of up to t out of n participants can be tolerated. Although we will describe the protocols below in terms of threshold structures, it will usually be possible to substitute other partitions of the power set of participants into minimum access and maximum attack structures.A given property of a system has perfect security if its access structure is any participant and its attack structure is the empty set. An example of a property with perfect security is the use of a spinning neutron star called a pulsar as a clock. Its access structure is any party that can receive its natural broadcasts, and its attack structure is the empty set \u2013 given the reasonable presumption that there are no aliens out there who can and want to manipulate the very high energy outputs of pulsars in pursuit of some human ends they have learned about.Another perfect security property is that of encryption against third parties, assuming the encryption is unbreakable. However, if we take into account the receiver of a message as a possible attacker, the broader privacy property is not secure \u2013 the receiver is an attack structure of one who can compromise privacy of the entire message encrypted to him.A security property is almost perfect if its attack structure must contain T-1 out of N participants. For example, in the digital mix of Chaum[C81], for a single message, it would take collusion of N-1 out of N of the mix servers to trace a message. The untraceability property of this system has almost perfect security for a single message. On the other hand, the reliability property of the digital mix is almost perfectly insecure, since any one of the n mix servers can block a message from getting through. Often we must trade off two different properties like this. Since reliability is an error reversible by the end user and a privacy breach is not, the tradeoff made here by Chaum makes sense.Alas, for many desirable properties we cannot achieve either perfect or almost perfect security. For some properties of replicated services \u2013 for some kinds of rules they advertise as following \u2013 we can achieve almost perfect security through, for example, the use of cryptography.For any other properties, the maximum attack structure of malicious and colluding servers that can be tolerated is the set complement of the access structure. For the threshold case, this means that T, the maximum number of malicious and colluding servers that can be tolerated, is a certain fraction of the total number of servers, such as 1/3 or 1/2, of the total number of servers comprising the service, N. That is to say, if T+1 out of N of the servers jointly decide to violate the service's rules and thereby corrupt the system, they can do so. Those who wish to stick to the rules must back out of the corrupted transaction and restart the service out-of-band. For this large class of service properties where the access structure is the set complement of the attack structure, the security of a property is neither perfect or almost perfect at one extreme, nor fully depends on a single trusted party at the other extreme. We say that this class of service properties can be implemented with distributed security.Three of the properties we most often want to protect are privacy, liveness (a.k.a. availability) and integrity. For a replicated service, the main focus of this article, we focus on the security of the integrity and liveness of a single operation of a service. The goal is to create attack structures that are very highly unlikely to fail. If or when such failures of widespread collusion do occur, relying parties, i.e. parties who depend on the properties being secured, must go \"out-of-band\" and use supplementary systems to repair the system. These supplementary systems might include a wide variety of interparty integrity constraints, audits, blacklisting, and other schemes involving auditing, reputation, and/or cryptography by participants, relying parties, or third parties. These can further motivate servers to preserve the integrity and liveness of these services, and help users to recover after a (now much rarer) successful attack.Since a wide variety of trust assumptions can now be made by a security protocol and this variety can for the first time be described mathematically \u2013 as attack and access structures \u2013 these supplementary systems can focus on keeping the actual attack structures smaller than the maximally tolerated attack structure, rather than on vastly more difficult task of plugging wide-open security holes called \"trusted third parties\" with these more loosely defined or traditional supplementary institutions.A basic issue of security and fault tolerance that must be resolved is the secure determination of which order events occured in. If a contract specifies a deadline and it goes down to the wire, how can a relying party or third party adjudicator determine whether the deadline was met? The outcome itself, and its fairness, may rest on fairly deciding who came first. If Alice tries to double-spend a piece of digital cash[C82], only the recipient who checks with the bank first is entitled to its value. But if the bank servers are replicated, which of the two recipients Bob or Charles checked with the bank first? In the case of a replicated property title service[S98] we have a similar problem \u2013 if Alice transfers her title to two other owners, which new owner actually received the deed? If property is homesteaded on a first-come first-serve basis, which of two or more \"land rushers\" competing for a lucrative parcel is entitled to the land?Imagine a network where computers don't know how to keep time very well \u2013 they are always getting out of synchronization. (Alas, all you have to really think of here is the actual Internet with PCs). Such a network, called an asynchronous network, lacks an accurate and secure global clock time by which computers can determine the order in which events, which might be messages sent or instructions executed on a particular local machine, have happened. Lamport[L78] was among the first to tackle the problem of how to determine the order of events in such a network.A partial order means that we know in what order some of the elements are, but we aren't sure about some of the others, or some of the others may be equal. An example is the \"less than or equal to\" relationship among a group of integers, some of which can repeat. Some of the integers we know are less than some others, but an integer paired with itself is equal. A total order, on the other hand, is like the \"less than\" relationship among unique integers \u2013 we can always tell when one integer is less than another \u2013 there is no ambiguity left. In the case of events, a partial order means for some pairs of events we know whether one occured before another, and for some others we don't know. We use the same symbols as we would use for the analogous case of the integers, so that \"x <= y\" means \"x either occured before y or we don't know whether it occured before or after y\". In a total of events, we know for any two events which one happened first. We write \"x < y\" meaning \"x occured before y.\"Lamport's answer to the event ordering problem was to show that parties (or, we use the terms equivalently here, nodes on the network) can agree on a partial order of events based on causal relationships between these events \u2013 or at least the subset of events where we can determine that causation could occur. On a network, parties influence each other by talking to each other \u2013 in other words, by sending each other messages. Lamport used these messages as the basic building block for constructing his partial order, according to the following rules:The partial order leaves us with the need to agree on how to break ties \u2013 how to resolve the ambiguities where we can't agree which event took place first \u2013 and thus create a total order of events. We want to do so in a way that is fair, in other words, in a way that cannot be manipulated to the advantage of any particular party.An unfair way to create a total order would be to impose a certain predictable rule for breaking ties. For example, we could decide on a total order for the processes and break ties in the causal order by referring to this total order.However, such a procedure creates a bias that may, depending on the application, favor certain servers over others, and therefore allow those servers to favor certain clients over others.One way to break ties fairly is have the participants toss fair coins \u2013 in other words, generate random numbers in a way that cannot be manipulated and then assign those random numbers to events. There are several ways to toss fair coins over a network and we describe one such way below.Another way to break ties fairly is to have the participants agree to a global clock time that is more accurate than the message delays faced by those who would manipulate timing in favor of some party. This entails using a network with very predictable message lag for the clock synchronization protocol and a less predictable one for the other services. We will describe how to do this below.Certain cryptographic primitives play a crucial role in the recent breakthroughs in distributed security that we will discuss here.Oblivious transfer is an important building block of multiparty secure computations and related protocols. Rather than describing it here, we recommend this good introduction.Alice wants to prove that she can predict the stock market. But she doesn't want to actually reveal her choice to Bob or anybody else until she's actually had a chance to trade on her prediction. But after the fact, she could just read the closing price and pretend to Bob that she predicted it. How can Alice prove to Bob that she actually predicted the market? Using bit commitments.Bit commitments are ways to commit to a string of numbers or data, in such a way that if or when one later publishes the data, it cannot be forged \u2013 it must be the same as the data you earlier committed to.Alice can commit to her data using one-way functions \u2013 functions that are much harder to compute one way than another. (One-way functions are the most basic building block of cryptography). A common kind of a one-way function is a cryptographic hash function.To create a bit commitment, Alice first generates two random numbers. Then she computes the bit commitment by hashing the two random numbers and the data to be committed to. Append on of the random numbers to the end of the hash and sends it to Bob. The next day when Bob wants to examine the data, and prove that it matches the data Alice originally committed to, Alice provides the data along with the second random number. Bob can verify that it is astronomically unlikely that Alice was able to commit to one predication and then later tell Bob she predicted something else.This protocol is called \"bit commitment\" because one can commit to even an individual bit this way. If the data has enough entropy one can commit to that data simply by using a hash function and dispense with the random numbers. We will see below how with secure timestamping other parties can determine when the data was committed to.The ideal protocol would have most trustworthy third party imaginable \u2013 a diety who is on everybody's side. All the parties would send their inputs to God. God would reliably determine the results and return the outputs. God being the ultimate in confessional discretion, no party would learn anything more about the other parties' inputs than they could learn from their own inputs and the output.Network security theorists have recently solved this problem to an astonishing extent. They have developed protocols which create virtual machines between two or more parties. Multiparty secure computation allows any number of parties to share a computation, each learning only what can be inferred from their own inputs and the output of the computation. These virtual machines have the exciting property that each party's input is strongly confidential from the other parties. The program and the output are shared by the parties.For example, we could run a spreadsheet across the Internet on this virtual computer. We would agree on a set of formulas and set up the virtual computer with these formulas. Each participant would have their own input cells, which remain blank on the other participants' computers. The participants share output cell(s). Each input our own private data into our input cells. Alice could only learn only as much about the other participants' input cells as she could infer from her own inputs and the output cells.More information on this exciting breakthrough can be found in the accompanying article \"The God Protocols\". Often, as in the spreadsheet example above, the resulting protocol would be very slow. We will now discuss a special efficient kind of multiparty secure computation \u2013 threshold cryptography.Threshold cryptography has been used to help achieve Byzantine-resilient replication in Rampart, Fleet, SITRA, and several other distributed service or filesystem architectures. Threshold cryptography is an optimized special case of a more general technique called multiparty secure computationIn a threshold public-key cryptosystem there is a single key for encryption, but each party holds a key share for decryption. A threshold scheme implements the threshold case of distributed security as described above. Any T+1 key share holders are needed to jointly perform a decryption, and any N-T key share holders can collude to prevent a decryption from being performed. The parameter T can be set at any positive integer between 1 and N. Often a more general access structure, under the distributed security constraint that the access structure is the set complement of the attack structure, can be implemented as well.For some algorithms one must assume a trusted dealer to generate a private key and distribute shares; for some other algorithms a mutually confidential generation of key shares is possible. During the decryption protocol, each party processes a decryption request for a particular ciphertext and output a decryption share together with a proof of its validity. When a party obtains the ciphertext and at least T+1 valid encryption shares, it can recover the message. In the case of threshold signatures, when at least T+1 signature shares have been obtained, a valid signature can be constructed. [C01]Joe Killian introduces this problem as follows[K90]:Alice and Bob wanted to flip a fair coin, but had no physical coin to flip. Alice offered a simple way of flipping a fair coin mentally.First, you think up a random bit, then I'll think up a random bit. We'll then exclusive-or the two bits together,\" she suggested.\"But what if one of us doesn't flip a coin at random?\" Bob asked.\"It doesn't matter. As long as one of the bits is truly random, the exclusive-or of the bits should be truly random,\" Alice replied, and after a moment's reflection, Bob agreed.A short while later, Alice and Bob happened upon a book on artificial intelligence, lying abandoned by the roadside. A good citizen, Alice said, \"One of us must pick up this book and find a suitable waste receptacle.\" Bob agreed, and suggested they use their coin-flipping protocol to determine who would have to throw the book away.If the final bit is a 0, then you will pick the book up, and if it is a 1, then I will,\" said Alice. \"What is your bit?\"Bob replied, \"1.\"\"Why, so is mine,\" Alice said slyly. \"I guess this isn't your lucky day.\"Bruce Schneier[Sh96] goes on to describe what is wrong with this protocol:Needless to say, this coin-flipping protocol has a serious bug. While it is true that a truly random bit, x, exclusive-ORed with any independently distributed bit, y, will yield a truly random bit, Alice's protocol did not ensure that the two bits were distributed independently. In fact, it is not hard to verify that no mental protocol can allow can allow two infinitely powerful parties to flip a fair coin. Alice and Bob were in trouble until they received a letter from an obscure graduate student in cryptography. The information in the letter ws too theoretical to be of any earthly use to anyone, but the envelope the letter came in was extremely handy.The next time Alice and Bob wished to flip a coin, they played a modified version of the original protocol. First, Bob decided on a bit, but instead of announcing it immediately, he wrote it down on a piece of paper and placed the paper in the envelope. Next, Alice announced her bit. Finally, Alice and Bob took Bob's bit out of the envelope and computed the random bit. This bit was indeed truly random whenever at least one of them played honestly. Alice and Bob had a working protocol, the cryptographer's dream of social irrelevance was fulfilled, and they all lived happily ever after.On a computer, those \"envelopes\" are committed bits \u2013 see the protocol for bit commitment above. Also see Manuel Blum's landmark paper \"Coin Flipping By Telephone\"[B82] for more details. He subtitled the paper \"A Protocol for Solving Impossible Problems\", which was more prescient than he knew.Fair coin tosses can be used to create a fair total order of events out of a partial order of events, defined by sending and receiving times for messages, in an asynchronous distributed system. They can similarly be used to achieve atomic broadcast, and thus Byzantine agreement and replication[C01][CP02].The threshold coin-tossing system developed by Cachin, Kursawe, and Shoup [C01] solves the fair coin tossing problem by implmenting a cryptographic pseudorandom number generator (PRNG) is a distributed manner using threshold cryptography. They use their protocol to solve the Byzantine generals problem for asynchronous networks. We will describe the Byzantine generals problem and its solution on asynchronous networks further below.There are a wide variety of other cryptographic primitives and protocols, beyond the well-known symmetric and asymmetric cryptosystems, that give us security properties not otherwise in distributed systems, including and mixing and channel padding[C81] and blind signatures[C82] to combat traffice analysis.In our time, the tallest and most expensive buildings belong to some of our most important economic institutions \u2013 multinational corporations. The size and expense of our skyscrapers will provide future archaeologists an important clue that these institutions played a big role in our economy. In the high and late Middle Ages, the tallest structures in Europe were bell towers \u2013 larger and more numerous in that region than on any other continent. Chartres in the year 1169 boasted a 437 foot tower, the world\u2019s tallest. These towers, besides the churches they were built upon, were also the most expensive structures in town.Some historians claim that the size and expense of Europe\u2019s steeples and public clocks, like the size and expense of the churches they were built upon, reflected the predominant role of religion in medieval life, as opposed to business in ours. Given that the churches and cathedrals themselves were expensive, this is a plausible claim. However, the Church also played a leading role in the economy, both by its own economic activities and by its role in commercial law. The church bells and their clocks also played a major economic role.Telling time was not the only, and perhaps not even initially the main, function of church towers and their bells. An important early function of the bell tower was as an alarm, to inform the town of emergencies such as a fire or attacking army. The towers also sometimes made a good vantage point to detect such events. They tolled for events such as baptisms and funerals. Timekeeping became its primary function, first in order to call people to mass, but soon as a general service the Church provided to the surrounding Catholic community that supported it. Long before the mechanical clock, residents within a few miles of a church started working their schedules around the canonical hours \u2013 sundial-based unequal hours \u2013 tolled on its bells. Thus in many European cities, long before the invention of the mechanical clock, the local church was trusted to ring the hours. Churches, funded mainly by the nearby parishioners, but often also by the city or directly by a guild of merchants, lavished enormous resources to build, operate, and maintain the towers as well as the bells, and later for the clocks that were installed in those towers. The productive synchronization of human relationships funded the bell towers; the bell towers would provide a ready market for public clocks. Thus did in Europe emerge a \"virtuous circle\" that would advance both its timekeeping technologies and time-dependent institutions beyond those of the other continents.The time rung on the bells was mainly read from a sundial. By the 11th century these were often supplemented by water clocks. By the end of the 14th century most were using the new mechanical clock, backed up by another new technology of that century, the more reliable and personally secure sandglass.In the larger and more important belfries were present at least two bell-ringers. They lived up there full-time[D96]. This arrangement is an example of the pattern of dual control \u2013 each ringer served as a check for the other; neither could spoof the time or other bell signals without the collusion of both.The heaviest and most expensive elements of the towers were the bells. Bells smiths competed to produce the most distantly hearable ringing. The \"Maria Angola\" bell, cast in 1659 and installed in a cathedral in Cusco, Peru could be heard up to 25 miles away[G95]. In Cordova in the 16th century, a cathedral boasted a one-ton bell that could be heard 8 miles away. At the cathedral at Rouen, in 1321, a carillon was installed that played on an array of bells a hymn audible 5 miles away[D96]. The typical range of a parish church\u2019s bells was 3-5 miles. These bells would primarily be heard and in the surrounding town; larger bells could also be heard by peasants working in the fields miles away.The most valuable property of the bell tower time was not its accuracy, but its fairness. Even if it broadcast the wrong time, it broadcast the same wrong time to everybody. An employer, even if he was colluding with the Church to bias the sometimes subjective ringing of the canonical hours, couldn\u2019t tell his favorite employees that it was time to go home, while making other employees work extra, and pretend that it was the same time. (In contrast, on our computer networks such \"Byzantine\" attacks are possible, without advanced safeguards, when \"broadcasting\" time or other information).While nearby churches or monasteries provided the public, standard time, workers and employers both often employed their own timekeeping devices as a check. Peasants could tell the time by observing their own shadow against some standard sized object. In Germany and Flanders, even the smallest peasant villages had \"quadrants to indicate the hours without the sun\". Miners, working underground, followed work bells, operated by the employers, and passed their signal on through the tunnels by workers banging on tools. As a check, the miners had their own marked tallow candles[D96]. Despite the public broadcast of authoritative time, few dispensed with the option to check their own independent sources.See the accompanying article \"On Time\" for more of the fascinating history of Europe's development of clocks and accompanying economic institutions.Broadcasts using sound or radiation, from sources such as bell towers, radio towers, satellites, and pulsars, must send out the same value to every receiver. A remote beacon such as a pulsar has perfect security: the access structure is any party, and its complement, the attack structure, is the empty set. For human controlled broadcasts, the attack structure consists only of the broadcaster and the access structure is any receiver.Natural broadcasts are thus immune to the problem, described in the discussion of the Byzantine Generals problem below, of a transmitter sending different values to different receivers. Indeed, as we will see below, distributed researchers have gone to great lengths just to recreate this simple property on the Internet with logical broadcast protocols.Nature provides clocks that are oblivious to the malicious intentions of any outside parties. In the case of a remote high-energy system such as a pulsar, this means anybody. and many orders of magnitude more accurate than random delays that face attackers on the Internet. If critical Internet servers were synchronized to natural clocks in a secure and timely fashion, they would be immune to attacks that relied on uncertainties in timing. Here are some comparisons of the stability (error creep) in good natural clocks:Pulsars overtake atomic clocks in accuracy after about 4 months.The Internet with its wide and unpredictable variances in message delays makes for an extremely poor method of distributing time. Some clock synchronization protocols for an asynchronous network are described in [C??][CF94]. Unfortunately, their accuracy is limited to the same order of magnitude of uncertainty as that would face an attacker. So they don't clearly eliminate the possibility that an attacker could take advantage of the different servers hosting a critical service disagreeing on the time.Far more accurate are the distribution methods, especially radio broadcast, described in this excellent survey of timekeeping techniques.This article also contains an excellent discussion of the highly distributed system used for reaching agreement on the global standard UTC time. Over 200 centers use their own atomic clocks to update UTC time. This recalibration uses a sophisticated averaging formula that throws out extreme values. There are also 50 centers in 30 different countries that can be queried at any time during the month for the current recalibration according to their own atomic clocks. In addition, there are a variety of services that broadcast UTC time, with varying levels of delay uncertainty and cost that the article describes in detail. The security and tolerance to extreme faults of the entire system from atomic clock to delivery of time updates to relying parties is not clear but probably high. The jurisdictional diversity of the atomic clock sources is far higher than that of common delivery systems such as GPS, but the results of the latter can after the fact be easily checked against the former, keeping the latter honest, so that the resulting end-to-end system is almost universally trusted (taking into account certain well-known adjustments such as selective availability in GPS).Secure time-stamping is a way for a party with a confidential document, or two or more parties sending private messages, to commit to each other and third parties an unforgeable, non-repudiable time-stamp. This time-stamp consists of a place in a total order consisting of this message, other parties' messages, and clock ticks. This commitment is accomplished without the parties having to reveal the actual contents of those messages, unless or until challenged for proof, to any third parties. (Even then, there exist zero-knowledge proofs that allow the party to prove he has a document corresponding to the time-stamp without revealing the document).These protocols work by users sending a cryptographic hash (a.k.a. message digest) of their document to the time-tstamping servers. The servers chain messages and click ticks together by order of arrival. Replicated servers can break ambiguities in order of arrival with a protocol such as fair coin tossing to achieve a fair total order.Lamport created a theoretical structure for security and fault tolerance in a distributed service with the Byzantine generals problem. These generals might be loyal, following orders and passing them on faithfully, or they may be traitors. The worst-case behavior of traitorous generals is modelled by the nasty trick of sending out contradictory orders \u2013 for example, telling one general that the order is to march and another general that the order is to retreat.(Lamport just meant the Byzantine generals story as an interesting, cartoonish illustration of the theory of fault tolerance against corruption by malicious adverseries, but this kind of problem has actually sometimes occurred among generals. The actual generals of the Byzantine Empire were no more prone to such treachery than any of their enemies, such as the Persians or Turks. If one is partial towards the Byzantines, one can think instead of the Iraqi generals in the current war there \u2013 the Coalition generals hope that some of the Iraqi generals will defect and are trying to insert forged messages into their communications network. They hope some generals will be duped into following these specious orders).There are N generals; one of them is the commanding general or field marshall. They can send and receive messages between each other. The Byzantine generals problem is to develop a protocol for the commanding general to send messages to his N-1 subordinates so thatThe protocol should be able to resist up to T traitorous generals. In the case of a fully deterministic protocol (no random choices or cryptography allowed) the best we can do is tolerate T = floor(N/3) - 1 generals for a synchronous network. For an asynchronous and deterministic network no traitors at all can be tolerated.[FLP85]However, the Byzantine general's problem is easily solved by unjammable physical broadcast. Not coincidentally, solving the logical broadcast problem on network where physical broadcast is absent is very similar to, and as hard as, solving the Byzantine generals problem.The above pessimistic results regarding T on deterministic networks \u2013 and the inefficiency of protocols that could provide these weak solutions to the Byzantine generals problem \u2013 until recently has discouraged researchers and engineers from finding practical solutions to securing distributed services. However, under only slightly weaker assumptions \u2013 those of cryptography, that we need only achieve security with a very high probability \u2013 agreement between the Byzantine generals has not only been achieved [Ben-Or] but achieved efficiently [Cachin]. The basic insight in these solutions is that we can break ties in a Lamport partial order in a an unbiased way with random numbers.Point-to-point communications is sufficient for many applications. For many others, nodes need to send a message to many other nodes, or multicast. We call the simple case where a node sends messages to all other nodes participating in a system broadcast.As we've seen, broadcast can be implemented directly in physical media such as sound and radio. We will discuss the problem of implementing logical broadcast over an asynchronous network that directly supports only point-to-point communications. Such broadcasting protocols are subject to node and communications failures, including malicious attacks.Four important design criteria of such a logical network are reliability, consistent ordering, causality preservation, and fairness. Reliability means that a message once broadcast be received by all the functional nodes. Consistent ordering means that different messages sent by different nodes are delivered to all the nodes in the same order. Causality is preserved if this order is consistent with with the causal order in which messages were sent and received. Fairness means that no node can breach the rules or properties of the system we want to protect, particular to some parties advantage or disadvantage, by manipulating this order.Note that physical broadcasts, if they cannot be jammed, easily have these properties. Since the broadcast medium has a finite velocity, messages might not all be received in the same order as sent. However, the receiving nodes can deduce from the physical properties of the medium the expected time lag at their distance and thereby deduce sending times. We say in this case that messages are received in a certain order, queued, and then delivered in a possibly different order.The basic issue here is message delays \u2013 some servers receive messages in different order from others. Clock synchronization can reduce the scope of this problem \u2013 even eliminate it if done over a network where unpredictability in message lag times are much less than in the network over which we run the other services we wish to secure. In such cases clocks can be synchronized with sufficient accuracy that global clock time cannot be spoofed to reorder messages with significant probability. Where we choose not to implement such a global clock (because, for example, the price of retrofitting services with a radio time synchronization service as described above), we have another option for creating a fair total order \u2013 the fair coin flipping methods described above. The result is a logical broadcast with the same basic security properties as an unjammable physical broadcast.The theory of the Byzantine generals has a practical equivalent \u2013 the problem of replicating a serivce \u2013 or, equivalently, a distributed object \u2013 in such as way as to provide distributed security, or fault tolerance against arbitrary behavior of up to T malicious and colluding servers.These services or distributed objects are sometimes called \"intrusion tolerant\", because the replicated service can resist attack and corruption of up to T servers. However, in the real world more perpetrated by insiders rather than intruders. Byzantine-resilient replication of a service across administrative domains or jurisdictions solves both problems.Several Byzantine-resilient replicated service infrastructures have been implemented . They use techniques such as threshold cryptography and fair coin tossing to achieve logical broadcast on asynchronous networks like the Internet, protected against attack structures of colluding and malicious servers, such that the attack structure is the set complement of the access structure. See Appendix A below for sources of more information. A wide variety of Byzantine-resilient services can be built on top of logical broadcast. A high bandwidth, many-to-many unjammable physical broadcast network might provide similar but more efficient solutions in the future. A Byzantine-resilient replicated object library, for implementing online services with distributed trust in the CORBA distributed object system is described in this presentation and this paper.The basic system has the ability to replicate stateful objects resilient to up to 1/3 Byzantine (arbitrarily malicious) failures.In other words, object replication is used to distribute trust in the integrity of data and computations. Instead of obtaining a critical service from a single trusted server \u2013 which may be innately malicious or may get cracked by an outsider \u2013 one obtains the service from N different servers, and the service maintains its integrity as long as less than N/3 of the Vats are malicious.Note that the \"voting\" implicit in Byzantine resilient protocols like that used here protects the integrity of a particular remote method call. Between such invocations, clients can update their own blacklists of servers they have found to be unreliable. With such a blacklist the attacker must manifest their faulty behavior in over N/3 servers during the same call in order to corrupt the call. Once this is discovered the client can blacklist them, removing them from the list of trusted Vats for subsequent calls.Integrity techniques such as cryptographic hashes, digital signatures, secret sharing, and threshold cryptography can be layered on top of this basic Byzantine-resilient replication system to further increase the integrity of certain properties of the replicated state. Which of these techniques are used, and how, depends on what the critical functionality is that one is protecting.Replication of course does not distribute trust in the privacy of the data \u2013 quite the opposite, it magnifies the exposure. However, where this problem is relevant it can easily be overcome with encryption and/or multiparty secure computation, described above.A necessary part of any good distributed security toolkit is a diverse cryptographic library, implementing not only symmetric and assymetric primitives but also those described or referred to in this article.A wide variety of other applications once thought \"impossible\" to secure can now be implemented securely.On a public network a wide variety of values must be agreed upon across trust boundaries, such as mappings of names or addresses to keys (as in a public key infrastructure) or of names to addresses (as in the Domain Name System). Such agreements across trust boundaries can best be thought of as simple kinds of private property to be controlled by their owner, within constrains enforced by the rules followed by the replicated service, a public property titles system.Whether thought of as property rights or not, a wide variety of such currently centralized services can be re-implemented with much greater ensurable integrity and availability by distributing their trust with techniques such as Byzantine-resilient replication.Another large class of potential services that can be distributed are issuers of digital bearer instruments, such as digital cash.This author's design for a secure property title service uses cryptographic hash functions and digital signatures (without the need for a PKI) on top of a Byzantine-resilient replicated object service to maintain the integrity of chains of property titles. It's also suitable for property-like directories such as the Internet's Domain Name System (DNS).The old pessimism has been overturned. Old proofs of \"impossibility\", based on strict insistence in perfect certainty, have given way to new proofs demonstrating how to do the \"impossible\" by being satisfied with extremely high probability against a sophisticated but computationally bounded opponent \u2013 the assumption of cryptography \u2013 rather than of absolute certainty. This overturning of the old view has led to a raft of new possibilities for securing distributed applications. The simple protocol of the bell tower, which broadcast to every resident of a medieval town the same time, can now be implemented on a network \u2013 either through logical broadcast on the Internet or physical broadcast with radio. For the first time we can implement on the Internet the integrity properties on which civilization depends \u2013 including synchronized clocks, unforgeable transactions, and censorship-proof publishing. Where today's Internet, lacking this technology, fails to provide many of these properties, we now know how to provide them with a greater degree of integrity and availability than either the Internet or any previous media was capable of.[A01] Agilent Application Note AN 1289, \"The Science of Timekeeping\"[AMPR00] L. Alvisi, D. Malkhi, L. Pierce, and M. Reiter, \"Fault detection for Byzantine quorum systems.\"[AMPW00] L. Alvisi, D. Malkhi, L. Pierce, M. Reiter, and R. Wright, \"Dynamic Byzantine Quorum Systems\"[B83] M. Ben-Or, \"Another advantage of free choice: Completely asynchronous agreement protocols\", in Proc. 2nd ACM Symposium on Principles of Distributed Computing (PODC), 1983[B82] M. Blum, \"Coin Flipping by Telephone: A Protocol for Solving Impossible Problems\", Proceedings of the 24th IEEE Computer Conference (CompCon), 1982, pp. 133-137. \u21a9[BT85] G. Bracha and S. Toueg, \"Asynchronous consensus and broadcast protocols\", Journal of the ACM, vol. 32, pp. 824-840, Oct. 1985[CP02] C. Cachin, J. Poritz, \"Secure Intrusion-tolerant Replication on the Internet\" \u21a9[C01] C. Cachin, \"Distributing Trust on the Internet\" Conference on dependable systems and networks (DSN-2001). This is an excellent survey of the state of the art in Byzantine-resililient replication as well as presenting his own Byzantine-resilient replication system that uses fair toin cossing. \u21a9[C98] C. Cachin , \"On the foundations of oblivious transfer\", Advances in Cryptology: EUROCRYPT '98, Lecture Notes in Computer Science v. 1403, Kaisa Nyberg, ed., pp. 361-374. Springer-Verlag, 1998.[CT96] T.D. Chandra and S. Toueg, \"Unreliable failure detectors for reliable distributed systems\", Journal of the ACM, vol. 43, no. 2, pp. 225-267, 1996.[C81] \"Untraceable Electronic Mail, Return Addresses, and Digital Pseudonyms,\" D. Chaum, Communications of the ACM, vol. 24 no. 2, February, 1981. \u21a9 \u21a9[C82] \"Blind Signatures for Untraceable Payments,\" D. Chaum, Advances in Cryptology Proceedings of Crypto 82, D. Chaum, R.L. Rivest, & A.T. Sherman (Eds.), Plenum, pp. 199-203. \u21a9 \u21a9[C85] \"Online Cash Checks\", D. Chaum[CE86] \"A Secure and Privacy-Protecting Protocol for Transmitting Personal Information Between Organizations,\" D. Chaum & J.-H. Evertse, Advances in Cryptology CRYPTO '86, A.M. Odlyzko (Ed.), Springer-Verlag, pp. 118-167.[C89] \"Showing Credentials Without Identification: Signatures Transferred Between Unconditionally Unlinkable Pseudonyms,\" D. Chaum, Accepted but not Presented Auscrypt '89.[C89b] \"Privacy Protected Payments: Unconditional Payer and/or Payee Untraceability,\" D. Chaum, Smart Card 2000, D. Chaum & I. Schaumuller-Bichl (Eds.), North Holland, 1989, pp. 69-93.[CV] \"Group Signatures,\" D. Chaum & E van Heyst, Advances in Cryptology EUROCRYPT '91, D.W. Davies (Ed.), Springer-Verlag, pp. 257-265.[C97] C. Cocks. \"Split knowledge generation of RSA paremeters.\" Presented at the 6th IMA Conference on Coding and Cryptography, Cirencester, England, to appear in the proceedings, December 17\u201319, 1997.[CGT95] C. Cr\u00e9peau , J. van de Graaf , and A. Tapp , \"Committed Oblivious Transfer and Private Multi-Party Computations\"; Advances in Cryptology: Proceedings of Crypto '95, Springer-Verlag, pages 110-123, 1995.[C??] F. Cristian [et. al?] on external clock synchronization \u21a9[CF94] F. Cristian and C. Fetzer, \"Probabilistic Internal Clock Synchronization\", 13th Symposium on Reliable Distributed Systems\", 1994 \u21a9[D96] Dohrn-van Rossum, History of the Hour \u2013 Clocks and Modern Temporal Orders, University of Chicago Press, 1996. \u21a9 \u21a9 \u21a9[DA01] W. Du, M. Atallah, \"Secure Multi-Party Computation Problems and Their Applications: A Review And Open Problems\" (2001), New Security Paradigms Workshop \u21a9[FLP85] M.J. Fischer, N.A. Lynch,, and M.S. Peterson, \"Impossibility of distributed consensus with one faulty process\", Journal of the ACM, vol 32, pp. 374-382, April 1985. \u21a9[G95] Vicente Goyzueta, \"Cathedral of Qosco City\" \u21a9[HM97] M. Hirt and U. Maurer, \"Complete characterization of adversaries tolerable in secure multi-party computation\", 16th ACM PODC J. Kilian, Uses of Randomness in Algorithms and Protocols, MIT Press 1990.[ISN93] M. Ito, A. Saito and T. Nishizeki. Secret Sharing Scheme Realizing General Access Structure. J. Cryptology, 6 (1993) 15--20.[K90] J. Kilian, The Use of Randomness in Algorithms and Protocols, MIT Press 1990 \u21a9[L78] L. Lamport, \"Time, Clocks, and the Ordering of Events in a Distributed System\", Communications of the ACM 21(7):558-565, July 1978 \u21a9[L95] Susan K. Langford. \"Threshold DSS signatures without a trusted party.\" In D. Coppersmith, editor, Advances in Cryptology Crypto '95 proceedings, number 963 in LNCS, pages 397 409. Springer-Verlag, 1995. (some context online at http://citeseer.nj.nec.com/context/478327/0)[MR97] D. Maklhi & M. Reiter, \"Byzantine Quorum Systems\", also in 21st ACM STOC, 1979[MM95] L. E. Moser and P. M. Melliar-Smith, \"Total ordering algorithms for asynchronous Byzantine systems.\" In Proceedings of the 9th International Workshop on Distributed Algorithms, Springer-Verlag, September 1995.[MMA99] L. Moser, P.M. Melliar-Smith, V. Agrawala, \"Total ordering algorithms\", Proceedings of the 19th annual conference on Computer Science 1991 , San Antonio, Texas, United States, Pages: 375 - 380 Series-Proceeding-Article Year of Publication: 1999 ISBN:0-89791-382-5 ACM Press New York, NY, USA[MM99] L.E. Moser and P.M. Mellar-Smith, \"Byzantine-resistant total ordering algorithms\", Information and Computation, vol. 150, pp. 75-111, 1999.[NW96] M. Naor and A. Wool, \"Access control and signatures via quorum secret sharing\", 3rd ACM Conf. on Computer and Communications Security[MB94] M. Reiter and K. P. Birman. \"How to securely replicate services.\"\" ACM Transactions on Programming Languages and Systems, 16(3):986\u20131009, May 1994.[P91] T.P. Pedersen. \"A Threshold Cryptosystem without a Trusted Party.\"\" In Eurocrypt'91, LNCS 547, pages 522--526. Springer-Verlag, 1991.[PSL80] M. Pease, R. Shostak, and L. Lamport, \"Reaching Agreement in the Presence of Faults\", Journal of the ACM 27(2):228-234, April 1980[Rab83] M. Rabin, \"Randomized Byzantine Generals,\" Proceedings of the IEEE Symposium on the Foundations of Computer Science, pp. 403-409, IEEE, 1983[SMNTWB02] David Sames, Brian Matt, Brian Niebuhr, Gregg Tally, Brent Whitmore, and David Bakken, \"Developing a Heterogeneous Intrusion Tolerant CORBA System\", Proceedings of the 2002 International Conference on Dependable Systems & Networks, Washington, D.C., June 23-26, 2002.[Sh79] A. Shamir. \"How to share a secret.\"\" In Com. of the ACM, 22(11):612613, 1979. (online at secret.html)[Sh96] B. Schneier, Applied Cryptography, 2nd edition, John Wiley & Sons 1996 \u21a9[SG98] V. Shoup and R. Gennaro. \"Securing Threshold Cryptosystems against Chosen Ciphertext Attack\", in Eurocrypt '98, LNCS 1403, pages 1\u201316. SpringerVerlag, 1998. cf. the extended version for the Journal of Cryptology, available at http://www.shoup.net/papers/[Sh00] V. Shoup, \"Practical threshold signatures\", in Advances in Cryptology: EUROCRYPT 2000 (B. Preneel, ed.) vol. 1087 of Lecture Notes in Computer Science, pp. 207-220, Springer, 2000[S97] N. Szabo, \"Contracts With Bearer\"[S97b] N. Szabo, \"The God Protocols\"[S98] N. Szabo, \"Secure Property Titles with Owner Authority\" \u21a9[S00] N. Szabo, \"Trusted Third Parties are Security Holes\"Please send your comments to nszabo (at) law (dot) gwu (dot) eduCopyright \u00a9 2003 by Nick Szabo\nrough draft \u2013 quoting or redistribution without permission of the author prohibitedEditor's note: Some links may be broken."}
{"prompt": "Online Cash Checks", "completion": "Savings of roughly an order of magnitude in space, storage, and bandwidth over previously published online electronic cash protocols are achieved by the techniques introduced here. In addition, these techniques can increase convenience, make more efficient use of funds, and improve privacy.\"Offline\" electronic money[CFN88] is suitable for low value transactions where \"accountability after the fact\" is sufficient to deter abuse; online payment[C89], however, remains necessary for transactions that require \"prior restraint\" against persons spending beyond their available funds.Three online schemes are presented here. Each relies on the same techniques for encoding denominations in signatures and for \"devaluing\" signatures to the exact amount chosen at the time of payment. They differ in how the unspent value is returned to the payer. In the first, all change is accumulated by the payer in a single \"cookie jar,\" which might be deposited at the bank during the next withdrawal transaction. The second and third schemes allow change to be distributed among unspent notes, which can themselves later be spent. The second scheme reveals to the shop and bank the maximum amount for which a note can be spent; the third does not disclose this information.For simplicity and concreteness, but without loss of generality, a particular denomination scheme will be used here. It assigns the value of 1 cent to public exponent 3 in an RSA system, the value of 2 cents to exponent 5, 4 cents to exponent 7, and so on; each successive power-of-two value is represented by the corresponding odd prime public exponent, all with the same modulus. Much as in [C89], a third root of an image under the one-way function f (together with the pre-image modulo the bank's RSA composite) is worth 1 cent, a 7th root is worth 4 cents, and a 21st root 5 cents. In other words, a distinct public prime exponent is associated with each digit of the binary integer representation of an amount of payment; for a particular amount of payment, the product of all those prime exponents corresponding to 1 's in the binary representation of the amount is the public exponent of the signature.A signature on an image under f is \"devalued\" by raising it to the public powers corresponding to the coin values that should be removed. For instance, a note having a 21st root could be devalued from its 5 cent value, to 1 cent, simply by raising it to the 7th power.In earlier online payment systems[C89], the number of separate signatures needed for a payment was in general the Hamming weight of the binary representation of the amount. Since online systems would be used for higher-value payments (as mentioned above), and extra resolution may be desired to provide interest for unspent funds[C89], an average of roughly an order of magnitude is saved here.In this first scheme the payer periodically withdraws a supply of notes from the bank, each with the system-wide maximum value. Consider an example, shown in Figure 1.1, in which two notes are withdrawn. The n and ri are random. The ri \"blind\" (from the bank) the images under the public, one-way function f. The bank's signature corresponds to taking the h-th root, where h = 3*5*7*11. As in all the figures, the payer sends messages from the left and the bank sends from the right.In preparing the first payment, the payer divides r1 out. The signature is then raised to the 55th power to devalue it from 15 cents to 5 cents. Figure 1.2 shows this first payment. Of course the shop is an intermediary between the payer (left) and the bank (right) in every online payment, but this is not indicated explicitly. Also not shown in the figures are messages used to agree on the amounts of payment.The first two residues sent in paying, n1 and its signed image under f, are easily verified by the bank to be worth 5 cents. The third residue is a blinded \"cookie jar,\" a blinded image under f of a randomly chosen value j. This cookie jar is modulo a second RSA composite that is only used for cookie jars. Once the bank verifies the funds received, and that n1 has not been spent previously, it signs and returns the blinded cookie jar (under the cookie jar modulus) with public exponents corresponding to the change due.The second payment, shown in figure 1.3, is essentially the same as the first, except that the amount is 3 cents and the cookie jar now has some roots already on it. If more payments were to be made using the same cookie jar, all resulting signatures for change would accumulate.The cookie jar might conveniently be deposited, as shown in figure 1.4, during the withdrawal of the next batch of notes. It is verified by the bank much as a payment note would be: the roots must be present in the claimed multiplicity and the pre-image under f must not have been deposited before.The cookie jar approach gives the effect of an online form of \"offline checks\"[C89], in that notes of a fixed value are withdrawn and the unspent parts later credited to the payer during a refund transaction.Figure 2 depicts a somewhat different scheme, which allows change to be spent without an intervening withdrawal transaction. Withdrawals can be just as in the cookie-jar scheme, but here a single modulus is used for everything in the system. The products of public exponents representing the various amounts are as follows: d is the amount paid, g is the note value, the \"change\" c is g/d, and h is again the maximal amount, where d | g | h. A payment (still to the bank through a shop) includes first and second components that are the same as in the cookie-jar scheme. The third component is the amount of change c the payer claims should be returned. The fourth is a (blinded) number m, which could be an image under f used in a later payment just as n is used in this one.The signature returned contains a \"protection\" factor (shown inside the padlock). This factor ensures that the payer actually has the c-th root of f(n), by requiring that the payer apply f to it before dividing the result out of the signature. Without such protection, a payer could get the systemwide maximum change, regardless of how much change is actually due; with it, the change claimed can only be recovered if the corresponding roots on n are in fact known to the payer.The change returned in a payment can be divided into parts that fill in missing denominations in notes not yet spent. Suppose, for example, that the last payment is spent with d = 5*11, c = 3*7, and that m is formed by the payer as shown in the first line of Figure 3.1. Then unblinding after the payment yields the a shown in the second line.(Use === for \"is equivalent to\")From a, the two roots shown in the last two lines of Figure 3.2 are readily computed. (This technique is easily extended to include any number of separate roots.) Thus the values unused in the last payment fill in roots missing in notes n1 and n2.Because overpayment allows change to be returned in any chosen denominations (not shown), the payer has extra flexibility and is able to use all funds held. This also increases convenience by reducing the need for withdrawals.Although the combination of the previous two subsections is quite workable, it may be desirable for the payer not to have to reveal c to the shop or the bank. Figure 4 shows a system allowing this. The payment message is just as in the declared note value protocol above, except that c is not sent. The protection factor (shown again in a lock) is also placed under the signature, but it is missing the extra f and is raised to a random power z chosen by the bankIf z were known to the payer before payment, then the payer could cheat by including f(n) in the third component; this would yield the payer the system-wide maximum change, even if none were due. Consider a single change exponent q. If z mod q is guessed correctly by a cheating payer, then the payer improperly gets the corresponding coin value. Thus the chance of successful cheating is 1/q. If, however, the divisors of h are chosen sufficiently large, quite practical security can be achieved. When the possibilities of distributing change and refunding are included, this scheme's privacy surpasses that of a coin system.Combining online coins improves efficiency, use of funds, convenience, and privacy.Chaum, D., \"Privacy Protected Payments: Unconditional Payer and/or Payee Anonymity,\" in Smart Card 2000, North-Holland, 1989, pp. 69-92. \u21a9 \u21a9 \u21a9 \u21a9Chaum, D., A. Fiat, & M. Naor, \"Offline Electronic Cash,\" Proceedings of Crypto '88. \u21a9"}
{"prompt": "Why I Wrote PGP", "completion": "Whatever you do will be insignificant, but it is very important that you do it.It's personal. It's private. And it's no one's business but yours. You may be planning a political campaign, discussing your taxes, or having a secret romance. Or you may be communicating with a political dissident in a repressive country. Whatever it is, you don't want your private electronic mail (email) or confidential documents read by anyone else. There's nothing wrong with asserting your privacy. Privacy is as apple-pie as the Constitution.The right to privacy is spread implicitly throughout the Bill of Rights. But when the United States Constitution was framed, the Founding Fathers saw no need to explicitly spell out the right to a private conversation. That would have been silly. Two hundred years ago, all conversations were private. If someone else was within earshot, you could just go out behind the barn and have your conversation there. No one could listen in without your knowledge. The right to a private conversation was a natural right, not just in a philosophical sense, but in a law-of-physics sense, given the technology of the time.But with the coming of the information age, starting with the invention of the telephone, all that has changed. Now most of our conversations are conducted electronically. This allows our most intimate conversations to be exposed without our knowledge. Cellular phone calls may be monitored by anyone with a radio. Electronic mail, sent across the Internet, is no more secure than cellular phone calls. Email is rapidly replacing postal mail, becoming the norm for everyone, not the novelty it was in the past.Until recently, if the government wanted to violate the privacy of ordinary citizens, they had to expend a certain amount of expense and labor to intercept and steam open and read paper mail. Or they had to listen to and possibly transcribe spoken telephone conversation, at least before automatic voice recognition technology became available. This kind of labor-intensive monitoring was not practical on a large scale. It was only done in important cases when it seemed worthwhile. This is like catching one fish at a time, with a hook and line. Today, email can be routinely and automatically scanned for interesting keywords, on a vast scale, without detection. This is like driftnet fishing. And exponential growth in computer power is making the same thing possible with voice traffic.Perhaps you think your email is legitimate enough that encryption is unwarranted. If you really are a law-abiding citizen with nothing to hide, then why don't you always send your paper mail on postcards? Why not submit to drug testing on demand? Why require a warrant for police searches of your house? Are you trying to hide something? If you hide your mail inside envelopes, does that mean you must be a subversive or a drug dealer, or maybe a paranoid nut? Do law-abiding citizens have any need to encrypt their email?What if everyone believed that law-abiding citizens should use postcards for their mail? If a nonconformist tried to assert his privacy by using an envelope for his mail, it would draw suspicion. Perhaps the authorities would open his mail to see what he's hiding. Fortunately, we don't live in that kind of world, because everyone protects most of their mail with envelopes. So no one draws suspicion by asserting their privacy with an envelope. There's safety in numbers. Analogously, it would be nice if everyone routinely used encryption for all their email, innocent or not, so that no one drew suspicion by asserting their email privacy with encryption. Think of it as a form of solidarity.Senate Bill 266, a 1991 omnibus anticrime bill, had an unsettling measure buried in it. If this non-binding resolution had become real law, it would have forced manufacturers of secure communications equipment to insert special \"trap doors\" in their products, so that the government could read anyone's encrypted messages. It reads, \"It is the sense of Congress that providers of electronic communications services and manufacturers of electronic communications service equipment shall ensure that communications systems permit the government to obtain the plain text contents of voice, data, and other communications when appropriately authorized by law.\" It was this bill that led me to publish PGP electronically for free that year, shortly before the measure was defeated after vigorous protest by civil libertarians and industry groups.The 1994 Communications Assistance for Law Enforcement Act (CALEA) mandated that phone companies install remote wiretapping ports into their central office digital switches, creating a new technology infrastructure for \"point-and-click\" wiretapping, so that federal agents no longer have to go out and attach alligator clips to phone lines. Now they will be able to sit in their headquarters in Washington and listen in on your phone calls. Of course, the law still requires a court order for a wiretap. But while technology infrastructures can persist for generations, laws and policies can change overnight. Once a communications infrastructure optimized for surveillance becomes entrenched, a shift in political conditions may lead to abuse of this new-found power. Political conditions may shift with the election of a new government, or perhaps more abruptly from the bombing of a federal building.A year after the CALEA passed, the FBI disclosed plans to require the phone companies to build into their infrastructure the capacity to simultaneously wiretap 1 percent of all phone calls in all major U.S. cities. This would represent more than a thousandfold increase over previous levels in the number of phones that could be wiretapped. In previous years, there were only about a thousand court-ordered wiretaps in the United States per year, at the federal, state, and local levels combined. It's hard to see how the government could even employ enough judges to sign enough wiretap orders to wiretap 1 percent of all our phone calls, much less hire enough federal agents to sit and listen to all that traffic in real time. The only plausible way of processing that amount of traffic is a massive Orwellian application of automated voice recognition technology to sift through it all, searching for interesting keywords or searching for a particular speaker's voice. If the government doesn't find the target in the first 1 percent sample, the wiretaps can be shifted over to a different 1 percent until the target is found, or until everyone's phone line has been checked for subversive traffic. The FBI said they need this capacity to plan for the future. This plan sparked such outrage that it was defeated in Congress. But the mere fact that the FBI even asked for these broad powers is revealing of their agenda.Advances in technology will not permit the maintenance of the status quo, as far as privacy is concerned. The status quo is unstable. If we do nothing, new technologies will give the government new automatic surveillance capabilities that Stalin could never have dreamed of. The only way to hold the line on privacy in the information age is strong cryptography.You don't have to distrust the government to want to use cryptography. Your business can be wiretapped by business rivals, organized crime, or foreign governments. Several foreign governments, for example, admit to using their signals intelligence against companies from other countries to give their own corporations a competitive edge. Ironically, the United States government's restrictions on cryptography in the 1990's have weakened U.S. corporate defenses against foreign intelligence and organized crime.The government knows what a pivotal role cryptography is destined to play in the power relationship with its people. In April 1993, the Clinton administration unveiled a bold new encryption policy initiative, which had been under development at the National Security Agency (NSA) since the start of the Bush administration. The centerpiece of this initiative was a government-built encryption device, called the Clipper chip, containing a new classified NSA encryption algorithm. The government tried to encourage private industry to design it into all their secure communication products, such as secure phones, secure faxes, and so on. AT&T put Clipper into its secure voice products. The catch: At the time of manufacture, each Clipper chip is loaded with its own unique key, and the government gets to keep a copy, placed in escrow. Not to worry, though\u2014the government promises that they will use these keys to read your traffic only \"when duly authorized by law.\" Of course, to make Clipper completely effective, the next logical step would be to outlaw other forms of cryptography.The government initially claimed that using Clipper would be voluntary, that no one would be forced to use it instead of other types of cryptography. But the public reaction against the Clipper chip was strong, stronger than the government anticipated. The computer industry monolithically proclaimed its opposition to using Clipper. FBI director Louis Freeh responded to a question in a press conference in 1994 by saying that if Clipper failed to gain public support, and FBI wiretaps were shut out by non-government-controlled cryptography, his office would have no choice but to seek legislative relief. Later, in the aftermath of the Oklahoma City tragedy, Mr. Freeh testified before the Senate Judiciary Committee that public availability of strong cryptography must be curtailed by the government (although no one had suggested that cryptography was used by the bombers).The government has a track record that does not inspire confidence that they will never abuse our civil liberties. The FBI's COINTELPRO program targeted groups that opposed government policies. They spied on the antiwar movement and the civil rights movement. They wiretapped the phone of Martin Luther King. Nixon had his enemies list. Then there was the Watergate mess. More recently, Congress has either attempted to or succeeded in passing laws curtailing our civil liberties on the Internet. Some elements of the Clinton White House collected confidential FBI files on Republican civil servants, conceivably for political exploitation. And some overzealous prosecutors have shown a willingness to go to the ends of the Earth in pursuit of exposing sexual indiscretions of political enemies. At no time in the past century has public distrust of the government been so broadly distributed across the political spectrum, as it is today.Throughout the 1990s, I figured that if we want to resist this unsettling trend in the government to outlaw cryptography, one measure we can apply is to use cryptography as much as we can now while it's still legal. When use of strong cryptography becomes popular, it's harder for the government to criminalize it. Therefore, using PGP is good for preserving democracy. If privacy is outlawed, only outlaws will have privacy.It appears that the deployment of PGP must have worked, along with years of steady public outcry and industry pressure to relax the export controls. In the closing months of 1999, the Clinton administration announced a radical shift in export policy for crypto technology. They essentially threw out the whole export control regime. Now, we are finally able to export strong cryptography, with no upper limits on strength. It has been a long struggle, but we have finally won, at least on the export control front in the US. Now we must continue our efforts to deploy strong crypto, to blunt the effects increasing surveillance efforts on the Internet by various governments. And we still need to entrench our right to use it domestically over the objections of the FBI.PGP empowers people to take their privacy into their own hands. There has been a growing social need for it. That's why I wrote it.Philip R. Zimmermann\nBoulder, Colorado\nJune 1991 (updated 1999)"}
{"prompt": "Measuring Value", "completion": "A crucial issue in transaction costs economicsAn acquaintance does you a favor. How can you pay her back and deepen the relationship? An investor examines the balance sheet of a company. What do the numbers mean? Are they even trustworthy? A judge must decide on an award for damages done to a plaintiff. What amount of money, if any, fairly compensates for the plaintiff's suffering?A wide variety of human relationships and institutions, from the most friendly to the most antagonistic, must tackle the thorny problem of value: how can we securely distinguish, using the inputs of our fallible senses, that which we value from that which we do not? How can we figure out what another person values? Money, wage labor, markets, and many other economic institutions take the forms they do primarily because they solve problems of measuring value. Such questions also lie at the heart of the current crisis in accounting.Questions of value are inherently subjective and personal. Value is very different from the objective phenomena of physics, chemistry, and the like. Societies have evolved institutions such as firms and competitive markets to set prices, legal precedents and judicial proceedings to make judgments, and so forth. These institutions in turn often rely on answering the second question, the topic of our essay \u2013 how can we securely determine value from what we observe? We will examine tax collection as an antagonistic instance of the measurement problem. The last section of this essay will focus on a particular institution developed to measure value \u2013 accounting \u2013 and suggest how it might rise to challenge the radical changes underway in our services and information economies.In the nineteenth century economists developed a theory of perfectly competitive commodity markets (often now called the \"neoclassical model\"). This is the source of supply and demand curves, for example. In the ideal market, supply balances demand resulting in a price that incorporates all the relevant skills and preferences of the market's participants. In such a market, this balance between skills needed to create a commodity and the preferences for that commodity constitute the value of that commodity \u2013 we can measure value by the equilibrium market price. Some modern markets, especially well known ones such as the commodity futures markets, approach this ideal in practice. However, many other institutions, such as the hierarchical firm, operate in very different ways. And modern markets are mostly quite recent in origin. Even today most human economic relationships, such as those that occur within a firm, are far from this ideal.In the competitive market, one commodity is traded for another. (Money is just a particularly interesting kind of commodity). In order for this market to work \u2013 in order for prices to accurately communicate value \u2013 first the participants must be able to measure the value of the two commodities traded. Indeed, that's the main property that distinguishes a commodity from a less economically tractable good or service \u2013 the ability of parties to measure its value \u2013 the ability of parties to observe properties of a good or service, matching what they observe against their private preferences, and making sure this process isn't spoofed by wily traders.The competitive market model was so successful that modern economists are now approaching other economic institutions that we take for granted \u2013 such as the firm \u2013 and asking why they exist at all! They are working backwards from a very clear theory of competitive markets to explain the wide variety of other kinds of economic relationships, usually formalized by property rights and contracts, that we enter into. This school is most widely known as the \"transaction cost\" school of economics. Often it is referred to as \"new institutional\", or \"property rights school.\" The idea of transaction costs was developed by Nobel prize winning economist Ronald Coase. His brilliant heirs include Oliver Hart and Oliver Williamson, along with Steve Cheung, Yoram Barzel, Armen Alchian, Harold Demsetz, Janet Landa, Robert Ellickson, and many others.By comparing a wide variety of contractual forms to the ideal commodity market, and by re-using many of the same assumptions used by neoclassical economists \u2013 individuals with rational self-interest, unique preferences, and unique skills \u2013 we are better understanding these other economic institutions. Modern economies contain a wide variety of commercial institutions, from hierarchically commanded firms on the one hand to freely competitive commodity markets on the other. In between are a wide variety of institutions and the contracts that formalize them.When somebody starts a new company rather than hiring on as an employee at a current one, we can think of this decision as a \"vote\" that the economy needs more market relationships and less employee-employer relationships. Contrariwise, when one firm buys out another, they are implicitly betting that the economy needs less market and more firm. Socialists, seeing the trends of integration and economies of scale in industrial capitalism, thought the world would end up as one big firm, and decided this firm should be run by the government. That worked out horribly. Others have idealized a world in which there are no firms \u2013 everybody is a private contractor, selling their services to other individuals. In many industries that's a non-starter as well. Oliver Williamson and other economists have studied many of these forms and come up with some criteria that make competitive commodity markets less than perfect, causing other contractual forms to be used. (Here \"contractual form\" is shorthand for a certain kind business relationship \u2013 employment, franchising, commodity exchange, etc. The contract used by the parties is usually the most formal and complete description of their relationship, as well as the \"security protocol\" that defines the basic rules of the relationship).These economists have identified a number of limitations of ideal commodity exchange that often cause other contractual forms to be used instead. These include:Security costs. Other kinds of transaction costs are incurred from parties that are opportunistic \u2013 they are self-interested, but they follow the letter if not necessarily the spirit of the rules of a relationship (whether these rules are legal, contractual, or informal). Security costs are incurred from, or to protect a relationship against, parties that are outright malicious \u2013 they might break any of the rules, use threats of force, or actually carry out acts of trespass, theft, or violence, in order to satisfy their (alas, not so rare) coercive kinds of preferences.Rule incompleteness \u2013 the difficulty for parties to anticipate all contingencies that might occur in a relationship, and thus the inability to plan for them with rules (for example, by terms in a contract). Most disputes that go to court, and most interesting new legal precedents, occur over situations that the parties entering into a relationship didn't foresee well enough to deal with up front.Exit costs and/or investments that are specific to a particular relationship. For example, when you take a class to learn how to use Windows or Word, you are investing in a relationship with Microsoft. Another example is when a railroad is built to a coal mine \u2013 the railroad now depends on the mine for business, and the mine operator depends on the railroad to ship his coal. A third example is the layout on a factory floor, where the results of one machine's operation feed into another specific machine. The most common examples are employees developing relationships and learning skills that are specific to a particular job. In these kinds relationships with high investments or exit costs, without good contractual safeguards you can end up stuck in a bad relationship \u2013 even if it goes sour, the other guy cheats on you, it may be too expensive to exit the relationship, or you may lose your investment.When there is both lack of ability to specify rules and relationship specific investments, the result is often vertical integration into a single firm. The coal mine might buy the railroad, the machine operations occur on a factory floor owned by a single company, and so on. On the other hand, a firm has diseconomies of scale due to the increasing inability to match preferences to skills in larger firms. As Friedrich Hayek pointed out, diseconomies of scale in the distribution of knowledge about skills and preferences are a big reason why socialism works so much more poorly than market economies. More generally, these diseconomies limit firm size. Certain innovations (such as in accounting at the beginning of the industrial revolution, or in supply chain management in the last two decades) have improved the reliable distribution of knowledge within a firm and thereby allowed firms to grow larger.Innovations that better cover contingencies or reduce the need for relationship specific investments and exit costs can disadvantage larger firms and advantage a larger number of smaller firms. Rather than an commodity market often a contractual form intermediate between a market and a firm, such as a franchise, is used. A franchise is a long term contract that, roughly speaking, specifies many basic rules for operating a business but leaves temporary or unique problems to the discretion of the local operator.We will shortly turn to perhaps the most important kind of transaction cost, the measurement of value, the main subject of our essay.Before we do that, however, let us note that these kinds of transaction costs, while first studied in the context of markets, are not confined to markets or even market-embedded institutions. They occur any time a good is transferred or a service rendered according to a set of rules or customs, however simple or complicated. Not only do these transaction costs provide a basis for comparing non-market or extra-market institutions such as the firm to the market; they also apply to a wide variety of other institutions, including many we may not typically think of as economic institutions. So, for example, the ancient institutions of inheritance, marriage, tribute, tax collection, and tort law all involved an important component of wealth transfer. All are subject to the main kinds of transaction costs outlined here \u2013 including that of our main topic.The measurement problem is very broad. It comes into play in any system of exchange \u2013 reciprocation of favors, barter, money, credit, employment, or purchase in a market. It is important in extortion, taxation, tribute, and the setting of judicial penalties. It is even important in reciprocal altruism in animals. Consider monkeys exchanging favors \u2013 say pieces of fruit for back scratches. Mutual grooming can remove ticks and fleas that an individual can't see or reach. But just how much grooming versus how many pieces of fruit constitutes a reciprocation that both sides will consider to be \"fair\", or in other words not a defection? Is twenty minutes of back-scratching worth one piece of fruit or two? And how big a piece? And just how long is twenty minutes anyway? In some cases this is relatively easy to solve, as with the delayed barter of blood for blood in vampire bats. These bats can come home from a hunting mission either overstuffed or starving. Overstuffed bats can regurgitate blood to feed hungry ones. The grateful recipient can remember the favor an return it in a future hunting trip when the tables might be turned. And indeed, some degree of reciprocal trade takes place between vampire bats, even among non-kin.Even this simple case of trading blood for blood, is, however, far more complicated then it seems. Just how do the bats estimate the value of blood they have received? Do they estimate the value of a favor by weight, by bulk, by taste, by its ability to satiate hunger, or other variables? Just the same, measurement complications arise even in the simple monkey exchange of \"you scratch my back and I'll scratch yours\".For the vast majority of potential exchanges, the measurement problem is intractable for animals. Even more than the easier problem of remembering faces and matching them to favors, the ability of both parties to agree with sufficient accuracy on an estimate of the value of a favor in the first place is probably the main barrier to reciprocal altruism among animals.It is also likely the most important barrier to exchange among humans. Many kinds of exchange, probably many more than most economists perceive, are rendered infeasible by the inability of one or both parties to the exchange to estimate its value. For most of human history, most kinds of markets that are possible today were not then feasible, in large part due to the inability of potential market participants to measure value: to estimate the value of the transaction to themselves and then use these estimates to discover and agree on a common objective measurement. Measurement of value was and is also important to the development of many economic institutions related to markets. Accounting, which we will examine below, was crucial to the development of large companies and modern systems of taxation.The process of determining the value of a product from observations is necessarily incomplete and costly. For example, a shopper can see that an apple is shiny red. This has some correlation to its tastiness (the quality a typical shopper actually wants from an apple), but it's hardly perfect. The apple's appearance is not a complete indicator \u2013 an apple sometimes has a rotten spot down inside even if the surface is perfectly shiny and red. We call an indirect measure of value \u2013 for example the shininess, redness, or weight of the apple \u2013 a proxy measure. In fact, all measures of value, besides prices in an ideal market, are proxy measures \u2013 real value is subjective and largely tacit.Such observations also come at a cost. It may take some time to sort through apples to find the shiniest and reddest ones, and meanwhile the shopper bruises the other apples. It costs the vendor to put on a fake shiny gloss of wax, and it costs the shopper because he may be fooled by the wax, and because he has to eat wax with his apple. Sometimes these measurement costs comes about just from the imperfection of honest communication. In other cases, such as waxing the apple, the cost occurs because rationally self-interested parties play games with the observable.Measures are critical components of institutions \u2013 such as auctions, contracts, accounting systems, legal damage rules, tax rules, etc. \u2013 that align incentives between parties who, prior to participating in the institution, have incompatible incentives. We can divide the measurement problem into two components \u2013 the first, choosing the phenomena and units that will be measured, and second, measuring those attributes in a way that minimizes spoofing of the measure between parties whose incentives with respect to the value are misaligned.Cost can usually be measured far more objectively than value. As a result, the most common proxy measures are various kinds of costs. Examples include:We now look at a particularly challenging set of measurement problems \u2013 those faced by a tax collector. Taxation being the least cooperative kind of economic relationship \u2013 the incentives between the parties being the most misaligned \u2013 the measurement game played between the parties takes its most serious form.Tax collection is the most efficient department of government. Its efficiency rivals that of many private sector institutions.From the point of view of many taxpayers this is an incredible claim, given that tax collectors take money we ourselves know how to spend quite well, thank you, and often spend it on amazingly wasteful activities. And the rules by which they take it often seem quite arbitrary. Tax rules are usually complex but nevertheless fail to let us account for many events important to the earning of our incomes that differentiate us from other taxpayers.How the money gets spent is outside the scope of the claim that tax collectors are uncommonly efficient. It is the collection process itself that is the subject of that claim, and the tax collection rules. This essay will demonstrate the efficiency of tax collector's rules by two arguments:The tax collector's incentives are aligned with the other branches of their government in a task that benefits all associated with the government, namely the collection of their revenue. No organization of any type collects more revenue with fewer expenditures than tax collection agencies. Of course, they have the advantage of coercion, but they must overcome measurement problems that are often the same as other users of accounting systems, such as owners of large companies. It is not surprising, then, that tax collectors have sometimes pioneered value measurement techniques, and often have been the first to bring them into large scale use.Like other kinds of auditors, the tax collector's measurement problem is tougher than it looks. Investment manager Terry Coxon has described it well[6]. Bad measures or inaccurate measurements allow some industries to understate their income, while forcing others to pay taxes on income they haven't really earned. Coxon describes the result: the industries that are hurt tend to shrink. The industries that benefit pay fewer taxes than could be extracted. In both cases, less revenue is generated for the tax man than he might be able to get with better rules.This is an application of the Laffer curve to the fortunes of specific industries. On this curve, developed by the brilliant economist Arthur Laffer, as the tax rate increases, the amount of revenue increases, but at an increasingly slower rate than the tax rate, due to increased avoidance, evasion, and most of all disincentive to engage in the taxed activity. At a certain rate due to these reasons tax revenues are optimized. Hiking the tax rate beyond the Laffer optimum results in lower rather than higher revenues for the government. Ironically, the Laffer curve was used by advocates for lower taxes, even though it is a theory of tax collection optimum to government revenue, not a theory of tax collection optimal to social welfare or individual preference satisfaction.On a larger scale, the Laffer curve may be the most important economic law of political history. Adams[1] uses it to explain the rise and fall of empires. The most successful governments have been implicitly guided by their own incentives \u2013 both their short-term desire for revenue and their long-term success against other governments \u2013 to optimize their revenues according to the Laffer Curve. Governments that overburdened their taxpayers, such as the Soviet Union and later Roman Empire, ended up on the dust-heap of history, while governments that collected below the optimum were often conquered by their better-funded neighbors. Democratic governments may maintain high tax revenues over historical time by more peaceful means than conquering underfunded states. They are the first states in history with tax revenues so high relative to external threats that they have the luxury of spending most of the money in non-military areas. Their tax regimes have operated closer to the Laffer optimum than those of most previous kinds of governments. (Alternatively, this luxury may be made possible by the efficiency of nuclear weapons in deterring attack rather than the increased incentives of democracies to optimize to tax collection).When we apply the Laffer curve to examining the relative impact of tax rules on various industries, we conclude that the desire to optimize tax revenues causes tax collectors to want to accurately measure the income or wealth being taxed. Measuring value is crucial to determining the taxpayer's incentives to avoid or evade the tax or opt out of the taxed activity. For their part, taxpayers can and do spoof these measurements in various ways. Most tax shelter schemes, for example, are based on the taxpayer minimizing reported value while optimizing actual, private value. Tax collection involves a measurement game with unaligned incentives, similar to but even more severe than measurement games between owner and employee, investor and management, store and shopper, and plaintiff-defendant (or judge-guilty party).As with accounting rules, legal damage rules, or contractual terms, the choice of tax rules involves trading off complexity (or, more generally, the costs of measurement) for more accurate measures of value. And worst of all, as with the other rule-making problems, rule choices ultimately ground out on subjective measures of value. Thus a vast number of cases are left where the tax code is unfair or can be avoided. Since tax collectors are not mind readers, tax rules and judgments must substitute for actual subjective values its judgments of what the \u201creasonable\u201d or \u201caverage\u201d person's preferences would be in the situation. Coxon provides the following example. Imagine that we wanted to optimize the personal income tax rules to measure income as accurately as possible. We might start reasoning along these lines:... look a little closer and you find that an individual incurs costs and expenses in earning a salary. He has to pay for transportation to and from work. He may spend money on clothes he wouldn't otherwise buy and on lunches that would cost less at home. And he may have spent thousands of dollars acquiring the skills and knowledge he uses in this work.Ideal, precise rules for measuring his income would, somehow, take all these and other costs into account. The rules would deduct the cost of commuting (unless he enjoys traveling about town early in the morning and later in the afternoon). They would deduct the cost of the clothes he wouldn't otherwise pay (to the extent it exceeds the cost of the clothes he would buy anyway). They would deduct the difference between the cost of eating lunch at work and the cost of lunch at home (unless he would eat lunch out anyway). And each year these ideal rules would deduct a portion of the cost of his education (unless he didn't learn anything useful in school or had enough fun to offset the cost).Because there are limits to complexity, andbecause tax agents can't read minds, the government gives them arbitrary rules to follow: no deductions are allowed for commuting expenses, for clothing that is suitable for wearing outside of work, for lunches that aren't part of the \u201cbusiness entertainment\u201d or for the cost of acquiring the skills a job requires (although you can deduct the cost of improving your skills).The resulting rules often seem arbitrary, but they are not. They are trade-offs, often non-obvious but brilliant, between the costs of measuring more value with greater accuracy and extra revenue extracted thereby. However, the value measurement problem is hardly unique to tax collection. It is endemic when assessing damages in contract and tort law, and when devising fines punishments in administrative and criminal law. Many private sector rules found in contracts, accounting, and other institutions also have the quality that they use highly non-obvious measures of value that turn out, upon close examination, to be brilliant solutions to seemingly intractable problems of mind-reading and the unacceptable complexity of covering all cases or contingencies. Such measurement problems occur in every kind of economic system or relationship. The best solutions civilization has developed to solve them are in most institutions brilliant but highly imperfect. There is vast room for improvement, but failed large-scale experiments in attempts to improve these measures can be devastating.The Laffer curve and measurement costs can also be used to analyze the relative benefits of various tax collection schemes to government. Prior to the industrial revolution, for example, the income tax was infeasible. Most taxes were on the prices of commodities sold, or on various ad-hoc measures of wealth such as the frontage of one's house. (This measurement game resulted in the very tall and deep but narrow houses that can still be found in some European cities such as Amsterdam. The stairs are so narrow that even normal furniture has to be hauled up to the upper story and then through a window with a small crane, itself a common feature on these houses).Taxes distorted the economy of the Netherlands \u2013 quite literally. Here are some houses in Amsterdam built in the 17th and 18th centuries, and a typical narrow staircase. Furniture and other large objects must be hauled up by the small cranes seen above the top-story windows.Prior to the industrial revolution, incomes were often a very private matter. However, starting in England in the early nineteenth century, large firms grew to an increasing proportion of the economy. Broadly speaking, large firms and joint-stock companies were made possible by two phases of accounting advances. The first phase, double-entry bookkeeping, was developed for the trading banks and \"super companies\" of early fourteenth century Italy. The second phase were accounting and reporting techniques developed for the larger joint stock companies of the Netherlands and England, starting with the India companies in the seventeenth century. Accounting allowed manager-owners to keep track of employees and (in the second phase) for non-management owners to keep track of managers. These accounting techniques, along with the rise of literacy and numeracy among the workers, provided a new way for tax collectors to measure value. Once these larger companies came to handle a sufficient fraction of an jurisdiction's value of transactions, it was rational for governments to take advantage of their measurement techniques, and they did so \u2013 the result being the most lucrative tax scheme ever, the income tax.While the incentives between investors and managers of public companies are not as badly misaligned as that between tax collector and taxpayer, the incentives to play games with measurements are still quite substantial. Let's now look at the challenges that investors, playing an accounting game with management, face as we move beyond the industrial era.Intangible assets \u2013 in the form of trade secrets, intellectual property, brands, human resources, and so on \u2013 have become more valuable than tangible assets to many of today's businesses. In business in general, and accounting in particular, it is common to use cost as a proxy measure for value. Indeed, while the actual economic value of an asset is the discounted value of expected future cash flows, most assets are assigned a value based on their costs rather than their expected future cash flow stream.This usually works because (a) costs are usually based on verifiable events which can be signed off on and audited, whereas predictions of cash flow are mere speculations about the future, (b) under most conditions we expect that managers have acted rationally, expending money only where they expect, on average, an eventual greater return, and (c) skilled readers of financial statements have learned from experience what games can be played by managers (because their incentives differ from other stakeholders), and to detect signs that managers have acted irrationally (e.g. over or under investment in particular assets).Thus, accounting numbers for tangible assets have never been take too literally or in isolation by skilled readers of financial statements. Indeed, the seeming concreteness of tangibles can be quite misleading. A skilled reader knows that most accounting numbers represent costs not value, and apply their knowledge of the industry to determine for themselves how well value may actually be estimated by these costs. For example, a naive reader will take current assets at face value, whereas a skilled reader will look for conditions such as abnormal growth of inventory or receivables. The actual function of a financial statement is to provide clues for analysts based on well-verified facts, not to provide pat final answers for those seeking to evaluate a company.Some objections to including intangibles on the balance sheet are invalid. For example, it is argued that internally generated intangibles cannot be valued because they have not been purchased on the market. However, this is also often the case for unique industrial investments and inventories. We have developed methods such as specific identification to value internally generated assets, and these could be applied to internally generated intangibles as well. Allocation of costs common to several intangible assets (e.g. a software library used in two different software products) can be based on long experience allocating costs common to multiple tangible assets.Another more valid objection is that the actual value, in expected cash flow, of intangibles is far more uncertain than for most physical assets. Thus, the mapping from cost to value is far more uncertain. This mapping can be done with greater certainty only over an aggregate of diverse investments. However, there are certain kinds of physical assets whose value is also highly uncertain, yet are assigned a value based on costs. Rational managers discounted their original investments to take into account such risks. The same is true for intangible assets. Skilled readers of financial statements know when to expect high uncertainty. Often they will demand further details from management about the specific investments. Providing greater detail where intangibles are involved is highly advisable, a point I return to below.On the other hand, many proposed measures of intangible value are non-starters for the purposes of accounting or financial statements. For example, various measures have been put forth allegedly related to expected cash flows (e.g. measuring web site hits, customer retention rates, etc. to try to estimate the value of a brand). The only time expected value rather than cost is used on a balance sheet for tangibles is when the asset can be currently priced on an efficient, competitive, and public market. (For example, inventories of publically traded commodities can be valued in this manner). Otherwise, it is far better to use cost, the actual event of expenditure, and let the skilled readers of the financial statement interpret these numbers properly.Here are some specific comments and proposals for specific kinds of intangible assets:A company owns these legal rights in all developed and most undeveloped economies. Copyrights are very well defined but in some cases very difficult for the company or the state to actually control. Patents can be very ill defined, so that the occurrence of a loss of rights over the actual technology is unclear. However, presumably managers discount their original investments to take into account such risks. Thus, if costs can be allocated to particular patents and copyrights, they constitute a proxy measure for the value of patented and copyrighted assets. This is quite similar to using the cost of a physical asset, whose eventual cash flow value is highly uncertain, to value that asset, and allowing the skilled reader to interpret the resulting number properly.A company owns legal rights to its trademark in all developed and most undeveloped economies. Companies further have some control over perception in people's minds, insofar as their observable actions influence this perception. Some major brands names have shown a very persistent value, while lesser ones are more likely to be forgotten. One can map current accounting treatments for investment in, maintenance of, and depreciation of physical assets to investment in and maintance of a brand, as well as the tendency of customers to forget over time a brand that is not maintained.Employees are not owned, but the labor market is not perfectly fungible. There is some stickiness to it. Indeed, this stickiness can be measured by the turnover rate for the company. The turnover rate, a quite auditable number, may provide an excellent way to depreciate an asset defined by the costs of hiring and training.Until long experience is gained by stakeholders with particular kinds of intangible investments, the ability to judge whether costs are rational, and satisfy the interests of stakeholders besides management, will be poor. A wide variety of reporting experiments, most of which will fail, are nevertheless essential to achieving more accurate reporting of asset values to stakeholders. Interpretation of intangible-heavy financial statements is a job for skilled analysts, not casual readers. For the expert more information is better \u2013 the detailed records of expenditures and their allocation to intangible assets are more important to the skilled stakeholder than the summary totals. Such detailed records should be released to stakeholders despite objections about confidentiality. Only long experience with these details will teach stakeholders whether and how to judge summary totals involving intangibles.The measurement of value is one of the most intractable problems of civilization. Brilliant and highly non-obvious solutions to this problem \u2013 from markets to money to the time-wage to cost accounting \u2013 have constituted some of the most important steps from animal to civilization. Historically, the solutions to one value measurement problem (e.g., accounting for value in a large firm) made possible other institutions as well (e.g. income tax, which must first solve the same kind of problem in order to be Laffer competitive with other kinds of taxation). Intangible asset accounting may now be the most important value measurement problem we face as we move beyond the era where tangible industrial commodities dominated the economy.(under construction)Adams, Charles, For Good and Evil: The Impact of Taxes on Civilization \u21a9Barzel, Yoram, 1982. \"Measurement Cost and the Organization of Markets\", Journal of Law and Economics 25, no 1:27-48Cheung, Steven N.S., 1969. A Theory of Share Tenancy. University of Chicago Press.Cheung, Steven N.S., 1983. \"The Contractual Nature of the Firm\", Journal of Law and Economics 2, no 1:1-22Coase, R.H., 1937, \"The Nature of the Firm\", Economica 4, no. 3:386-405Coase, R.H., 1988 The Firm, the Market and the Law, University of Chicago Press 1988 \u21a9Coxon, T., 1996 Keep What You Earn, Times Business/Random HouseHayek, F., \"The Use of Knowledge in Society\"Williamson, Oliver, The Economic Institutions of Capitalism, Free Press 1985"}
{"prompt": "Financial Cryptography in 7 Layers", "completion": "Abstract: Financial Cryptography is substantially complex, requiring skills drawn from diverse and incompatible, or at least, unfriendly, disciplines. Caught between Central Banking and Cryptography, or between accountants and programmers, there is a grave danger that efforts to construct Financial Cryptography systems will simplify or omit critical disciplines.This paper presents a model that seeks to encompass the breadth of Financial Cryptography (at the clear expense of the depth of each area). By placing each discipline into a seven layer model of introductory nature, where the relationship between each adjacent layer is clear, this model should assist project, managerial and requirements people.Whilst this model is presented as efficacious, there are limits to any model. This one does not propose a methodology for design, nor a checklist for protocols. Further, given the young heritage of the model, and of the field itself, it should be taken as a hint of complexity rather than a defining guide.Financial Cryptography is substantially complex[3]. For a field that is nominally only half a decade old, by some viewpoints, it is apparent from the implementation work that has been done that many more aspects were involved than envisaged by early pioneers.Financial Cryptography appears to be a science, or perhaps an art, that sits at the intersection of many previously unrelated disciplines:At such a busy juncture of so many distinctive bases of knowledge, problems are bound to arise. Not only the inevitable confusion and wasted resources, but the difficulty in acquiring technical, management and marketing talent that can comfortably work in the field is an issue.As a preliminary step to the better understanding of Financial Cryptography projects, it is often of some interest to structure these disciplines into models that aid dialogue, comparisons and decision making.This paper presents one such model that attempts to describe the field in an introductory manner, as a preamble to greater learning. In this model, the terms Finance and Cryptography are stretched out in order to reveal the disciplines that might have been hidden within the name.Of course, no one model can plausibly cover the depth and breadth of a complex subject. The intent of this present model is to allow the reader to conceptualise the entire field, identifying the relationships of the disciplines, without spending too much time on the detailed nature of each component. Depth is sacrificed for breadth.This paper introduces a 7 layer model, akin to the Open Systems Interconnect Reference Model of networking fame, as shown in Figure 1[5][6]. In this model, Finance and Cryptography are stretched out, revealing five more areas of interest.An advantage of this model is traversal from the technical to the application, giving major stakeholders easy points of entry.We can start at the top, the Finance layer, and work top-down; this is a process of mapping requirements and following them down into lower layers. This might be the place to start if engaged in high-level application discussions.Or, we can start at the bottom, the Cryptography layer, and describe tool kits to offer the higher layers. From ever more sophisticated lower layers, we can build our way up to offering a smorgasboard of options to the all-encompassing financial applications layer.Here, we choose a descriptive presentation that traverses bottom-to-top. Later, an example is presented in the reverse order, top-to-bottom.At the bottom is Cryptography[7]. To some extent, the pure science domain of cryptography solves problems in a mathematical sense only, but it delivers useful properties, including:Cryptography also can solve special problems, when correctly formulated[8]. For example, how can Alice sign a statement of Bob's without being aware of the contents of the statement[9]?It takes Software Engineering, layer 2, to usefully benefit from the properties of cryptography. We draw from database theory (atomicity, transactional integrity and recovery) and networking theory (feedback and idempotency) in order to add such properties as reliability and robustness in the face of network and nodal unreliability, or, designed unavailability such as smart cards and handhelds[10][11].Software engineering provides us with a practical network. We can talk about sending a message across an open network and know that a message will eventually get to the addressee. With the integrity techniques of the previous layer, we can know that the information received by the addressee is as intended by the addressor. By using the specialised sequences of database theory, we can preserve the integrity of the messages over time, in the face of software and hardware failure.With both cryptography and software engineering providing a network upon which we can rely, we can think about distributing messages that are designed to Financial Cryptographic purposes[12]. In the Rights layer, we are looking for a protocol that provides a user with control over assets, in an unequivocable, determinable fashion[13]. Techniques aimed at achieving this include:although this is not an exclusive list[19][20].The previous layers provide methods reliable enough to be used for passing something of value, which we call rights, over an otherwise unsuitable network. Now, we need the techniques of Accounting in order to store and manage rights over time, To financial cryptographers, accounting is a mundane field, and it has perhaps been attractive to ignore it, but experience shows that systems without conventional accounting features tend to lose the value entrusted to them.The techniques of the accounting discipline include double-entry bookkeeping, balance sheets, and the accounting equation[21]. Accounting concepts permit builders of Financial Cryptography systems to build complex systems that guarantee not to lose value as long as everyone follows the rules; and to efficiently identify where the rules are not followed.The above layer, Rights, defines what needs to be accounted for. As an example, the most basic method would be token money. An accounting model based on tokens or coins would need a simple store of coins for the client. The server would be more complex, requiring an account for unissued value, a float account, and a double spend database that matches the float amount[22].Once there is a guarantee that the digital amounts \u2013 the accounting numbers \u2013 under management can be securely passed over the net, and stored on nodes safely, we need to cast our view wider to threats outside the technical domain[23].In any working technology, whether it be trading or cash purchasing, the threat of theft or abuse exists from parties who are trusted to manage the system. This problem, known as the agency problem, can be overcome with a wide variety of techniques that here I will label governance[24].Governance includes these techniques:As technologists, we strive to make the protocols that we build as secure and self-sustaining as possible; our art is expressed in pushing problem resolution into the lower layers. This is an ideal, however, to which we can only aspire; there will always be some value somewhere that must be protected by non-protocol means.Our task is made easier if we recognise the existance of this gap in the technological armoury, and seek to fill it with the tools of Governance. The design of a system is often ultimately expressed in a compromise between Governance and the lower layers: what we can do in the lower layers, we do; and what we cannot is cleaned up in Governance[31].With a system that provides internal and external stability and security, we are now in a position to assign value to the structure. By value, we mean the unit of account, the meaning of that unit, and the range of numbers that are applicable.For example, a Value layer might ascribe any one of the following to the virginal numbers of lower layers:As the software is somewhat unconcerned about this decision, we could just as easily used the software for any other value \u2013 but the business needs to harmonise the security and cost implications.We might also call this the Contract layer, as any value in electronic form is an agreement between the holder and the owner[35]. It is here that we design the contract that formalises the agreement between an Issuer and a user.Finally, on top of the value layer, which provides a structure for financial transactions, we can build our application. As we are concerned with Financial Cryptography, it is convenient to call this last layer the Finance layer. Here, we build an application that adds financial meaning to our designs.In the Finance layer, we construct any and all applications that might readily be useful to users. For example,And many more.In order to see the model in its descriptive role, I present an example, starting from the Finance layer and working down, by following the roadmap of requirements.In practice, the model is not a design methodology for setting and mapping requirements, but can be used to reverse-engineer an existing design, for the purposes of presentation and discussion of the mutually agreed contract between the builders and the stakeholders. The following description reflects such a process.Systemics, a company specialising in Financial Cryptography, built a system to trade financial securities[41]. The Ricardo system, as an application, required clients and servers to maintain securities, and they communicated using a value system suitable to manage securities and cash[42].As trials evolved into experience, and strategic analysis of the securities industry evolved into appreciation, if not wisdom, the following primary requirements were built up.These led to many subsidiary requirements:The following discussion concentrates on the value architecture of the Ricardo system built by Systemics, rather than the trading aspects. However, experience shows that trading becomes a tractable problem if the value architecture is solid.The requirements of the Finance layer result in a derivative requirement for a Value architecture, amongst other things. This Value architecture follows directly after the Finance layer, as the former defines the scope of the security requirements for the remaining layers.We developed a notion of instruments as follows:To meet many of these requirements, the notion of a contract for value was developed[43]. This document, which we call a Ricardian contract, documents an agreement between the holder of a security and the issuer of that security, and provides for the flexibility requirement by allowing many and arbitrary clauses to be included.It is both program- and user- readable, and is signed by the Issuer of the instrument as a binding agreement for any holder of units of that issue. By having a strong basis to determine the nature of the contract, in both human and program terms, we support the auditability requirement, and we can clearly identify the regime for resolution of disputes.Once set in stone with a digital signature, an identifier can be allocated, leading to efficient description in packets. Thus, this invention requires two things of lower layers \u2013 a signature form and a unique document identifier \u2013 which are addressed below.Once the Value context is defined, indicating the size and nature of instruments, we can address the Governance issues of payment systems and trading.These are substantially complex[44]. In order to preserve systems intact in the presence of active fraud in the non-technical domain, many disclosure and informational duties abound. In the Ricardo system, we address the governance layer in three main ways:Each of these is discussed below[45].In static governance, we ensure that the user has the contract, and that all concerned know that the user has the contract[46].In order to ensure that the Ricardian contract is always present and available to the user, and is continuously binding to the Issuer, we take the message digest of the document and use that message digest as the identifier of the instrument[47].Consider a message digest, for example, 9c7c9e7bb564224977aea8674623a37407b8f6ee being a large number of bits encoded in hexadecimal. The user cannot meaningfully interpret this string of apparently random information, so the software (and thus, the software engineer) is more or less forced to maintain a database that describes what the message digest represents. As the contract is readable by software, it makes a superior source of data than any other (such as an intermediate database that holds the contents) and thus we can reasonably assume, to the extent that the software can, that the user has the full contract available[48].The system will thus ensure that, to all practical intent, the user has the contract. This provides two cost savings, limiting both on-going support and the likelihood of litigation[49].Within structural governance, we consider the question of insider fraud, the theft of both digital value within the Financial Cryptography system and of any physical value that underlies the virtual value managed by the system.With any payment system, there is an ability to create new assets, or misdirect existing assets, all with no more work than a few button pushes. To address this, we use the approach of separation of concerns to address the agency problem of holding owners' assets, but protecting them from internal attack. This problem is normally handled by separating out management of day-to-day assets with the creation of assets in the system, and increasing the work required for any fraudulent transactions.The general schema that is advised to Issuers is as follows[50]. In order to limit the creation of value, for each issuance, a special account is designated as the mint, or the creator of value. This account is placed in the hands of a reliable professional source such as an accountant or lawyer, who will hopefully only have an interest in using the account under the probity of the governance regime.Then, a manager account is designated that receives any new float from the mint, and also returns any redemptions.It thus becomes the Issuer's responsibility to ensure that the mint account is rarely used, and then with full authorisation and wide scrutiny. Meanwhile, the manager's account is regularly used, but holds only limited amounts of value for day to day requirements.The above are general techniques that are supported within the Ricardo system, but are as applicable elsewhere. Certain features get specific support, such as value caps on accounts and target account limitatons.Note how these protection techniques that we use are partly outside the domain of the technical system. Rather than being outside scope, their discussion here is simply a reflection of the claims that the total security of the system is a holistic issue, and governance is the layer where we solve the security challenges that remain after we have attempted to solve as many as possible in the lower layers.Finally, in dynamic governance, we provide for monitoring of key values by the user community, and thus share the auditing burden. These values can be audited in an issued currency within the Ricardo system:It is also worth noting that when a currency is reserved by an underlying asset (for example, if a gold-denominated currency had physical metal escrowed to reserve it) then the above governance features should be mirrored for the reserves.That is, to continue the example of gold, there should be separate parties responsible for the ingress and egress of metal into storage, and there should be independent verification of the number of bars currently placed in escrow.In order to meet the conflicting objectives of privacy and flexibility, Ricardo uses a conventional accounting model with some additional features:Because of the top level requirement for cheapness, the accounting model was designed for complete reliability, right up to the support desk level. It does this by employing a group of non-obvious techniques:Using these techniques, the accounting model supports the Finance level requirement of being cheap to operate. If the client software is missing something, then it is a bug, and it properly belongs with the software developer, rather than being covered up as an Issuer help desk problem.In order to ensure that owners maintain rights to assets that are managed on the servers, the SOX protocol provides these three major features[56]:Each user creates key(s) which are registered with the server. These keys are as determined by Cryptography layer, below, and are required to provide a unique identifier.Value transfer is via three components:A key can be used to sign a payment order. This payment order can be directed to a target account, or be open (bearer), and it has a fixed amount of some determined type of value[57].In this sense, the payment is analogous to a cheque. It differs from chequing systems in that the SOX payment has no value until settled, whereas a cheque is expected to have value on signing[58].A payment order can be deposited to a sub-account. Settlement depends on a number of checks, such as funds in the source sub-account, and a valid payment order signature from the source key.The Issuer server returns the receipt, mentioned in the above Accounting layer.Finally, in order to cope with network failure, the SOX protocol includes a mail feature, that allows the server to communicate reliably with the client. Packets that must be delivered to the client are placed in the mailbox, and returned on every mail request. Each piece of mail must be signed for, and if not signed for, is simply returned again.In the context of the value transfer above, there is only one piece of mail, being the receipt.SOX is a flexible protocol. By replacing the deposit request, above, with trading requests, it can be used for market trades as well as settlements[59].In the trading context, requests that are implemented emulate standard market functions such as looking at the order book for an instrument, placing an order (buy or sell), monitoring the progress of an order and cancelling an order. The SOX mailbox is used for the return of orders (assets and results).SOX as a protocol spans both the Rights layer and the Software Engineering layer.In networking, every transmission must be considered as a contender for failure. As a corollary to this, relying on a connection-oriented protocol such as TCP will not guarantee reliability, as its promise is only that that the data that gets there is the correct data as sent[60].To cope with these problems, SOX asumes a datagram network only, and handles reliability itself[61].Secondly, it bases communications on a request model, with each request being independent of the next, and each request only being complete when positive feedback is received.Thirdly, SOX requests are idempotent, so they can simply be repeated until some confirmation comes back that one attempt has succeeded. Unique request identifiers are included and used to filter out retries.Fourthly, in order to implement SOX, a client must treat each request as unreliable. For example, when a payment is written by the current client, that payment is recorded as pending, which is eventually matched up with a receipt arriving from the Issuer.Or, the client gives the user the opportunity to cancel the payment simply by re-using the unique identifer, and thus stopping the lost payment ever settling. In this way, where it is impossible to guarantee a result, Ricardo extends reliability management out to include the user.Finally, SOX includes a comms layer that provides for key exchange for confidentiality and authentication purposes.The cryptography demanded by the upper layers includes:All of these algorithms are implemented as part of Cryptix, an open source project that was spun off by Systemics in 1996. Cryptography and the cryptographic techniques used in Ricardo are well discussed in the literature[62].The model works well in tackling and reducing the inherent complexities of Financial Cryptography. It does this by dividing the field into 7 areas, and providing an interconnection method (layering).Once a project is so layered, professionals within different disciplines can clearly deliniate those areas within their expertise, and those which call for other specialisations. Thus, lawyers can recognise the Governance layer as their bailiwick, and pay due attention to it. Other layers can be treated, more or less, as black boxes, interconnecting with requirements down and features up. Likewise, programmers can concentrate on Software Engineering and Rights, with more interest in Accounting than Governance.A project manager, with responsibility for delivery of a Financial Cryptography system, finds this even more powerful, as the model offers a natural checklist and vocabulary for coordinating the activity.As an analogue of the 7 layer ISO Reference Model, it also wins on easy familiarity with what we are trying to achieve.The designation of 7 layers does not, in and of itself, encourage the design or implementation of system components that fall neatly into one layer or another. The notion of a layer 3 protocol providing services to a layer 4 protocol simply does not work in practice[63].Likewise, this model is not a design methodology. The description of a top-down requirements process is illusory, and in practice, the requirements analysis is more modelled by continuing and volatile negotiations between the layers. Whilst it is descriptive to state that a requirement is bouncing up and down between layers one and five, inclusive, this does not give much assistance to a team leader in assisting a design process.It is easy to criticise any model, as by definition, a model falls short of reality. Here are some points:Does the set of layers describe Financial Cryptography accurately? Hettinga suggests, perhaps only partly in jest, the name cryptographic finance, implying that layers one to three may have greater claim to the original term[64].The 7 layer model is static rather than dynamic. Once described, it works, but how did we manage to construct it in the first place?Are there really 7 layers? Are the layers as described? About each of the different layers we can ask many questions, including some troublesome ones:My answer, today, is 'yes' to each, but only time will provide the real answer.The top-down requirements example of Ricardo seems to indicate a natural design flow or methodology, but in practice the design process does not follow that path.Experience has shown that concentration on Finance, and then Value is worthwhile. Then, the vertical flow breaks down; in particular, a lot of time is spent bouncing around the lower 4 layers in a negotiation for the best compromise, with occasional forays upwards in order to tune the requirements. Governance always seems to come last in the design process, as its contents are an admission of what the rest of the architecture has failed to cover.Layers one to four, up to Accounting, are fairly solid in terms of their disciplines, practices and methodologies. Layers five and up (Governance, Value, and Application) are less well-defined.This might represent a flaw, or it might indicate an intrinsically messy area. Perhaps coincidentally, the ISO Reference Model exhibits the same pattern.I believe that these criticisms are valuable in indicating that the model is promising, as they help to refine ideas, rather than destroy them.Ian Grigg can be reached at iang at systemics dot com. He is a founder of Systemics, Inc, a developer of Internet Financial Systems software. \u21a9This paper was presented at FC00 and is originally published in the Proceedings of Financial Cryptography Fourth International Conference, Anguilla, British West Indies, 21st - 24th February 2000. A web copy is located at http://www.iang.org/papers/.The model was initially inspired by discussions on the DBS mailing list, and was progressively refined in discussions with Twan Van Der Schoot. This paper has also benefitted from review remarks by Ian Brown, Zooko Journeyman and Rachel Willmer. \u21a9The term Financial Cryptography was invented by Robert Hettinga as a name for a conference held annually in Anguilla. \u21a9Ian Grigg, Virtual Finance Report, Digital Trading, November 1997. \u21a9Search on Google for ISO OSI Reference Model Seven Layer \u21a9It is mostly coincidence that there are 7 layers, and it may change if we find compelling reasons to add or subtract layers. \u21a9The Cryptix Resources Page lists popular cryptography books, including links for purchasing. \u21a9A large area of such problems, including the blinding property, is described in Rethinking public key infrastructures and digital certificates --- building in privacy Stefan Brands, ISBN 90-901-3059-4, 1999. \u21a9The blinding concept is most easily accessible in Achieving Electronic Privacy Scientific American David Chaum, August 1992. \u21a9An Introduction to Database Systems, Volume 2, by C.J Date, 6th Edition, Addison Wesley, 1995 \u21a9I studied with this text book nigh on 20 years ago, and it still appears to be the main text in the field of protocols and networking: Computer Networks, by Andrew S. Tannenbaum, 3rd ed., Prentice Hall, 1996 \u21a9A fullsome page of links to electronic purses \u2013 implementations of Rights protocols \u2013 is included in Leo Van Hove's bibliography. \u21a9I am indebted to Mark Miller for providing me with the name of this layer. \u21a9At the time of writing, the canonical example would be www.e-gold.com which provides identity-based access to currencies reserved in precious metals. \u21a9For example, the eCash (tm) tokens as implemented by eCash Technologies, Inc. \u21a9Originally presented in the Gary Howland, Development of an Open and Flexible Payment System. \u21a9Mark S. Miller, Chip Morningstar, Bill Frantz, Capability-based Financial Instruments, accepted by Financial Cryptography 2000, Anguilla, February 2000. \u21a9Systems such as Chipper and Mondex. Note that there is no need for a new hardware layer \u2013 the distinction here is that the hardware is supplied, rather than assumed. \u21a9For many more examples of theoretical approaches, see Financial Cryptography First through Fourth International Conferences, Anguilla, British West Indies, February 1997-2000. \u21a9For examples of approaches that have reached practical implementation stage, if not to market, see Edinburgh Financial Cryptography Engineering a new workshop that includes presentations of running code only. \u21a9Check any basic accounting text book for these terms. Google may provide some assistance on these terms. \u21a9As a wider comment, it is possible to model any electronic value scheme as a method of accounting. See Alan Tyree, The legal nature of electronic money.Whilst a valuable modelling exercise, caution is advised, as most conclusions drawn from such exercises are too broad. Specifically, institutional observers tend towards a line of logic: \"it can be modelled as a series of accounts, therefore it should be regulated like banking;\" such an approach is fraught with difficulties and unlikely to be satisfactory. \u21a9For general articles on the Governance aspects of Financial Cryptography, check John Muller's ABA site Electronic Financial Services Resources. \u21a9The Agency Problem:Also sometimes referred to as the principal-agent problem. The difficult but extremely important and recurrent organizational design problem of how organizations can structure incentives so that people (\"agents\") who are placed in control over resources that are not their own with a contractual obligation to use these resources in the interests of some other person or group of people actually will perform this obligation as promised \u2013 instead of using their delegated authority over other people's resources to feather their own nests at the expense of those whose interests they are supposed to be serving (their \"principals\"). Enforcing such contracts will involve transaction costs (often referred to as agency costs), and these costs may sometimes be very high indeed.A Glossary of Political Economy Terms Paul M. Johnson. See also Google. \u21a9Michael Froomkin's writings on Separation of Powers. \u21a9Robert Hettinga suggests some models in The Players \u21a9In Ricardo documentation, and also further below in the section on Structural Governance I suggest breaking up the system into 5 parties, Owner, Mint, Manager, Users, Operator. \u21a9See Jane Kaufman Winn's writings on the validity of current contracts in governance: Jane Kaufman Winn, Couriers without Luggage: Negotiable Instruments and Digital Signatures, South Carolina Law Review, 1998. \u21a9See the DigiGold Page for an example of a real time report on the currency balance sheet. \u21a9See the e-gold Examiner for an example of a real time report on reserves. \u21a9See Jane Kaufman Winn, op cit, for a classic description of the Certificate Authority industry's attempts to clean up a poor security model with an implausible contract. \u21a925 cents is a fair minimum for credit cards, due to the cost of these transactions. $500 is a popular upper limit imposed on smart cards by the threat model (actually, it is 500 of the local unit, for some obscure reason). \u21a9For a description of Individual Transferable Quotas \u2013 ITQs \u2013 describing instruments for quantities of fish stocks, see Policy, Fencing the Oceans A Rights-based Approach to Privatising Fisheries, Professor Birgir Runolfsson, Autumn 1998. \u21a9Ian Brown (ianb at acm dot com) points out that pollution is in fact a public bad. \u21a9Ian Grigg, Universal Value, work in progress. This is introduced later in the example. \u21a9For example, this was the target application of Cybercash Inc, First Virtual Inc, and DigiCash BV (now eCash Technologies Inc). \u21a9Digital Trading, op cit. \u21a9For example, see the so-called second wavers: Beenz, Flooz, Cybergold. \u21a9See Fencing the Oceans, op cit. Whilst not discussed in the article, there are a small number of marketmakers in Iceland that work the thin market in ITQs. For more background on fishing property rights, see The Ecological Implications of Establishing Property Rights in Atlantic Fisheries, Elizabeth Brubaker, April 1996. \u21a9Ian Grigg and C. Petros, Proceedings of Financial Cryptography, Using Electronic Markets to Achieve Efficient Task Distribution, February 1996. \u21a9Ian Grigg and Gary Howland designed the Ricardo system in 1996-1997. \u21a9The Ricardo system is currently in use for a series of metal based currencies managed by DigiGold. \u21a9Ian Grigg, work in progress, Universal Value. \u21a9Many designs of Financial Cryptography systems have limited Issuers to being banks, which allows the designer to assume away many complications. \u21a9This section is based upon Ian Grigg, Talk on DigiGold Governance, Financial Cryptography 1999, commercial sessions. \u21a9The same logic would also imply that the user must have access to dynamic trading information such as prices, but we pass over that here. \u21a9Having abstracted the contents from the identity of the document by taking a message digest of it, we can discuss value, from payment systems perspective, as being fully and uniquely defined by the message digest. This ensures that the Issuer of the security cannot change the terms of the contract in any way without offering to the user terms for exchange. \u21a9This also has a secondary effect of shortening the distance between the contract and the software that manages it, thus simplifying the design. However, the prime objective was, and remains, a system where we know that the user has strong access to contract information. \u21a9Such a scheme might not prevent the software engineer from providing a client application that misrepresents the contract. However, this would be an issue between the user and the software supplier, rather than the system itself, especially, the operators of the system and issuers of securities would clearly not be at fault. \u21a9This is described more fully in a FAQ question on Structural Governance \u21a9In order to force the client to maintain the data, the SOX mail facility, introduced in layer 3, requires signatures for all important documents such as receipts. \u21a9Or, more correctly, to treat such a support call as a bug, in that the client is not making the information available. \u21a9A signed request from the user has more meaning to the user \u2013 the client software must keep track of these as promises to pay, and in this sense, the system is analogous to a cheque system. \u21a9The receipt includes the authentication request supplied by the client in order to provide the chain of authentication back to the user. \u21a9In programming terms, stored balances are banned. The balances that are displayed by the software client are calculated on the fly, including every time the client redraws. Getting this right has proven to be a sizeable cost in development time, but it is believed that the requirements are valid and the costs are covered in the long run. \u21a9SOX is variously Systemics Open Transactions or Secure Open Transactions. It is discussed by its original author in Development of an Open and Flexible Payment System, Gary Howland, 1996, and also in an Executive Summary. An implementation exists in open form as a part of the WebFunds Project. \u21a9SOX provides a string or byte array that determines the type of value, which is open as an implementation detail. But, practically, this is the unique identifier for the Ricardian Contract as discussed in the Value layer. \u21a9Note the way in which SOX melds with the Internet, as implication of layer 2. When passing a payment to someone on the other side of the planet, that payment only has value if it is settled and cleared by the Issuer. Otherwise, the payment is an uninteresting series of bits, with similar value to any other random nonsense.In contrast, the passing of rubber cheques is illegal in some countries, and traumatic in most others. SOX payments are not cheques in that sense. \u21a9The value Issuers are distinct servers to market servers, it is just the protocol that is common. The protocol can also be used for other purposes, wherever a primary requirement is made for a reliable delivery. \u21a9The specific problem with a connection protocol arises when the connection dies. Did the last few bytes make it to the other end or not? With such protocols, there is generally no way to recover from this uncertainty without building an additional reliable protocol over the top of the first. Which of course raises interesting design questions that may lead to alternate paths such as connectionless protocols. \u21a9SOX packets can, and are, sent over TCP connections, but mostly so that firewalls may be easily navigated. \u21a9The Cryptix Resources Page. \u21a9Indeed, in my opinion, neither is it useful for networking. For critiques of the OSI 7 layer models, see M.A. Padlipsky, Elements of Networking Style, and RFC 874. \u21a9Robert Hettinga, email on dbs at philodox dot com. \u21a9Copyright \u00a9 1998 Systemics Ltd. All rights reservedEditor's note: Some links may be broken."}
{"prompt": "The Playdough Protocols", "completion": "Commercial security at the birth of writing, arithmetic, and religion in ancient Sumer (modern Iraq).It is five thousand years ago, and you pace fretfully in your office. Located in the temple of the great goddess Inanna in ancient Nippur (now in Iraq) you are buried, not in a blizzard of paper, but an avalanche of clay. You fret. You have entrusted a valuable cargo of sheep, barley, and beer to a crusty group of sailors from the Baba Temple in the nearby Lagash[1]. These navy types are far from pious devotees of the goddess Inanna and the great god Enlil with whom you are familiar.The sailors\u2018 job, and your payoff \u2013 take the goods down the Persian Gulf and across the sea to Mohenjo-Daro, in the valley of the Indus River (in modern Pakistan). There they will be delivered to your old friend, a trusted agent of Inanna, and sold to the locals for a very substantial amount of silver.Will the sailors get hungry and eat the sheep and barley? Party and drink the beer? Get nasty and poison the lot, throwing disrepute on the great goddess Inanna? Perhaps they will get clever and water down the beer \u2013 or get still more clever and resell your high-quality goods under the name of their crude god.You needn\u2018t worry so much. Long-distance commerce may be a novelty, but you have the clay.Nor, thanks to five thousand years of experience with the technologies of tamper evidence, need we worry so much in our modern era. The occasional embezzlement and rare but quite nasty poisoning occur far less often due to our technological and institutional descendants of the ancients\u2018 clay. And using the digital equivalent of seals, we can bring data integrity and unforgeable identities to online commerce.Terra cotta sealing (bottom) and rectangular stamp seals, Mohenjo-Daro, Indus Valley, c. 2,000 B.C. The central sign on the top seal may represent a house or temple and is a symbol that is often repeated on Indus seals with horned deities seated in yogic position. Courtesy harappa.com.Let\u2018s follow the professional archaeologists and distinguish between seals, the often cleverly carved cylinders or stamps that make the impressions, and sealings, the resulting impressions rolled or stamped on wet clay, and the clay they were impressed upon. Sealings of clay were wrapped around rope knots to seal bales of goods, and around the rims of wicker baskets and pottery jars to seal in their contents. Since these ancients lacked good locks, clay sealings were wrapped around door latches to seal rooms. The security provided \u2013 evidence of tampering, due to damage of the container itself or the clay that sealed it.Seals were carved from hard materials \u2013 usually stone but sometimes faience, glass, metal, wood, or bone. Sometimes sun-dried or baked clay itself was used. The Greeks and Romans used signet rings, their action ends shaped from metal or carved from gems, to stamp wax.The seal design was usually recessed, resulting in a raised impression; occasionally this was reversed. To creating a sealing, first wet clay was shaped around the plug of a jar, the rim of a basket, the knot of a well wrapped rope on a bale, or the latch of a door. Then the surface of the clay was thoroughly covered by the impressions of the seal. The Sumerians commonly used cylinder seals, repeating the pattern across the entire clay surface. Sometimes stamp seals were used for smaller surfaces. Finally, the clay was left to dry, in the sun if possible.While sun-dried clay could usually be remoistened and rewritten, it would have been very difficult to hide from a trained eye. Rejoining the breached container lid, knot, or latch and replacing the broken seal with a new, identical seal would have been, short of stealing the original unique seal carving, impossible to hide from the inspector. Looking for a particular seal impression and examining the container, the inspector could reliably tell whether the contents had been tampered with. The difference between an accidental crack, from dropping or hitting the object, and a breach that allowed the thief or adulterator access to the goods, would also be apparent. Ancient inspectors undoubtedly became experts at looking for clues to distinguish accident from fraud. In any case, a broken seal then as now indicated suspect goods suitable perhaps for the discount bin, but more normally for the trash. It also indicated error for fraud \u2013 and potential punishment.Cylinder seal (left) and its sealing (right), King Darius the Great, Persia, 586\u2013522 B.C., with weapons of warThe earliest stamp seals found were used in Iran in 5,000 B.C. Later on archaeologists can use both the trade in seals themselves, as well as the distances between seals and the corresponding sealings, to trace long-distance trade networks. One such set of seals were manufactured around 1,900 B.C. on two important island trading cities in the Persian Gulf \u2013 Bahrein and Failaka. These seals were traded all over the Middle East, and have been found at diverse and distant locations such as Susa in Iran , Bactria in Afghanistan, Ur in Iraq, and Lothal on the west coast of India. By 1,750 B.C. Common Style seals are found in locations ranging from Spain, to Mycenaean Greece, to Marlik near the shores of the Caspian Sea. These seals were made from faience, a less expensive material, and used by smaller merchants.[2]The first cylinder seals belonged to the now long dead civilization of the Sumerians, the inhabitants of Nippur, Lagash, and other cities on the Euphrates and Tigris rivers in what is now Iraq. They spoke a strange language \u2013 neither Semitic nor Indo-European, the family of languages spoken by many later civilizations and the most current inhabitants of the Middle East. Sumerian was an agglunative tongue, bearing resemblance to such diverse agglutinative languages as Turkish, Finnish, Japanese, and Dravidian. Indeed, it was probably some version of the latter tongue that was spoken by their neighbors, the early inhabitants of the Indus river valley. These Indus valley people developed, soon after the Sumerians, their own civilization and unique style of seals. Modern speakers of Dravidian languages are scattered all over the Indian subcontinent, including remnants in Afghanistan and a large number of Tamils in southern India. Seal impressions have been found in the ancient city of Harrapan, in the Indus River valley (modern Pakistan), that had been made by seals found in Lagash in Sumeria (modern Iraq). From 3,600 B.C. in Sumer, and a little later in the Indus Valley, we can find seals made out of a rare high-quality stone, lapis lazuli. These stones could only have originated from rather distant and inaccessible mines in Afghanistan.For the Sumerians a business protocol was also a religious ritual, and the reverse was usually true as well. In the Middle East seal breaking became one of the most important of these rituals, with terrifying spiritual consequences if the seal were broken by the wrong person or at the wrong time. Three thousand years later these poetic images had reached apocalyptic proportions in the writings of the early Christian mystic John. The grave religious powers that could be unleashed by breaking a seal are well illustrated by his book of Revelations, in which the breaking of the first four seals of a holy book release the Four Horsemen of the Apocalypse:6:1 And I saw in the right hand of him that sat on the throne a book written within and on the backside, sealed with seven seals.6:2 And I saw a strong angel proclaiming with a loud voice, Who is worthy to open the book, and to loose the seals thereof? \u2026A worthy deity is found, who starts breaking the seals and thereby loosing the Horsemen \u20136:5 When he opened the third seal, I heard the third living creature saying, \u201cCome and see!\u201d And behold, a black horse, and he who sat on it had a balance in his hand.6:6 I heard a voice in the midst of the four living creatures saying, \u201cA choenix of wheat for a denarius, and three choenix of barley for a denarius! Don\u2018t damage the oil and the wine!\u201d[3]The Sumerians used thin wires and flat ingots of gold and silver, carefully weighed in balance scales, rather than coins like the Roman denarius. Except for paying the price in coins rather than coils, the commerce of the Third Horseman would have sounded quite familiar to our Sumerian merchant.Wire ring and coil money, Sumeria, c. 2,500 B.C.The first documents ever written, in the 4th millennium B.C., were also about wheat and barley, and also sealed. Far earlier still, at least as far back as 8,000 B.C., archeologists have found even more alient artifacts \u2013 vast numbers of little clay tokens. In the first half of the 20th century archaeologists, looking for important artifacts of civilization like statues of gods and Moses-style law tablets, dismissed these tokens as some kind of trivia, probably game tokens or cheap unstrung beads. Now we know that these tokens led directly to what are now the very basics of our civilization \u2013 reading, writing, and arithmetic.Recall our merchant, entrusting goods to sailors. Not all goods could be sealed in a jar or small room \u2013 a flock of sheep entrusted to shepherds, for instance. And in some cases it was expected that goods would be have to be opened en route \u2013 for example, to be audited by a customs inspector. For this reason, a separate record of the goods was needed. Without writing, how was such a record created?Pebbles, shells, and other counters have long been used to count things. Without even knowing how to verbally count in order \u2013 some cultures do not have words for numbers above three \u2013 one can \u201ccount\u201d objects by placing a pebble, on a pile or in a bag, one for each object. One nomadic tribe in Africa[4] counts cattle passing through a gate by drilling furrows. As each cattle paces, a pebble is placed in the rightmost furrow. When there are nine pebbles in this furrow, and the tenth cow goes through the gate, the pebbles are removed from the first furrow and a single is placed in the next furrow to the left. This is a \u201ccarry\u201d operation, used in abacuses around the world and even used in modern computers. These nomads have, along with many other cultures, invented a kind of abacus, with a ones place, a tens place. A zero is simply an empty furrow. Many other cultures (though not this one) have taken this to the next step and used this abacus, in the form of pebbles on a board or beads strung on rods, to add, subtract, multiply, and perform other computations. Indeed, until the advent of our modern Arabic numbers, everywhere calculations were done by the abacus or fingers, not on paper.Clay envelope and tokens, Sumer, c. 3,400 B.C.In the ancient Middle East, these pebbles took the form of dried clay tokens. The clay was formed into pebbles of various shapes and sizes. Some represented sheep, some standard sized pots of barley, and so on. The number of kinds grew as commerce grew. Some represented one, five, or a dozen of the kind.Soon after 4,000 B.C., the clay tokens were combined with the idea of sealing to create bills of lading and warehouse receipts. To create a bill of lading for a consignment of sheep, the owner put in a one-sheep token for every sheep. Every time he counted five sheep, a five-sheep token could be substituted for a one-sheep token. Once the owner and the consignee agreed on the count, the tokens were placed in a wet clay envelope. The owner and the consignee rolled their seals over the envelope, then let it dry. The procedure for a warehouse receipt was similar. An owner of wheat or barley could consign his fresh harvest to the protection of a warrior-priest in his walled fortress. The receipt was tokens sealed in an envelope \u2013 when the owner got hungry, or wanted to sell to the hungry, or wanted the seed to plant next spring \u2013 he would take the envelope to the warehouse. The claimant and the warehouse operator would inspect the seal, break it, inspect the tokens, and then deliver the goods.It would be nice if one could learn the contents of the envelope \u2013 the number and kind of tokens \u2013 without having take the ominous and irreversible step of breaking the seal. Around 3,400 B.C. in Sumer, marks started appearing on the outside of these envelopes. These marks were simply made by the tokens themselves. The different shapes and sizes of the tokens created correspondingly unique impressions, and thus the same symbols.[4][5]. Such external marks weren\u2018t as secure \u2013 they could be erased, albeit not without detection by a well trained eye.As warehouse receipts and bills of lading became common, commerce diversified. So many different kinds and numbers of goods were involved that the shapes and sizes of clay tokens were growing out of control. What computer scientists call a \u201clevel of indirection\u201d was needed. With different tokens for one sheep, five sheep, one pot of barley, five pots of barley, and so forth, we get m*n different tokens, where m are the numerical denominations of the tokens and n are the number of different kinds of commodities. By creating separate tokens for the numbers and the goods, the number of different kinds of tokens were reduced to m + n, at the cost of up to twice as many tokens per envelope.This development wasn\u2018t entirely new. Abstract counting tokens, reused for sheep and people and pots of barley, are probably far more ancient. Nor were separate words for \u201csheep\u201d, and \u201cbarley\u201d new. What was new were the separate tokens for \u201csheep\u201d, \u201cbarley\u201d, to be used, like the counting tokens, in the bills of lading and warehouse receipts. The were still thought of as corresponding to the objects they represented, not the words \u201csheep\u201d and \u201cbarley\u201d, but it was a big step towards written language. Naturally these symbols also became external marks[4][5].The first written tablets, dating around 3,300 B.C. and again in Sumer, were simply these external marks, inscribed on clay tablets. To maintain the security properties of tokens in clay envelopes, some the tablets were themselves are sealed in clay envelopes.The evolution of writing proceeded from there. A hundred years later reed styluses were being used to badly mimic the clay token marks. Over succeeding centuries, scribes supplemented or replaced token-derived symbols with pictographs for the objects. The pictographs attempted to bring to mind the object visually. Both kinds of symbols became stylized as wedges, or \u201ccuneiform\u201d, optimized for the reed stylus. Still later, words represented by neither pictographs nor token-derived symbols come to be represented by a rebus. An example of a rebus in English is representing the word \u201cI\u201d with a pictographic symbol for \u201ceye\u201d. This gave rise to a semi-phonetic alphabet. From this evolved the Phoenician or true phonetic alphabet, which was in turned borrowed by the Greeks and Romans. We use the Roman alphabet.Evolving beyond clay tokens, accounting was the first use of the external marks and started to take a familiar form. Along with the tamper evident clay, the Sumerians developed a kind of virtual tamper evidence. It took the form of two sets of numbers. On the front of the tablet, each group of commodities would be recorded separately \u2013 For example on the front woudl be recorded 120 pots of wheat, 90 pots of barley, and 55 goats. On the reverse would simply be recorded \u201c265\u201d \u2013 the same objects counted gain, probably in a different order, and without bothering to categorize them. The scribe, or an auditor, would then verify that the sum was correct. If not, an error or fraud had occured. Note the similarity to tamper evident seals \u2013 if a seal is broken, this meant that error or fraud had occured. The breaker of the seals, or the scribe who recorded the wrong numbers, or the debtor who paid the wrong amounts of commodities would be called on the carpet to answer for his or her discrepancy.Checksums still form the basis of modern accounting. Indeed, the principle of double entry bookeeping is based on two sets of independently derived numbers that must add up to the same number. Below, we will see that modern computers, using cryptographic methods, can now compute unspoofable checksums.Breaking a seal still, but fortunately only quite rarely, can have implications that are apocalyptic \u2013 at least for the individuals involved. Tylenol in 1982 and 1986, Excedrin and Lipton Cup-A-Soup in 1986, Sudafed in 1991, and Goody's Headache Powder in 1992 all were tampered with by sickos who added cyanide to the product and killed people. This spurred a new emphasis on tamper evident plastic packaging which can now be found protecting a wide variety of the products we use.Everybody is familiar with shrink-wrapped plastic, a less secure but commonly used technology \u2013 as common as the ubiquitous price tag. Another favorite tamper-evident device is the seal used to protect pill bottles.Evidence bag. Courtesy Custom Specialties Inc. [no relationship to author].Bank employees, our modern descendants of ancient temple accountant-priests, still sometimes work in edifices designed to look like Roman temples. They carry cash, checks, and other valuables in tamper-evident clear plastic envelopes. Evidence of tampering comes either as a tear in the plastic, or from opening the bag normally. In the latter case, a seal (the same place you'd find the zip seal on a Zip-Loc bag) chemically alters, and words such as \u201cVOID\u201d or \u201cOPENED\u201d appear in large letters. When these bags carry unique serial numbers, inspectors at both ends can record the serial number while examining the bag for tampering. The unique serial number prevents the tamperer from simply transferring the contents from one such bag to another. Modern plastic bags with the altering chemical seal, used in conjunction with the tracking of unique serial numbers, provide a very strong kind of tamper evidence, and are used by high security institutions ranging from banks to the military to cryptographic certificate authorities. The evidence bags used by many police departments work the same way.Tamper evident tape on a cabinet door. Note the sequential number, which when recorded and checked detects the replacement of the original tape with a new one. (The security of the serial number assumes that this label is not easy to duplicate using a laser printer). On the right, the broken seal has left a difficult to remove mark including the word \u201ctamper\u201d. Courtesy tamper.com [no relationship to author].Many other kinds of security, from ancient to modern, can be thought of as providing a kind of tamper evidence. Laser-break and glass-break sensors can make an entire building trespass evident. Similarly, guard dogs bark to protect their territories, alterting their masters to visitors.One of the most high-tech kinds of security, cryptography, is no longer just secret writing, but has spawned a whole new family of mathematical functions to protect the integrity of digital data. These functions are quite analogous to the function of ancient seals.One cryptographic function, the hash function, acts like the Sumerian checksum described above. The difference is that the \u201cnumbers\u201d it adds up are the binary digits that make up text, images, or other data. A second difference is that, by using a one way function and very large numbers, it can make the checksum practically unspoofable. The way accountants normally use checksums, the fraudster can sometimes with some ingenuity guess what the input numbers are. With cryptographic hash functions, this is practically impossible for a human, and for a computer it would almost always take millions of years of brute-force guessing to reverse-engineer the checksum.Another cryptographic protocol, the \u201cdigital signature\u201d, resembles one of these ancient seals much more than it does a modern autograph. The protocol operates in two steps. In the first step, a piece of data is sealed using a hash function as describe above. This is analogous to surrounding a basket lid with clay. Then a reverse public key cryptography operation (mathematically equivalent to decrypting a message) is performed. This second step is analogous to rolling the cylinder on the seal to identify the sealer.The digital signature can be made only by the possessor of a private key just as a seal could be made only by the possessor of the unique seal carving. If the digital signature is bad, this provides evidence that the data was tampered with or the signature forged.Rhee, 1981 \u21a9Colon, Dominique, Near Eeastern Seals \u21a9Book of Revelations, Ch. 6 \u21a9Ifrah, Georges, The Universal History of Numbers, John Wiley & Sons 1998, pg. 73 \u21a9 \u21a9 \u21a9Rhee, 1981 \u21a9 \u21a9Schmandt-Bessarat, Denise, Accounting with Tokens in the Ancient Near EastMy thanks to Andrew Odlyzko and K. Eric Drexler for their insightful comments.Originally published on Nick Szabo\u2019s Papers and Concise Tutorials.Please send your comments to nszabo (at) law (dot) gwu (dot) edu"}
{"prompt": "Digital Cash & Privacy", "completion": "I agree with Anonymous that there are problems with the actual use of digital cash in the near term. But it depends to some extent on what problem you are trying to solve.One concern I have is that the move to electronic payments will decrease personal privacy by making it easier to log and record transactions. Dossiers could be built up which would track the spending patterns of each of us.Already, when I order something over the phone or electronically using my Visa card, a record is kept of exactly how much I spent and where I spent it. As time goes on, more transactions may be done in this way, and the net result could be a great loss of privacy.Paying in cash is still possible through the mail, but it is insecure and inconvenient. I think that the convenience of credit and debit cards will overcome most people\u2019s privacy concerns and that we will find ourselves in a situation where great volumes of information exist about people\u2019s private lives.This is a place that I could see digital cash playing a role. Imagine a Visa-like system in which I am not anonymous to the bank. In this model, imagine that the bank is granting me credit similar to a credit card. But instead of giving me just an account number which I read over the phone or send in an email message, it gives me the right to request digital cash on demand.I keep some digital cash around and spend it for transactions as I described in my previous posts. When I get low I send some email to the bank and get some more dcash. Every month I send a check to the bank to cover my account just as I do with my credit cards. My relations with the bank are very similar to my current relationships with the credit card companies: frequent withdrawals and a single payment each month by check.This has several advantages over the system which we are heading towards. No records are kept of where I spend my money. All the bank knows is how much I have withdrawn each month; I may or may not have spent it at that time. For some transactions (e.g. software) I could be anonymous to the vendor; for others the vendor might know my real address, but still no central location is able to track everything I buy.(There is also a security advantage over the ridiculous current system in which knowing a 16 digit number and an expiration date allows anyone to order anything in my name!)Furthermore, I don\u2019t see why this system could not be as legal as current credit cards. All that really differs in this system is the inability to track where users spend their money, and as far as I know this ability was never an important legal aspect of credit cards. Certainly nobody will admit today that the government has a vested interest in moving towards an environment in which every financial transaction is tracked.Granted, this does not provide full anonymity. It is still possible to see roughly how much each person spends (although nothing stops a person from withdrawing much more cash than he will spend in a given month, except perhaps for interest expenses; but maybe he can lend the extra digicash itself and gain interest on that to compensate). And it is oriented around the same customer/vendor model that Anonymous criticized. But I maintain that this model represents the majority of electronic transactions, today and in the near future.It\u2019s worth noting that it is not trivial to become a merchant who can accept credit cards. I went through this with a business I had a couple of years ago. We were selling software through mail order, and this makes the credit card companies very nervous. There is so much phone fraud in which credit card numbers are accumulated over a few months, then large amounts of charges made against them. By the time the user receives his monthly statement and complains, the vendor has disappeared. In order to get our credit card terminal we went to a company which \u201chelps\u201d startups with this. They seemed like a pretty shady outfit, themselves. We had to fudge our application to say that we\u2019d be selling something like 50% of the units at trade shows, which apparently counted as over-the-counter sales. And we had to pay about $3,000 up front, as a bribe, it seemed. Even then we probably couldn\u2019t have done it if we hadn\u2019t had an office in the business district.Under the digital cash system, this might be less of a problem. The main problem with digital cash is double-spending, and if you are willing to go with online verification (reasonable for any business which is going to take anything over several hours to deliver the merchandise) this can be completely prevented. So there is no longer any possibility of merchants collecting credit card numbers for later fraud. (You still have problems with non-delivery of merchandise, though, so not all risks are eliminated.) This might eventually make the system more widely available than current credit cards.I don\u2019t know whether this system could be used to support illegal actions, tax evasion, gambling, or whatever. That is not the purpose of this proposal. It does offer the prospect of improving personal privacy and security, in a framework that might even be legal, and that\u2019s not bad.Hal Finney\nhal@rain.orgHal Finney Home Page"}
{"prompt": "Bitcoin and Me", "completion": "Originally posted on BitcointalkI thought I'd write about the last four years, an eventful time for Bitcoin and me.For those who don't know me, I'm Hal Finney. I got my start in crypto working on an early version of PGP, working closely with Phil Zimmermann. When Phil decided to start PGP Corporation, I was one of the first hires. I would work on PGP until my retirement. At the same time, I got involved with the Cypherpunks. I ran the first cryptographically based anonymous remailer, among other activities.Fast forward to late 2008 and the announcement of Bitcoin. I've noticed that cryptographic graybeards (I was in my mid 50's) tend to get cynical. I was more idealistic; I have always loved crypto, the mystery and the paradox of it.When Satoshi announced Bitcoin on the cryptography mailing list, he got a skeptical reception at best. Cryptographers have seen too many grand schemes by clueless noobs. They tend to have a knee jerk reaction.I was more positive. I had long been interested in cryptographic payment schemes. Plus I was lucky enough to meet and extensively correspond with both Wei Dai and Nick Szabo, generally acknowledged to have created ideas that would be realized with Bitcoin. I had made an attempt to create my own proof of work based currency, called RPOW. So I found Bitcoin facinating.When Satoshi announced the first release of the software, I grabbed it right away. I think I was the first person besides Satoshi to run bitcoin. I mined block 70-something, and I was the recipient of the first bitcoin transaction, when Satoshi sent ten coins to me as a test. I carried on an email conversation with Satoshi over the next few days, mostly me reporting bugs and him fixing them.Today, Satoshi's true identity has become a mystery. But at the time, I thought I was dealing with a young man of Japanese ancestry who was very smart and sincere. I've had the good fortune to know many brilliant people over the course of my life, so I recognize the signs.After a few days, bitcoin was running pretty stably, so I left it running. Those were the days when difficulty was 1, and you could find blocks with a CPU, not even a GPU. I mined several blocks over the next days. But I turned it off because it made my computer run hot, and the fan noise bothered me. In retrospect, I wish I had kept it up longer, but on the other hand I was extraordinarily lucky to be there at the beginning. It's one of those glass half full half empty things.The next I heard of Bitcoin was late 2010, when I was surprised to find that it was not only still going, bitcoins actually had monetary value. I dusted off my old wallet, and was relieved to discover that my bitcoins were still there. As the price climbed up to real money, I transferred the coins into an offline wallet, where hopefully they'll be worth something to my heirs.Speaking of heirs, I got a surprise in 2009, when I was suddenly diagnosed with a fatal disease. I was in the best shape of my life at the start of that year, I'd lost a lot of weight and taken up distance running. I'd run several half marathons, and I was starting to train for a full marathon. I worked my way up to 20+ mile runs, and I thought I was all set. That's when everything went wrong.My body began to fail. I slurred my speech, lost strength in my hands, and my legs were slow to recover. In August, 2009, I was given the diagnosis of ALS, also called Lou Gehrig's disease, after the famous baseball player who got it.ALS is a disease that kills moter neurons, which carry signals from the brain to the muscles. It causes first weakness, then gradually increasing paralysis. It is usually fatal in 2 to 5 years. My symptoms were mild at first and I continued to work, but fatigue and voice problems forced me to retire in early 2011. Since then the disease has continued its inexorable progression.Today, I am essentially paralyzed. I am fed through a tube, and my breathing is assisted through another tube. I operate the computer using a commercial eyetracker system. It also has a speech synthesizer, so this is my voice now. I spend all day in my power wheelchair. I worked up an interface using an arduino so that I can adjust my wheelchair's position using my eyes.It has been an adjustment, but my life is not too bad. I can still read, listen to music, and watch TV and movies. I recently discovered that I can even write code. It's very slow, probably 50 times slower than I was before. But I still love programming and it gives me goals. Currently I'm working on something Mike Hearn suggested, using the security features of modern processors, designed to support \"Trusted Computing\", to harden Bitcoin wallets. It's almost ready to release. I just have to do the documentation.And of course the price gyrations of bitcoins are entertaining to me. I have skin in the game. But I came by my bitcoins through luck, with little credit to me. I lived through the crash of 2011. So I've seen it before. Easy come, easy go.That's my story. I'm pretty lucky overall. Even with the ALS, my life is very satisfying. But my life expectancy is limited. Those discussions about inheriting your bitcoins are of more than academic interest. My bitcoins are stored in our safe deposit box, and my son and daughter are tech savvy. I think they're safe enough. I'm comfortable with my legacy.\n[edited slightly]"}
{"prompt": "Intrapolynomial Cryptography", "completion": "Researchers have proposed a variety of \u201cclient puzzle\u201d or \u201cbusy-work\u201d proposals like hashcash, MicroMint, bit gold, and compute-cost postage to create independent currencies or make spamming costly. The mathematical implication of these proposals is that there is such a thing as intrapolynomial cryptography. Four motivations for intrapolynomial cryptography theory are (a) novel constructions such the aforementioned applications, (b) more accurate estimation of the computational cost of cracking a cipher, (c) it might be easier to prove lower bounds, rather than just conjecture them as is the case with superpolynomial (standard) cryptography, and (d) if there do not exist one-way functions, standard cryptography is intrapolynomial rather than superpolynomial.I propose the following formalization:In other words, there is no algorithm running faster than q(n,k)p(n) which can invert f for more than a negligibly small number of values.One can similarly define average-case, best-case, and worst-case k-degree benchmark functions, analogously to one-way functions. Open question (analogous to the open question in superpolynomial cryptography of whether one-way functions exist): can one prove (3) as lower and upper bounds for some function and k>=1 on some realizable machine model such as RAM-log?Strong and average case are most apropos to cryptography related applications. Unfortunately for these purposes we'd also need:Since this is at least very tedious, one hopes we can in practice get away with a short list which covers all plausibly implemented machine architectures. This might work where for example the total exposure from cracking a protocol is less than the R&D costs of designing and building a novel machine architecture to defeat it. Cryptanalyis would include discovering the machine architectures optimal for breaking an intrapolynomial cipher.There are at least two practical implications of the above analysis. One is that there is very little room for error in the analysis and implementation of compute-cost postage, hashcash, bit gold, MicroMint, and other such intrapolynomial cryptography schemes. Another is that, unless the opponent has a very low budget and is thus limited to standard personal computers, it does not make sense to analyze the security or cost of these schemes without reference to machine architecture. For example, spammers may be able to defeat compute-cost postage by using custom chips optimized for computing the particular puzzle function."}
{"prompt": "RPOW - Reusable Proofs of Work", "completion": "Archived website\nGitHubI'd like to invite members of this list to try out my new hashcash-based server, rpow.net.This system receives hashcash as a Proof of Work (POW) token, and in exchange creates RSA-signed tokens which I call Reusable Proof of Work (RPOW) tokens. RPOWs can then be transferred from person to person and exchanged for new RPOWs at each step. Each RPOW or POW token can only be used once but since it gives birth to a new one, it is as though the same token can be handed from person to person.Because RPOWs are only created from equal-value POWs or RPOWs, they are as rare and \"valuable\" as the hashcash that was used to create them. But they are reusable, unlike hashcash.The new concept in the server is the security model. The RPOW server is running on a high-security processor card, the IBM 4758 Secure Cryptographic Coprocessor, validated to FIPS-140 level 4. This card has the capability to deliver a signed attestation of the software configuration on the board, which any (sufficiently motivated) user can verify against the published source code of the system. This lets everyone see that the system has no back doors and will only create RPOW tokens when supplied with POW/RPOW tokens of equal value.This is what creates trust in RPOWs as actually embodying their claimed values, the knowledge that they were in fact created based on an equal value POW (hashcash) token.I have a lot more information about the system at rpow.net, along with downloadable source code. There is also a crude web interface which lets you exchange POWs for RPOWs without downloading the client.This system is in early beta right now so I'd appreciate any feedback if anyone has a chance to try it out. Please keep in mind that if there are problems I may need to reload the server code, which will invalidate any RPOW tokens which people have previously created. So don't go too crazy hoarding up RPOWs quite yet.Thanks very much -Hal Finney"}
{"prompt": "Negative Reputation", "completion": "An important and general problem seems to be that of tagging a negative behavior source for future recognition. The tag might be used for negative information shared publically (eg, credit ratings) or kept private (eg, kill files). The behavior source might be non-human (eg, recognizing virus patterns for the purposes of virus scanning). Where the behavior source is adaptable and self-interested, it has an incentive to spoof the tagging: a debtor to change names to avoid paying his debt, a virus to scramble its pattern to avoid scanning, and so on. If the tag carries a greater positive reputation (where zero is the reputation of a newcomer) this incentive is lost and the negative side of the reputation \u2014 the disreputation \u2014 must be borne.Can digital credentialling systems facilitate such negative reputation handling?Service-specific, aka local, nym reputation may not be able to accomplish such tracking of negative reputation. If a local nym accumulates more negative than positive credentials, it can simply be replaced by a newcomer local nym for this service, without harming the positive reputation capital of the other behavior source local nyms. Hostile sources can continuously spoof innocent newcomers. Counterparties lose the ability to determine a history of previous hostile behavhior \u2014 kill files, virus scanning, credit ratings, etc. fail.Chaumian credentials also give the credential holder control over the transfer of credentials between his local nyms, creating an incentive to show positive credentials and hide negative ones. To remedy this, counterparties can demand \"non-negative credentials\" (in a form such as, \"Alice in many transactions recorded by me in area X has never done bad things x,y,z\"), Non-negative credentials are limited to areas that can be well-tracked. One such may be credit ratings, as long as one is doing the bulk of one's credit transactions through is-a-person linked local nyms.Where Chaumian credentials are inapplicable, we might raise the cost of entry to be greater than that of a newcomer. This gives us two clearly defined reputation points to compare on an otherwise rather subjective scale: participation threshold and newcomer reputation. Both are subjective in the eye of the party choosing whether or not to participate in an activity with the nym.A participation threshold greater than newcomer reputation clashes with the desirable goal, that one be able to make a fresh start. For that matter, unless previous nyms and their positive reputations are linked to their new nyms, the pioneers cannot make a start, so that the institution itself cannot be started. Ditto for for institutional growth.Tags that bundle the results of a wide variety of transactions \u2014 global nyms, aka universal IDs, aka \"True Names\" \u2014 seem to provide the most incentive for parties to carry their negative credentials. Most people have accumulated enough positive reputation is some areas that it is well-nigh impossible for them to start over their entire lives as newcomers.A big problem arises with negative credentials when they are used, not merely to avoid engaging in a particular activity with a party, but for retribution against that party. Retribution may take some nonviolent online form, such as slander, denial of service attack, and so on, but the most worrisome form of retribution is a violent physical attack. Could we have digital tags that, while tracking negative behavior sources through the digital world, remain strictly unlinked to any kind of physical location data? Alas, we have several important systems, such as cellular phones, shipping addresses, etc. that provide such linkage.A big problem arises with negative credentials when they are used, not merely to avoid engaging in a particular activity with a party, but for retribution against that party. Retribution may take some nonviolent online form, such as slander, denial of service attack, and so on, but the most worrisome form of retribution is a violent physical attack. Could we have digital tags that, while tracking negative behavior sources through the digital world, remain strictly unlinked to any kind of physical location data? Alas, we have several important systems, such as cellular phones, shipping addresses, etc. that provide such linkage.The question may become one of deciding what of these three dimensions are most important, and how they can be traded off:Keep in mind too, that in practice these are evaluated primarily by a market evolving from its current state, rather than by abstract ethical philosophies.Robin Hanson has noted that in a world of global nyms, the use of a local nym may signal the hiding of negative credentials, so that the use of global nyms is in equilibrium. A further problem with local nyms is that our relationships are often not neatly compartmentalizable into standard service types, and even where they are we might like to expand them into new areas. I suggest that, at minimum, we will want to reveal progressively more local nyms to our counterparties as our relationships with them become closer and more co-exposed.While the global nym equilibrium may hold for many of our relationships, there may be plenty of areas where the privity benefits of localizing nyms outweigh the costs of being less or unable to differentiate newcomers from hostiles. (By \"privity\" I refer the entire general task of protecting relationships from hostile third parties; confidentiality and protection of property from theft are two examples of privity). For example, the preference-tracking service at www.firefly.com increases participation via the use of pseudonyms, and suffers little exposure from hostiles. On the other hand, credit transactions typically demand identifying information, because the contractual exposure typically outweighs benefits of privity.Global nym public keys, which have many drawbacks in terms of privity, may be the best way to track negative reputation, but they are no panacea. There is an important conundrum in an ID-based key system: the conflict between the ability to get a new key when the old one is or could be abused by another (key revocation), and the ability of another to be sure they are dealing with the same person again. This may also provide an opportunity for parties to selectively reveal positive credentials and hide negative ones. For example, a person with a bad credit rating could revoke the key under which that rating is distributed and create a new one, while selectively updating their positive credentials to the new key (eg, have their alma mater create a new diploma). Key revocation authorities might combine forces with credit rating agencies to avoid such erasure of negative history, but this gives them even more centralized control \u2014 not merely over IDs but over important elements of reputation associated with those IDs. This further violates the principles of separation of powers and segregation of duties, providing added opportunity for fraudulent issue or revocation of IDs along with fraudulent communication of reputation information.The current universal (non-cryptographic) key in the U.S., the SSN, is very difficult to revoke. Much easier to change your name. This policy is probably no accident, since the biggest economic win of global nym identification is the tracking of negative reputations, which revocation can defeat. As long as the SSN is a shared database key, not used for the purpose of securely identifying a faceless transaction, there is little need for revocation beyond the undesired erasure of negative history. Combining a secret authentication key, which must be revocable, with a public universal ID is quite problematic.Please send your comments to nszabo (at) law (dot) gwu (dot) eduCopyright \u00a9 1996 by Nick Szabo\nPermission to redistribute without alteration hereby granted"}
{"prompt": "PGP Web of Trust Misconceptions", "completion": "One of the key concepts widely used to describe PGP is the \"web of trust\". This brings to mind a network of connections between people who know and communicate with each other. Two people who want to communicate can do so securely if there is a path of connections in the form of signed keys that joins them.But this is not quite right. The fundamental fact about PGP key signatures, which is often misunderstood, is this:You can only communicate securely with someone whose key is signed by a person you know, either personally or by reputation.In other words, if I want to communicate with joe@abc.com, I can only do so if one of the signators of his key is a person I know. If not, I have no way of judging the validity of his key.This belies simple interpretations of the \"web of trust\". I may have signed A's key, A has signed B's, B has signed C's, C has signed D's, and D has signed Joe's, but this is of no value unless I know D. Only then can I trust Joe's key.This means that, in the \"web\" picture, I can only communicate securely with people who are at most two hops away in the web of connections. I can communicate with the people I know, and I can communicate with the people they know, and that is it.This is unfortunate, because the simple web model ties into some famous research which suggests that any two people chosen at random are only about half a dozen steps apart in the web of who-knows-whom connections. (This result is where the title of the movie \"Six Degrees of Separation\" comes from.) If you had a system which actually supported communications via such a web model, it actually would have hope of letting two people communicate who did not have a very long chain between them. But PGP, with a maximum chain length of two, will not allow this.What would have to be added in order to allow a true web of trust model to be used in a program like PGP? Basically what is needed is some way to judge the trustworthyness of signatures by people you don't know. This would most plausibly be provided by the people who had signed their keys. For example, if there were another type of key signature which did not only vouch for the person's identity, but also for his trustworthyness and care in signing keys, then a chain of such signatures could serve as the basis for a true web of trust. Obviously such signatures could not be given out nearly as easily as the kind we have now, where a glance at some stranger's drivers' licence is often all we get, but they could be given to close friends and those we know and trust.More elaborate systems might include numerical ratings of trustworthiness which would help to estimate the strength of any given path. The main point is that some information of this kind would be needed in order to allow communication with people distant in the web of connections.Without this, I think we will continue to have problems with PGP being unable to validate keys of people we want to communicate with. People will collect huge laundry lists of signatures in the hopes that whoever wants to communicate with them will know one of those people. Centralized key validators will appear (as in the case of the SLED service being started now, which will sign a key based on a signed check with your name on it). The result may be a choice between using an unsigned key or using one signed by some faceless bureaucracy, which is no better than the original PEM conception.(People may be confused by this essay because they thought PGP worked this way already. PGP does have a follow-the-web model, but that is only for following signatures. In the example above, where I wanted to talk to Joe and there was a chain to him through A, B, C, and D, we have to first suppose that I know and trust all of A, B, C, and D. Given that, what PGP can do is to determine whether I have valid keys for all of those people. It will notice that A has signed B's key, so it is valid. I know B and told PGP he was trustworthy, and he signed C's key, so therefore that one is valid. Similarly, I know C and I know D so PGP can follow the chain through them. Finally we come to Joe, whom I don't know, but because I know D and PGP followed the web to determine that D's key is valid, PGP can determine that Joe's key is valid. But again, that was only because I knew D and everyone else in the chain. The bottom line is still that I can only communicate with people who know someone I know.)Hal Finney\nhal@rain.orgHal Finney Home Page"}
{"prompt": "Scarce Objects", "completion": "A more intuitive and secure approach to programming with objects distributed across trust boundaries is presented. The approach involves scarce objects and software to support markets in trading scarce objects \"rights.\"Scarce objects are computational objects that like physical objects are finite and excludable, and force the client to either conserve or consume (use up) their own rights to use the object. References to scarce objects are bearer certificates with two key properties: (1) they are use-once or use-N-times tokens, and (2) like digital cash they are transferred using online clearing using \"spent lists\" to conserve the number of these scarce object references.Scarce objects, a.k.a. conserved objects, provide a user and programmer friendly metaphor for distributed objects interacting across trust boundaries. (To simplify the language, I will use the present tense to describe architectures and hypothetical software). Scarce objects also give us the ability to translate user preferences into sophisticated contracts, via the market translator described below. These innovations will enable us for the first time to break through the mental transaction cost barrier to micropayments and a micromarket economy.A scarce object is a software object (or one of its methods) which uses a finite and excludable resource \u2013 be it disk space, network bandwidth, a costly information source such as a trade secret or a minimally delayed stock quotes, or a wide variety of other scarce resources used by online applications. Scarce objects constrain remote callers to invoke methods in ways that use only certain amounts of the resources and do not divulge the trade secrets. Furthermore, scarce object wrappers form the basis for an online economy of scarce objects that makes efficient use of the underlying scarce resources.Scarce objects are also a new security model. No security model to date has been widely used for distributing objects across trust boundaries. This is due to their obscure consequences, their origins in single-TCB computing, or both. The security of scarce objects is much more readily understood, since it is based on duplicating in computational objects the essential intuitive features of physical possessions. Our brains reason in much more sophisticated ways about physical objects than about computational objects. Scarce objects are thus readily understood by programmers and end users alike. Scarce objects lower mental transaction costs, which are the main barrier to sophisticated small-scale commerce on the Net. Finally, scarce objects will solve for the first time denial of service attacks, at all layers above the primitive scarce object implementation.The intuitive physical metaphor of scarce objects gives scarce objects the following basic properties:Closely related to these is a social property of objects critical to the success of economies:Property rights and contracts are highly evolved methodologies for dealing with economic objects and each other across trust boundaries. Scarce object architecture can reuse this working paradigm, because it reuses the mental model of the physical world in which this security paradigm was invented.With scarce objects, any computation across trust boundaries will have these properties of atomicity, conservation, composition, and the accompanying clear delineation of rights and responsibilities. This model is rather restrictive compared to what we are used to within trust boundaries. However, it will much more readily keep programmers from writing obscurely insecure code, which is easy to do with either ACLs, capabilities, or cryptography. Furthermore, conservation (scarcity) and lack of externalities are the two major assumptions of microeconomics, the study of commercial transactions across trust boundaries. So the scarce objects security model allows us to inherit a rich literature of formal reasoning about such systems.Scarce objects are, in other words, online commodities. These commodities may represent, typically, rights (or expectations) to services \u2013 the right to use an e-mail or news service (or a component of that bundle of rights, e.g. the right to use that service\u2019s e-mail server), the right to upload or cache content, the \"right\" (here more like an expectation) to have e-mail read (digital postage to prevent spam), etc. Such service rights will usually be limited against the client by time or resource usage or number of invocations. When represented properly, by scarce objects, these services are conserved. Such \"rights\" or codified expectations are enforced against the server by reputation, by the \"physics\" of scarce objects, or both, in substitute for or in addition to expensive traditional legal means.Scarce objects may also represent unique or finite relationships between people and bits \u2013 names that correspond to addresses, ownership of trademarks, authorship of content, ownership of certain rights to content (which probably does not, for security reasons, include the right to exclude others from copying the bits), etc.Scarce objects are not a complete model of computation across trust boundaries. Indeed, there are many smart contracts that can be implemented with cryptographic protocols and/or secure hardware but not with scarce objects. What scarce objects provide is a straightforward basis for implementing, in an intuitively secure way, the anonymous commodity exchange economies formalized in microeconomics in a P2P fashion on the Internet.Another area important to scarce objects is in reasoning about supply chains. In distributed objects, the call graph is the supply chain. To stretch call graphs across trust boundaries, we must replace rigid client-server relationships with dynamically adaptable customer-supplier relationships. The ideal here is to create a rich toolset of exception handling across trust boundaries. Note that credit risks are a proper subset of supply chain risks. Ka-Ping Yee recently put the supply chain problem succinctly: \"be wary of return values from objects you don't trust.\"The scarce object architecture suggested here shares some things in common with capabilities, but it secures more kinds of resources and is far more affordable for users and programmers. Capabilities (along with ACLs) are a means of implementing access control. Access control simply deals with the first-level of issue of whether an entity has access or not to a given resource. If an entity has such access, this access is, as modelled or implemented by basic capabilities or ACLs, effectively unlimited in scope. Scarce objects, on the other hand, limit resource usage in three ways \u2013 first, by limiting the amount of resources used per invocation, second, by limiting the number of resources used per right (per ticket), and third, by limiting the number of tickets issued.A raw distributed capability system (i.e. what Mark Miller refers to as \"caps-as-data\", to distinguish from capabilities local to the TCB (\"object caps\") which have strictly stronger security properties) give out capabilities of infinite duration and unlimited invocations, cannot be considered to be a true principle of least authority (POLA) system. For an object reference to implement POLA, it must be finite in every dimension. A true POLA system never gives out more authority than is necessary and proper to compute the needed function. It is never either necessary or proper to allocate infinite resources, and usually it is not necessary to allocate large resources. The scarce object architecture is the first design for object systems to achieve finite authority, and to allow small allocations for objects that need only small amounts of resources. Scarce objects are thus the first architecture to make true POLA possible.Scarce object architecture depends on a distributed object architecture that makes minimal security assumptions. A good implementation strategy may be therefore to implement this model on top of E. No sophisticated use of its distributecd capability architecture need be made to securely distribute scarce objects; rather the resource-conserving features of scarce objects can be relied on for securing resources.A bearer right to invoke a scarce object method takes the form of a bearer certificate, or ticket. It can be generic, meaning a right to an N invocations of one of a set of similar or identical objects, or specific, meaning a right to invoke a particular object method in a unique way. Generic rights are fungible and can be transferred unlinkably, using Chaumian blinding.The general steps to build a scarce object are (1) define a normal object, then (2) wrap it in a layer that protects its public methods using tickets. Our sketch of the architecture here describes how this wrapping layer can work.The wrapping layer involves three different servers: a transfer agent (TA), a Provider, and an Issuer. The Issuer and TA operate like an accountless digital cash mint. The Issuer signs tickets. The TA clears the transfer of tickets for generic rights. Both the Issuer and TA have copies of the private keys (\"plates\") corresponding to each issue of generic right. A particular kind of generic right (e.g., a particular denomination of digital coin) can have multiple issues, usually ordered sequentially. Digital cash is a special case: money is the most generic of rights. Here is another example of a generic right, or class of fungible objects: \"A queriable SQL database with up to 10 MB of storage, and certain standard response time guaruntees\".It is a design option whether to combine the Issuer and TA into a single server (thereby reduce exposure of the private key) or keep them separate (thereby enable certain personell controls based on separation of duties). Distributed servers, described below, are an even better way to increase the trustworthiness of Issuers and TAs.The Provider is responsible for actually holding the object, which can contain unique state. It publishes a signed description of its scarce object method, describing a particular kind of generic right (e.g. in the form of design-by-contract pre- and post-conditions). The issuer and transfer agent then create plate(s) and prepare to issue tickets for the method.Any or all of these component servers can be distributed, using the methods described here and here. A distributed signature is used to issue tickets (M out of N must sign using a distributed private key for a verifiable signature to be produced). Such distribution greatly reduces exposure to breach of trust and thus lowers the mental transaction costs of reputation tracking.To implement exclusive transfers, the TA keeps a list of cancelled ticket numbers. A ticket is cancelled whenever it is transferred or used. The Provider instructs the TA when a ticket has been used, or alternatively they both write to a shared list of cleared tickets.The TA and Issuer see only classes of fungible objects. The Provider and users see particular instances with unique state. In the above example of a database generic right, the Provider sees a database filled with unique information while the TA and Issuer see only the generic description of the database object invocation methods.In contrast to the servers, the remote user of a scarce object wraps his object invocation stub with calls that trade for needed tickets (again using a market translator), send the tickets as needed with method invocations to those methods\u2019 Provider(s). In some (hopefully many) cases sufficiently identical generic services will be provided by competitors. Where this occurs a \"ticket client\" may also \"shop around\" in the sense that if the pre- or post-conditions of the method invocation fail, or if the invocation is otherwise detected as faulty, the ticket client will retry by invoking the competitor's method.The Provider server is almost just another ticket client to the TA, which like other clients can transfer or receive tickets. It special role is in informing the TA when tickets have been used thus should be cancelled (or, altrneatively, writing the cancelled ticket number directly to a list of cancelled ticket numbers that it shares with the TA). Only the Issuer can create tickets, and only the Provider can consume them.At the core of the Provider is the raw object itself, the set of methods that provide the defined services for scarce object clients. The Provider is the wrapper around this object. Besides its gatekeeping, ticket verification, and ticket consumption functions, the Provider can keep track of and inform the Issuer regarding resource usage.The Issuer in turn is the interface to the micromarket functions, especially the market translator described below. The Issuer may, for example, via a market translator, which incorporates the preferences of the person who operates the Provider, negotiate barter deals in which certain tickets are issued and exchanged for certain other tickets giving rights to invoke the counterparty's or a third party's scarce object methods. The negotiations might also be multi-party, i.e. auctions, and secondary exchanges for generic rights may also be developed for scarce object tickets. In turn, the market translator, to enable automated (low mental transaction cost) bartering operations, depends on the existence of reasonably liquid online exchanges of generic scarce object rights.The TA generates ticket supply only at the behest of the Issuer, and destroys it only at the behest of the Provider. All its own transfers conserve the supply of a particular generic right. The Provider is also responsible for the delivery of service to the client that satisfies the service description (contract, e.g. pre and post conditions), at which time the Provider \"deposits\" the generic ticket(s), i.e. adds them to the cancelled list.The Provider issues along with the initial generic rights ticket a signed affadavit, machine or human readable, describing aspects of the object which may be non-exlusive and unique, along with that instance's ticket number and the public key(s) of the generic right(s) for which it is valid. For example, it might say \"a database containing quotes of these two dozen listed stocks as of 12:22 pm Monday\", without actually containing those quotes. Often such description is worth more when bundled with generic exclusive rights, such as the right to a fast response time. The specific rights can elaborate in unique ways upon the generic rights, as long as these elaborations are not taken to define exclusive rights. The generic rights let the TAs garuntee exclusivity to users and conservation of resources to Providers, while the specific rights describe the unique state to any desired degree of elaboration. The Provider must be prepared to service any specific promise it has issued, as long as it is accompanied by the proper conserved generic tickets.This method of composing specific and generic rights, transferred as a bundle but with exlusive generic atoms cleared by different TAs, allows arbitrarily sophisticated rights bundles, referring to objects with arbitrarily unique state, to be transferred unlinkably. A wide variety of derivatives and combinations are possible. The only restriction is that obtaining rights to specific exclusive resources must either be deferred to the consumption phase, or transferred with online clearing via expensive communications mix.If the Provider wished to garuntee exclusivity to a specific right, transfer seems to require an expensive communications mix between Provider and transferee, rather than a cheap blinded ticket. For example, \"Deep Space Station 60 from 0500-0900 Sunday\" or \"a lock on autoexec.bat now\" demands exclusivity to a specific right, and thus seems to require a communications mix to unlinkably transfer. On the other hand, \"A one hour block on DSS-60 in May\" and \"the right to lock autoexec.bat at some point\" are generic and can be transferred privately with the much less expensive blinding, given a sufficient population of other ticket for this class of generic right transfered between the issuance and consumption of a given ticket.Clients can deal with the TA without a communications mix. They deal with the Provider via a communications mix. If both the initial and final holders failed to do this, the Provider could link them. If just the final holder failed to do so, the Provider could identify him as the actual user of the resource. Thus for full privacy generic transfers are cheap, and nonexclusive transfers are cheap, while specific exsclusive transfers and actually using the object seem to require the expensive communications mix.Here's a review of our architecture:Scarce objects, by creating a simpler and far more intuitive model of computation across trust boundaries, can make the distribution of objects on the global Internet a reality, just as the simplification of hypertext into HTML made the Web a reality.Click for larger versionThe mental transaction cost problem is one that underlies all markets \u2013 the mental effort it takes to shop \u2013 to map private preferences to prices to decide whether a bundle of rights is worth the cost. In particular this problem presents a severe barrier to micropayments and market-based resource allocation for networks and computers.The market translator is aimed squarely at solving, for the first time, this problem for Internet commerce. A market translator both enables and depends on online micromarkets to automate resource allocation among scarce objects. It will do so by enabling the following:The problem of \"translating\" between bearer contracts (which represent and secure rights to scarce objects) can be cast as a problem of translating between monetary currencies. For our purposes, a \"currency\" in a scarce object economy is simply any kind of bearer contract used for holding and transferring wealth, rather than for consumption by the holder. It is thus a \"collectible\" (or \"intermediate commodity\", to use Carl Menger\u2019s term). The market translator, incidentally, makes the O(n^2) prices in a barter economy, versus O(n) in a monetary economy, a far less important distinction.So let\u2019s look at currencies. Let's say small businessman Alice is negotiating cyberspace contracts with Bob, Charlie, etc. Typical of international contracts, terms can be denominated in a variety of ways. These are potentially unreliable: Joe-Bob's remailer postage, U.S. Federal Reserve Notes in their 1970s mode (or in 2003), Seychelles gold cache warehouse receipts, \"Asian Tiger\" currencies in 1997, and so on.Unreliable currencies can play havoc with:Each problem interferes with potential solutions to the other. On the one hand, picking one single best currency for all contracts concentrates risk. In some cases there is nothing close to a reliable currency, and in any case diversification is preferable. Without hedging Alice remains exposed to risks that more sophisticated traders can easily hedge.Another way of looking at it: there are no issuers in the world who are 100% trustworthy and 100% reliable. Lacking a security protocol to ensure that a currency retains its value, Alice needs risk management.On the other hand Alice, to plan her (personal and/or small business) budget and properly express her preferences, needs a simple, consistent long-term unit of account. Budgeting with a single fluctuating currency is bad enough, but if Alice denominates different expenditures and revenues in different currencies, her budget becomes an inconsistent mess. It's also unreasonable to ask a non-financial professional to worry about the finer points of exchange rates, hedging, etc.What is Alice to do? Old answer: Alice either hires, at a cost of both money and privacy, an accountant or financial planner, and may gain a few crude improvements. Mostly, she's out of luck: small businessmen have left most international trade to big corporations, whose finance officers partake in sophisticated hedging strategies.Proposed new answer: use a market translator to help Alice draft her contracts. This market translator should be useful for both normal law-enforced contracts and untraceable self-enforcing contracts, where the latter are feasible. In the following post I will sketch how a market translator can work.Automatic currency conversion, as done today by some credit cards and ATM machines, is a useful primitive kind of market translation. The casual reader (and user) can think of the market translator (MT) as a fancy kind of automated currency convertor, and get the basic gist of it. The MT serves to convert, hedge, and in general restructure the payment terms contracts negotiated in any manner.Our main novelty is to account for personal budgets, not in terms of any external standard of value, but rather in terms of personal accounting units (PAUs). PAUs correspond to what Alice can express of her personal utility. The MT determines Alice's static and and temporal preferences from the budget Alice already maintains (for example, her small business budget in Quicken). Additional preference specification forms may be provided beyond those of a normal budgeting program. For example, Alice\u2019s software preference settings, her behavior with keyboard and mouse, and similar clues might be usefully interpreted as economic preferences, for example with regard to where to allocate scarce screen real estate and network bandwidth.For convenience Alice's PAU might correspond to the local currency most commonly used by Alice. If most of Alice's budget items deal with online contracts negotiated via MT, then using the local currency is by no means necessary, and is undesirable if that currency is unstable.Here is a diagram showing Alice and Bob negotiating a contract using their market translators:One mode in which the MT can be used is to have Bob offer a take-it-or-leave-it binary contract, corresponding to the current retail practice of take-it-or-leave-it prices. In the mode pictured above, Alice and Bob negotiate back and forth. The negotation of the source contract terms will usually be manual. The \"source language\" will typically be a human readable GUI, while the \"target\" will be a standard formal contract language. If Alice and Bob can input preferences leading to automated negotiations, then a \"shopping bot\" and \"catalog bot\" respectively may be used. This is a layer above and beyond the scope of the MT. The MT is only a \"shopping bot\" in the restricted but important area of contracts composed of atomic bearer contracts \u2013 rights to scarce objects \u2013 to the extent that the price relationships between these bearer contracts are available from quoted markets.The MT acts like a computer language compiler. But it translates both ways, and in real time as Alice and Bob negotiate payment terms. So, for example, Alice changes a term in her contract, proposing to pay fewer Alice-PAUs for Bob's services. Her MT translates this into a series of payments and hedges: a sophisticated synthetic contract as obscure to Alice and Bob as binary code is to many programmers these days. This synthetic is constructed out of liquid market securities (bearer contracts) and derivatives of low transaction cost. A synthetic contract is naturally represented as a composite object, a part-whole hierarchy composing primitive contractual \"atoms\", such as securities and derivatives.Bob's MT reverse-translates the actual market terms into Bob-PAUs. Although they each agree to different looking amounts of payment, the visible structure besides amounts and the complete underlying contract is the same. They can be confident that when their preferences have been satisfied, their minds have met and they can commit to the contract.As a result, both Alice and Bob see the contract in terms of their own consistent personal utility units. All consideration of exchange rates, inflation risks, and so on is handled by the MT.Alice and Bob's MTs can make side conversions, hedges, and restructurings to balance their portfolios. These side hedges are not revealed to each other. Any binary terms which can be side hedged can be made almost arbitrarily distant from what Alice and Bob prefer financially. Thus Alice and Bob need not reveal their financial preferences to each other.(Note: For contracts with delayed payment terms, Alice and Bob determining the credit risk caused by each others' credit exposures is an important problem, but beyond the scope of the MT as I have described it).The whole set of Alice's contracts with all her counterparties constitutes her complete portfolio \u2013 not merely a segregated investment portfolio, but a complete portfolio encompassing all her finances. This portfolio is is represented as a composite of composite contracts, and forms the basis for all of Alice's financial planning, and for the automated portfolio rebalancing activity of the MT.The main data structure representing the contracts for analytical purposes is the chance/choice decision tree. This tree has two kinds of nodes, \"chance\" nodes which iterate through all material possibilities, and \"choice\" nodes where the optimal choice is made. The result is the expected value of a set of contractual terms. The trees can represent a large number of contracts with low resolution (lots of pruning and heuristics), or a simple contract with high resolution (all possibilities considered). Desktop computers are or will soon be fast enough to search through thousands of contingencies, and synthetic contracts composed of hundreds of atomic contracts, with delays less than Internet latencies. So the binary contract can be a very sophisticated synthetic, as long as its analysis is fully automated, and still conserve mental transaction costs.The MT relies on online, automated exchanges hosting liquid markets for fixed income securities and derivatives. These markets reveal the information the MT needs to properly hedge currencies. Market makers and arbitrageurs maintain these markets, ensuring the most accurate information on risk premiums, yield curves, and so on is available to MTs. Some information not automatically derivable from market prices might be made available online by financial consultants, in a standard format, downloadable by MTs for a fee.The source contract is normally negotiated and closed manually, as per normal shopping. The MT is a a \"shopping bot\", but only in the very restricted but important realm of finance related to payment terms. Sincethere should be no need for manual intervention in the hedging translation process. If such manual intervention is required, the system very quickly loses its appeal for most users.If the preference or market information is not available, or the securities and derivatives exchanges are not available, the market translator can revert back to simple automated currency conversion.The market translator thus solves a vexing problem faced by multinational small business, the hedging of payment terms using potentially unreliable currencies. More generally, the market translator built on a scarce object architecture will lower the mental transaction cost barrier to micropayments and micromarkets. It will translate skills and preferences into microrights and microduties for use in fine-grained allocation of resources and services \u2013 whether online e-mail accounts, online game collectibles, screen real estate, network bandwidth and caching, or a variety of other network objects which, thanks to scarce object architecture, become economic objects."}
{"prompt": "The Geodesic Market", "completion": "\u201cThe path-breaking work of Robert Hettinga was published in a series of newsletters issued by FT Virtual Finance Report during 1998-1999. Bob is well-known for starting the famous e$ and e$pam mailing lists, to which I was an early subscriber, and as the founder of the Internet Bearer Underwriting Corporation (IBUC). Along with fellow privacy stewards, Vince Cate and Ray Hirschfeld, he launched the world's first conference on financial cryptography, FC97, on the island of Anguilla.\u201dSince the invention of the telegraph, financial transaction settlement has had a problem: how do you transact business at a distance when the simplest way to execute, clear and settle a transaction is with an exchange of bearer certificates?Our current system of so-called \u2018book-entry\u2019 transaction settlement was invented in order to handle the problems caused by remote transaction execution and the subsequent need to physically exchange bearer certificates for settlement. We now have the means to return to \u2018digitally encoded\u2019 bearer settlement with a three orders of magnitude cost saving.Soon enough, the era of book-entry settlement, our way of representing money as offsetting debits and credits exchanged between the two parties of a trade through a hierarchy of trusted intermediaries, will be over.I think that the social and economic impact of the new alternative to book-entry settlement, digital bearer settlement, will be quite large, because, at the root of the status quo\u2019s book-entry transaction protocols is the need to involve government and regulation at the most intimate levels. Essentially, \u2018\u2026and then you go to jail\u2019 is the penultimate error-handling step in a book entry transaction.In the old days, before telegraphy, most financial transactions were done by trading bearer certificates, or tokens, of one form or another. Exchanging cash for a bearer bond would be a good 19th century example. Even trading bearer forms of equity was trivial and instantaneous: the offer, the acceptance of the offer, and the settlement of the transaction occurred almost all in one operation.With the advent of telegraphy and eventually telephony, it was possible to make the offer and accept the offer at a distance, but settlement had to wait until bearer certificates were physically relocated, sometimes over long distances and then exchanged. After all, you couldn\u2019t very well send them over a wire.The solution was to move all the certificates to a central trusted location, called a clearinghouse, and for the trading parties to swap debits and credits between themselves and the clearinghouse. It\u2019s pretty apparent that having the certificates physically locked down in the clearinghouse\u2019s vault becomes superfluous in such a scheme, because what really matters is the impartial arbitration of the clearinghouse in the case of a transaction dispute. All except for one thing. If someone lies or reneges on a book entry transaction, there isn\u2019t much that the other two parties can do except bar them from trading, which, of course, works in bearer certificates, but not nearly as well in book-entry settlement.So, we need several things to cope with nonrepudiation in book-entry settlement. First, we need the ability to determine who physically made what book-entry so we can find them and send them to jail for fraud if necessary. That\u2019s because book entries are inherently unstable, insecure, digits sitting in a database somewhere. Many people in Asia are familiar with commodities and derivatives traders who were capable of hiding fraudulent book-entries for long enough periods of time to bring down their respective firms, for instance. In cryptography we call this an authentication problem.So, besides authentication of the book-entries themselves, we need to secure the links between various charts of database accounts, first by authenticating the users of those electronic links, originally with passwords, then with cryptographic keys and signatures, and now with some combination of biometrics (finger or retinal prints, say) and digital signatures. And, second, by actually encrypting the links themselves so that no one can see what they are even if they can\u2019t change the authenticated data without someone noticing.Sorry for the long-winded explanation, but it\u2019s long-winded stuff, as most people who clear trades on the net for a living will tell you. Anyway, for all intents and purposes, you now know everything there is to know about the guts of electronic commerce on the Internet. When you punch your credit card number into a secure web page, pretty much all of the above happens, plus or minus the retinal scan.However, all this stuff about moving book-entries down encrypted pipes on the internet, including the much-heralded SET protocol for credit cards, is so much financial \u2018shovelware\u2019.Fortunately, there is much more that can be done with financial cryptography. There\u2019s a whole string of cryptographic protocols out there, beginning with David Chaum\u2019s blind digital signature patent in the middle 1980\u2019s. You can actually create unique digital objects which can\u2019t be forged if you handle them right (if you only exchange them on-line, for instance). You can attach any arbitrary financial value you want to these cryptographically secure objects as long as everyone else agrees with you, and, most important, you honor your agreements concerning their exchangeability into some other financial instrument. So, I call these objects \u2018digital bearer certificates\u2019, after the paper bearer certificates of yore, which I claim these crypto-blobs behave like, more or less.The fun part comes when you actually start to trade these things. The first thing you notice is that they settle instantly. I give you digital cash certificates, you give me digital bearer bond certificates. Trade over. Elapsed time, thousandths of a second. I can turn right around and take that bearer bond and sell it again, if I want. More to the point, I don\u2019t have to wait for my broker work out how to move my money to your broker through the clearinghouse, for their banks to arrange to pay each other, all of which takes days and costs lots of money. The cost of your on-line Schwab or E-trade transaction could move from being measured in dollars to somewhere in the sub-penny range, and probably less over time.Actually, these aren\u2019t account based protocols at all. So there ain\u2019t no Schwab, or Merrill Lynch, or Morgan Stanley, required. Well, not completely true. You still need financial intermediaries, no matter how small, to \u2018rent\u2019 reputation to a given transaction.As far as non-repudiation goes, I know that what you gave me is real because I can test it with the issuer. You can do the same thing. It\u2019s so trivial that I equate the act with the physical inspection each of us does, unconsciously or not, when we\u2019re handed a piece of cash. If I don\u2019t like what I \u2018see\u2019 (determined by the calculation of the cyptographic protocol, of course), I don\u2019t trade with you. I\u2019d say it\u2019s much better than detecting fraud after the fact, finding who made the offending book-entry, and apprehending, trying, and jailing the miscreant. Frankly, I\u2019d go one further and say book-entry settlement is so complicated and unwieldy that the only reason we have book-entry settlement now is because we couldn\u2019t shove paper down a wire back when telegraphy was invented.Finally, there\u2019s no real recordkeeping of transaction logs with digital bearer settlement. Like a pile of cash, you count it up, and that\u2019s what you have. There is no need for seven years of audit trails at up to six different transacting parties because you don\u2019t have to hunt someone down and send them to jail for reneging on a trade before it settles, and more frequently, to prove you\u2019re innocent should you be suspected of something untoward. You don\u2019t need a lawyer or an accountant to keep you out of jail at tax time for making the wrong book entry somewhere.In fact, you don\u2019t care who gave you what money as long as they\u2019re happy with what you gave them in exchange for it. Reputation becomes the most important thing there is, because damaging someone\u2019s reputation is your only recourse in a world where your digital signature is your only identity. The threat of blackballing is in fact a very effective fraud deterrent, and once a digital reputation is trashed, it takes time and higher transaction risk premia to build a new one. To quote J. Pierpoint Morgan on the subject, \u2018I wouldn\u2019t buy anything from a man with no character if he offered me all the bonds in Christendom.\u2019Once we get to digital bearer bonds, stocks, and derivatives thereof, the world starts to change considerably. However, I still claim that reality is not optional. If you reduce the cost of settling a transaction to effectively zero (okay, past the last basis point but not zero), then the financial markets are going to figure out how to use the technology. Not only is it cheaper, but by being cheaper, it allows for smaller and smaller publically held entities. And automated financial intermediaries. The asset sizes of various trades could get much smaller, but, in addition, I claim, that because trading of financial instruments can happen so quickly, efficiently, and by so many self-interested actors, it\u2019ll probably be the way money is raised for very large security issues and for very large projects. Maybe Intel\u2019s inevitable $10 billion chip fab, for instance, will be floated into a market \u2018swarm\u2019 of financial intermediaries. Microintermediation, instead of disintermediation, in other words\u2026Okay. I\u2019ve now walked you up the edge of the abyss, and pushed you over the cliff, and, you\u2019ll notice, you didn\u2019t get hurt at all. That\u2019s important to think about, because sometimes being quantitatively cheaper has qualitative effects, but, for modern society at least, the future is no different from the past, except that we\u2019ve figured out how to live better. I expect if we can blow the doors of the cost of financial services with digital bearer settlement, the world will be a much better place to live in, indeed.Back to table of contentsWhen I\u2019m working on a problem, I never think about beauty. I think only how to solve the problem. But when I have finished, if the solution is not beautiful, I know it is wrong.This is the first of a series of articles Duncan Goldie-Scot has commissioned me to write on the future of financial technology in an age of ubiquitous internetworks, Moore\u2019s law, and strong financial cryptography.I\u2019m calling this series The Geodesic Market, in the spirit of a \u2018popular\u2019 book I\u2019ve in the works named, oddly enough, Beyond Civilization: Life in a Geodesic Society. Actually, the core technology we\u2019re going to talk about is a group of financial cryptographic protocols I have termed digital bearer transaction settlement, which is the title of another book I\u2019m working on.When I was a teenager in the 70\u2019s, my best friend Jeff Blanton and I zealously devoured all of Stewart Brands\u2019 Whole Earth \u2018Domebooks\u2019. Back in 1974, when capitalism was the farthest thing from our mildly drug-addled minds, who would have thought that \u2018Bucky\u2019, R Buckminster Fuller, the greatest designer since Leonardo, we thought, had discovered not just an easy way for freaks like us to build cheap housing and squat on someone else\u2019s land, but that he had actually discovered the way that society, mapped as always to our communication topologies, would look in the not too distant future.Buckminster Fuller, for all his latter-day attempts to solve global resource allocation by good old fashioned top-down hierarchical industrial centralism, might not have imagined that the economics of semiconductor switching on telephone networks would eventually create giant, decentralized, capital markets. Markets so powerful that they would make the most out-of-control, rapacious 19th century industrial trust look like the most bucolic feudal guild. On a feast day. With their feet up. Capital markets operating on a network topology almost identical to the geodesic structures my friend and I were all so enamored with back in the days of the Allman Brothers, Levi\u2019s Big Bells, and ubiquitous low-yield psychochemicals.Even more ironic, you and I are going to raucously cheer these new geodesic markets on, as they surfact large concentrations of financial information and capital into fractally smaller and smaller bits, microintermediating it all like so much grease in soapy dishwater, in an instantaneous transnational market for capital. We\u2019re going to cheer these new markets on because they\u2019re going to make us so damned much money.These market will operate, finally, under the control of economics, instead of the confiscatory \u2018policies\u2019 of aristocrats or nation-states. Nation-states will eventually be as ceremonial as modern-day constitutional monarchs. Like the way physics and philosophy got out from under theology at the end of the dark ages, economics will no longer be the handmaiden of politics in a geodesic market.The fun part is, it\u2019s inevitable. It will come from the collapse of microprocessor prices, the 50% decline every 18 months that is Moore\u2019s \u2018Law\u2019, more an observation of the human ability to learn than any physical law. The geodesic market will come from the ubiquitous geodesic internet those prices create, and, in a remarkable reversal of history, a reemergence of the kinds of transaction settlement methods thought to be killed by the telegraph, and, ironically, mainframe batch computing.A geodesic market will use digital bearer transaction settlement protocols, perfect pseudonymity, and reputation sanction on ubiquitous public networks, instead of book-entry settlement, audit trails, and la, on the closed, private networks that we now have.Stunning? Outrageous? Preposterous? Before you click away in disgust, remember we only have what we use now because it was cheaper than what we used to use. Hence you and I don\u2019t go down to a bunch of merchants in the City to trade paper cash for paper shares anymore. I am perfectly serious. With financial cryptography and digital bearer transaction settlement, we can do perfectly safe, rational business on the internet without lawyers. Or, for that matter, cops.In addition to transaction costs three orders of magnitude cheaper than book-entry settlement (yes, past the last basis point: it\u2019s time to pick a new measurement unit), you will have perfect financial privacy as a happy accident of the same technology which drastically reduces transaction prices. Just like requiring the privacy-invading physical force of a nation-state in our very transaction clearing processes was an unhappy accident of book-entry settlement.All of this will happen with more non-repudiation and more asset safety features, including seemingly impossible things like limited liability and shareholder voting.The reason we have database marketing, book-entry taxes, (like income, capital gains, value added, and sales taxes), and book-entry regulations, (like, well, practically all regulation, these days), is because the book-entries are there.We need those book-entries in order to prevent repudiation of transactions. And, to enforce rules against a transaction\u2019s proven repudiation, we need the police. So, if you don\u2019t need book-entries, you can\u2019t have that other stuff, including, as Doug Barnes of C2NET likes to say \u2018\u2026and then you go to jail\u2019 as the error handling step in your transactions protocol.Impossible? If we can do digital bearer transactions, safely and anonymously over the internet for, say, 1000 times cheaper than book-entry settlement, what do you think will happen?As a brief preview, let\u2019s take a look at the things you can do with digital bearer settlement. Not surprising, it\u2019s everything you can do with book-entry settlement, and more.Consumer Debt: Instead of using a credit card, imagine issuing personal bearer bonds. Whole bond issues, actually. Microintermediated, by, you guessed it, a syndicate of micro-underwriters, living in the ubiquitous internet, all of whom, like under- writers always do, intermediate the market\u2019s loan of money to you based upon your reputation for repayment.Digital Cash: Since most people pay off their credit card purchases within a month after purchase, you will be relieved to know that instead of having to hassle with a credit card bill just to cover your normal monthly purchases, and the lack of privacy which goes with it, you will be able to use digital bearer cash, which will be as safe to use as checks or a credit cards are now, all without interest, or at least annual fees.The main reason you\u2019ll use digital bearer cash is, however, that eventually there\u2019ll be no float on your checks or even your credit cards. Notice how debit cards are cheaper already to use than credit cards, and that merchants are starting to see the advantages of getting their money without chargebacks hanging over their head.This is so fundamental a process that it should be a law of finance or something: the closer an electronic book-entry transaction system gets to instantaneous, the more digital bearer settlement becomes financially necessary. As a friend at a large IT consultancy in Cambridge (Massachusetts) likes to say, \u2018Real-time gross settlement is digital bearer settlement.\u2019Capital Markets: Instead of purchasing a stock through a broker with limited, hierarchical, almost oligopolistic access to the capital markets, you\u2019ll be able buy your digital bearer bonds or shares in public, or at least privately, using public networks. The internet is the equivalent of the old buttonwood tree on Wall Street, as I once wrote in Wired. I show up on the net with cash, you show up with your bearer shares, we exchange the two, and the trade is over. Execution, clearing and settlement, all in one step. Anonymously, because it\u2019s cheaper. That\u2019s the beauty of digital bearer settlement. You can do this for any financial instrument, debt, equity, or derivative.Internet Resource Allocation: Also, there are the things you can do with digital bearer settlement that you just can\u2019t do any other way. It\u2019s easy to imagine very small packets of digital bearer cash \u2018buying\u2019 a message across the internet, with each router buying packet switching low, and selling it high. Look, Ma, no human hands: No \u2018peering\u2019 arrangements, probably no network \u2018engineering\u2019 either, in the long run, as the internet becomes, like any free market, a complex self-adaptive system. I joke about \u2018picomoney as processor food\u2019. \u2018Micromoney mitochondria\u2019. Auction markets for bandwidth, certainly. Maybe for the guts of the machine itself, memory and processing time. All you need is Moore\u2019s Law, fast enough processors, and, of course, digital bearer financial cryptography protocols.Utilities: But, wait, it gets worse. You can pay for electricity, in cash, as you use it, down, of course, the same wire you got the electricity from. You can pay for roads as you use them, perhaps every few hundred yards or at every intersection. Like you can on the internet, you can pick the cheapest or fastest route to your destination. So much for \u2018public\u2019 roads. Just about everything you think of as a \u2018public service\u2019, or a \u2018natural monopoly\u2019 may be reduced some day to a continuous cash-settled electronic auction between competing parties. Moore\u2019 s law creates diseconomies of scale and geodesy. Hierarchy and economies of scale are a function of expensive (human) information switching.Geodesic Warfare?: Even force can be auctioned off and sold, same as it ever was, only this time to the highest microbidder. Imagine your land covered with semiautonomous landmines, keyed to your digital signature, which only go off when you tell them to. No, don\u2019t imagine them taking bribes to change sides. It\u2019s real. Someone at the US Army War College wrote a paper on just such a scenario four years ago. Of course, whether we\u2019ll need state-funded armies in a world where force has been disintermediated to such an extent or where taxes might be \u2018optional\u2019 is an entertaining proposition.So, who knows what the future\u2019s really going to look like. I may almost have my videophone now, but I have yet to see a (useable!) flying car, for instance. However, there\u2019s one thing we can be certain of. Information and knowledge will be developed and sold in much cheaper and smaller bits than we do it now. The prices for industrial goods will fall in a geodesic economy just like agricultural goods and raw materials did in the industrial economy.Just how far it goes is limited by Moore\u2019s Law. Moore\u2019s Law also enables the ubiquitous use of cryptographic financial protocols, like Chaum\u2019s original blind signature algorithm for digital bearer certificates, or the one for Rivest\u2019s MicroMint micropayment protocol.This series of articles is about how those markets, well capital markets, will come to be, how they will operate, and what actors will probably succeed in those markets.Next month I\u2019ll discuss geodesic networks and why I think they create geodesic social institutions like geodesic markets, how trade and money, how human society itself looks when viewed historically through the lens of their communications architectures. Then, I\u2019m going to talk in laymen\u2019s terms about the financial cryptography underpinning digital bearer transaction settlement, and then survey some of the different kinds of digital bearer settlement protocols on the market and in the labs at the moment.After that, I\u2019m going to apply these different protocols to different pieces of the capital markets we now have, and show you what the world looks like in a geodesic market for capital.Back to table of contentsIn this second instalment of the Geodesic Market, I\u2019m going to show how to underwrite digital bearer securities, using cash as an example.The business model I\u2019m using should be familiar to anyone who\u2019s been in the securities business for more than 20 years, and especially to anyone who\u2019s studied financial history. There\u2019s no surprise in that. We have 5,000 years of experience with bearer transactions. There\u2019s nothing new, except the cryptographic protocol, to worry about, and we\u2019re not going to talk about cryptography here in any detail.Another nice thing about this model as applied to cash is that it will be possible for people to convert their money to digital cash in and out of their own bank accounts, just like they can for paper cash. The underwriter, as I call the issuer of digital cash, becomes the internet equivalent of a third-party ATM machine, something everyone\u2019s familiar with.Because of this modular plug-and-play approach, it\u2019s pretty simple to obey all the rules we currently have about handling cash, while dramatically reducing the cost of cash transactions in the process.So, let\u2019s get started with a look at the players in this market.A consumer is someone who buys a piece of digital cash from a financial intermediary, an underwriter, in exchange for some other kind of money, a change in a bank account balance in this case, in order to effect a transaction on the net.A merchant is someone who accepts a digital bearer certificate in payment for something else.Of course, I hate the use of the words consumer and merchant because they don\u2019t describe geodesic peer-to-peer transactions very well, but the banking world understands them perfectly, like they do underwriter or trustee or custodian, so I use them here.The underwriter issues digital bearer certificates, and is fiduciarily responsible for exchanging them into other forms of money, again a bank account balance change, held by a custodian in a reserve account. Someday, of course, the reserve assets collateralising an issue of digital cash could be some other digital bearer asset.The second most important thing an underwriter does is to verify, at every transaction, that a given digital bearer cash certificate hasn\u2019t been double spent, copied by someone and spent twice. After that, the underwriter issues a brand new signature- blinded certificate to the person accepting the cash in payment. If the exchange fails at any point, so does the transaction, and the person offering the cash is prevented from double spending it, thus preventing repudiation of the transaction at execution time. Cheques, credit cards, or any book-entry transaction can\u2019t offer that security. Even with on-line validation for fraud, the merchant is still at risk of stopped checks or chargebacks.Finally, the most important thing an underwriter does is to market its certificates to the world. Which, if you look at an underwriter in the capital markets, is exactly what they do for both primary and secondary transactions, and that\u2019s why I use the label here.The original DigiCash ecash mint at Mark Twain Bank was a used 486 machine, just to give you an example of the hardware cost of being an under- writer. Eventually underwriting may be automated to the point of processor husbandry in the same way that one tends a web or router farm today, but it should always be done by a separate financial entity other than the trustee.A trustee, or custodian, holds the money reserving an issue of digital cash, on behalf of the cash certificate holders, in a bank account, though someday the reserve assets could be held in bearer form under the trustee\u2019s control. Like bond trustees or mutual fund custodians, the trustee operates according to an agreement, like a bond debenture, between the underwriter and the certificate holders. This agreement could specify fees and, most important in the early adoption process, reserve ratios.So, while the underwriter is the direct financial intermediary, and keeps the interest which accrues on the reserve account, the trustee risks their reputation by holding the reserves, is compensated for it, and controls that risk by making sure that the reserve agreement is adhered to.Put simply, there is no way to to get exchangeability of digital bearer securities into book-entry assets without a genuine, fully regulated trustee/custodial bank, which, in my opinion, is why we don\u2019t have internet digital bearer settlement today.The holders of the blind signature patent, and other protocol inventors, have a hard time understanding this. DigiCash, as the canonical example, will only license their patent to a single bank in a single country, and not to any one else, forcing the trustee and underwriter to be the same entity, creating a very brittle and not very robust network of financial entities. The result has been market failure, for the most part. Having a competitive, many-to-many, underwriter/trustee market system fixes that problem completely, as we\u2019ll see in a bit.For all intents and purposes, the consumer, merchant, underwriter and trustee are really all the financial entities necessary in a market for a digital bearer instrument.There are other entities required to make this work, of course. There are developers of the software for that market and, most important, the inventors of the financial cryptography protocols, like David Chaum, Mark Manasse, Stephan Brands, Ron Rivest or Ian Goldberg.Developers can either sell their software directly to customers or merchants, or they can sell servers to the underwriters and the underwriters can give away clients to their users.Inventors can license their protocol to the market as a whole through the trustee. This way, trustees can take royalties out of a percentage of the underwriters\u2019 interest earnings on the reserve account, or from the fees charged when some other asset is converted into the bearer instrument in question, or some combination of both.With book-entry or bearer-collateralised trustees, this rewards innovation cheaply and easily. You don\u2019t even need patents to do it. Even with bearer-collateralised trustees, the inventor of the protocol still gets paid, no matter who or where he is. This, among other things, is part of the judge role I was talking about above. The trustee, who\u2019s in business to be fair and impartial, loses reputation capital otherwise.The consumer buys, from a software developer, or is given, by an underwriter, a wallet: a client application which allows the storage and disbursement of digital bearer certificates. Wallets will probably be specific to the cash-protocol used, and not to the underwriter using the protocol.With a wallet installed, maybe as a browser plug-in, the consumer goes to the underwriter\u2019s secure web page. The consumer enters, either by swiping a card or emitting stored information on her hard drive, the account and PIN number for her bank account just like she would at an ATM. The consumer\u2019s account information is probably blinded, so that not even the underwriter, or even the trustee, sees it as it goes through the trustee and onto the ATM network for authorisation.The consumer\u2019s bank sends an authorisation message back to the trustee, who notifies the underwriter of the reserve account change, who in turn disburses digital cash certificates to the customer in the amount of her request. With the exception of the issuance of digital bearer cash instead of paper cash, this is roughly what happens with a private ATM machine.This is all done for whatever fee the underwriter charges, in the same way traveller\u2019s checks are sold at a premium at the time of sale, or that a foreign ATM machine charges for non-customer transactions. In fact, redeeming it off the net at par like a traveller\u2019s cheque, and exchanging it free for other digital bearer cash online is probably fundamental for merchant acceptance.The consumer then uses the new cash to buy something from a merchant on the net. In theory, a merchant could do offline transactions, without involving a direct exchange and replacement of certificates from the underwriter, but they\u2019re ridiculously insecure from the standpoint of double spending.This exchange of certificates, this printing of new certificates at the time of each transaction, is still orders of magnitude cheaper than book-entry payment methods, and, since it\u2019s blinded by cryptographic protocol, the transaction retains its bearer quality. That is, the asset changes hands anonymously (on the net at least), it exists in only one place at one time, and the only proof required for non-repudiation is the certificate itself. Just like dollar bills, only three orders of magnitude cheaper than an internet debit or a credit card transaction.With the transaction over, the merchant can instantly spend his newly minted cash certificate somewhere else, this time for free, because the longer it stays on the net, the more interest it earns in the underwriter\u2019s reserve account, all at minimal cost to the underwriter.Or, the merchant can turn around and redeem the certificate at par through the underwriter, who in turn has the trustee clear the money through the ATM system to the merchant\u2019s bank in the exact reverse of the process which got the money onto the net in the first place.Notice, for the first time, it is technically possible to use the ATM system for a cash deposit from a foreign bank, in this case, from the trustee, on behalf of the underwriter, to the merchant\u2019s bank account. Finally, notice that, since the wallets will probably be free, anyone can get paid in cash over the internet. They only need a bank account to put money on the net or take it off, important in the early stages, but not nearly so as time goes on.It should be obvious by now that we\u2019re looking at a classic case of Metcalfe\u2019s Law. The more entities there are in this market\u2019s network the more robust and valuable it is.The model gives us a many-to-many universe of interdependent underwriters, trustees, software developers and protocols, all in competition with their peers to offer the best price, collateral, reputation, quality of execution, and so on. The idea is to create a ubiquitous geodesic capital market composed of efficient, instantaneously cash-settled auctions of fungible, non-branded, risk-graded, digital bearer financial instruments.The other thing the model creates is something I call microintermediation. Because of the information processing diseconomies of scale in Moore\u2019s law, we have lots of small, automated financial intermediaries, each one operating directly between a given buyer and seller. This, I believe, is the logical outcome of financial disintermediation, which, until now, has been about removing multiple intermediaries between a buyer and seller. As we\u2019re starting to see in the internet search engine market, we\u2019ll start to see a speciation of financial intermediaries, by financial instrument, risk, etcetera, all brought about by Moore\u2019s law. After all, no single processor in a geodesic network can handle all the traffic.Note also that everyone who puts money on to the net or takes it off is identified to the complete satisfaction of government regulators everywhere. Digital bearer cash is treated just like physical cash in the eyes of regulators, and is subject to the same regulations. There is no functional difference between a digital cash underwriter and an ATM machine. And, yet, on the net itself, transactions are perfectly anonymous.This is the ultimate paradox of digital bearer settlement. The transaction protocols are so strong cryptographically that you don\u2019t need identity to keep your trades from breaking. More to the point, you don\u2019t even need biometric identity to prevent fraud. A digital signature is persistent enough to actually attach a reputation to.We\u2019ll talk more about this, and about digital bearer bonds, next month.Back to table of contentsIf you read the last instalment of The Geodesic Market, you now know how to put digital bearer cash on to the net. Of course, you can put every type of financial instrument into digital bearer form, and this month we\u2019re going to look at debt, which is the simplest extension of the cash model I showed you last time.Of course, to issue debt, the borrower (or any other market actor, of course, except secondary buyers and sellers) needs a good reputation, and we\u2019re going to talk about that first.With much fanfare, I now trot out my favourite quote from J Pierpoint Morgan, the last major denizen of the bearer-settled financial universe.At the time he uttered this pearl of financial wisdom, Morgan was more or less on his deathbed, and was literally hauled in front of the US Congress to testify before he died.So, imagine yourself there, in a congressional committee-room in 1913, (one year after 1912, the year libertarian columnist Vin Suprynowicz says was the high water mark in American liberty) and there you are, looking at the only man in history to refill Fort Knox with the proceeds of a typically-oversubscribed European bond issue on the strength of his signature alone, after this very same Congress had spent that treasury empty in the first place.A man who single-handedly stopped several bank panics, one of them by while playing solitaire in one room of the Morgan Library, with a roomful of bank presidents arguing in the room across the hall, shuttling occasional proposals to him for his hoped-for approval over the course of a few days, all while Wall Street held its breath.A very old man, now. An old man, being commanded, upon contempt of the best Congress money could ever buy before or since, to tell them the ultimate secret of banking. The most important thing a banker had to have to succeed.Is it the right, um, \u2018family background?\u2019 they seem to ask this paradigm of New England WASPiness. The right school tie? Never mind that Morgan was tutored for the most part. The right secret society membership? Of course, Morgan wasn\u2019t much of a joiner, except that he ran the board of trustees of his church, and that of the Metropolitan Museum of Art, like he did the rest of his enterprises, with an iron fist.Morgan just scowls at them. His answer is very simple:\u2018Character.\u2019Our would-be congressional inquisitor was probably dumbstruck. He was surely some loutish turn-of-the-twentieth-century urban machine politician, or maybe a rural silver-shoes-on-yellow-goldbrick-road bimetal free-silver populist in extreme Dorothy-Gone-to-Oz Mode.Whatever he was, he was almost certainly hoping for a financial conspiracy story of Bilderburg proportions to put into the next day\u2019s muckraking headlines. And, I bet, this modern Torquemada couldn\u2019t believe his ears.\u2018Character?\u2019, he sputters. Like he\u2019d never heard the word before.Morgan puffs himself up to his full 5-foot-rotund-something, gives the man one of those famous withering glares over a rosacea-mangled nose.\u2018Sir, I wouldn\u2019t buy anything from a man with no character if he offered me all the bonds in Christendom.\u2019Parsing that language to account for, um, \u2018late nineteenth-century Episcopalian sexism\u2019, we get as clear a definition of the enforcement power of reputation as has ever been stated this side of \u2018Caveat Emptor\u2019.In other words, if you lie, I don\u2019t do business with you again. Ever.And, in the world Morgan found himself in, that kind of financial shunning was pretty much all anyone really could do.It was really ever thus, throughout the history of money, much less finance. Sure, you could go to your friendly local force monopoly, be they monarchical, tyrannical, empirical (in the manner of Napoleon, not Hume), or oligarchal (or, even, democratic, on extremely rare occasions), and you could try to get them to beat up someone who ripped you off. But, usually, that was way too much work. Said regional force monopoly had to actually find this person, and then apprehend, try and convict him, and, frankly, more likely than not, he\u2019s changed his name and venue and spent the cash you paid him for those bogus bearer bonds you\u2019re now holding, and, well, so sorry, sir, but them\u2019s the breaks.And so, to sanitise and paraphrase the immortal Bluto Blutarski of \u2018Animal House\u2019 fame, it was actually you who screwed up: you trusted this brigand to begin with. You believed he had character, a good reputation, in other words, and it turned out that he didn\u2019t, at all.This was true up to and including J Pierpoint Morgan\u2019s day, where, although you could use a telegraph to execute a trade on the New York Stock Exchange floor, you still had to bring in actual paper and swap it for some other actual paper to clear and settle the trade.Yet, oddly enough, reputation sanction, plain old fashioned shunning, worked just fine for over 5,000 years. Marvellously well, in fact.Though, we now know what happened to J Pierpoint Morgan\u2019s tidy little financial universe of men with good character. Tabulators and comptometers begat computers, and, next thing we know, we\u2019re all using wires and computers to move accounting entries around, my debits for your credits, and bang, financial transactions execute, clear and settle more or less electronically, modulo a tape swap and a batch job or two.And, now, all I need to buy something over the internet is to give you a credit card account to take the money out of, and, maybe, but not necessarily, a cryptographic authentication (obviously, I hate the current misuse of \u2018signature\u2019, much less \u2018certificate\u2019) to prove that it was I who told you where the account with the money in it was.Yet, there\u2019s a little problem with book entry settlement and clearing, and it involves that force monopoly I was talking about.When we have to make copies of our transactions and give them to a \u2018trusted\u2019 third party to keep us from lying to each other, that\u2019s pretty awful, and not only from the standpoint of simple privacy.More important, there\u2019 s something particularly insidious to freedom itself about just shoving around debits and credits, instead of physical objects, or, now, digital objects, when you pay for things or convert one asset into another.With book entry settlement, you have to keep a virtually perpetual audit trail, so that on a \u2018syntactic\u2019 level, you can prove the trade happened some indeterminant date in the future, and so you can prevent the other party from denying (that famous legal double-negative, \u2018non-repudiation\u2019) the trade ever took place. And, once you\u2019ve done that, it\u2019s real easy to use those records to call a cop and send that person to jail. Actually, you\u2019re forced to, for any of a number of reasons, not the least because the clearing/settlement lag is such that someone might have absconded before you knew what happened to your money, and giving the clearing house physical enforcement capabilities in meatspace would make cause undue competitive pressure on the sovereign\u2019s monopoly on force.Now you can see why book-entry transaction settlement requires very strict biometric identification for anyone who changes the book-entries themselves, or even those who order book-entries to be changed. Everyone else (us customers, in other words) must deposit in advance of any significant financial activity, as sort of hostage capital to whatever transactions we execute.Everyone under the jurisdiction of the SEC has their fingerprints on file, for a reason, not to mention their current name and address. Enough information to drive a totalitarian tyranny through, frankly.And, so, the real reason governments have grown to control such an increasingly huge part of our lives, through book-entry taxes (sales, VAT , capital gains, income) and regulation (think of a regulation which doesn\u2019t eventually rely on transaction audit trails), is because, we require government intervention in our economic processes, our very transactions themselves, or those selfsame transactions wouldn\u2019t occur at all. Book-entry settlement and the ad baculum argument at the core of the very idea of the modern industrial nation-state are intimately related. A tax on income is easy to enforce because you need force to make the income transactions execute to begin with. One hand washes the other. Pay packets with paper cash cost too much to handle when you can just issue cheques for people to deposit into mainframe-enabled chequing accounts.Seen from a network perspective, a book-entry transaction is about shoving a very insecure piece of data, a positive or negative integer, a debit or credit, down a very secure pipe. And, to get access to that pipe, you have to be physically, um, obtainable, to law enforcement at any point in time before, during, and after the fact, should you lie about it.With digital bearer settlement, we have turned that last paragraph completely on its head. With a blind signature cryptographic protocol, for instance, we can send a secure transaction, a strongly encrypted and cryptographically authenticated token (a digital bearer certificate, if you will), down an insecure pipe, the internet, in other words, and with the right software, that\u2019s the end of the transaction.We don\u2019t need biometrically authenticated access control to a proprietary secure network in order to shove an inherently insecure book entry back and forth out of someone\u2019s database of transactions and, by extension, their chart of accounts. We actually don\u2019t need to keep audit trails at all anymore, much less for years at at time, and, more dramatically, we don\u2019t even need cops to hunt down miscreants who \u2018break\u2019 our trades, either in execution, settlement, or clearing.Instead, with a simple exchange of digital bearer certificates, we can execute, clear, and settle the transaction all at once, and the cryptographic financial protocol, executed in software, simply won\u2019t operate unless all conditions are met for the transaction to occur.Which, oddly enough, is exactly the way a physical bearer certificate works: I show up with my cash, you show up with your paper bonds, we agree on a price, we inspect and swap our various pieces of paper, and we walk away. I know the bonds are good by inspecting them, you know the cash is good by inspecting that, and, frankly, we don\u2019t care who each other is. Ever.Now, with digital bearer certificates, we can do exactly the same thing on the net. That \u2018inspection\u2019 step now occurs when we test and redeem our cash or bond certificates with their issuers online, and, if the certificates can\u2019t be redeemed, the trade can\u2019t even execute.It stops before it starts. Nobody gets burned, frankly, except the criminals who want to double spend the certificates. The only people who even need a reputation in the transaction itself are the issuers of the respective digital bearer certificates involved, and not the buyers and sellers of those certificates in the secondary markets.And, of course, that \u2018reputation\u2019 we\u2019re talking about here is the past behaviour, on the net, of a public-private keypair used in the authentication and issuance of a given digital bearer certificate. Or in the sale of anything else, for that matter. Just by using the public key and the signature on the certificate, anyone in the market can validate that the certificate was issued by the entity issuing or underwriting it. And, in the course of a transaction, as we said, the issuer itself can validate the \u2018semantic\u2019 part of the transaction, that the certificate is in fact unique and exchangeable at no cost for another unique set of bits representing the same value.So, a digital bearer certificate is authenticated by the issuer of that certificate, in the same way that the intaglio printing, special paper, serial numbers and signatures on a given paper bearer bond make it unique and non-replicable.That makes not only for a more secure, and completely private, transaction, but it also makes for a radically cheaper transaction, which is really the whole point. As we all know by now, the reason we have book-entry settlement to begin with is because it\u2019s radically cheaper than the physical delivery of paper bearer certificates, not so the government, or anyone else, can surveil us in our very grocery purchases.On the net, we talk about accumulating and quantifying reputation in some imaginary future denomination and we call that stuff \u2018reputation capital\u2019. Which immediately leads to the cypherpunk inside-joke about permanent shunning being \u2018reputation capital punishment\u2019. And, actually, that\u2019s pretty understandable. Instead of going off to San Francisco in the 1850\u2019s to change your name and venue after screwing up, you just delete your private/public key pair, and start a new reputation over from scratch. In a bearer settled world, of course, it happened all the time.I expect, like corporations today, reputations will be sold, and the variance between the market value of the assets controlled by that reputation, and the market value of the reputation itself will be our imaginary reputation \u2018capital\u2019, something we call \u2018goodwill\u2019 today.Now, to quote Bill Cosby, \u2018I told you that story to tell you this one.\u2019With digital bearer settlement, and the sanction of reputation against public keys which have bad character, as Morgan called it (reputation, to you and me) it is now possible to create digital bearer bonds.Actually, last time, in my underwriting model for digital cash, I cheated. When you think about it, a bank note, cash in other words, is an instantly callable, perpetually issued bond which pays no interest. It represents a claim, in the old days, at least, on some principal amount of a given debt, and not its interest, redeemable upon demand in the asset the note is reserved against and denominated in.So, to issue a digital bearer bond with a simple coupon, you just issue a digital bearer certificate for the principal amount, redeemable at the end of the life of the bond, and you bundle a bunch of coupons with that certificate for the redemption of principal, one for each interest period, and redeemable at the end of that interest period, and sell them all together as a unit.To do a zero-coupon bond, simply issue a certificate payable at expiration and sell it for the net present value of that amount given some fixed interest rate.Strips are just that. Strip the coupon certificates from the principal one and sell them all as individual certificates with their own prices. Notice that we bump into the old fixed income analysis chestnut about a bond being a series of options on cash flow, which, of course, I\u2019ll muck around with a bit more, when we get to derivatives.Convertible bonds should be redeemable either in cash or stock. Bearer stock, of course, which we\u2019ll talk about next time.Money market instruments, for the most part, are just bonds with extremely short lifespans.It\u2019s even conceivable to have microbonds, issued by individuals. After all, the size of an individual underwriter, and the resulting syndicates of underwriters, to boot, is probably completely driven by Moore\u2019s law. I joked in Wired a few years ago about a syndicate of microbond \u2018bots\u2019 loaning me the money for lunch, payable at the end of the month.If you can have microbonds, macrobonds are also possible. I expect that digital bearer settlement will be a universal phenomenon, just like book-entry settlement is today.Secured bonds, like equipment mortgage bonds, can use various trusted entities to validate the worth of the assets securing the bond, just like a trustee/custodian does for a bond or cash issue.And, of course, you can add all kinds of call provisions, redemption exclusions, and anything else you can think of, to a digital bearer bond, only this time, you\u2019re writing software, and not law, as the old cypherpunk mantra goes.Finally, any of the above bonds will be rated, just like bonds are today, yielding the same market we have now, with fungible graded commodities, in perfect competition, only, now the velocity of those markets can be greatly accelerated. After all, you are executing, settling, and clearing, instantly, and for cash.Notice several things here. First, the language of bearer settlement completely underlays our very discussion of bonds even today. The word \u2018coupon\u2019, for interest, \u2018holding\u2019 a bond, all of that. Digital bearer settlement makes it that more relevant. Back to the future, and all that. It says to me that we\u2019re not going to have too much conceptual trouble thinking about a world of digital bearer settlement, which is one of the principal attractions, besides reducing transaction cost by three orders of magnitude, of course.Second, and probably more important, by creating actual digital financial objects, objects which make electrons behave in certain ways online, just like the mouseprint covering those huge paper bearer bonds of yore caused lawyers and judges to behave in certain ways in meatspace, you have freed finance from a huge chunk of legal cycle-time itself, and you get a genuine financial ecology on the net, on top of that geodesic economy I talk so much about. In fact, most of the time it seems to me that they\u2019re part of the same thing. The geodesic network being the substrate upon which this bestiary of financial entities and objects are born, live, and die. It gets worse when I talk about the idea of \u2018micromoney mitochondria\u2019 at the end of this series, but I\u2019ll soften you up a bit before we get that far out over the edge of the cliff, into cartoon physics, as it were.Anyway, in this new financial ecosystem, financial theory and practice become one and the same thing, the behaviour of financial software and digital bearer objects on a ubiquitous global internetwork. It may be that, after years of using mathematics and physical analogs to describe financial economics, the ultimate anathema to mathematical finance will occur, and finance will become an observational science again.Frankly, I think we\u2019re looking at some combination of the two, where mathematical finance will propose, and the genetic behaviour of the market will dispose. Which, when you think about it, is exactly what happens today.Next month, we\u2019ll talk about digital bearer stock, and, implicit in that, how to achieve limited liability in \u2018cypherspace\u2019.Back to table of contentsSince law attempts to be as logical as possible, and software is nothing but mathematics, I\u2019m about to show you how to turn common law, or some of it, anyway, into software. We\u2019re going to do it all, of course, by talking about digital bearer equity.One of my favourite people in philosophical history is Bertrand Russell. Most people familiar with the history of computational logic know that not only did Russell discover a paradox that eventually undermined the foundations of logic when Goedel solved it a few decades later, that consistent systems could never be complete and complete systems could never be consistent, but also that Russell and his partner Alfred North Whitehead quite literally broke their brains proving, logically, that 1+1 was 2 using symbolic logic alone, unifying maths and logic for the first time.The idea of joint control of an enterprise is as old as western civilisation. Before the time of the Greeks, hierarchy and property rights had gotten so evolved that everyone belonged to someone else. Ministers of the pharaohs used to routinely sign their correspondence to their superiors, \u2018Your Slave\u2019. Hydraulic monopoly has a weird effect on people that way. Certainly the Chinese, Brahmins, and, to a lesser degree, the Mesopotamians, refined hierarchical lifetime control of their subjects to a fine art.It\u2019s questionable whether the Greeks were the sole inventors of democracy, small hunter-gatherer bands like the Australian aborigines had a more egalitarian society than most larger agricultural societies, for instance. Nonetheless, the Greeks are certainly the people we like to remember as the originators of the practice of voting as a \u2018protocol\u2019 for group decision-making. Especially since they actually had agriculture and actually kept written records of the votes they took.The Roman republic, literally, \u2018re publica\u2019, the public thing, abstracted direct voting up one level by electing representatives who in turn did the actual voting, proxies, if you will. This allowed a much greater span of control than a simple city state, Delian League or not. First \u2018pecunia\u2019, then \u2018re publica\u2019. Those Romans got to invent all the fun words, didn\u2019t they?Notice that neither democracies or republics are necessarily stable or even representative. Greece and Rome, or any of their early modern replicas including the one I\u2019m fond of, excluded most of their populations from actual voting control, but, as communication technology and industrial requirements for education increased in prevalence, suffrage tended to become universal, and, ironically, slavery itself has been shown to be a peculiarly agricultural institution, all of Marx\u2019s protestations to the contrary.Another way to think about it comes from an old college logic professor of mine. We all have the same information and intelligence, and the future is uncertain, so we might as well vote about what to do next.Of course, joint ownership is not new either, and neither is proportional voting control of businesses, or anything else. The corporation, peculiar this time to industrialism and the modern nation-state, has direct antecedents in other common-law business forms not requiring the force of that nation-state for their very existence, something important to anyone trying to code up erst-corporate behaviour in software instead of law.You don\u2019t even need the legal sanction of a nation state to have limited liability. Common law created limited partnership long before corporations. Britain had fully functioning non-corporate limited liability entities at least until the end of the nineteenth century. Lloyds not withstanding, of course.So, the point is, can you make all this fun stuff happen in software?Let\u2019s look at the cryptography for a bit. For starters, you can store multiple \u2018hashes\u2019 of the same data in such a fashion that with any m of n pieces, you can reconstruct the whole dataset. That is useful for storing, say, your digital bearer bonds, in various blinded cryptographic storage areas all over the net, for a fee of course, but it also provides a pointer to controlling a business entity as well.Why? Remember that \u2018identity\u2019 directly maps to \u2018key-pair\u2019 in cypherspace. With an m-of-n reconstruction scheme, any m members of a board could vote to control the \u2018root\u2019 key of a virtual corporation, for instance, you could actually control that key. There\u2019s considerable doubt whether hierarchies make sense in this context at all. In fact, most global name-space schemes based on key-management hierarchies bump right into Russell\u2019s Paradox and Goedel\u2019s Result as if their designers never took logic at all.Anyway, this form of m-of-n key-control works best for simple partnerships, but you still have the problem of voting control of larger entities, particularly if you want lots of shareholders. Fortunately, there are cryptographic protocols for anonymous voting, as well. I\u2019ll spare you the gory cryptographic details, but there are ways to elect a board, and for boards to vote control of a key, which can then be used to authenticate the actions of as large a business entity that you want. The creation of voting proxies, in other words.So, we\u2019ve taken care of common stock, and, because we know about digital bearer bonds, we can get a hint about how to do dividends: just present some token at the time of the dividend and collect cash. But, what kind of token do we use when all we have is a stock certificate? Clearly we don\u2019t want to redeem that at dividend time, do we?No, we don\u2019t have to. There is yet another class of cryptographic protocol called, weirdly enough, zero-knowledge proofs of knowledge. Using these methods, it is possible to hash a given bit of information and use that hash to prove to someone that you have that information in its entirety. No, it\u2019s not magic, it\u2019s mathematics. Using zero knowledge proofs on a stock certificate, you can prove not only that you are entitled to vote, but that you are entitled to collect dividends as well. In fact, you can use it to prove that you are a preferred stockholder, or that you are a holder of Class B instead of A, or anything else. Finally, the issuer can use these proofs to show that you have already collected a dividend, voted a stock, whatever.Oh. One other thing. Want to authenticate the books of a corporation for a given price earnings ratio without seeing the entire set? Want to authenticate an actual cashflow or asset holding for a debtor? Use the same zero-knowledge proof cryptography. Eric Hughes even claims to have invented a way to publish completely \u2018open\u2019, publicly available files, cryptographically munged, of course, which, when, a business entity wanted to prove a certain figure or set of line-items was in that otherwise encrypted information, they could use their unique key pair and a zero knowledge proof to show that the expenditure was in fact there. This could even be audited by a trusted third party, whose signature would be on the encrypted data. It just keeps getting weirder.Frankly, the reason we don\u2019t use zero knowledge proofs for bond payments is because bonds have finite duration. They all, with one exception proving the financial rule called a \u2018perpetuity\u2019, expire sooner or later. It\u2019ll probably be cheaper to just issue all the digital bearer certificates, principal and interest, en masse. It\u2019ll certainly be more financially reasonable from the standpoint of calculating the value of those certificates, as any student of fixed income mathematics will tell you. Simply issue all the certificates at once, and let them each be priced, and traded, accordingly.But getting back to equity, what about limited liability? Well, think about this for a minute. If, for instance, you have anonymous control of information, then the only thing you can do to the holder of that information in any meaningful sense is to discount the value of that information in the market. Remember, when we talked about reputation, we talked about reputation \u2018capital punishment\u2019, where a given cryptographic key pair is shunned, its economic value effectively zero.These days we do it with laws which say that a shareholder of a corporation is only liable for whatever money he invested into it, and, when the market says a stock is worthless, there isn\u2019t anything such thing as negative value.But, again, in cypherspace, we try to replace law with strong cryptographic software, and, most of the time, we get the same result. Funny how symbolic logic works that way. Call it Russell\u2019s revenge.In other words, if a shareholder spends money on a digital bearer certificate signifying partial ownership in an enterprise, and that bearer certificate, for whatever reason, is worth nothing, that\u2019s all the shareholder has lost. Since he\u2019s holding a certificate normally, his key is completely blinded, and he is thus anonymous. Only if he double spends the certificate is he unmasked. So, on a \u2018semantic\u2019 level, there\u2019s no other \u2018recourse\u2019 the market has but to the value of the equity certificates he holds. And, as any person who\u2019s holding shares of a fraudulently accounted company can tell you, that penalty is a good enough proxy for limited liability.Issuing digital bearer equity, or debt and cash, of course, is different, in that the key issuing the certificate must be known to have a good reputation, and have proven asset value in the case of collateralised debt. The holders of the certificates, though, don\u2019t need to be known at all for the system to work.Pretty cool, huh? With digital bearer equity, you can have publicly held business entities whose size limits are only driven by transaction cost, just as Coase\u2019s theorem says it should be, and, the shareholders can be completely anonymous.And, of course, as we all know by now, I claim, at least three times before breakfast every day, that digital bearer settlement will drop transaction costs by at least three orders of magnitude, which is why you have anonymous shareholders, and not though any desire for privacy per se. The reason we have registered stock ownership, remember, is because we have book-entry settlement. If we could do digital bearer settled equity, there would be no need to register securities from an economic standpoint, and, as I\u2019m also fond of saying, physics begets economics, which begets common law, which begets legislation and \u2018policy\u2019. You cannot run the causation movie backwards and get any money.So, no, I don\u2019t think that absolute deregulation of equities markets will be the only component of that cost reduction, though it may one of the most interesting effects of that cost reduction, no matter what its magnitude.Next time, we\u2019ll talk about digital bearer derivatives, but, after that, we\u2019ll come back to equity, and Coase\u2019s Theorem, and talk about micromoney, and its impact on the size of the firm. Stay tuned.Back to table of contentsDigital bearer derivatives are possible and, at the margin, digital bearer settlement is probably the technology most suited for the execution, clearing and settlement of derivatives.With the free-falling price of microprocessing, we\u2019re going to get more, and more complicated, derivatives, whether we want them or not, and, with ubiquitous internetworks, they\u2019re going to be digital bearer derivatives, because that\u2019s going to be the cheapest way to do them.So, before we start, let\u2019s review my (and Russell\u2019s) mantra that reality starts with physics and economics and ends with law, \u2018policy\u2019, and philosophy. Trying to legislate economics and finance, for instance, is one of the sillier things any sovereign, much less any religion, can do.I say religion here because, at some point in Christian theology, probably in deference to the Temple money-changing episode, interest was declared immoral, and, from that now-curious beginning, we get modern derivative transactions.Christian monarchs, in trying to outlaw interest, found that, no matter how hard they tried, they just couldn\u2019t, really. Eventually, in the late middle ages, they let religious undesirables, like Jews, be the money lenders and charge interest, but only after a ridiculous amount of creative denial.Muslim countries still outlaw interest today, for instance, and they go through an amazing amount of gyrations to keep their banks in business as a result. But, as Joe McCarthy used to say about communism, no one in, say, Saudi Arabia, dare call it \u2018interest\u2019, even today.Nonetheless, buried, deep in the glosses, palimpsests and marginalia, among all the shucks and jives that mediaeval sovereigns did to avoid the \u2018i\u2019 word, were some very interesting residents of the then-hand-illuminated financial bestiary. These critters really did look an awful lot like bonds, and, even, derivatives. Of course, they couldn\u2019t possibly be those unholy chimera, because they would be, quite literally, an abomination, a sin unto God Himself.Yet, in England, for instance, there was the ever-ubiquitous tally-stick, which started out being a poor man\u2019s depository receipt for taxes, with big notches for big money, and small notches for small, and split between the two counterparties to keep everyone honest. These sticks ended up, in rather short order, representing \u2018fictitious\u2019 transactions, and, more important, contingent claims, on some other asset, usually, bullion. The king would, instead of paying creditors in gold, pay them with tally-sticks, which would then \u2018mature\u2019 sometime later at the time of the bullion\u2019s eventual arrival in the treasury. These discounts were, of course, representing the, um, opportunity cost, of the money involved. Certainly not interest. That would be evil, of course.In fact, the considerable fortunes of the Knights Templar, and Hospitalar, too, were built on bills of exchange, issued to crusading nobility, who could, magically, deposit money in one place in Europe, and take it out of somewhere else upon their arrival in the Holy Land. \u2018Of course, Sire. Interest would be a sin. We can, however, sell you this bill of exchange at a discount, if you would should desire it\u2026\u2019You can account for a multitude of risks, if not sins, in the discounted price of that bill of exchange, including the obvious one of said Sovereign getting lost, bill and all, at sea on occasion.Not to mention creating bills of exchange for assets which never leave a country at all, thus avoiding taxes, even for the sovereign, at least in countries like England where the sovereign was accountable, even marginally, to the law. Bills of exchange were even created representing assets which might never exist, except if some contingency occurred. Guess what those were?Of course, most reasonably clueful bond folks will gladly haul out a trusty Fabozzi book or two and show you that, yes, a bond is, in fact, an option on some future cashflow that the bond promises, or, more precisely, that a bond is a bundle of options (interest coupons, remember?) on that future cash-flow, the granularity of the option\u2019s settlement date being either every quarter, if you feel discrete, or infinite, if you feel continuous and remember that most bonds are quite liquid assets. And this tide of financial calculus floats all boats, even a crusader\u2019s fleet mired in the middle ages, modulo the occasional Mediterranean storm.So, just like quarks, it seems that options and other derivatives are the very conceptual building blocks of the financial universe, and to ignore or restrict them is to do so at one\u2019s own economic peril, if not one\u2019s mortal soul.Thought about in those terms, of course, derivatives become as old as civilisation itself. Thales of Meletes (who was the world\u2019s first philosopher if you\u2019re in a medieval mood, and believe in the infallibility of Aristotle), answered the world\u2019s oldest taunt, \u2018if you\u2019re so smart, how come you aren\u2019t rich\u2019, by cornering the local olive oil-pressing futures market, monopolising those presses at harvest time. It not only made him rich, but famous, too, especially to everyone who\u2019s taken the nickel tour at the Chicago Board of Trade and walked away dreaming of being latter-day Hunt Brothers. Doing that ill-fated silver corner right, of course...Even before Hellenic Asia Minor, the owners of various grain depositories in Egypt, and even Babylon, raked it in one haircut at a time, purchasing grain before it was even planted, and flipping that imaginary grain, over and over again, until the harvest actually came in.This kept people from dumping grain in the streets at harvest time, certainly, because the prices were too low then, which is exactly the apocryphal event precipitating modern futures exchanges in places like Chicago, sans hydraulic monopoly. Those who forget history, and so forth.At the root of every derivative is a polite, and frequently mathematical, fiction. A fiction, which, if it turns to real prophecy, makes money. And, if you\u2019ve ever listened to any entrepreneur in heat spouting his latest funding pitch, you\u2019ll notice that predictions are pretty cheap to make. Moreover, an awful lot of of those predictions exist about any one event at any one point in time. Putting a value on that vast quantity of fiction might have been worth a Nobel Prize to some people who should now know better than to hang out with the likes of Mr Merriwether, but, more important, the process is driven by supply and demand. The initial price of futures, options, and other contingent claims, relative to the assets they make claims on, are, like talk, cheap for the most part.In addition, if the underlying asset of a class of contingent claims is volatile, it\u2019s a very good idea to settle and clear the purchase and sale of those claims as soon as possible, so people won\u2019t forget their sometimes large obligations, or can collect on their occasionally formidable returns. Which, oddly enough, is exactly what happens at options exchanges all over the world. Chicago, for instance, now has next day settlement, if I remember, and the trend has been towards even shorter settlement times, wherever possible.And digital bearer transactions settle fastest and cheapest.We need to look at something else about a derivative. All those conditions under which the contingent claim will be executed make things very complicated. You simply cannot have a modern derivative without computers and online real-time information. You need even more computational horsepower to model the damn things to see if they do what you want them to.This complexity, and the corresponding computational modelling requirements, has always been seen to be a bug. It\u2019s really a feature, though. The more you automate the process the better it works, and now, it can be automated up to and including settlement, scaring the wits out even the hardiest of souls.Already I can hear quite a few disgusted \u2018harumphs\u2019 out there, particularly from those of you who have seen formerly boring equity exchanges go limit-down like some CBOT pork-belly pit. You\u2019ve seen \u2018portfolio insurance\u2019 contracts blow up like so many World War I barrage balloons under the tracer bullets of illiquidity, causing markets to crash around the world.More to the point, we\u2019ve seen countless portfolio managers who claimed to be using derivatives, but who were doing nothing but speculation with large amounts of other people\u2019s money as if it were just another game of liar\u2019s poker.So, what does digital bearer settlement bring to the party? For starters, increased automation, of course. You can build an actual object, which lives out there on the network all by itself, waiting for the proper market conditions to be met before it executes. Furthermore, because of those extremely reduced transaction costs, you can do transactions at extremely small sizes. Well, sizes considerably less than the hundred-million, or even billion, dollar transactions required to make institutional-scale money in derivatives today.Because of this small transaction cost, you could actually create a bunch of micro-derivatives, set them loose, and see if they work. Nothing like small-scale working models to see what really works, certainly. You could even create, abomination of abominations, auto-mutating derivatives, following genetic algorithms, spawning slightly altered copies of themselves at settlement time with some of the proceeds. Fast, cheap, and out of control, indeed. It\u2019s enough to send you scurrying back to the monastery, sandals flying every which way\u2026Dragging us back to the human universe, with this kind of granularity you could also create a whole array of derivatives, representing a whole spectrum of possible positions, in smaller transaction sizes, allowing you much more flexibility in your financial plans. That\u2019s why derivatives exist, after all, to hedge your purchase or sale of something else against the unforeseen. At the expense of Godless speculators, of course.But, the primary problem with modern derivatives is that nobody is there on the other side of a desired trade at crunch time. Nobody there in the specific volume desired, and so, most hedging transactions, like the limit orders they are, go unanswered until the price is much lower, defeating the purpose of the derivative in the first place. Being able to execute a score of smaller transactions, instead of one giant one, at some intermediate prices in an avalanche of continuously falling prices gives a portfolio manager at least some comfort of dollar-cost averaging on the way down. Frankly, I expect that it will tame volatility as a result. It is precisely these precipitous free-falls with no answering bid, which cause the volatility problem in the first place.Oh. Right. Before I forget, the transactions are all anonymous, of course.So, how do you do all this fun stuff? Well, if you couple some bit of autoexecutable code with a digital bearer instrument, or a bundle of digital bearer instruments, you can execute all the pricing, and other financial data, requirements you want. Certainly a bit of XML, or Java, done right and properly authenticated, could do the trick, but, like most problems in financial cryptography, that trick is usually harder than it looks.Fortunately, what looks like an initial solution to the problem was presented at the 1998 International Conference on Financial Cryptography, FC98 to its friends, held this past February in Anguilla.X-Cash, a new transaction protocol by Markus Jakobsson of Bell Labs and Ari Juels of RSA Labs, is a bundle of digital bearer instruments which look for the terms they want, and when those terms meet with an acceptable offer, they execute, clear, and settle the transaction, all at once. If you\u2019re interested in this paper, and a whole bunch of others on the cutting edge of Financial Cryptography, you might want to look at the conference\u2019s proceedings, which are now available from Springer-V erlag. See www.fc98.ai for details.Of course, figuring out how, and doing it, are two entirely different things, and, frankly, X-Cash is only the first of what will necessarily be many attempts at solving the problem of autoexecutable, digitable bearer, derivatives.It\u2019s the same problem financial cryptographers fight every day: the problem of turning law and legal agreement into something much better: running software. Turning law, and apparently, thrill-addiction, into economic, literally physical, objects.Objects beyond the control of gamblers and, apparently, experts at liar\u2019s poker.Back to table of contents\u201cWhen the going gets weird, the weird turn pro\u201d, as Hunter S. Thompson once said, and the going, for this article, is going to get pretty weird, and in hurry.I\u2019ve taken you from digital bearer cash, through bonds and equity, and, last month, we ended up with derivatives, showing you could get as weird as you wanted, financially, and still use digital bearer settlement technology to make transaction settlement cheaper to use than book-entry methods. Probably by several orders of magnitude, or a thousand times, cheaper.Now we\u2019re going back to cash, microcash, to be exact, and, in the weird spirit of Mr. Thompson, we\u2019re going to talk not about Yage, or Ibogaine, or various reptilian pineal extracts, but about different kinds of hash.Well, okay, not hashish, exactly. Hashes, actually. And not anything even vaguely psychochemical, though the consequences of hashes might get pseudobiological sooner than you might imagine, and simply mind-bending to contemplate when we get there.The technology I\u2019m talking about here is that venerated mathematical algorithm and staple of computer science, the hash function.A hash function is something they teach you in your first year of computer science. Properly defined, a hash is a usually smaller, mechanically derived, fixed-length sample, subset, or just plain correlated bunch of bits related to usually a larger, and variable-length, bunch of other bits. A hash is something that allows you to mechanically check the integrity of data without actually examining the data itself. I can send you a hash of some computer program I\u2019ve written, so that you can run a hash of your copy, compare the hash you have to the hash I gave you, and, if they\u2019re identical, it\u2019s highly unlikely that your copy is different than mine.It\u2019s that \u201chighly unlikely\u201d bit that\u2019s important, here. For instance, if I hash a given bit of information and the result is 2128 bits in size, and the hash method is a one-way function which gives me a more or less random output, I have a 1 in 2128 chance of getting the same hash from some other bunch of data. Nice large number, that. Longer than the number of seconds the universe has been alive, even. Longer the total age of the universe if Mr. Hawking, and, more recently, experimental data, were both wrong and the universe is in fact closed.However, like all large numbers, including infinity, you can control those, um, astronomical probabilities if you want, and that control is at the heart of micromoney.If you reduce the output size of a one-way random hash function which uses a key (a \u201ccryptographic\u201d hash, in other words) you can control how much computation (money, in other words) is spent in the generation of a hash \u201ccollision\u201d, which is the name for happens when two entirely different blobs of data generate exactly the same hash value. Finally, if you use the right kind of hash function this way, and you find a hash collision, you can use that information to generate as many collisions like it as you want, with very little extra computation at all. Each one of those hashes are as hard to forge as the first one is.What you get is exactly the economics of minting a penny, only with bits, which are much cheaper to mint with. To mint a penny you have to literally build a factory, because that\u2019s what a modern mint really is. But, the next penny after the first one is barely noticeable in terms of marginal cost, and, so, it behooves you to mint as many pennies as possible to earn back the investment in your mint. That is, if you were selling pennies for a living, which governments claim they really don\u2019t do, though they book it on their balance sheets as seignorage income, nonetheless\u2026 Using hash collisions, as found in various the various micromoney algorithms out there including MicroMint from Ron Rivest and it\u2019s several progeny, and in Millicent by Mark Manasse, and in HashCash, a simple anti-spam protocol by Adam Back, that\u2019s exactly what you can do. You can take in people\u2019s money in one form or another and quite literally print them a positively huge amount of extremely low-value cryptographic hash-collision tokens, all while still turning a tidy profit. Seignorage for the rest of us, to paraphrase Mr. Jobs.The disparity in cost between the cost of \u201cminting\u201d the first token and minting the second is enormous, much greater than that required to mint the second penny in our example above. Remember, again, how long it takes to \u201cbrute-force\u201d a hash-string the size of 16 bytes, the size of this one: \u201c1234567812345678\u201d. That is, 128 bits divided by 8 bits per byte.Those 16 bytes, if handled properly, are certainly small enough to stick onto the most mundane events in cyberspace and pay directly for some service at the time it\u2019s rendered. All without an invoice, or clearing a check, or authenticating a credit card. and, without, of course, the finance and accounting departments backing them up.You can use those 16 bytes to pay for sending a piece of email. Or downloading a web page. Or, even, with enough 18-month turns of Moore\u2019s law and a stiff tailwind, routing a group of packets from here to there across the net.Imagine every router on the net buying bandwidth low and selling it high in a continuous, digital-bearer, microcash-settled, cash-on-the-routerhead auction for internet switching. In such a world, you don\u2019t even need network engineering, at least as we\u2019ve defined it today, because the market, and not some grand top-down design, will determine where the next router will go, without any human intervention in the purchase at all.\u2026Good. I see you\u2019ve drunk the Electric Kool-Aid, and the visuals are just starting to kick in. Great stuff, huh? Remember, I did warn you this was going to get weird in a hurry, and now, I believe, it\u2019s time for the weird to turn pro. Hold on\u2026But, wait, as they say in the more manic infomercials, there\u2019s more. As the internet becomes more and more ubiquitous, and microprocessors become cheaper and cheaper to make, the internet, defined as the TCP/IP protocol (or it\u2019s progeny, whatever that will be), it interlinks the most amazing places into a unified geodesic network, reachable through the air from local antennas, or satellite antennas, or just physically, by connecting you to the network with a wire or fiber optic cable. With an increasingly ubiquitous internetwork, you can sell even more and more mundane things this way. In the ultimate throes of this anarchocapitalist madness, everything can be for sale.Let\u2019s start with the obvious one first. Electricity. Already, they have demonstrated IP over electric lines in Britain. It is mostly trivial to do, especially over higher voltage power lines. Now, if you squint, you can see, with your newly dilated pupils, the very electrical appliances in your house, your microwave oven, your toaster, your teakettle, paying for their very electricity as they use it. With microcash.It\u2019s not that hard to do. I just showed you how, right? All you need is a hash-handling chip in the toaster a little smarter than the chip in that expensive \u201cgourmet\u201d toaster sitting right there, right now, on the shelf in the gourmet kitchen store down the street. I call these imaginary chips micromoney mitochondria, and with them you get the quasibiological effect of picomoney as processor food.If you remember the history of this century, and the first article in this series, it wasn\u2019t until checking accounts and hierarchical industrial networks became prevalent that lots of working folks stopped paying for their flat\u2019s electricity with actual coins in a meter somewhere on the premises. As we\u2019ll find out in the next article, that kind of \u201cunwinding\u201d of history is a very quick and dirty way to figure out how a bearer settled geodesic economy looks, if not how to implement it from scratch.To continue the weirdness, think about a world where an internet router can save enough retained cash out of operations to buy a new line to a less busy router. Or copy of itself. Or to sell itself off into \u201cslavery\u201d(?) to another router (which is buying a copy of itself, remember?) after losing too much money to stay in business anymore. Transported. Mr. Macawber, thy name is \u201ccypherspace\u201d. More time, running backwards, on Moore\u2019s law.Great acid, yes?But wait, there\u2019s more. If you can really do this with roads, paying at every intersection to get through it (money\u2019s cheap and small, remember?), does a, um, hierarchically organized force monopoly, a nation-state or it\u2019s smaller hierarchical subdivisions, need to \u201cown\u201d that road anymore? Shades of a favella in Sao Paulo, where the \u201cproperty\u201d lines extend into the middle of the street. Actually, not so \u201cproperty\u201d anymore, as the favella dwellers, along with their private piece of concrete to the middle of the street, now have secured real property rights to that concrete and the now-legally recognized road under it. So, are they charge you to drive over their little piece of micro-road? Stop this trip. Now. Please, make it go away\u2026 What\u2019s next? Paying microcash for water as it comes out of the tap? No, let\u2019s not think about the inverse of that particular plumbing operation, as it\u2019s fraught with images of misers, Gordon Gekko (as someone likened me to, after I started thinking too hard about this in public on the net), and of course, Scrooge himself, speaking of unwinding the clock to a more Dickensian universe.Paying auction prices for force? Landmines which won\u2019t blow up if you have the right key? And keep paying them? Mama told me not to come\u2026Okay. Let\u2019s abstract our selves back a level or two, and think about actual micro-economics for a while, both to cool off our blazing neurons, and to honor a promise I made last time. Early in this decade, Ronald Coase, formerly of the LSE \u2013 and now, I believe, at the University of Chicago, where all good Nobel laureates go to die \u2013 won, you guessed it, a Nobel prize in economics. Coase won the Nobel by hypothecating (without actual mathematics, a boon and comfort to innumerates like me everywhere), that firm size is directly related to transaction costs.That is, the cheaper the transaction cost, the smaller the firm can be. This has been proven, with actual data, to as much certainty as a fact of physics itself in the decades since the 1920\u2019s when Coase made this prediction.Well? Notice something? Some digital bearer protocols are really cheap to use. Some get us to efficient transaction spreads in milli-to-microcent range. That makes for really small \u201cfirms\u201d. Market actors. Proprietors, in other words.More to the point, if Moore\u2019s law reduces the price of switching enough to bearer-settle even the smallest conceivable purchases, like bandwidth, or road passage, or electricity, you end up a very strange universe, populated with a swarm of extremely competitive, dumb, randomly-behaving business entities motivated only by, as Dickens\u2019 Mr. Macawber said, \u201ckeeping income over expenditures\u201d. Curiouser and curiouser, to mix my Victorian fiction a bit.You don\u2019t just have an invisible hand, anymore.To steal the name of the Cato Institute\u2019s football team, you have an invisible foot. Something which can kick the pants off any large, vertically-integrated, hierarchically-organized industrial-era business now trying to combat its transfer pricing problems in order to compete with a market which, these days, values that business in pieces much more than it does the entire business, because, of course, the transaction costs are now low enough for those pieces of the old firm to sell their services directly to the market instead of doing it behind the \u201cfirewall\u201d of a company\u2019s chart of accounts.Diseconomies of scale, in other words. The world turned upside down. \u201cCats and dogs\u201d, as Bill Murray (who played Mr. Thompson once), \u201cliving together.\u201dThe weird have indeed turned pro.Cheers,\nRobert HettingaBack to table of contentsIn the final part of his series on the use of digital bearer financial instruments, Robert Hettinga moves on from the theory to explain how we can actually deploy these instruments.You couldn\u2019t have gotten through the capital market upheavals of the 1980\u2019s, much less Oliver Stone\u2019s movie Wall Street, without bumping into Sun Tsu, the ancient Chinese military thinker who, for our purposes, is best summed up by the Stonewall Jackson maxim, \u2018Hit \u2018em where they ain\u2019t\u2019.Among other things, Sun said that a small army should look large, a large army small, that one should attack when the enemy retreated, and retreat when the enemy attacked. You can almost hear P.T. Barnum muttering, somewhere, \u2018Never give a sucker an even break.\u2019 Mao, accommodating his intended audience with many simple single-worded exhortations and lots of exclamation points, recapitulated Sun\u2019s logic and won his wars in much the same way.I propose, in less florid terms here, to think about the deployment of digital bearer transactions in that same spirit. That is, start where book-entry settlement ain\u2019t, and move on from there. With that fulcrum, we can lever complexity of digital bearer settlement against itself, and start \u2018surfacting\u2019 the existing glops of book-entry markets into smaller, more geodesic ones.If you think about it, we face almost the same task that Copernicus, Kepler, and Gallileo did when they removed the earth from the centre of the universe. Like Kepler, we\u2019re going to use the simple mathematical ellipses of financial cryptography to replace the financial and legal Ptolomaic epicycles industrial economies had to build on top of their electronic, but still human-switched, information networks. We want to move money across these new geodesic networks we\u2019ve built in cypherspace without the financial shovelware that currently passes for internet transaction settlement. If, of course, that\u2019s what you can call the out of band settlement of internet-executed transactions, which is what internet credit card and even check transactions really are.I\u2019ve already spent the last six months telling you, with a broad brush, how to apply digital bearer transaction technology to every security imaginable. This article is about specific applications of digital bearer transaction technology to problems people have told me about. It\u2019s an effort to jump-start your own thinking about digital bearer settlement in your own business.Last November I went to to London, where, when I wasn\u2019t speaking to the E-Finance Forum, or to someone in the City, and, ultimately, to the Adam Smith Institute\u2019s conference on internet trading, all thanks to Duncan Goldie-Scot, I spent two evenings in a Kensington Australian wine bar, thinking about a couple of capital market bearer-settlement ideas with a few of the conference\u2019s participants.After we\u2019re through with those two, I\u2019d like to talk about micromoney mitochondria some, and an effort underway at DARPA to make the internet \u2018smarter\u2019.The first example, and the easiest to think about, is an already existing bearer-held Swiss hedge fund. Of course, bearer in Switzerland (or the BVI\u2019s, or wherever else) is quite different from the bearer I\u2019ve been talking about the past few months. Bearer shares are typically registered with a trustee of some kind, but that registration is blinded from the portfolio manager. So, imagine, in the spirit of my previous \u2018Bill and Ted\u2019s excellent mutual fund\u2019 scenario, we created Bill and Ted\u2019s excellent bearer hedge fund.That is, this existing hedge fund puts up a blind-signature certificate mint, right in the same room with their existing web server. When people pay the server digital cash, they are issued a digital bearer certificate representing assets in the fund. Right. What\u2019s digital cash? Okay, so we don\u2019t have digital cash. So we use checks, or bank wires. Somebody goes to a web page, is issued a non-transferable provisional certificate right off the bat, and, when the wire or cheque clears, they can come back and get real bearer certificates in exchange for the provisional one.If done right, such an automated customer service scheme will probably be much cheaper the way it\u2019s done now, even with the added complication of transaction latency, which is there right now, anyway. Whenever digital bearer cash is available, handling shareholder exchanges will be even that much cheaper. Again, as a portfolio manager, you don\u2019t ever know who your customers are, anyway. The trustee administers your customer\u2019s money in the logical opposite of an American blind trust. Instead of the customers not knowing what the portfolio\u2019s invested in, though, the portfolio manager doesn\u2019t know, legally, who\u2019s invested in his fund. Which is the rub.Notice my use of the word legally. There\u2019s this whole industry of fund trustees in Switzerland, using lots of lawyers no doubt, all devoted to administering those blinded lists of shareholders in bearer funds. I would even venture to guess that my digital bearer version of Bill and Ted\u2019s excellent Swiss bearer hedge fund is illegal, in order to perpetuate this cottage industry, though it might be fun to push the legal envelope a bit, to see how strong it is. We\u2019re still figuring it out.However, I would bet that if using digital bearer certificate servers lowered the trustee\u2019s customer service by three orders of magnitude, they would have to adopt the technology, and that\u2019s exactly how to sell this idea in Switzerland. Portfolio managers would much rather just run their money, without having to think about such things for the time being. Save that box in Bill and Ted\u2019s machine room for some later regulatory regime and a few more iterations of Moore\u2019s law.Which brings me, again, to the most important point I\u2019ve been making throughout this series of articles. There\u2019s not a cryptoanarchist cypherpunk in the world who wouldn\u2019t jump at doing this particular contract. If the blind signature patent was clear, which we\u2019ll talk about in a bit. But, unfortunately, those people are jumping at this kind of work for entirely the wrong reasons. It\u2019s almost as if they think that just because they can put up a digital bearer-settled fund, that in and of itself will sell the fund to investors.Remember again, slipping the surly bounds of earth is all well and good, but it\u2019s coach fare from Kitty Hawk to Dayton which put people into the air. Nobody\u2019s going to invest in \u2018Bill and Ted\u2019 s\u2019 excellent Swiss bearer hedge fund at all unless they can make more money there than they can at home. Part of that present advantage, is, of course, taxes, and, probably, more than one case of investing ill-gotten gains, defined how you will in the jurisdiction of the money\u2019s origin.However, the market for financial privacy is infinitesimally, ludicrously, small when compared to the market for cheaper transactions in general. And, frankly, the Swiss trustee, much less Bill and Ted themselves, are profitable enough already with the legislated privacy they already have, or they wouldn\u2019t be in business as it were.No, what will sell this contract to some lucky financial cryptography systems integrator is lowered cost of customer service, pure and simple. Again, I claim, issuing bearer certificates to the net is the way to do this, even if those certificates are purchased the old fashioned way, with cheques, bank wires, or, given the location in question, suitcases full of cash. Again, we\u2019re eventually looking at a world where digital cash will be involved, and, when that\u2019s possible, the whole idea of safe jurisdictions like Switzerland may end up an interesting footnote in financial history. If they don\u2019t do it in Switzerland first, of course, and get a technological jump on the rest of the world\u2026Now, lets look at the second deployment idea. This one is one where you\u2019d least expect it, in the heart of the institutional clearing system, literally under EuroClear\u2019s nose. Big institutions in Europe decided they needed a place to function for the myriad European exchanges in the same way that the Depository Trust Company does for the New York Stock Exchange. They hired J.P. Morgan to play that role, and called the system EuroClear. The problem is that the costs of the system are such that smaller institutions can\u2019t really afford to clear their trades there. A bunch of us figured, over some nice Australian Cabernet (and, um, kangaroo), that if you applied the model of digital bearer underwriting we talked about in July, and used Morgan as the institutional custodian for a jointly-held aggregate account, you could underwrite a bunch of closed-system bearer certificates against those shares and money, which a \u2018club\u2019 of smaller institutions could use to instantaneously clear trades against each other. Since this \u2018club\u2019 of smaller institutions would all be known to each other in the aggregate, all of the \u2018know your customer\u2019 rules could be adhered to, and, yet, the system could still, paradoxically, settle trades anonymously between club members.The result would be extremely lowered transaction costs between the club\u2019s members, and, of course, instantaneous clearing and settlement. Something which might even be interesting to the much larger members of EuroClear to use someday, we figured. Maybe, someday, anonymity in settlement could translate to anonymity in execution itself\u2026 This rather insidious application of digital bearer technology, at the very place where one would expect the next generation of book-entry technology to be deployed, is exactly what Sun Tsu, Stonewall Jackson, and I mean by \u2018hit \u2018em where they ain\u2019t\u2019.In other words, deploy digital bearer settlement where book-entry settlement, well, ain\u2019t, yet, and don\u2019t fool around with attacking the Maginot Line of the existing book-entry-settled capital market infrastructure until the battle\u2019s already over. Dropping a few geodesic smart-mines on their escape routes, like we did in the two examples above, would work perfectly.For the final deployment example, I\u2019ve just learned about a project which which leads me to believe that the era of cash-settled switching-level auctions of internet bandwidth is not too far off after all. DARPA, the Defense Research Projects Agency, the very agency which funded the original internet, has hired firewall/security/spook-crypto company Trusted Information Systems (now part of McAffee\u2019s and PGP\u2019s parent, Network Associates, Inc.), to build a so-called Active Network, a technology where internet packets include code which tells the router where they want to go.This is instead of a router needing increasingly larger route-lookup tables, requiring, you guessed it, hierarchical networks with big fast routers at the top-level \u2018backbone\u2019. Moreover, these packets will be cryptographically signed, to prevent their execution instructions from being tampered with.All of this is so the network can be more, you guessed it again, geodesic in structure and thus cheaper to use. Will wonders ever cease? So, avoiding geek-vs-spy conspiracy theories and the odd technological ad hominae against TIS in the expectation that the market requirement for cryptographic open source code solves the cypher-paranoia problem, this executable-as-network-packet idea looks like exactly like a running-code proof of my assertion that attaching micromoney to the information at the packet level is completely within technological reason. Welcome, one final time, to the future.Which brings me to a final hobbyhorse. Most of the problems, I think, with the deployment of digital bearer transactions are legal ones. Oddly enough, it\u2019s not even laws and regulation against bearer transactions themselves, which, on the face of it, are quite considerable. Even these regulations are completely surmountable given enough cost-reductions and increased profit margins. Law follows economics, in other words.The primary problem, as I see it, is the effective control, by the nation-state, of intellectual property. I tend to be extremely Coasian when it comes to my definition of private property. I believe that once information is on my hard drive, decrypted, and in a form useful to me, that\u2019s about as private as property can possibly be. It\u2019s mine. I can do anything I want to with it including sell it. Furthermore, as the internet becomes more and more location independent, you can\u2019t keep me from selling it.I challenge anyone to enforce an intellectual property patent against me in an environment where anything, encrypted or not, watermarked or not, can be auctioned to the highest bidder, in usable digital form, for digital bearer cash. Cryptolopes, or electronic software distribution, or stenographic watermarks, even custom-compiled executable code and escrowed funds, do not add a whit of value in such a world. As an inventor, much less a seller, of digital goods, there is simply no reason to increase your transaction costs, and, correspondingly, reduce your profit, in order to control your digital product once it has been sold to someone. Just auction your product off to the highest bidder and be done with it.The economics of the geodesic auction market says that if you have the first information of a specific type, you will make more money on that information than anyone else. Yet, before we can get there from here, there is a rather juicy irony involved. Because you need to cash digital bearer certificates into book-entry money sooner or later, the patents for digital bearer certificate technology are completely enforceable at the point of conversion, the gateways between the cypherspace and meatspace.As I\u2019m fond of saying, bankers and corporation presidents, as very creatures of the law itself, don\u2019t like to get sued for patent infringement anymore than they like to go to jail for financial crime in general. In fact, I think that patents on digital bearer transaction technology are so enforceable that they are completely obstructing progress in digital bearer settlement right now.I would even go so far as to say that none of the current holders of digital bearer patents, (and, frankly, most of the current crop of people who want to control those patents in the future) know the least thing about financial markets and about how to market digital bearer transaction settlement to the financial community.Well, actually, there is one person who might be the exception to that rule, and that\u2019s Scott Loftesness, the recently appointed President of DigiCash, Inc. DigiCash, you will remember, was founded by David Chaum, the father of modern financial cryptography, and is the company which holds the blind signature patent, the original patent on anonymously-transferable digital bearer certificates.Unfortunately, after finally getting control of his company\u2019 s intellectual property, Mr Loftesness now has to pay down a mountain of debt, mostly in failed bridge loans to venture capitalists, all of which are secured by those patents.In my opinion, this debt may already exceed the estimated experimental licensing revenue remaining in the useful lifetime of the patents involved. And, given DigiCash\u2019s failure to find a market for their digital bearer certificates, licenses for experimental purposes is about the only alternative left.DigiCash is already in Chapter 11, and, unless someone can see a way to market for that technology that others haven\u2019t seen already, the firm may not re-emerge.And so, a group of us are looking at putting together a research-based syndicate to hold the DigiCash patents, or at least the most important internet-only pieces of that portfolio, in order to keep it from being tied up for the rest of its usable lifetime. The idea would be to license it for research purposes to all comers, and only when bearer certificates using the patented technology were exchanged into book-entry assets would a modest royalty accrue to the syndicate membership, payable at the gateway between the internet and the proprietary financial networks.Syndicate members would get unlimited use of the patent, or at least a reduced royalty rate, as further remuneration for their investment. As much as I hate the idea of path dependency, I think that there are only so many neurones which any one company can apply to the problem of digital bearer settlement. If one company controls a critical bit of technology, the chances are too great, in a still incredibly experimental marketplace, of a dog in the manger preventing anyone else from making something happen.Internet years are too short for the rules on patent duration as it is without financial cryptographers trying to be software developers, or banks, or anything else; something I\u2019ve railed about on the net many times in the past few years. Since invalidating the very idea of software patents anytime soon is not reasonable (to the contrary, even business processes seem patentable at the moment, one look at the Walker Digital patent farm tells you that much), it might be worth figuring out a way for cryptographic protocol inventors to get paid for their intellectual property without holding up research in the field for everyone else.While I think forming a syndicate to hold those patents, or a royalty association, something like what ASCAP does for songwriters, is the way to solve the problem, I\u2019m certainly open to other suggestions.So, there, after about six months, you have it. Not only have I discussed the enormous possibilities of the emerging world of digital bearer transaction settlement, but I\u2019ve shown you how to do every financial instrument you can ever imagine in digital bearer form, using ubiquitous geodesic internetworks as your marketplace. All of this, hopefully, for significantly less cost than it would be to drag all those book-entry audit trails behind you all over the internet. I certainly enjoyed this series of articles, and I hope you did, too.Back to table of contentsThe weeks running up to this year\u2019s Financial Cryptography Conference (FC99) were really amazing, especially if you\u2019re a fan of digital bearer transaction settlement.First, there was a lot of excitement about the forthcoming disposal, out of bankruptcy, of the DigiCash patent portfolio. This includes David Chaum\u2019s blind signatures, which are useful, as you remember, for macro-scale cash, bonds, and even equity.Mark Briceno, a former DigiCash employee now turned dealmeister, said at FC99 that he has put together a syndicate which includes all of DigiCash\u2019s former licensees, and that upon acquisition, the patents will be royalty-free for open source and experimental use. Unfortunately, two of his promised closing days since have come and gone, however.Yet, I recently talked to Nicholas Negroponte at the joint MIT Media Lab/USENIX Things that Think / Embedded Systems Workshops. Negroponte, the Media Lab\u2019s founder, is also, hopefully, the final Chairman of DigiCash, and has arrows in his back to prove it. He was talking to me quite nicely about Zero Knowlege Systems, the primary sponsor of Briceno\u2019s syndicate effort, so maybe something is in the offing. Finally.Another wierd thing happened to me the week before the conference, when I got a query from a local investment banker, representing a public corporation with $5 million in cash and $7 million in market value. He proposed creating a company by buying both DigiCash and DEC/Compaq\u2019 s Millicent technology. I went downtown to visit him, and said no, that wasn\u2019t a good idea, but that doing some kind of publicly-held financial cryptography patent royal trust, a cross between an oil-patch deal and Buffet\u2019s Berkshire Hathaway, might be a fun thing to try. His firm didn\u2019t like the idea, but I still think it\u2019s a good one, and, upon leaving, I felt like I was resigned to evangelizing this stuff to deaf ears forever.But, that very night, things changed enormously. I got an email message that night from Ron Rivest, sent to John Gilmore and Paul Kocher and cc\u2019d to me and Adi Shamir. Rare company, indeed.Ron Rivest and Adi Shamir are, of course, the R and S of RSA, the DC3 of the public key cryptography business. Rivest, himself of MIT, is responsible for RC4, the cipher behind the lock that appears on your browser when you encrypt your credit card number to Amazon and purchase a book.In addition to co-inventing RSA with Rivest, Adi Shamir, from the Weisman Institute in Israel, has blown up more ciphers, more smart-card hardware, more supposedly secure commercial cryptosystems than practically any other man alive.John Gilmore is one of the founders of Sun Microsystems, one of the founding board members of the Electronic Frontier Foundation, and a founding cypherpunk. For someone who\u2019s stirred up so much trouble, and with all the right people, he\u2019s one of the kindest folks I\u2019ve ever met.Gilmore\u2019s also the man who funded, for $250,000 of his own money, a special-purpose cryptographic supercomputer humorously called \u2018Deep Crack\u2019, which broke the US Government-mandated 56-bit Data Encryption Standard, or DES. In less than 3 days. At an amortized cost per key of about $360.Paul Kocher, a well-respected cryptographer with several famous cryptosystem attacks of his own to his credit, was the man who designed and built \u2018Deep Crack\u2019 for Gilmore, and who now runs it occasionally, on behalf of the EFF, under whose auspices the DES effort was undertaken to begin with.DES is ubiquitous in finance: $3 trillion a day in currency transactions are encrypted using DES, for instance. Breaking DES, in so short a time, and especially for so little money, was an act which sent shivers up the spine of bank security professionals everywhere.It\u2019s even worse than that. 56 bits, the largest keysize possible with DES, is also the largest key-size allowed for export by the US government. Not a good place for the financial community to be in, technology-delaying \u2018exemptions\u2019 for financial cryptography aside.So, into my email inbox arrives a message by and for the aforementioned cryptographic pantheon. The message says, quite simply, that just by designing and building a special-purpose machine to brute-force-search the DES keyspace, Kocher and Gilmore had inadvertently constructed a prototype MicroMint machine. They had, without knowing it, built a machine which would mint money in very, very, small denominations. A production machine would start at one thousandth of a dollar and go down from there.I just sat there, stunned. I thought it would be years before something like this was going to happen. Digital bearer microcash has always been my \u2018way out there in left field\u2019 scenario, something I used to scare old people, children and politician with. I joked about routers that would use micromoney to buy bandwidth low and sell it high, saving enough out of operations to buy a copy of themselves. Or about toasters which would buy their electricity out of the wall. Or cars which pay tolls to use neighborhood streets and roads. Privately owned streets and roads, much to the joy of libertarians everywhere.Rivest apparently cc\u2019d me on this amazing email message because I had talked to him over lunch, almost two years ago, about commercializing MicroMint someday.So, in my reply to this email message from cryptographic Olympus, I effused, at typical great length, about my underwriting model for digital bearer settlement, and how, since the prototype was already there in the form of \u2018Deep Crack\u2019, it was probably time to talk about building a production version of a MicroMint machine. Somehow. An actual financial cryptography supercomputer, probably costing several million dollars or more. Somehow.Since everyone but Gilmore was going to Anguilla the next week for FC99 anyway, something I\u2019m sure Rivest knew when he\u2019d sent the email, I proposed that all of us talk about it there.Immediately, I started emailing all the other people I thought I needed to make this work. Fortunately, they, too, were almost all going to Anguilla for FC99.The very first person I wanted sitting on my shoulder for a reality check, Jiminy to my Pinnochio, was Paul Guthrie, VP of Advanced Technology at VISA. Paul has been a long-time subscriber to my all digital commerce and financial cryptography lists, and has gone to every one of my Financial Cryptography conferences since the beginning.Paul and I have talked extensively in the past about what it takes to effect a withdrawal of digital bearer cash from the automated teller network on to the internet, instead of a mere purchase of digital bearer cash with a credit card. Even more important was solving the problem of deposits from the net, which, oddly enough, is not intractable at all. Since VISA has it\u2019s hand in practically all funds-transfer and payment-systems networks, especially, for my purposes, the PLUS ATM network (Cirrus is owned by MasterCard), Paul\u2019s a very good person to know, and we have a lot of fun talking about this stuff.It dawned on me, as we approached the conference, that the only two people I really needed to talk to to see if this was technologically possible, better, to have talk to each other, was Paul Kocher, the builder of \u2018Deep Crack\u2019, and Paul Guthrie, who could figure out in detail what integrating a MicroMint machine with the rest of book-entry financial system meant. Everyone else was just window dressing.Did I get some amazing window dressing. I ended up with a dinner, for 17 people, at a nice French resturaunt just down the beach from FC99\u2019s first-night cocktail reception. I just went around the room towards the end of the reception, grabbing everyone I thought I needed and hauling them down the beach to dinner.Besides Duncan Goldie-Scot, of this newsletter, this crypto-herding exercise included people like Nicko van Someren, the founder and CTO of nCipher, a British company which makes cryptographic accellerator hardware for internet commerce; Adam Shostack, cypherpunk turned CTO of Netect, a network security software company; Fearghas McKay, former British Internet Society chairman and now CTO of MIDS, an internet traffic-analysis company; Derek Atkins, of PGP 3.0 fame and now of Lucent; and Jason Cronk, owner of a large Florida web-hosting firm, and a big advocate of cash-settled geodesic recursive markets for intellectual property.I didn\u2019t grab Ron Rivest himself and shove him down the beach towards dinner like I did the rest, because as someone with lots of people wanting his attention I figured he would be busy. But, to my surprise, after we had all sat down to dinner, Rivest and his wife wandered in for dinner on their own, and they came and sat with the rest of us. I was very happy.So, after sitting all the right people together so they could talk to each other afterward, I banged on a glass for attention and got everyone caught up on Rivest\u2019s email message about the possibility of \u2018Deep Crack\u2019 being used to run MicroMint, kicking off an excellent dinner conversation on how to make an internet bearer microcash system happen.It turns out that while it may be a little complicated to make changes to the ATM system to allow deposits from a third-party machine in much the same way that you can make withdrawls now, you can use other systems like ACH to get the same result, and, in fact, most of the problems faced by a nacent MicroMint are regulatory. People like Paul Guthrie kept beating me over the head with Federal Reserve Regulation E, which, as currently written, prevents digital bearer cash from being treated the same way as paper bearer cash is.At this point I said something fateful. I said, \u2018If you guys can design a system which allows me to withdraw money, in microcash, from my bank account over the internet, and to deposit it later the same way, I\u2019ll get you guys, Ron (Rivest), Paul (Kocher), Paul (Guthrie), and Nicko (van Someren) in front of Alan Greenspan himself if I have to, demo it, and get Reg E changed.\u2019 Dead silence. Followed by skeptical laughter all around.Fortunately, I\u2019m still immune to this stuff. I\u2019d been there before, and I consoled myself with my favorite Schopenhauer quote, the one about how new ideas are first ridiculed, then fought violently, and then declared obvious.Yet, Greenspan, a not-so-closet libertarian, if not a closet \u2018Austrian\u2019 economist, loves the idea of private currencies like we would be doing with this MicroMint box, and, if talked to in the right way, he would probably become an advocate for a revision of Reg E to account for digital bearer cash.So, for the next day or so, I couldn\u2019t get this idea out of my mind. It was dawning on me that, because of developments with the DigiCash patents, and especially with this news about MicroMint, that there was simply no scientific or technological obstacle whatsoever to the underwriting of internet-based digital bearer instruments, not just microcash, not just \u2018macro\u2019cash, but, someday soon, debt, equity, and any derivative thereof.It\u2019s time to do some actual finance with all the financial cryptography. Later in the conference II came up with a company name for an internet bearer underwriting corporation. I called it, oddly enough, the Internet Bearer Underwriting Corporation. The fact that the corporation\u2019s initials sound like \u2018I-Buck\u2019 never entered into my mind.Two weeks ago, I went downtown to the lawyers who incorporated my last company and got the ball rolling. We registered the Internet Bearer Underwriting Corporation in Delaware a week later, and I\u2019m actively seeking officers, a board of directors, and, of course, shareholders. I have signed the incorporation papers, so I guess it\u2019s official.I\u2019m hoping to turn the key on all of this, to go live to the net, by the first week of July, 2000. That should allow whatever Y2K hysteria is left to transpire, certainly, but it\u2019s mostly because I don\u2019t think I can raise money and get anything built faster than that, anyway. And, frankly, it will probably be later, \u2018internet years\u2019 or no.I want IBUC to underwrite, after 5 years, $30 billion a year in internet microcash, in bearer form, at an average front-end load of 85 basis points. That\u2019s how the investment hockey-stick looks, anyway. $30 billion is a scary number in the technology business, but it\u2019s not too scary in finance remember that $3 trillion-a-day currency market.So, wish me luck, everyone.Back to table of contentsAt the end of last month I began building the revenue model for IBUC, the Internet Bearer Underwriting Corporation, which I founded here in Boston, and wrote about in the last issue. You can \u2018back\u2019 into some pretty interesting numbers without doing a market test at all, something which is, frankly, impossible anyway, given the mostly unknown, and not insignificant capital cost of building the MicroMint box, for instance. First, you need an adoption curve. Typically, people in marketing use the logistics equation\u2019s curve. In our case, however, we had some real data, the historical and estimated future dollar volume of internet retail transactions, which, of course, are mostly credit card transactions. We got some from a fairly reliable source. These adoption curves start in the small hundreds of millions in 1995 or so, and, from 1996, they grow at a compound annual growth rate of about 100% or so over the last four years, into the tens of billions for this year. Using this time series, we now have as good a guess for an adoption curve as any for a proposed digital bearer payment technology. If something proves useful, it\u2019ll probably be adopted this fast, and if done right, probably won\u2019t be complementary or competitive with existing transaction types, thus increasing the dollar volume of internet transactions over time. So, we can take this normalised curve and tweak it for all transactions executed by mulitiplying the credit card number by some factor, or, we can use it fractionally, like we did, to gin up some numbers for a specific product. Again, you can back into a fairly nice approximation with actual data. Every year, the Bank for International Settlement publishes a report showing the global transaction counts and dollar volumes by each payment method, cash, credit cards, checks, wire, ACH, and so forth. Since virtually all transactions on the internet are executed with credit cards, if an meatspace-equivalent-risk digital form existed in digital bearer form, it\u2019s safe to assume that we might apply the meatspace ratio of that method to credit cards to the cypherspace credit card number. Of course, that doesn\u2019t work so good for MicroMint-based microcash, which doesn\u2019t have a meatspace equivalent, but it\u2019s a good start. So, use that factor times whatever market penetration number you think you can justify, and you have, voila, a revenue curve. So, now, we need an upper bound to all this unbounded enthusiasm. My CFO and I were wondering how we were going to do this, when, we remembered that we were in the underwriting business. After rooting around a bit, it dawned on us that Goldman Sachs had just filed a shelf offering for their IPO, so we went to the Securities and Exchange Commission\u2019s EDGAR website to go look at it. Right up there, on a metaphorical movie screen, was about a megabyte of information on how to be an underwriter, including the size of the global capital markets, Goldman\u2019s underwriting revenue and profits, and a whole host of other goodies. When we got through reading this, we were swinging from the lamp posts.Cheers,\nRobert HettingaBack to table of contentsRegulators have not even started to get to grips with the challenges they will face in the wired world.In the summer of 1996, about a year after a bunch of us started the Digital Commerce Society of Boston, friend and fellow ex-cypherpunk Perry Metzger, formerly of Bellcore and Morgan Stanley and now owner of Piermont Systems (www.piermont.com), a well-regarded financial computer security integrator, came up from New York to talk to us about how financial cryptography would allow the issue, on to the net in digital bearer form, of any financial instrument we could conceive of. Perry discussed some whimsical \u2018gold-denominated Burmese opium futures\u2019, for which he named his talk that day.Implicit in that title, of course, was the point that government financial regulation, and, someday, governments themselves, were somehow \u2018optional\u2019 in a world of totally anonymous, but still non-repudiable transactions.Eric Hughes, one of the co-founders of the cypherpunk cryptography enthusiasts\u2019 list, went even further in his thinking. He liked to say that, in imagining a world with ubiquitous internetworks and strong cryptography, it helped to \u2018think like an illegal actor\u2019. Imagine, in other words, a world of ubiquitous recreational vices, murder-for-hire, and all the other staples of any good mob novel: all of it available, with impunity, everywhere, all the time, on the net, for a price. A frankly romantic vision, now, in hindsight.If anything, recent history seems to show otherwise: all law seems to be enforceable everywhere, all at once.For instance, several years ago a gentleman was extradited to Tennessee and convicted for the pornographic contents of his California computer bulletin board.Within the last few years, two members of the cypherpunks list themselves have been convicted, and sent to jail, for making public threats to specific federal judges and officials, both involving completely hypothetical digital-cash-settled assassination auctions. Hypothetical, of course, because there isn\u2019t a working digital cash system, among other things. One of those convictions seemed, to me at least, more for a form of tacky political performance art than any physical threat to a judge, though the judge apparently thought otherwise.And, of course, we should expect equivalent international incidents of these kinds, sans theatrics, sooner or later. After all, almost all countries have extradition treaties with each other for violent crime, and most at least for fraud, if not necessarily for other financial or tax crimes. If the aforementioned gold-denominated Burmese opium futures were illegal in one place at all, current legal opinion holds, cyberspace makes them extraditable, and thus illegal, everywhere, no matter the server\u2019s physical jurisdiction.Yet, cryptography itself, the thing which could so romantically change this state of affairs, is still being \u2018decriminalized\u2019, and, recently, it has been done so an astonishing rate. Within the last month alone, Canada, Germany, and Britain, even France, who virtually outlawed cryptography of any strength whatsoever, have all seen the writing on the digital commerce wall, and have announced, grudgingly, that they will explicitly \u2018decontrol\u2019 cryptography in some fashion or another.As people on the net have known for years, nation-states can now see that digital commerce means financial cryptography, and that financial cryptography must, of necessity, be the strongest possible cryptography available if it is to be of any use at all.In other words, nation-states understand one of Hettinga\u2019s many \u2018laws\u2019 of digital commerce: Financial cryptography is the only cryptography that matters.Even national security is taking a back seat to commercial \u2018signals intelligence\u2019. Last month, the US Congress found itself the scene of the most amazing spectacle, with the National Security Agency claiming, of all things, attorney-client privilege in order to keep from discussing Echelon, a 40-year-old \u2018I\u2019ll spy on your people if you spy on mine\u2019 co-operative eavesdropping arrangement between the intelligence services of most developed nations.Yet, the primary reason for such sunshine in dark places is not politics at all: it is business.In the ultimate swords-to-ploughshares exercise, Echelon data, obtained at enormous taxpayer cost, is now being used, evidently, to give US companies an economic advantage in their international business negotiations. Why? Because, of course, other countries do it for their citizens. France, with its ironically strict cryptography controls, has been repeatedly caught informing companies like Bull and Airbus about the results of its operations against companies like IBM and Boeing.Access to Echelon data seems to have even been offered by David Aaron, the Clinton administration\u2019s erstwhile roving cryptography ambassador, as an inducement for countries like Australia to sign on to the Wassanar \u2018 arrangement\u2019, an \u2018informal\u2019 agreement among a large number of industrial nations to promote so-called \u2018key-escrow\u2019 encryption, a form of cryptography where the government has a copy of everyone\u2019 s encryption keys. Key-escrow, or Government Access to Keys (GAK) to its foes, is, of course, mutually exclusive from digital commerce, and GAK\u2019s various US legislative incarnations have been steamrollered accordingly.My guess is that the Jospin government finally figured out that \u2018infowar\u2019, when it happens, will occur not between nation-states, but between businesses, and that the best way for France to protect her businesses, and thus her tax base, is to allow their use of the strongest possible financial cryptography available. Which, given the eventual use of financial cryptography on the internet to hide private financial assets from confiscation by nation-states, makes for a marvelous paradox indeed.So, what about that romantic vision of \u2018cryptoanarchy\u2019 , as Tim May, another founding cypherpunk, called it?Remember, most of the acts that we call criminal today, especially those involving violence and property, still happen in \u2018meatspace\u2019, the abode of humans, and not \u2018cypherspace\u2019, the abode of encrypted electrons.Meatspace, as anyone who has seen (or suspected) a surveillance camera knows, is becoming more and more supervised with every iteration of Moore\u2019 s Law. A digital CCD video camera, ready to be plugged into the internet as a web-cam, sells for less than $100 these days. Thus, it\u2019 s no surprise that an overwhelming majority of this surveillance is the completely private supervision of completely private property to prevent that property\u2019s theft or damage. Yet, people don\u2019t complain about this ubiquitous videography nearly as much as they would if a government did it. In fact, except for ostensibly personal spaces like restrooms or employee locker rooms, people don\u2019 t complain at all about private supervision of private property.As we encrypt our digital property to protect it in \u2018cypherspace\u2019, making it more invisible to nation- states, we increasingly supervise our physical property to protect it in meatspace, making it more visible if you will, all without requiring a nation-state to do it for us.More important, we increasingly enforce those property rights with private means: security guards, for example, armed or otherwise. That\u2019s because, like everything else we buy, it is increasingly cheaper to buy private goods and services than \u2018public\u2019 ones, even force.Put another way, direct payments, priced in auction markets, are increasingly cheaper than transfer payments, at a calculated price, between various accounts on a firm\u2019s, or a country\u2019s, books. Professor Von Mises and his calculation argument against socialism strikes one more time.Moore\u2019s law accelerates this by dramatically reducing transaction costs, both in obtaining and processing necessary market information, first with cheap telephony, personal computers and faxes, and now with email and the web, but also in reducing the execution cost of those transactions themselves, with SSL and digital signatures for credit cards and checks, and, eventually, the clearing and settlement cost of those transactions as well, with digital bearer financial cryptography.The result of lower transaction costs, as Coase tells us, is smaller, and more autonomous, \u2018firms\u2019: private, public, or otherwise. The fractal disintegra- tion of large hierarchical empires like the former Soviet Union, or Yugoslavia, is a case in point, but so too is the peaceful \u2018devolution\u2019 of centralized power to smaller governmental units in both the US and Britain. Or, even, when one thinks about it, the apparent commercialisation of the Chinese People\u2019s Liberation Army.Nation-states, like their aristo/theocratic predeces- sors did with industrialism, will have to stand back and let the geodesic train go by. And, like aristo- crats and theologians before them, politicians will increasingly become mere ceremonial appendages to a larger, more geodesic, economy and society. The nation-state as entertainment, if you will.So, we might actually have gold-denominated Burmese opium futures someday. Financial cryp- tography allows anything to be bought and sold, of course, as long as it can be represented on a wire with bits. Getting delivery of physical goods in some eventually private \u2018 jurisdictions\u2019 may be an- other thing altogether.We might even have, heaven forbid, auction mar- kets for private-sponsored assassination itself, just as Hughes and May predicted, so long ago, at least in net-years. Certainly the death penalty is a type of state-sponsored assassination, and lots of countries still have that. Commercial assassination, ala \u2018The Godfather\u2019 is a, um, horse, of a different colour en- tirely, though.War is, of course, murder on a grand scale, and something the more centrally-controlled nation- states have been particularly good at in this century.But, I think, on the whole, with enough private supervision of private property, physical crimes, especially violent ones, will decline over time, and maybe even dramatically.War and murder, are, after all, seriously bad for business \u2013 ask any Serbian shopkeeper these days \u2013 and the best way to prevent vandalism and the destruction of property, even on a large scale, is to identify the people doing it and then physically prevent them from doing so. This process would start from the ground up, it would seem to me, just by securely broadcasting criminal actions to a geodesic network, and warning others nearby to secure their property, and by force, if necessary.So, even if, over time, most financial assets will migrate to the net, and the ability for an individual to act remotely to effect a physical outcome \u2013 even a violent one \u2013 increases, this action-at-a-distance can only occur within the bounds of someone else\u2019s private surveillance and protection scheme.Your freedom to act ends where my nose begins, in other words.That is not an intolerable state of affairs at all.Back to table of contentsBob Hettinga continues his series about his start-up Internet Bearer Underwriting Corporation \u2013 IBUCI started IBUC, my new internet bearer underwriting venture, because bearer micropayments, a technology I had left for the distant future of internet commerce, had come out of nowhere to be the easiest technology to implement first?The same kind of unexpected, amazing thing happened on the demand side of the equation last month, when internet advertising revenue began to decline precipitously.It was only within the past year that advertising revenue was overtaken by commerce revenue as the mainstay of the internet economy. First with brochure sites for companies such as AT&T made by companies with names such as net. genesis and RazorFish, and then with internet gold-rush sites such as Pathfinder, HotWired, Yahoo, Lycos, and Excite, it seemed that the only way to make money on the net was to either construct a brochure site, which itself was nothing but an advertisement, or own a content site, which was itself supported by advertising. Even better, obviously, was selling equipment and services to those who did one or the other of the above. Gold pans and blue jeans to the miners.The realisation that inventory databases could be linked with financial cryptography on a web-server means that commerce for things normally stored in warehouses and sold by salesmen has exploded on the net. Companies such as Dell and Cisco get a majority of their multi-billion-dollar revenues straight from the web, for instance. The total amount of internet commerce is expected by several sources to top a trillion dollars by 2002. With the very sizeable exception of financial assets (a majority of all individual stock trades will soon be originated from the internet, for instance), and travel services, most of that projected internet commerce revenue will still be for items you can physically touch, things which are delivered later, instead of now, things which you\u2019ll keep after you purchase them and not literally throw away after a single use.But it isn\u2019t that commerce for books, computers, and other actual stuff is just getting bigger than that for advertiser-paid content. Not at all. Advertisements on the web have shown themselves to be eminently ignorable by the web-browsing public, and, as a result, advertising revenue has actually fallen, and considerably so. Every large web-content site you have ever heard of has a huge budget for advertising outside the net, print, magazine, television, even radio, because ads on the internet itself just aren\u2019t that effective. And, yet, what these very firms sell, ostensibly, is internet advertising, and not the actual content of their websites. So, while things haven\u2019t reached panic proportions yet in the content business, it will be interesting to see how content providers are going to react to all this.The very definition of industrial-age mass media is that it is produced on something cheap enough that it can thrown away after consumption. Of course, geodesic media has the same or cheaper delivery cost. Furthermore, Moore\u2019s Law on a ubiquitous internetwork allows the size of a \u2018production run\u2019, or \u2018audience size\u2019, to approach one. Or, at least, you could do it that way, if you could lower your transaction costs far enough. In other words, in a geodesic medium such as the net, it will probably turn out cheaper to actually pay the content\u2019s creator directly for custom content with digital bearer microcash than it is to \u2018target\u2019 advertising through one or more industrially-organised \u2018infomediaries\u2019 (or whatever McKinsey\u2019 s buzzword-du-jour is these days).That\u2019ll be true no matter how big, or fast, your customer datamines can be. The market is your database, in other words. Database marketing, just like database transaction settlement, will choke on the sheer volume of \u2018targeted impressions\u2019 it has to monitor, and, more important, transfer prices it has calculate to pay for those impressions. A geodesic market sees such information choke points as damage, and routes around them.Advertising supported mass-media, is, of course, the quintessential transfer-priced command economy. That is, accountants, not markets, attempt to calculate the value of whatever content an advertiser purchases on behalf of that content\u2019s consumers, using not-always-accurate heuristics like cost per thousand impressions, say, or percentage audience share. As most serious students of finance already know, it was the demonstration of the near-impossibility calculating a transfer price which resulted in most of the Nobel prises in economics given out in the last few decades. And so, as I\u2019ve said about financial cryptography and cryptography itself, financial economics is the only economics that matters these days. In fact, the only time transfer pricing is even attempted is when transaction costs outside the firm were too high, for one reason or another, to get a market price. This is, of course, Coase\u2019s theorem, the fundamental theorem of microeconomics, and that theorem, in turn, is the very definition of what is, or isn\u2019t, a firm. More to the point, transaction cost determines exactly how large any firm can be.The very concept of economy of scale comes from this. Since we at IBUC have sworn ourselves the equivalent of a barbarian blood-oath against transfer pricing on the internet, we have always considered web-page advertising as an almost unitary proxy for the potential content segment of digital bearer microcash market, and thus completely fair game when we go \u2018viking\u2019 in that direction. However, it now appears, the market for that unitary proxy has fallen. Does mean that there\u2019ll be no more content on the internet, especially at very low cost? Hardly. It only means that transfer pricing doesn\u2019t work as a way to pay for internet content. It\u2019s only really a problem for industrial-style distribution hierarchies, not the people who actually produce new content. As the technology of internet content delivery keeps exploding, and the price of distribution itself collapses accordingly.MP3 audio files proliferate, much to the consternation of record company executives everywhere. And much to the delight of those artists getting heard by more people just by disintermediating those very same record companies. And, it\u2019s getting cheaper.All this new networked content business needs is a new way to pay for it all at that exponentially falling delivery price. (Shhhh. If you listen very carefully, you can hear a Norse rowing song coming up the river.) So, while most industrial content \u2018infomediaries\u2019 may be hiding behind their castle walls of lawyers, professional managers and strategic consultants, the smarter ones are investing a little danegeld to get involved in these new markets for content and get along with their new barbarian neighbours. After all, artists just want to be seen and heard, not sell to themselves.Intermediation doesn\u2019t go away in this new world: it atomises into smaller and smaller bits with each iteration of Moore\u2019s law. So there is a way to pay for micro-cost content, and that is digital bearer micropayment. It\u2019s simple to imagine a protocol where a content client keeps putting pennies into a server\u2019s coinbox for a certain number of megabytes or seconds of additional streamed content. It\u2019s even easier to see some kind of XML function for doing things with each web page we see. The problem is, most of this potentially valuable content is still, for all practical intents and purposes, buried deep inside the transfer-priced cost of other things, like advertising, and even internet access. Internet access which, itself, is buried in the cost of telephony in certain tariff-mandated transfer-priced markets such as Great Britain. It\u2019s \u2018free\u2019, in other words. That the word \u2018free\u2019 actually means a redirected payment and a transfer price makes no difference to an uninformed, and, frankly, innumerate, public. They are \u2018paying\u2019 all that they want to for using the web, for internet access, and especially for telephony and, they expect the price to fall as time goes on.It\u2019s what Michael Eisner likes to call the financial \u2018box\u2019 we have to operate in. As long as a customer\u2019s cost to use the net falls over time, he\u2019s happy, whether he pays cash to every website he sees, or he pays for it by the month to an ISP, or he pays what amounts to a tax on his phone calls, to get it.How does a content provider bootstrap this? Easy. Damn the torpedoes, sell stuff for cash anyway, and let the market sort it out. Transfer-priced content is going to go away, one way or another, and clinging to the sinking ship of advertiser revenue and other equivalents won\u2019t help matters.What will happen in the content market is what always happens when revenue dries up: a shakeout. If it\u2019s not currently underway, that is. Pathfinder, for instance, is gone, subsumed by a separate site for each Time Warner\u2019s media properties. The people who do things for free will continue to do so until their expenditures, or their opportunity cost, causes them to quit. The people who do really valuable things will continue to do so as well, and get paid for it somehow. For the rest, it\u2019s really a question of either being the lowest cost producer/ distributor, or finding new revenue streams, or some combination of both.My claim is that those in the last group will be people who focus on aggregating and distributing content instead of creating it, that everyone\u2019s going to be the lowest cost producer/distributor, that the transfer-priced revenue they were invented for will dry up. Any good market eats it\u2019s young, and all that.That brings me to something I\u2019ve called a geodesic recursive auction. I\u2019ve actually talked about the idea here in this column before, but this new \u2018emergency\u2019 in internet content revenue dictates a little more detail in the discussion.The idea itself is pretty simple. I create new content. I sell it to you for the most I can get for it, and I keep doing that until nobody else wants to buy it anymore. If people are deluging my server with purchase requests, I raise my prices until the load goes down to something manageable. If I have no traffic, then I\u2019m charging too much. Buy low, sell high; charge all that the market will bear. Darwin rules. By the same token, if I download something from you, I can turn right around and sell it again to anyone who wants to buy it, thus maybe recoup my costs, and even make a profit. The assumption is that on the net, things like copyright and other intellectual \u2018property\u2019 controls simply cost too much to enforce. It\u2019s hard to reach out and arrest somebody over the net, particularly if functionally anonymous bearer transactions are the cheapest possible transactions. Also, the additional cost of copy-control mechanisms such as \u2018watermarks\u2019, \u2018cryptolopes\u2019 and so on is simply too high for whatever extra value they might provide.Before the advent of ubiquitous geodesic internetworks, much less auction-priced digital bearer transactions, huge amounts of profit were eaten up in the inefficient transfer-pricing of production assets, or, more important, the information about that assets, up and down the organisation chart and its corresponding chart of accounts. Industrial-era record companies, publishers, and entertainment networks are all still fairly hierarchical entities today, even though the economics of Moore\u2019s law has changed their business considerably over the last thirty or forty years. It\u2019s not without a reason that the most important person in the movie business these days is the artist\u2019s agent, and not the studio head, for instance. Digital bearer cash, at sufficiently small denominations, probably the $10-3 (a tenth of a penny) range, or maybe lower, enables the direct purchase, and, more important, the immediate disposal of content after its use.In so doing, it solves precisely the problem that advertising does by batching impressions and transfer-pricing the cost of delivering the content responsible for those impressions. More to the point, it uses economics and software to solve the problem of copyright infringement, because storage cost should vastly exceed purchase price. (By the way, we at IBUC call $10^-3 a \u2018minidollar\u2019 because \u2018millidollar\u2019 sounds too close to \u2018Millicent\u2019 a proprietary trade-name belonging to Digital, now Compaq. Another transfer pricing problem, yes?) In other words, digital bearer minidollars give us the exact industrial definition of \u2018mass-media\u2019 \u2013 use it once and throw it away \u2013 but without the transfer-pricing overhead of hierarchically organised markets. Toffler\u2019s \u2018mass-customisation\u2019, indeed. Only there\u2019s no industrial-era \u2018mass\u2019 to any of it. Every single bit is paid for directly by the user of those bits, in a hyper-efficient, auction-priced, cash settled, geodesic, market. The customer, and the producer, get exactly what they want, and more of it, for less money. Sounds like progress, instead of disaster, to me. And, of course, for us at IBUC, it\u2019 s almost divine providence.Back to table of contents\"Who needs money anyway?\": The New Monetary Economics, Monetary Separation, and Digital Bearer SettlementOne of my best friends in the whole world is Mark Tenney of Mathematical Finance in Alexandria, Virginia. The best man at my wedding, I met Mark during my mostly sad attempt to go to the University of Chicago as a \u201cStudent-at-Large\u201d, where I snuck in the back door and hung out for almost a year before they threw me out \u2013 though, to my credit, or lack there of, it was for impecuniosity, more than anything else. \u201cFirst thing you do, you get the money\u201d, and all that.It was fun, though, and I did manage to transfer enough credit from Chicago to finish my undergraduate philosophy degree at Missouri. Up until the last five years or so, when I discovered the \u201cUniversity of the Internet\u201d, I\u2019d always wished I could afford to go back some day and play some more, especially in finance and economics.Anyway, Mark was one of those scary mathematical prodigies who finished both high-school and college in three years apiece, finished all-but-a-doctoral-dissertation in Physics at Brandeis in three years, hedging himself with an Master\u2019s, then turned on a dime and did the same thing in Finance at Chicago, hedging again with an MBA in Finance. All this before wading into the fray of quantitative fixed-income analytics-for-hire, swinging that claymore-sized intellect of his with both hands.Last year, I told Mark that I had decided to concentrate on digital bearer transactions full-time, and he asked a bunch of questions like he always does when I reveal my latest off-the-wall idea. And not saying much in reply, which he also always does, being one of the most laconic people I\u2019ve ever met. That\u2019s okay, I suppose. I talk enough for both of us.Anyway, a few days later, Mark calls me up, all excited. Well, as excited as Mark gets, anyway. \u201cYou could issue digital bearer certificates backed up by an S&P 500 portfolio,\u201d Mark says with not much affect, followed by dead air, which is my cue to talk.\u201cYup,\u201d says I, chattering away, \u201cThat\u2019s easy. Old hat. We talked about stuff like that on cypherpunks years ago. The only problem is, it\u2019s illegal in the US for various reasons, and proving that you\u2019re only issuing to and redeeming from foreign nationals is really too complicated. We don\u2019t call it \u2018digital bearer settlement\u2019 for nothing. Of course, that doesn\u2019t keep several smash-the-state cryptoanarchists out there from daydreaming, in color, about that idea pretty much full time. Expressions like \u2018tax-evasion\u2019 and \u2018money-laundering\u2019 only make them work harder, after all. Me, I\u2019m only in it to reduce transaction costs. Illegal business is chump change compared to putting the entire global economy onto the net in digital bearer form.\u201cSteve Schear and I even figured that you could do it with just about any stock, anywhere, from anywhere, as long as it was legal in the jurisdiction you did it from. Sort of an \u2018Unsponsored Network Depository Receipt\u2019, UNDRs, for short\u2026\u201d and then, I proceeded to go into an entire rant on that. In four-part harmony. Arlo Guthrie would have been proud\u2026Finally, I run out of gas, like I always do, and Mark says, \u201cIf you issue digital bearer certificates collateralized by the S&P 500, you won\u2019t need cash anymore.\u201d More dead air.\u201cWell,\u201d I said, jumping back in, \u201cmaybe, maybe not. I mean, the dollar\u2019s pretty much pecunia franca right now, yes? Anyway, you wanna write something up about it, and we\u2019ll zing it out onto some of my mail lists for comment?\u201dI figure that if Mark was excited enough, he could bash on the mathematical finance of this idea much better than I ever could, being mostly innumerate myself, with my undergraduate philosophy degree from a midwestern state-school, and leftover student-at-large credit from UofC.I mean, the closest thing I ever got to a genuine financial education was sneaking out of the University of Chicago Bookstore Graduate School of Business textbook section with books like Brealy & Meyers\u2019 \u201cCorporate Finance\u201d, and Sharpe\u2019s \u201cInvestments\u201d. Needless to say, reading stuff like that, and hanging around people like Mark at a place like Chicago pretty much set my \u201cif there\u2019s not a market for it, it really doesn\u2019t matter\u201d view of reality into steel-reinforced concrete. It\u2019s kind of the core of my anti-state bias as well, I suppose.Mark is, of course, a pro at this kind of stuff, having figured ways to use Green\u2019s functions to kill off lots of Monte-Carlo modeling, building closed-form solutions for various security prices, and so forth. His asset-liability models sit in the guts of several very large insurance companies, and there are questions about his asset-value calculation methods on the US actuarial exam. One of his latest projects is building the analytical core of start-up e-finance company in an as-yet undisclosed European country, and his client before that was one of the largest financial services firms in the world, owning well-known insurance and mutual fund companies everywhere you would care to name.So, I didn\u2019t hear much from Mark about this idea of his anymore, probably because most of his \u2018wetware\u2019 bandwidth is paid for these days, with real money, and he doesn\u2019t have much time to spare for actual fun \u2013 much less writing a non-reviewed finance paper that I would just pass around the net for free. And so that\u2019s the last I heard of it for a while.Then, a few months ago, after I\u2019d started up my new company, IBUC.COM, to actually issue digital bearer cash and other stuff some day, some newbie on the cypherpunks list talked about trying to do yet another internet currency, a smallish rant with a whole bunch of, well, wrong stuff in it. So wrong, in fact, I can\u2019t even remember most of it. As is unfortunately usual in these circumstances, I ended up writing my own rant in reply. It centered around my own favorite point on the subject, that unless any \u201cinternet currency\u201d was exchangeable into dollars, or some other standard unit of exchange, nobody was going to pay any attention to it.There have been several efforts on cypherpunks and elsewhere to think about synthetic currencies based on attention, or machine cycles, for instance, and, while using machine cycles to prevent forgery is at the core of most decent micromoney protocols like MicroMint, but you have to denominate your digital bearer cash in something financial, or it will be of no real use to normal people. Not that most cypherpunks care about being normal, you understand, but there it is.Nonetheless, I did toss off some nice words in the direction of the e-gold guys, who, at the time, were issuing a kind of gold-backed \u201cinternet currency\u201d, albeit in book-entry form. They had been having some success with it, mostly among the anarcho-survivalist gold-bug crowd. Meaning that a lot of very bright erst- and proto-cypherpunks have been playing with e-gold, for reasons of politics, paranoia, or both. Or at least so I figured at the time, anyway.Dr. Douglas Jackson, the oncologist-turned-founder of e-gold, is quite a bit more phlegmatic about these things himself, though certainly never a fan of fiat currency. He understands, for instance, that storage costs can make gold-backed account balances actually depreciate over time. But, in implementing the e-gold payment system, he and several thousand e-gold users have ended up with quite a bit more experience in non-credit-card internet payments than anyone else has to date, mostly because they didn\u2019t try to do anything too complicated in the early stages.More to the point, all of Doug\u2019s competition (like First Virtual, CyberCash, and DigiCash, to name a few) have killed themselves off going for the main chance. They kept trying to conquer the world, trying to be some kind of sole transactor of business on the web, without understanding that finance is a business of herds and swarms and that nobody trusts anyone who\u2019s the sole anything.Meanwhile, Doug\u2019s still doing a tidy, if not land-office, business, precisely because he\u2019s not trying to take over the world. In fact, I\u2019d say that anyone who\u2019s interested in internet payment should pay more than a little attention to e-gold, or, as their evangelist Jim Ray likes to call it, \u201cThe little internet payment system that could.\u201dAnyway, Ian Grigg, an expatriate Australian who I can\u2019t really call a cypherpunk \u2013 more of a \u201cmoneypunk\u201d, maybe, since he\u2019s spent a lot of time lately down in Anguilla building things for e-gold, among other people \u2013 sees this cypherpunks rant of mine about internet currency after I forwarded it to dbs, the digital bearer settlement discussion list that I run. Ian observed there that if transaction speed was fast enough, the market would probably converge to a world without cash at all. Shades of Mark Tenney.Since I respect Ian\u2019s opinion, because Ian seems to have read every \u201cAustrian\u201d economist there ever was, and is a great fan of Scottish free banking, not to mention because of all his work for e-gold, which now runs on his \u201cRicardo\u201d web-market-making system, I thought to myself, \u201cOkay. Maybe. Someday. In the meantime, I want IBUC to do cash, dollars preferably, thank you very much, and after that, other actual securities, and, after that, we\u2019ll see if the dollar really does evaporate as the world\u2019s primary exchange currency.\u201d And having said so to the list in reply, I left the discussion there for the time being.Which brings me to a little while ago, when I was half-to-three-quarters of the way through with a nice rant for this column on something else entirely, and ended up throwing it all in the trash.That was because of something I got in email from another friend of mine, one of the best internet transaction lawyers in the business, John Muller, a partner at Bobreck, Fleger and Harrison, in San Francisco. Among other things, John is Chair of the Web Site Working Group of the American Bar Association Joint Subcommittee on Electronic Financial Services (say that ten times fast), and Co-chair of the Automated Transactions and Electronic Agents project of the ABA Cyberspace Law Committee.What John sent me was the most recent Electronic Financial Services Update, the back issues of which can be seen at http://www.abanet.org/buslaw/efss/whatsnew.html, and in that update was \u201cTowards a Moneyless World?\u201d, a paper by Malte Krueger, of the University of Cologne and the University of Western Ontario, for the International Atlantic Economic Conference, which was held in Vienna this past March. Apparently, this paper was also presented in different form to the Second Berlin Conference on Internet Economics a little while later.And, there, after converting PDF to PostScript, and then PDF to ASCII text so I could read it faster, there was a pointer to where my friend Mark Tenney \u2013 and, I bet, Ian Grigg \u2013 got the idea that as transaction latency and transaction costs go to zero, the value function of currency converges to that of more \u201cfinancial\u201d assets: They were quoting, whether they knew it or not, the so-called \u201cNew Monetary Economics\u201d (NME), a phrase coined by Robert Hall, but conceived, in the early 1980\u2019s, by no less a pair of financial luminaries than Eugene Fama, of the Efficient Market Hypothesis, and Fischer Black, of the Black-Sholes option equation. Others, like Krueger, apparently, call this the \u201cBFH system\u201d, in their honor \u2013 or for other reasons, it\u2019s hard for me to tell.Krueger says, of NME/BFH,In the current system money (cash and deposits) is used as medium of exchange and unit of account. In the BFH system there would be no common medium of exchange with a fixed nominal value in terms of the unit of account. Instead, assets with variable prices are used. This implies that, in principle, any asset could serve as a medium of exchange. An example that is often used to illustrate \u2018moneyless\u2019 payments are mutual funds shares. The value of mutual funds\u2019 shares varies with the value of the funds\u2019 assets and within certain limits they can be used for making payments. So, the medium of payment \u2018mutual fund share\u2019 has a value that is not fixed in terms of the commonly used unit of account. Eugene Fama (1980) argues that monetary separation is efficient because the financial system (Fama uses the term \u2018banks\u2019) serves two functions that are independent of each other: the accounting function and the portfolio management function. Banks could fulfill the accounting function without holding assets or using any medium of payment. It would be sufficient to have a unit of account. As an uninvolved third party, banks could just keep records of transactions. The issue of liabilities and the purchase of assets is derived from the second function, the portfolio management function. In this function banks help individuals to hold their wealth in a form they desire.What the above means to me is pretty much what Tenney and Grigg said, that Moore\u2019s law creates an increasingly geodesic, ubiquitous, public internetwork, which, coupled with the financial cryptography of digital bearer settlement, \u201csurfacts\u201d currency into its constituent parts. Why keep something which doesn\u2019t earn you money, in other words? Why not use something which is as risk-free as possible but still earns money while it\u2019s in your possession? Furthermore, the longer money\u2019s going to be in your possession, the more incentive you have to invest in something where short-term volatility isn\u2019t a problem. We\u2019ll leave discussion of my opinion on the \u201caccounting\u201d function as an exercise for the reader.Anyway, Macroeconomists call this division of unit of exchange from unit of account, monetary separation. And, as a result, we get more and more different kinds of exchange with decreasing transaction cost. Banks go back to being \u201ccounting houses\u201d instead of fiduciaries, trustees, keeping track of who owes what to whom, and the returns on money are higher for the users of that money. The advent of the money-market mutual fund, was, of course, a step down this road.As to whether this means the death of currency, Krueger comes down on the side of network effects \u2013 unfortunately conflating them with path-dependency; network effects being cool, and path dependency being balderdash \u2013 and says that the opportunity costs of keeping track of various different asset classes, and, more importantly, exchanging those different asset classes with others just to effect any trade whatsoever in a virtual re-emergence of barter, still costs too darn much, and thus, the internet gives us monetary integration, and not separation. As someone said of Mozart, \u201ctoo many notes\u201d.I\u2019m personally not so sure, Moore\u2019s law being what it is. It might be easy enough with with enough bandwidth and processing power to do all those exchanges and re-balance one\u2019s \u201cportfolio\u201d of money-equivalents, paying people in whatever asset class they want, and still make more money than parking money as dollars in a bank somewhere, or, worse, keeping cash on hand.However, I also think that it\u2019ll be a while, just yet, for that world to emerge, and, frankly, I want to buy things with dollars, and right now.By way of some even more twisted synchronicity, Krueger\u2019s paper then points to my friend Tatsuo Tanaka\u2019s paper on the macroeconomic consequences of internet free banking. Which, oddly enough, I edited and recommended for publication in the peer-reviewed internet journal First Monday four or so years ago. I even invited Tanaka to come up and present the paper at a Digital Commerce Society of Boston luncheon shortly after the paper came out.Tanaka says, first of all, that internet free-banking is like the expatriate-cash Eurodollar market on steroids. Internet free-banking drives the final nail in the coffin of central bank control of any nation\u2019s currency, because, if a currency is stable enough, and maybe even if it isn\u2019t, sooner or later more of the currency is \u201cissued\u201d on a fiduciary basis outside a country, collateralized by foreign-held dollar-denominated accounts, for instance, than is issued by the central bank itself. And the net makes where the money is, heh, immaterial.Unfortunately, Tanaka also says that competition for underwriting cash to the net causes the eventual fractional reservation of digital cash against its denominated currency, and that, sooner or later, crises of confidence in all those different issues, and their various partial reserves, force the creation of, you guessed it, monetary union of some kind. Tanaka liked to wax about the eventual creation of a central bank of cyberspace, thus setting most cypherpunks\u2019 and other free-money advocates\u2019 teeth on edge, mine included, skyward-rolling eyes and all.But the story gets weirder than that. Recently, Douglas Jackson and his crew at e-gold have been taking their association with \u201cmoneypunks\u201d like Mr. Grigg (and, um, others :-) ), to heart lately. They split themselves into a trustee-underwriter relationship of several firms, and, in the process, have created an offshore subsidiary, based in, where else, Anguilla, to, you guessed it, offer fractionally-reserved, (but non-blinded) gold-denominated digital bearer certificates, called, oddly enough, DigiGold.The idea behind DigiGold is to fractionally reserve gold denominated transactions, loaning out the reserve\u2019s other fraction to offset the cost of gold storage, which, as we noted above, at a percent or more a year, is a considerable one if you\u2019re trying to create a currency which is supposed to hold its value. In fact, Ian went so far as to start buying and selling notes denominated in gold recently, apparently as part of his work with DigiGold.\u201cGold-denominated Burmese opium futures\u201d, indeed.For one final bit of weirdness, I eventually got around to reading Glassman and Hassett\u2019s Dow 36,000 article in the Atlantic Monthly, which, at the core of its analysis, notes that among other things and contrary to received wisdom, equities held in the long term are much less risky than even long-term government bonds are, and how the market has been compensating for that for the last few decades or so by driving equity prices slowly upward to their risk-adjusted \u201creasonable\u201d price. Like their title says, they say that the Dow could be at 36,000 and still be \u201creasonable\u201d, whatever that means. Mercy.A splendid read nonetheless, whether you agree with them or not, and the bit about the risk of the equity market certainly makes a compelling argument for a very, very, interesting result for us, in light of all of the above.At the core of all modern financial analysis is the proposition that government bonds, especially short-term ones, are the safest investment. They\u2019re safe because, for instance, the chance of the US government defaulting on any given 90-day T-Bill on any given day is virtually non-existent. T-Bills are literally risk free, and all other investment is calculated against them for riskiness. The Net Present Value equation, for instance, says that if the returns of a proposed investment are less than you would get from a T-Bill, you should forget the investment and keep your money in T-Bills instead.And, at every year of bond maturity, the government bond sits at the lowest point of the risk \u201cwell\u201d for that maturity. Or so I thought, until I saw Glassman and Hassett\u2019s description of what all financial theorists knew already for a fact, that the long-term risk of the overall equity market is much less than that of even government bonds.So. Can we back that \u201czero\u201d equity-market risk down the maturity curve to the present? Maybe, with a derivative or two. I haven\u2019t gone looking for the answer, and it\u2019s press time already. I wouldn\u2019t be surprised, though, and to walk out on a very thin limb, I\u2019m going to assume it to be true.Certainly the idea of, say an S&P 500, or maybe a larger-index-based \u201ccash\u201d starts to make sense, if we can do it. After all, Ian Grigg and his friends are trying, for all intents and purposes, to do roughly the same kind of thing with gold. Gold hops around a bunch, and volatility is probably not a good thing for a currency to have. So any financial engineering you can do to at least take the volatility down a bit would be good. And you\u2019d want to do the same thing with equity indices, because, as a functional perpetuity, a stock can be just as volatile as a 30-year bond might be.What we get, if we do create a low-volatility equity-based currency, is really very interesting.We get what Gene Fama and Fisher Black must have been thinking about back in early eighties heyday of the \u201cNew Monetary Economics\u201d: a completely private form of \u201criskless\u201d return.Think about that for a minute. Not only do we have digital bearer settlement, so we don\u2019t need the nation-state to provide force and ensure the non-repudiation of our transactions, but we don\u2019t even need another kind of force either: the confiscatory force of a nation\u2019s tax system, making for \u201criskless\u201d government securities, which, in turn, undergird our very concept of what risk is.What we get is truly private money. That is, someday we can create a completely synthetic currency based upon a commonly-referenced equity market index.Look, Ma, no currency board, much less a central bank. No guns. No sovereign. And we still get money. Amazing.So now, instead of stepping back to a commodity economy to avoid state control of the monetary supply, using something like gold to anchor value on the net, we can step forward into the information economy, the geodesic economy: All we need to collateralize our transactions is a sufficiently representative and publicly known equity index, with the volatility hedged for short term use using other publicly known derivatives. Presto change-o, a synthetic internet security. And, of course, this works with bearer held stocks, if we ever get those, as well.Finally, anyone who wants to can do this \u2013 well, if their reputation\u2019s good enough. This is finance, after all.Of course, the sticking point all this fun is the state itself, as I said to Mark Tenney more than a year ago. Remember all the book-entry taxes and regulations about bearer ownership of bonds, TEFRA, et. al., here in the U.S., and then exponentiate that number to get the regulatory barriers for bearer equity.It\u2019ll certainly be easier, for the time being, to issue cash denominated in dollars than it would be to try to climb an enormous ziggurat of regulators and legislators, telling all of them that issuing bearer-form equity-index-denominated money would be a good thing, even if it completely removed their central banks, much less their very government bonds, from the center of the financial universe. A lead balloon, indeed. Almost makes you want to believe in path-dependency, that does.But don\u2019t despair. Remember that if digital bearer transactions really do something I\u2019m betting my company on, sooner or later an equity index-based \u201cinternet currency\u201d will in fact emerge as the best way to buy things.Even more interesting, if we\u2019re right, government-extorted revenue will cease to be the foundation upon which the concept of \u201criskless\u201d return \u2013 and all of finance itself \u2013 rests.But that\u2019s probably what Fama and Black had in mind, right?Back to table of contents"}
{"prompt": "A Declaration of the Independence of Cyberspace", "completion": "Governments of the Industrial World, you weary giants of flesh and steel, I come from Cyberspace, the new home of Mind. On behalf of the future, I ask you of the past to leave us alone. You are not welcome among us. You have no sovereignty where we gather.We have no elected government, nor are we likely to have one, so I address you with no greater authority than that with which liberty itself always speaks. I declare the global social space we are building to be naturally independent of the tyrannies you seek to impose on us. You have no moral right to rule us nor do you possess any methods of enforcement we have true reason to fear.Governments derive their just powers from the consent of the governed. You have neither solicited nor received ours. We did not invite you. You do not know us, nor do you know our world. Cyberspace does not lie within your borders. Do not think that you can build it, as though it were a public construction project. You cannot. It is an act of nature and it grows itself through our collective actions.You have not engaged in our great and gathering conversation, nor did you create the wealth of our marketplaces. You do not know our culture, our ethics, or the unwritten codes that already provide our society more order than could be obtained by any of your impositions.You claim there are problems among us that you need to solve. You use this claim as an excuse to invade our precincts. Many of these problems don\u2019t exist. Where there are real conflicts, where there are wrongs, we will identify them and address them by our means. We are forming our own Social Contract. This governance will arise according to the conditions of our world, not yours. Our world is different.Cyberspace consists of transactions, relationships, and thought itself, arrayed like a standing wave in the web of our communications. Ours is a world that is both everywhere and nowhere, but it is not where bodies live.We are creating a world that all may enter without privilege or prejudice accorded by race, economic power, military force, or station of birth.We are creating a world where anyone, anywhere may express his or her beliefs, no matter how singular, without fear of being coerced into silence or conformity.Your legal concepts of property, expression, identity, movement, and context do not apply to us. They are all based on matter, and there is no matter here.Our identities have no bodies, so, unlike you, we cannot obtain order by physical coercion. We believe that from ethics, enlightened self-interest, and the commonweal, our governance will emerge. Our identities may be distributed across many of your jurisdictions. The only law that all our constituent cultures would generally recognize is the Golden Rule. We hope we will be able to build our particular solutions on that basis. But we cannot accept the solutions you are attempting to impose.In the United States, you have today created a law, the Telecommunications Reform Act, which repudiates your own Constitution and insults the dreams of Jefferson, Washington, Mill, Madison, DeToqueville, and Brandeis. These dreams must now be born anew in us.You are terrified of your own children, since they are natives in a world where you will always be immigrants. Because you fear them, you entrust your bureaucracies with the parental responsibilities you are too cowardly to confront yourselves. In our world, all the sentiments and expressions of humanity, from the debasing to the angelic, are parts of a seamless whole, the global conversation of bits. We cannot separate the air that chokes from the air upon which wings beat.In China, Germany, France, Russia, Singapore, Italy and the United States, you are trying to ward off the virus of liberty by erecting guard posts at the frontiers of Cyberspace. These may keep out the contagion for a small time, but they will not work in a world that will soon be blanketed in bit-bearing media.Your increasingly obsolete information industries would perpetuate themselves by proposing laws, in America and elsewhere, that claim to own speech itself throughout the world. These laws would declare ideas to be another industrial product, no more noble than pig iron. In our world, whatever the human mind may create can be reproduced and distributed infinitely at no cost. The global conveyance of thought no longer requires your factories to accomplish.These increasingly hostile and colonial measures place us in the same position as those previous lovers of freedom and self-determination who had to reject the authorities of distant, uninformed powers. We must declare our virtual selves immune to your sovereignty, even as we continue to consent to your rule over our bodies. We will spread ourselves across the Planet so that no one can arrest our thoughts.We will create a civilization of the Mind in Cyberspace. May it be more humane and fair than the world your governments have made before.FDavos, Switzerland\nFebruary 8, 1996"}
{"prompt": "Smart Contracts Glossary", "completion": "Agent: A person or organization, usually represented by a true name or nym. Also, a computer program controlled by, and acting on behalf of, an agent. More generally, a combination of a nym with a persistent pattern of behavior, upon which can be based a reputation. Note that this differs from the legal and business definitions of\"agent\", but corresponds more closely to the economics and computer science uses of the term.Contract: A set of agreements or promises between agents.Parties (aka Principals): Agents who have agreed to the contracting question.Third Parties: Agents who have not agreed to the contract in question.Performance: Carrying out the promises specified in a contract.Contractual Security: A paradigm for making security arrangements between organizations, based on two claims: (1) the primary goal of inter-organization security is to protect and enforce the performance of contracts, and (2) where this goal is achieved, dependence on reputation, outside enforcement, and other factors for the secure performance of that organization's contracts is minimized.Contractual Key Distribution: a paradigm for distributing keys among individuals and organizations, in which the key distribution and certificate structure reflects the contractual arrangements between parties.Protocol: A sequence of messages between multiple agents.Smart contract: A set of promises, including protocols within which the parties perform on the other promises. The protocols are usually implemented with programs on a computer network, orin other forms of digital electronics, thus these contracts are \"smarter\" than their paper-based ancestors. No use of artificial intelligence is implied.Alice and Bob: Our exemplar parties to a smart contract.Eve: Our exemplar eavesdropper, whose objective is to find out valuable information about about a contract and its performance without being a party to that contract.Mallet: Our exemplar active attacker. His objective might either be stealing something of value involved in the performance of a smart contract, or denying it to the parties to the contract. He might either be an economically rational agent, out for pure personal gain,or Byzantine, a worst-case attacker who inflicts the greatest possible damage on one or more of the parties regardless of personal loss.Mediator: A third party involved realtime in the protocols between smart contract parties, trusted with some of the contents and/or performance of that contract.Arbitrator: A third party trusted with some of the contents,and some of the history of performance, of a contract, and trusted by contracted parties to resolve disputes arising from that contract fairly.Unbundling: The principle of distribution of trust. Unbundling of mediation and arbitration functions separates tasks, spreads risk, minimizes vulnerability, and reduces linkability, but often at the cost of greater complexity.Enemy (aka attacker): An agent whose preferences could cause another agent harm; a third party who influences performance of a contract to the detriment of one or both parties.Object: Herein used to refer generically to any kind of digital data, which could be a key, a credential, a contract, a program, or a wide variety of other things.Credential: A claim made by one agent about another.Positive credential: A claim made about an agent, that the agent would prefer to reveal, such as a degree from a prestigious school.Negative credential: A claim made about an agent, that the agent would prefer not to reveal, such as a bad credit rating.Cryptographic protocol: A protocol that uses mathematical principles and keys to accomplish smart contract objectives.Privity: The principle that only the parties to a contract, including its designated arbitrators, need to have knowledge of or control over the contents and performance of that contract. Privity as an objective of smart contract is a generalization of the legal principle of privity. It formalizes the tradition of \"it's none of your business\". Attacks against privity are epitomized by Eve the eavesdropper, a passive observer of contents or performance, and malicious vandal Mallet, who actively interferes with performance or steals value. Privacy and confidentiality, or protecting the value of information about a contract, its parties, and its performance from Eve, is thus subsumed under privity. Privity often comes into conflict with observability and verifiability.Observability: The ability of the parties to a contract to observe each other's performance of that contract, or to prove their performance to the other party. Also, the ability to differentiate between intentional violations of the contract and good faith errors. An important objective of smart contract design that often comes into conflict with privity.Verifiability: The ability of a party to prove to an arbitrator that a contract has been performed or breached, and to differentiate between intentional violation and good faith errors. An important objective of smart contract design that often comes into conflict with privity.Reputable name: A nym or true name that has a good reputation, usually because it carries many positive credentials, has a good credit rating, or is otherwise highly regarded. Companies strive to carry reputable brand names, while professionals such as doctors and lawyers strive to have many good personal recommendations of their name. Reputable names can be difficult to transfer between agents, because reputation assumes persistence of behavior, but such transfer can sometimes occur (for example, the sale of brand names between companies).True name: An identifier that links many different kinds of information about an agent, such as a full birth name or social security number. As in magick, knowing a true name can confer tremendous power to one's enemies. It also can have major economic value among those who cooperate peacefully, as in the use of direct marketing to target product information to those agents most likely to be interested in those particular products.Mix: A cryptographic protocol for messaging, in which analysis of who is talking to whom (traffic analysis) by Eve is prevented by the Russian-doll encryption of the message by the sender with the public keys of each mix operator in the chain, and the mixing of messages by each operator, so that panoptic wiretapper Eve loses track of the messages. Only 1 out of N of the operators needs to be trusted with the traffic information, although Eve can sometimes gather statistics over large numbers of messages to eventually guess who is talking to whom. The communicating parties can also be mutually anonymous, and with normal encryption need trust no other parties with the content of messages. Confidential messaging is necessary for the some of the privity features of Chaumian credentials and bearer securities to be strongly implemented on an actual network. Another confidential messaging system is the \"Dining Cryptographers\" net, also invented by Chaum.Nym: An identifier that links only a small amount of related information about a person, usually that information deemed by the nym holder to be relevant to a particular organization or community. Examples of nyms include electronic bulletin board nicknames, pen names, aliases, and brand names. A nym may gain reputation within its community. For example, a conglomerate may sell a wide variety of brand names, each reputable in its own market niche. With Chaumian credentials, a nym can take advantage of the positive credentials of the holder's other nyms, as provably linked by the is-a-person credential.Name space: a set of short identifiers with a simple syntax, such as telephone numbers, computer-readable Internet address numbers, human-readable Internet domain names, etc.Chaumian credentials: a cryptographic protocol for proving one possesses claims made about oneself by other nyms, without revealing linkages between those nyms.Is-a-person credential: In Chaumian credentials, the true name credential, used to prove the linkage of otherwise unlinkable nyms, and to prevent the transfer of nyms between agents.Key: A focus of obscurity and control; a random number drawn from a name space so large that a lucky guess is vastly improbable. The public key half of an assymetric key pair can also act as a nym.Biometric: Information pattern used to identify a particular body, such as a fingerprint, autograph, retina scan, password, etc.Authentication: Proof that one is communicating with an agent that possesses a particular key.Secret key (symmetric) cryptography: Uses a key shared between agents to communicate with confidentiality and authentication.Public key (assymmetric) cryptography: Uses two keys, the private key and the public key. The public key is used to encrypt objects,and to verify digital signatures. The private key is used to to decrypt and sign objects, and is typically kept secret by one or more key holders. Allows key distribution without exposing the key.Secret sharing: method of splitting a key (and thus, in effect,any object encrypted with that key) into N parts, of which only M are needed to recreate the key, but less than M of the parts provide no information about the key. A potent tool for distributing control over objects between agents.Digital signature: Cryptographic protocol, based on public key cryptography, that proves that an object was in active contact with the private key corresponding to the signature: the object was actively \"signed\" with that key. Probably should have been called a \"digital stamp\" or \"digital seal\" since its function resembles more those methods than an autograph.Bit commitment: A variant of digital signatures, used to commit an object, such as a promise or prediction, without revealing that object until later. It is impossible to unobservably violate the protocol, or to modify the object after it has been committed.Blind signature: digital signature and secret-key encryption protocols that together have the mathematical property of commutativity, so that they can be stripped in reverse of the order they were applied. The effect is that Bob \"signs\" an object, for which he can verify its general form, but cannot see its specific content. Typically the key of the signature defines the meaning of the signed object, rather than the contents of the object signed, so that Bob doesn't end up signing a blank check. Used in digital bearer instruments, where Bob is the clearing agent, and Chaumian credentials, where Bob is the credential issuer.Digital bearer instruments: Objects identified by a unique key,and issued, cleared, and redeemed by a clearing agent. When an the object is transferred, the transferee can request the clearing agent to verify that the key has never before been cleared, and issue a new key. The clearing agent prevents multiple clearing of particular objects, but can be prevented from linking particular objects one or both of the clearing nyms who transferred that object. These instruments come in an \"online\" variety, cleared during every transfer, and thus both verifiable and observable, and an \"offline\" variety, which can be transferred without being cleared, but is only verifiable when finally cleared, by revealing any the clearing nym of any intermediate holder who transferred the object multiple times (a breach of contract). Privacy from the clearing agent can take the form of transferree-unlinkability, transferrer-unlinkability, or \"double blinded\" where both transferrer and transferee are unlinkable by the clearing agent. Digital cash is a popular form of digital bearer instrument.Locality: * immediacy, such as that provided by online clearing of digital bearer instruments * dealing with the agents one knows best * dealing in one's area of specialtyHot Backup: A backup service which comes online upon failure of the current service. Usually triggered by a dead-man switch.Zero-Knowledge Interactive Proof (ZKIP): A cryptographic protocol that can be used to prove that an agent possesses a key (and by weaker implication, that otherwise normally functioning agents who have an incentive to respond properly to the challenge, but fail to do so, do not possess the key), without revealing any information about that key. Currently used for authentication, and in smart weapons for Identification Friend or Foe (IFF).Smart Property: Software or physical devices with the desired characteristics of ownership embedded into them; for example devices that can be rendered of far less value to agents who lack possession of a key, as demonstrated via a zero knowledge interactive proof. Methods of implementing smart property might include OND (cf.), and engrained immobilizing or destructive devices to foil attempts to hot-wire the property.Operation Necessary Data (OND): Data necessary to the operation of smart property. For example, a complex, proprietary firing sequence needed to operate a computerized engine, a CAD file needed to manufacture a specialized part, etc. To avoid theft of service, ZKIP is required to open an encrypted channel to the device. To avoid leaking the OND to Eve, tamper detection combined with a dead-man switch can be used on the device end of the channel.Smart Lien: Sharing control of smart property between parties, usually two parties called the owner and the lien holder. This property may be in the proximate possession of the owner or the lien holder, corresponding to the common-law notions of \"artisan's lien\" and \"innkeeper's lien\" respectively. Might be used to secure lines of credit, insurance policies, and many other kinds of contracts that involve smart property.Security: Represents a basic asset, such as a share of ownership (stock) or a claim debt (bonds, cash).Contingent contract: Contains terms which depend on the choice of a party or a state of the world. An option is an example of a contingent contract.Derivative: A call or put option, future, or synthetic asset;such a contract is \"derived\" from a basic underlying security.Synthetic asset: A derivative constructed, or \"synthesized\", by combining securities and other derivatives. Cash flows for sophisticated synthetics can be calculated to high precision, by means of finely grained decision trees.Cash flow: The expected sequence of payments according to the terms of a contract. From cash flow can be computed the basic financial objectives of a contract, such as net present value.Please send your comments to nszabo (at) law (dot) gwu (dot) eduCopyright \u00a9 1995 by Nick Szabo\nPermission to redistribute without alteration hereby granted"}
{"prompt": "For-Pay Remailers", "completion": "What if you could make money by running a remailer?Right now, most remailer operators are operating out of altruism. This is good in a lot of ways but it has its problems, as recent events have shown:I'm sure we can all think of more. I know that it would be a lot easier to justify continuing to run the remailer to myself if it were bringing in a few dollars a month.I think there are some experiments in for-pay remailers that have been tried. Sameer is, I think, charging for some services, although paerhaps that was just for anonymous return addresses. A long time ago Karl Barrus had a service which required pre-issued \"digital postage stamps\", but I don't think many people used it.The time may be ripe to look at this more seriously. Several factors are coming together:To expand on these:It is obviously difficult to operate a remailer service that charges if other people are offering the equivalent service for free. Since it is pretty easy to start up a remailer, the marginal cost to do so is low, hence the profits are low, too. However, although it is easy to start a remailer, it is not so easy to keep one running in the face of complaints from recipients of abusive mail or inappropriate posts; hassles from sysops, owners, net feeds, or others upwards in that great chain of command; possible law enforcement problems when illegal communications occur; possible threats of lawsuits (such as from the scientologists when their sacred documents are posted), etc. So we should not be misled into thinking that running a remailer is cost free.On the other hand I should be clear that I would not expect to make a killing on this service. Something on the order of a penny a message seems reasonable just at a guess. Maybe it should be a factor of 10 higher or lower.One issue is of course the additional difficulty this will cause in the use of the remailer. There are several things to consider here. On the one hand you could argue that it is already too difficult to use the remailers, and any additional hassles involved with including some kind of payment tokens would kill the market. OTOH I can agree in spirit with the sentiments expressed here recently about the low quality which seems to characterize much of the use of the remailers.I don't look at messages, but occasionally I do see bounces, and very frequently they are ugly little flames or similar worthless material. Now, I hope that I am seeing the dregs, that the kinds of clueless people who make the mistakes which cause me to see the messages are the ones least likely to use the service in a worthwhile manner. But still, it is discouraging. In that context, maybe making the system a little harder to use would be worthwhile, in that it would screen out the casual harrasser. (Or, more realistically, this might just keep the exceptionally motivated harrassers.)In any case, I think the presence of the remailer scripts can make using a for-pay remailer not much more difficult than using a free one. If the cost is as low as I suggested and the inclusion of payment tokens is nearly automatic, then adding costs should not have much negative impact on use, certainly not on meaningful, worthwhile use.And even a modest cost might arrest the wholesale spamming that Detweiler and/or the recent \"Scythe\" seem to love. At least we would be paid for enduring the hassle of the complaints.Now, the next question is the details of the payment. Frankly, I don't think any of the current systems are quite right for us due to our special needs, but things are changing rapidly. Let me describe something about how they work.I know of two systems that are VISA/Mastercard based. One is called First Virtual (http://www.fv.com). They are oriented towards information sales and say that they aren't for service providers, but in practice it looked to me like they could be used for services. When a customer wants to pay, he sends you his FV ID. You send this to FV and they send an email message to the customer asking whether he authorizes the payment. If he says \"yes\", FV credits your account. You get a check every month. Customers who always say \"no\" get booted out of the system (as do merchants who submit bogus bills). They charge 29 cents plus 2 percent per transaction, but merchants can batch up multiple orders by a single customer before sending it in.There are a few problems with a system like this, many of which are somewhat generic to our situation. The most fundamental is that we don't know who our customers are much of the time. In fact, the whole point of the remailer network is that we not know that fact for any case except the first hop in the chain. If we required customers to expose their FV account ID at every hop, it would make it a lot easier to track messages through the network (even if the ID's were hidden in the encryption envelope it seems risky). If we then sent a message to FV saying that we needed to charge ID XXX, and FV responds with an email to the person's home address, this offers more possibilities for tracing.One solution would be only to charge on entry into the remailer net. Perhaps remailer operators would even charge each other then, and the first remailer would charge some larger amount to deal with a \"typical\" chain length? Many interesting possibilities here.Another issue is that the overhead charges by FV would require batching up messages before submitting them. Let me make clear that the batch must consist all of charges to a single user. It doesn't do any good to send one message to FV asking them to please charge a penny to each of 100 VISA accounts. No, you would have to count messages from each user, separately, and when user XXX had sent, say, $1 worth of messages, you could send in the request to FV and get back 70 or so cents.So this adds some overhead and record-keeping that we don't currently have to do, although perhaps it is not so difficult. But it would raise new questions of authenticating FV ID's, and shares some of the negative privacy impacts and message linking issues mentioned above.The other VISA based system is called OpenMarket. I just read about it tonight so I don't know it as well (http://www.openmarket.com). It is pretty tied to the WWW so it would not seem to work for us. Customers get connected to a particular WWW server which authenticates them and charges their VISA card appropriately, then they get redirected to the merchant with some kind of token that says they have paid.The NetBank (email to netbank-intro@agents.com) is a digital-cash like system. Customers get tokens which are basically large secret numbers which have a cash value. They send them to the merchants, and the merchants then send them to the bank which credits their account. The NetBank sends you a check every month.The interesting thing is how customers buy the cash tokens. One way is by connecting to a 900 number with your modem. They charge the customer $10.00 and give him a digital cash token worth that much. Another way is by faxing a check to them. I wasn't clear on how you get the cash token back in that case; I guess they email it to you at an address you specify. From the privacy point of view, these are not that great; 900 numbers have Automatic Number Identification so unless you are willing to tramp out to a pay phone to get your cash then it could be linked to your phone number. And the fax system must have some kind of return address that would link to you.The other problem with NetBank is that the smallest denomination which can be spent is 25 cents. Due to the cash-like nature of the tokens, I don't see a natural way to accumulate several messages into one payment. Maybe we could layer our own low-value digital cash system on top of NetBank, where users could buy our anonymous cash for 25 cents and get enough tokens for 25 messages, then we would settle amongst ourselves (or actually with the anon-mail-token bank). Actually this might help with the privacy problems, too. Anonymous digital cash is heavily patented, though.With a cash-like system, each message would include a numeric token in the header which is the digital cash. The remailer would strip that out and send it in for credit. This is a simple system and could be largely automatic. However there are some tricky issues about cheaters re-using cash.NetBank charges $4 per month, plus, for the 900-number-based cash, 20% off of face value.The last system I'll describe is David Chaum's DigiCash (http://www.digicash.com). Chaum is the inventor of digital cash and he certainly knows his stuff, plus as I said he has the intellectual property pretty well sewed up patent-wise. The DC payment system is also WWW based at present. The customer has to be running a special program on his computer, separate from his web browser. This program holds his digital cash, which is similar conceptually to the NetBank cash but more sophisticated cryptographically. When he wants to buy something, the merchant's web server makes a connection to the customer's DC program, and it transfers the cash to the merchant.DigiCash says they are planning an email based system but for now their emphasis is on the WWW. Right now they are only in beta and not using real money. I don't know when they will be real and email based, and I don't know if they have said what their commission will be. But when this comes up it may be the best approach if small-value transactions can be supported. DigiCash is fully anonymous in the sense that once a customer receives the money, it is \"blinded\" in a special cryptographic way so that the bank cannot associate it with that customer (and no one else can, either). This kind of anonymity fits in very well with our remailer requirements.Well, I know this is a lot of information to work through, but mostly I want people to be aware of the possibilities. Most of this stuff is very, very new, only weeks old, generally. Probably over the next few months we will see a lot more options appear. I am confident that there will soon be payment systems that would provide the technical basis for fee based remailing. I don't expect anyone to get rich by this, but it might help compensate for the risks we all face, and it might serve to improve the quality of the remailer network.Hal Finney\nhal@rain.orgHal Finney Home Page"}
{"prompt": "Politics vs Technology", "completion": "This position seems to be fast becoming cypherpunks dogma, but I don't agree. The notion that we can just fade into cypherspace and ignore the unpleasant political realities is unrealistic, in my view.Have people forgotten the Clipper proposal, with the possible follow-on to make non-Clipper encryption illegal? To the extent this proposal has been or will be defeated, it will happen through political maneuvering, not technology.Have people forgotten the PGP export investigation? Phil Zimmermann hasn't. He and others may be facing the prospect of ten years in prison if they were found guilty of illegal export. If anyone has any suggestions for how to escape from jail into cyberspace I'd like to hear about them.Mike's SecureDrive is a terrific program for protecting privacy. But if we want to keep keys secret from politically-motivated investigations, we have to rely on the very political and non-technological Fifth Amendment (an amendment which Mike Godwin of EFF and others contend does not actually protect disclosure of cryptographic keys). Again, we need to win political, not technological, victories in order to protect our privacy.I even question Mike's point about the government's inability to ban books. Look at the difficulty in keeping PGP available in this country even though it is legal. Not only have FTP sites been steadily closed down, even the key servers have as well. And this is legal software.Sure, this software is currently available overseas, but that is because PGP's only legal limitations are the U.S. patent issues. Imagine how much worse it would be if non-escrowed encryption were made illegal in a broad range of countries, with stringent limits on net access to countries which promote illegal software? Here again, these kinds of decisions will be made in the political realm.Fundamentally, I believe we will have the kind of society that most people want. If we want freedom and privacy, we must persuade others that these are worth having. There are no shortcuts. Withdrawing into technology is like pulling the blankets over your head. It feels good for a while, until reality catches up. The next Clipper or Digital Telephony proposal will provide a rude awakening.Hal Finney\nhal@rain.orgHal Finney Home Page"}
{"prompt": "The Case for Privacy", "completion": "An old science fiction novel features a device that surrounds its bearer with an impenetrable bubble of force. The inventor rapidly discovers that every government and political faction on the planet wants what he has and is prepared to use any means, from persuasion to brute force, to get it. Our hero spends most of the book alternately listening to arguments, trying to decide who are the good guys and using his invention to help him escape attempts to capture him.After about a hundred and fifty pages he realizes that he has been asking the wrong question. The answer to \"what faction can be trusted with a monopoly over the shield\" is \"no.\" The right question is how the shield will affect the world\u2014how it will alter the balance between freedom and oppression, individual and state, small and big. The answer to that is easy. A world where the random individual is armored against anything short of an atomic explosion will be, on net, a better and freer world than the one he is currently living in. He writes out an explanation of how the shield works and spends two days distributing the information to people all over the world. By the time Military Security\u2014the most formidable of his pursuers\u2014catches up with him, it is too late. The cat is out of the bag.Poul Anderson's shield is fiction. The nearest real world equivalent is privacy\u2014my control over other people's access to information about me. Neither my government nor my neighbor can punish my thoughts, because neither can read my mind. That is why thoughts are free. However much other people are offended by what I write, they cannot retaliate unless they know who wrote it, what he looks like, where he lives. That is why Salmon Rushdie is still alive despite the death sentence passed on the author of The Satanic Verses fifteen years ago by Iranian authorities.Defensive weapons can be used for bad purposes; an impenetrable shield would be very useful for a bank robber. But it would be even more useful for the bank teller. Robbing banks would be harder in a world where everyone had the shield than in a world where nobody did.The ability to control other people's access to information about you can be used for bad purposes too. That is the usual argument against privacy\u2014\"If you haven't done anything wrong, what do you have to hide?\" The ability to conceal past crimes from the police and potential victims is useful to a robber. But the ability to conceal what I have that is worth stealing, where it is, how it is protected, is equally useful to the potential victim. Broadly stated, privacy gives each of us more control over his own life\u2014which on average, if not in every case, is likely to lead to a freer world.If I am a bad guy, the police are not the only people I might want to keep secrets from. When courting a wealthy widow, it helps if she does not know that my last three wives drowned in their bath tubs after taking out large life insurance policies. When borrowing money, it helps if the lender does not know that I have declared bankruptcy twice already.But in a world of voluntary transactions\u2014such as loans and marriages\u2014my privacy does not require you to take me on faith. You have the option of not taking me. I have the power to keep my past defaults secret from a potential lender but he has the power to refuse to lend to me if I do. Privacy is my ability to control other people's access to information about me. That does not mean that they cannot get the information\u2014only that they cannot get it without my permission. Someone who offers to take care of my children but refuses to allow me access to the records that would show whether or not he has ever been convicted of child abuse has already told me all I need to know.In some contexts I am willing to let other people know things about me. In others I am eager to. If only lenders knew a little more about my finances I would not be interrupted at dinner by phone calls from people offering to refinance my nonexistent mortgage. If sellers were better informed about what sorts of things I was interested in buying, advertisements would be less of a nuisance and more of a service. Even in a world where I could keep information secret, I often would choose not to. Privacy provides me protection when I want it and only when I want it.Government is not reason. It is not eloquence. It is a force, like fire: a dangerous servant and a terrible master.Privacy includes the ability to keep things secret from the government. The better I can do that, the less able government is to help me\u2014I might be keeping secret my weakness for alcohol, or heroin, or gambling or pornography and so preventing the government from stepping in to protect me from myself. And the better other people can keep secrets from the government, the harder it is for the government to protect me from them. If you view government as a benevolent super being watching over you\u2014a wise and kindly uncle with a long white beard\u2014you will and should reject much of what I am saying.But government is not Uncle Sam or a philosopher king. Government is a set of institutions through which human beings act for human purposes. Its special feature\u2014what differentiates political action from the other ways in which we try to get what we want\u2014is that government is permitted to use force to make people do things. A firm can try to fool me into giving it my money. A tax collector uses more direct methods. A preacher can try to persuade me to renounce my sins. The Drug Enforcement Administration, with the help of the local police, can arrange to have me locked up until I do.Part of the genius of American political culture is the recognition that making it hard for governments to control people is not always a bad thing. Political mechanisms, even in a democracy, give us only very limited control over what government can do to us. Reducing government's ability to do bad things to us, at the cost of limiting its ability to protect us from bad things done to us by ourselves or by other people, may not be such a bad deal. And since government, unlike a private criminal, has overwhelming superiority of physical force, control over what information it can get about me is one of the few ways in which I can limit its ability to control me.I have defined privacy and sketched the reasons why I think it is, on the whole, a good thing. The obvious next questions are where privacy comes from\u2014what determines how much of it we have\u2014and what we can and should do to get more of it.One of the things that determines how much control I have over other people's access to information about me is technology. If someone invents a mind reading machine or a reliable truth drug, my thoughts will no longer be as private as they now are. Or as free.Another is custom\u2014systems of social norms. The more willing my friends and neighbors are to gossip about something, the easier it is for information about that something to get from those who have it to those who want it. That is one reason why Israelis are better informed about how much money their friends and relations make than Americans are and modern Americans better informed about other people's sex lives than nineteenth century Britons were.A final factor is law. In the U.S., the Fourth Amendment to the Constitution prohibits \"unreasonable searches and seizures\" and requires that search warrants shall only be issued with probable cause. The more narrowly courts interpret that restriction, the easier it is to keep secrets from the police. One important example is the series of cases that applied the restriction to wiretaps as well as physical searches. Later cases have ruled on to what extent the use of high tech devices to figure out what people are doing inside their houses\u2014infrared photographs to spot illegal greenhouses growing marijuana, for example\u2014is a search and so requires a warrant.Law and technology interact in complicated ways. For your neighbor's nosy fifteen year old to use a scanner to listen to the phone calls you make on your wireless phone and tell his friends about them is illegal. It is also easy, making that particular legal protection of privacy in practice unenforceable. The substitute is technology\u2014encryption of the signal from the handset to the base station. Similarly with cell phones.As these examples suggest, technological developments can both decrease and increase privacy. So can law. Legal rules that ban or limit technologies for learning things about other people, such as laws against wiretaps, increase privacy. Legal rules that ban or limit technologies for preventing other people from learning things about us, such as restrictions on the use of encryption, decrease it.It used to be that one reason to move from a village to the big city was to get more privacy. Walls were no higher in the city, windows no less transparent. But there were so many more people. In the village, interested neighbors could keep track of what who was doing with whom. In the city, nobody could keep track of everyone.That form of privacy\u2014privacy through obscurity\u2014is doomed. I cannot keep track of the million people who share the city I live in. But the computer on my desk has enough space on its hard drive to hold a hundred pages of information on every man, woman and child in San Jose. With a few hundred dollars worth of additional storage, I could do it for everyone in California, for a few thousand, everyone in the country. And I can do more than store the information. If I had it I could search it\u2014produce, in a matter of seconds, a list of those of my fellow citizens who are left handed gun owners with more than six children. Privacy through obscurity cannot survive modern data processing.As it happens, I do not have a hundred pages worth of information on each of my fellow citizens. But with a little time and effort\u2014too much for a single individual, but not too much for a government, a police department, or a large firm\u2014I could. It is hard to pass through the world without leaving tracks. Somewhere there is a record of every car I have registered, every tax form I have filed, two marriages, one divorce, the birth of three children, thousands of posts to online forums on a wide variety of subjects, four published books, medical records and a great deal more.Much such information, although not all of it, was publicly available in the past. But actually digging it up was a lot of work. The result was that most of us went through life reasonably sure that most of the people we met did not know much about us beyond what we chose to tell them. That will not be true in the future.Data processing is one technology with the potential to sharply reduce privacy. Another is surveillance. One form\u2014already common in England\u2014is a video camera on a pole.A video camera in a park connected to a screen with a police officer watching it is, at first glance, no more a violation of privacy than the same police officer standing in the park watching what is going on. It merely lets the officer do his watching somewhere warm and out of the wet. Add a video recorder and it is arguably an improvement, since the evidence it produces is less subject to mistake or misrepresentation than the memory of the policeman. And, judging by British experience, such surveillance cameras are an effective way of reducing crime. What's the problem?To see the answer, add one more technology\u2014face recognition software. Combine that with a database, put up enough cameras, and we have a record of where everyone was any time of the day and\u2014with suitable cameras\u2014night. The arresting officer, or the prosecuting attorney, no longer has to ask the defendant where he was at eight P.M. of July ninth. All he has to do is enter the defendant's social security number and the date and the computer will tell him. And, if the defendant was in a public place at the time, show him.For a slightly lower tech version of the same issue, consider the humble phone tap. In the past, the main limit on how many phones got tapped by police was not the difficulty of getting a court order but the cost of implementing it. Phone taps are labor intensive\u2014someone has to listen to a lot of phone calls in order to find the ones that matter.That problem has now been solved. Voice recognition software originated by companies such as Dragon Systems and IBM lets computers convert speech into text\u2014a boon for computer users who are slow typists. The same technology means that the police officer listening to someone else's phone calls can now be replaced by a computer. Only when it gets a hit, spots the words or phrases it has been programmed to listen for, does it need to call in a human being. Computers work cheap.In an old comedy thriller (The President's Analyst, starring James Coburn) the hero, having temporarily escaped his pursuers and made it to a phone booth, calls a friendly CIA agent to come rescue him. When he tries to leave the booth, the door won't open. Down the road comes a phone company truck loaded with booths. The truck's crane picks up the one containing the analyst, deposits it in the back, replaces it with an empty booth and drives off.A minute later a helicopter descends containing the CIA agent and a KGB agent who is his temporary ally. They look in astonishment at the empty phone booth. The American speaks first:\"It can't be. Every phone in America tapped?\"The response (you will have to imagine the Russian accent)\"Where do you think you are, Russia?\"A great scene in a very funny movie\u2014but it may not be a joke much longer. The digital wiretap bill, pushed through Congress by the FBI a few years ago, already requires phone companies to provide law enforcement with the ability to simultaneously tap one percent of all phones in a selected area. There is no obvious reason why that cannot be expanded in the future. My current estimate is that the dedicated hardware to do the listening part of the job\u2014for every phone call in the U.S.\u2014would cost less than a billion dollars. And it is getting cheaper.So far I have been discussing technologies that already exist. Fast forward a little further and surveillance need no longer be limited to public places. Video cameras are getting smaller. It should not be all that long before we can build one with the size\u2014and the aerodynamic characteristics\u2014of a mosquito.Here again, if we regard government law enforcement agents as unambiguously good guys, there is no problem. The better our record of where everyone was when, the easier it will be to catch and convict criminals.The same technology would make keeping track of dissidents, or political opponents, or members of an unpopular religion, or people with the wrong sexual tastes, or people who read the wrong books, or anyone else, a great deal easier than it now is. It is true that the random government is rather less likely to have bad intentions than the random criminal. But if it does have bad intentions it can do a great deal more damage.The technologies I have been discussing so far\u2014database and face recognition software, surveillance hardware\u2014have the potential to make this a much less private world. So do other technologies that I have not covered: improvements in lie detectors and interrogation drugs to learn what we think, biometric identification by fingerprints, retinal patterns, DNA to learn who we are, with or without our permission. The future implications of such developments are sufficiently strong to have convinced at least one thoughtful observer that the best we can hope for in the future is a transparent society, a world without privacy where the police can watch us but we can also watch them (Brin 1999). I would find the symmetry of that future more appealing if it did not conceal an important asymmetry: They can arrest us and we cannot arrest them.But there are other technologies.We start with an old problem: How to communicate with someone without letting other people know what you are saying. There are a number of familiar solutions. If worried about eavesdroppers, check under the eaves. To be safer still, hold your private conversation in the middle of a large, open field, or a boat in the middle of a lake. The fish are not interested and nobody else can hear.That no longer works. The middle of a lake is still within range of a shotgun mike. Eaves do not have to contain eavesdroppers\u2260just a microphone and a transmitter. Phone lines can be tapped, cordless or cell phone messages intercepted. An email bounces through multiple computers on its way to its destination\u00e3anyone controlling one of those computers can save a copy for himself.The solution is encryption. Scramble the message. Provide the intended recipient with the formula for unscrambling it. Now it does not matter if someone intercepts your mail. He can't read it.There is still a problem. In order to read my scrambled message you need the key\u2260the formula describing how to unscramble it. If I do not have a safe way of sending you messages, I may not have a safe way of sending you the key either. If I sent it by a trusted messenger but made a small mistake as to who he was really working for, someone else now has a copy and can use it decrypt my future messages to you.About twenty-five years ago, this problem was solved. The solution is public key encryption. It works by using two keys, each of which decrypts what the other encrypts. One of the two\u2014my public key\u2014I make available to anyone who might want to send me a message. The other never leaves my hands. Someone who wants to communicate with me encrypts his messages with my public key. I use my private key to decrypt them.Public key encryption provides a free bonus\u2014digital signatures. In order to prove that a message was sent by me I can encrypt it using my private key. The recipient decrypts it using my public key. The fact that what comes out is text rather than gibberish proves it was encrypted with the matching private key\u2014which only I have. Hence, unless I have been very careless, the message is from me.Imagine a world where public key encryption is in general use. Add in related technologies such as anonymous digital money, to permit payments that leave no paper trail, and anonymous remailers, to keep who I am talking to, as well as what I am saying, private\u2014for details see (Friedman 1996). In that world I can email someone\u2014anyone\u2014with reasonable certainty that nobody else can read the message. I can have telephone conversations without worrying about who may be listening. In that world I can if I wish establish an online persona\u2014an identity defined by my digital signature\u2014while keeping control over the link between that and my realspace persona. However much my online persona offends someone\u2014even the rulers of Iran\u2014there is very little anyone can do about it. It is hard to murder someone when you don't know his name, what he looks like, or what continent he is on.I have been describing things we already know how to do. Most can already be done\u2014using free software that runs on the computers most of us have. I now take a small step forward to add one more element to the mix: Virtual reality. Using goggles and earphones\u2014if we are willing to step further into science fiction, direct links between mind and computer\u2014we create the illusion of seeing, hearing, perhaps tasting and touching. The world of strong privacy expands from text messages and phone conversations to something very much like the real world we currently live in. Just let your fingers do the walking.I have described two clusters of technologies. One\u2014database, voice and text recognition, surveillance\u2014has the potential to reduce privacy to the point where those who control the technology know very nearly everything that everyone does. The other\u2014encryption, online communication, virtual reality\u2014has the potential to increase privacy to the point where individuals have nearly total control over other people's access to information about them. What if we get both?It will be an interesting world. Everything you do in realspace will be known to the authorities, perhaps to everyone\u2014David Brin's Transparent Society. But most of the important stuff\u2014all transactions involving information, ideas, arguments, beliefs\u2014will have been moved to cyberspace, protected by the strong privacy of encryption. Freedom of speech will no longer depend on how the Supreme Court interprets the First Amendment. It will be protected, instead, by the laws of mathematics\u2014which so far, at least, heavily favor defense over offense, encryption over cracking.There will be\u2014already have been\u2014attempts to use law to block both futures. Supporters of privacy will try to get laws restricting the ability of law enforcement\u2014and other people\u2014to use technology to learn our secrets. Opponents of privacy will try to get laws restricting the ability of private individuals to use encryption to protect their secrets.There are at least two legal approaches to preserving privacy in the face of technologies such as computer databases and surveillance. One is to use law to prevent other people from getting information\u2014a data base is of no use if there is nothing in it. The other is to permit other people to get information but use law to limit what they can do with it.An example of the first approach is regulation of wire tapping and other forms of surveillance\u2014both laws against private surveillance and laws restricting surveillance by law enforcement agents. Such restrictions can keep some information about me from getting to other people. But they do nothing to protect the vast amount of information that I generate by going about my daily life in the public view\u2014buying and selling, marrying and getting divorced, writing and talking.An example of the second approach is the web of restrictions, legal, contractual, and customary, on the use of confidential information. I cannot keep my doctor from having access to the medical information he creates when he examines me and uses when he prescribes for me. But I can, to some limited degree, prevent him from sharing that information with other people. Credit bureaus are free to collect information on people in order to advise other people as to whether to lend them money but, under current Federal law, they are only permitted to release that information in response to requests from people who have a legitimate need for it.As the example of credit bureaus suggests, there are practical difficulties with protecting privacy by letting other people have information and then controlling what they do with it. Credit agencies could not serve their intended purpose at any reasonable cost if they engaged in an extensive investigation of everyone who asked for information. And even if the agency limits itself to giving the information to people who can prove they are entitled to it, there is no way it can control who they then give it to. It is probably prudent to assume that what the credit agency knows about you any else can know if he really wants to. The forms you sign when you shift to a new doctor include an extensive list of people to whom and circumstances under which your medical information will be made available, so it might be equally prudent not to rely too much on your medical privacy.As long as we limit our options to current technologies for protecting privacy, the outlook does not look good. We might succeed in restricting the use of surveillance, wiretapping, and similar technologies, although attempts to restrict their use by law enforcement face serious opposition by those concerned with the threat of crime and terrorism. But most information about us is public, and once information is out it is hard to control how other people use it or who they give it to.The technologies of strong privacy offer at least a partial solution. If I make a purchase with a credit card, I create a paper trail\u2014someone, somewhere, knows what I bought. Even if I use cash, a purchase in real space requires me to walk into a store where someone sees me\u2014the information about what I bought is now his as well as mine. In a world where the relevant software is a little better than it now is\u2014say ten years in the future\u2014that someone is a store video camera linked to facial recognition software linked to a database. Stores, after all, like to know who their customers are.If, however, I buy something over the phone or over the internet, using the digital equivalent of cash\u2014anonymous digital currency\u2014only I know that I bought it. If the something is not a physical object that must be delivered to me but information\u2014music, data, software\u2014I can collect my purchase online without ever revealing my identity or location.Thus the technologies of encryption and computer networking can permit us, to a considerable extent, to move through the world without leaving footprints behind. If I want to receive advertising based on my past purchases\u2014as it happens I often do\u2014I can choose to make those purchases under my real name and provide my real address. If I want to receive the advertising without making my acts publicly observable\u2014perhaps I am purchasing pornography\u2014I can do it via an online identity. The link that ties my realspace body to my cyberspace persona is under my control. I have privacy\u2014control over other people's access to information about me.If we go a little further into science fiction I could even have privacy from my doctor. He knows the information that an examination\u2014via remote controlled devices\u2014revealed about me. He does not need to know what my name is, my face looks like, or where I live. It is not likely that I would want to carry my privacy that far\u2014but I could.So far I have been considering ways in which we might preserve privacy against the threat posed by technology. But there is another side to the story. For those who think that we already have too much privacy, what I view as the solution may look more like the problem. There have already been attempts to restrict the use of encryption to protect privacy. There will be more.Suppose I concede, at least for the purposes of argument, that it is possible to have too much privacy as well as too little. Further, and less plausibly, suppose I believed that the strong privacy provided by encryption is a serious problem. How might one use law to solve it?One difficulty is that encryption regulation poses the problem summed up in the slogan\u2014\"when guns are outlawed, only outlaws have guns.\" The mathematics of public key encryption have been public for decades. The software to do it already exists in a variety of forms, some of them freely available. Given the nature of software, once you have a program you can make an unlimited number of copies. Keeping encryption software out of the hands of spies, terrorists, and competent criminals is not a practical option. They probably have it already, and if they don't they can easily get it. The only people affected by a law against encryption software are the law abiding.What about banning or restricting the use of encryption\u2014at least encryption that cannot be broken by law enforcement agents? To enforce such a ban law enforcement agencies could randomly monitor all communication systems, looking for illegally encrypted messages. One practical problem is the enormous volume of information flowing over computer networks. A second and even more intractable problem is that while it is easy enough to tell whether a message consists of text written in English, it is very much harder\u2014in practice impossible\u2014to identify other sorts of content well enough to be sure that they do not contain encrypted messages.Consider a three million pixel digital photo. To conceal a million character long encrypted message\u2014an average sized novel\u2014I replace the least significant bit of each of the numbers describing the color of a pixel with one bit of the message. The photo is now a marginally worse picture than it was\u2014but there is no way an FBI agent, or a computer working for an FBI agent, can know precisely what the photo ought to look like.Short of banning communication over computer networks or at least restricting it to text messages, there is no way that law enforcement can keep sophisticated criminals, spies, or terrorists from using encryption. What can be done is to put limits on the encryption software used by the rest of us\u2260to insist, for example, that if AOL or Microsoft builds encryption into their programs it must contain a back door permitting properly authorized persons to read the message without the key.This still leaves the problem of how to give law enforcement what it wants without imposing unacceptably high costs on the rest of us. Consider the description of adequate regulation given by Louis Freeh, at the time the head of the FBI\u2014the ability to crack any encrypted message in half an hour. The equivalent in realspace would be legal rules that let properly authorized law enforcement agents open any lock in the country in half an hour. That includes not only the lock on your front door but the locks protecting bank vaults, trade secrets, lawyers' records, lists of contributors to unpopular causes, and much else.Encryption provides the locks for cyberspace. If all legal encryption comes with a mandatory back door accessible in half an hour to any police officer with a court order, everything in cyberspace is vulnerable to a private criminal with the right contacts. Those locks have billions of dollars worth of stuff behind them\u2260money in banks, trade secrets in computers and in messages. If being a police officer gives you access to locks with billions of dollars behind them, in cash, diamonds, or information, some cops will become criminals and some criminals will become cops.In one important way, the consequence for cyberspace is even worse than the equivalent in realspace. If a police officer opens a safe and pockets a stack of cash or a bag of diamonds, the owner can see that something is missing and demand it back. But when information is copied the original is still there. If the officer who has decrypted your communications or stored data assures you that he found nothing relevant to his investigation and so took nothing away, there is no way to prove he is lying.For encryption regulation to be useful it must either prevent the routine use of encryption or make it easy for law enforcement agents to access encrypted data and messages. Not only would that seriously handicap routine transactions, it would make computer crime easier by restricting the technology best suited to defend against it. And what we get in exchange is protection not against the use of encryption by sophisticated criminals and terrorists\u2260there is no way of providing that\u2260but only against its use by ordinary people and unsophisticated criminals. It does not look like a very attractive deal.Some years ago Professor Etzioni, who has contributed a chapter to this volume, published a book arguing for some restrictions on privacy as ways of promoting the common good. In reading it, I was struck by two differences between our views that explain much of the difference in our conclusions.The first was that I did, and he did not, define privacy in the context of freedom of association. Consider the question of airlines requiring their pilots to be tested for drugs and alcohol. Professor Etzioni regards that as a (desirable) restriction on the pilots' privacy. I agree that it is desirable but not that it restricts privacy.In a society where privacy is protected you have a right not to be tested. You do not have a right to be hired to fly airplanes\u2014and, if you choose to exercise your right not to be tested, you should not be surprised if the airline exercises its right not to hire you. The background legal principle is not that I have a right to be hired as a pilot or that United Airlines has a right to have me fly their planes. The background principle is that they can hire me to fly their planes if and only if both they and I agree. Given that principle of free association many\u2014although not all\u2014of the problems that Professor Etzioni sees with privacy vanish.The second difference has to do with our different views of government. While Professor Etzioni makes occasional references to the risk of some future oppressive government misusing information, he does not take seriously similar concerns with regard to our current government. His implicit assumption is that government is to be viewed as a benevolent agent standing above the human struggle, not as a mechanism through which individuals seek to achieve their goals, often at the expense of other individuals. That is not a view that strikes me as realistic.Privacy, like almost anything else, can be used for good or bad purposes. My thesis in this chapter is that, on net, more privacy makes the world a better place. It does so because it is an essentially defensive weapon, a way of reducing the ability of other people to control us.Reducing the ability of other people to control us is not always a good thing\u2014someone may, after all, want to control me for my own good or control you to keep you from hurting me. But we live in a world where too much control is more of a problem than too little. In the entire world over the past century, something on the order of ten million people have been killed by private murderers. Between a hundred and two hundred million have been killed by the governments that ruled them (Rummel (1999) estimates about 170 million from 1900 to 1987). Quite a lot of individual pain, suffering, injustice has been due to the acts of private individuals; some could have been prevented by better law enforcement. But mass pain, suffering and injustice has been very nearly a monopoly of governments. If governments were better able to control us, there would have been more of it. And at the individual level, while privacy can be used to protect criminals against police, it can also be used to protect victims against criminals.It is tempting to try for the best of both worlds\u2014to restrict the privacy of bad people while protecting that of good, permit governments to collect detailed information about us but only allow it to be used for good purposes. But somebody must decide who are the good people and the bad, what purposes are worthy or unworthy. Whoever that somebody is will have his own agenda, his own purposes. Angels are in short supply.To put the matter differently, \"cannot\" is better protection than \"may not.\" If we permit law enforcement agents to know everything about everybody but forbid them fro using that information against individuals with unpopular views or political opponents of the party in power, we are protected only by a \"may not.\" The same is true if private parties are able to collect information but restricted in what they may do with it. If the law keeps the information from being collected in the first place, we are protected by a cannot\u2014however corrupt or dishonest they are, or however convinced that they are working for a greater good, people cannot use information they do not have.\"Cannot\" at one level may depend on \"may not\" at another. You cannot use information that you do not have. You do not have it because you may not collect it. But even if the law forbids wiretaps or unauthorized surveillance, a sufficiently determined agency\u2014or a sufficiently competent private criminal\u2014can violate the law. That is where technologies that support privacy come into the picture. In a world where encryption is routine it does you no good to tap my phone because you cannot understand what I am saying. It does no good to intercept my email because you cannot read it. \"Cannot\" is better than \"may not.\"We can and should fight a delaying action against the use of technology to restrict privacy. But in the long run technology\u2014useful technology\u2014is hard to stop. In the long run, the real battle will be the one fought in defense of technologies that protect privacy. That one we might win.Brin, David (1999), The Transparent Society: Will Technology Force Us to Choose Between Privacy and Freedom? Perseus (The first chapter is webbed at http://www.kithrup.com/brin/tschp1.html)Etzioni, Amitai (1999), The Limits of Privacy, Basic Books.Friedman, David (1996) \"A World of Strong Privacy: Promises and Perils of Encryption,\" Social Philosophy and Policy, pp. 212-228. Webbed at http://www.daviddfriedman.com/Academic/Strong_Privacy/Strong_Privacy.htmlRummel, Rudolph J. (1999), Statistics of democide: Genocide and mass murder since 1900, Lit Verlag.Anderson, Poul, ShieldEllen Frankel Paul, Fred D. Miller, Jr., & Jeffrey Paul (Eds). (2000) The Right to Privacy, Cambridge University Press.http://www.mega.nu:8080/ampp/rummel/20th.htm (detailed statistics on 20th century democide)http://www.daviddfriedman.com/future_imperfect_draft/future_imperfect.html (Much more detailed account of encryption, surveillance, and much else.)David Friedman is a professor of law at Santa Clara University; his specialty is the economic analysis of law and his current interests include the effect of technology on the world over the next few decades. His most recent book is Law's Order: What Economics has to do with Law and Why It Matters. You can learn more than you want to know about both him and his ideas at www.daviddfriedman.com."}
{"prompt": "Money, Blockchains, and Social Scalability", "completion": "Blockchains are all the rage. The oldest and biggest blockchain of them all is Bitcoin, which over its eight-year history so far starshipped in value from 10,000 bitcoins per pizza (before there were exchanges that priced bitcoin in traditional currencies) to over $1,000 per bitcoin. As of this writing Bitcoin has a market capitalization of over $16 billion. Running non-stop for eight years, with almost no financial loss on the chain itself, it is now in important ways the most reliable and secure financial network in the world.The secret to Bitcoin\u2019s success is certainly not its computational efficiency or its scalability in the consumption of resources. Specialized Bitcoin hardware is designed by highly paid experts to perform only one particular function\u2014to repetitively solve a very specific and intentionally very expensive kind of computational puzzle. That puzzle is called a proof-of-work, because the sole output of the computation is just a proof that the computer did a costly computation. Bitcoin\u2019s puzzle-solving hardware probably consumes in total over 500 megawatts of electricity. And that is not the only feature of Bitcoin that strikes an engineer or businessman who is focused on minimizing resource costs as highly quixotic. Rather than reduce its protocol messages to be as few as possible, each Bitcoin-running computer sprays the Internet with a redundantly large number of \u201cinventory vector\u201d packets to make very sure that all messages get accurately through to as many other Bitcoin computers as possible. As a result, the Bitcoin blockchain cannot process as many transactions per second as a traditional payment network such as PayPal or Visa. Bitcoin offends the sensibilities of resource-conscious and performance-measure-maximizing engineers and businessmen alike.Instead, the secret to Bitcoin\u2019s success is that its prolific resource consumption and poor computational scalability is buying something even more valuable: social scalability. Social scalability is the ability of an institution\u2014a relationship or shared endeavor, in which multiple people repeatedly participate, and featuring customs, rules, or other features which constrain or motivate participants\u2019 behaviors\u2014to overcome shortcomings in human minds and in the motivating or constraining aspects of said institution that limit who or how many can successfully participate. Social scalability is about the ways and extents to which participants can think about and respond to institutions and fellow participants as the variety and numbers of participants in those institutions or relationships grow. It's about human limitations, not about technological limitations or physical resource constraints. There are separate engineering disciplines, such as computer science, for assessing the physical limitations of a technology itself, including the resource capacities needed for a technology to handle a greater number of users or a greater rate of use. Those engineering scalability disciplines are not, except by way of contrast with social scalability, the subject of this essay.Even though social scalability is about the cognitive limitations and behavior tendencies of minds, not about the physical resource limitations of machines, it makes eminent sense, and indeed is often crucial, to think and talk about the social scalability of a technology that facilitates an institution. The social scalability of an institutional technology depends on how that technology constrains or motivates participation in that institution, including protection of participants and the institution itself from harmful participation or attack. One way to estimate the social scalability of an institutional technology is by the number of people who can beneficially participate in the institution. Another way to estimate social scalability is by the extra benefits and harms an institution bestows or imposes on participants, before, for cognitive or behavioral reasons, the expected costs and other harms of participating in an institution grow faster than its benefits. The cultural and jurisdictional diversity of people who can beneficially participate in an institution is also often important, especially in the global Internet context. The more an institution depends on local laws, customs, or language, the less socially scalable it is.Without institutional and technological innovations of the past, participation in shared human endeavors would usually be limited to at most about 150 people\u2014the famous \u201cDunbar number\u201d. In the Internet era, new innovations continue to scale our social capabilities. In this article I will discuss how blockchains, and in particular public blockchains that implement cryptocurrencies, increase social scalability, even at a dreadful reduction in computational efficiency and scalability.Cognitive capacity\u2014here in the form of the relative size of a species\u2019 neocortex\u2014set limits on how large primate groups can be. Maintaining animal or intimate human groups requires extensive emotional communications and investments in relationships, such as grooming in primates and gossiping, humor, story-telling, and other conversations, songs, and play in traditional human groups. Overcoming human cognitive limits to who or how many people can participate in an institution\u2014the famous \u201cDunbar number\u201d of around 150 people\u2014requires institutional and technological innovation. (Source)Innovations in social scalability involve institutional and technological improvements that move function from mind to paper or mind to machine, lowering cognitive costs while increasing the value of information flowing between minds, reducing vulnerability, and/or searching for and discovering new and mutually beneficial participants. Alfred North Whitehead said, \u201cIt is a profoundly erroneous truism, repeated by all copy-books and by eminent people when they are making speeches, that we should cultivate the habit of thinking what we are doing. The precise opposite is the case. Civilization advances by extending the number of important operations which we can perform without thinking about them.\u201d Friedrich Hayek added: \u201cWe make constant use of formulas, symbols, and rules whose meaning we do not understand and through the use of which we avail ourselves of the assistance of knowledge which individually we do not possess. We have developed these practices and institutions by building upon habits and institutions which have proved successful in their own sphere and which have in turn become the foundation of the civilization we have built up.\u201dA wide variety of innovations reduce our vulnerability to fellow participants, intermediaries, and outsiders, and thereby lower our need to spend our scarce cognitive capacities worrying about how an increasingly large number of increasingly diverse people might behave. Another class of improvements motivates the accurate collection and transmission of valuable information between an increasing number and variety of participants. Yet other advances enable a wider number or variety of mutually beneficial participants can discover each other. All these kinds of innovations have over the course of human prehistory and history improved social scalability, sometimes dramatically so, making our modern civilization with its vast global population feasible. Modern information technology (IT), especially by making use of the historically recent discoveries of computer science, can often discover many more mutually beneficial matches, can improve motivations for information quality, and can reduce the need for trust within certain kinds of institutional transactions, with respect to an increasingly large number and variety of people, thereby further increasing social scalability in some very important ways.Information flows between minds\u2014what I have called intersubjective protocols\u2014include spoken and written words, custom (tradition), the contents of law (its rules, customs, and case precedents), a variety of other symbols (e.g. \u201cstar\u201d ratings common in online reputation systems), and market prices, among many others.Trust minimization is reducing the vulnerability of participants to each other\u2019s and to outsiders\u2019 and intermediaries\u2019 potential for harmful behavior. Most institutions which have undergone a lengthy cultural evolution, such as law (which lowers vulnerability to violence, theft, and fraud), as well as technologies of security, reduce, on balance, and in more ways than the reverse, our vulnerabilities to, and thus our needs to trust, our fellow humans, compared with our vulnerabilities before these institutions and technologies evolved. In most cases an often trusted and sufficiently trustworthy institution (such as a market) depends on its participants trusting, usually implicitly, another sufficiently trustworthy institution (such as contract law). These trusted institutions in turn traditionally implement a variety of accounting, legal, security, or other controls that make them usually and sufficiently, at least for facilitating the functionality of their client institutions, trustworthy, by minimizing vulnerability to their own participants (such as accountants, lawyers, regulators, and investigators). An innovation can only partially take away some kinds of vulnerability, i.e. reduce the need for or risk of trust in other people. There is no such thing as a fully trustless institution or technology.The nonexistence of complete trustlessness is true even of our strongest security technology, encryption. Although some cryptographic protocols do guarantee certain specific data relationships with astronomically high probability against opponents with astronomically high computing power, they do not provide complete guarantees when accounting for all possible behaviors of all participants. For example, encryption can strongly protect an e-mail from direct eavesdropping by third parties, but the sender still trusts the recipient to not forward or otherwise divulge the contents of that email, directly or indirectly to any undesired third parties. As another example, in our strongest consensus protocols harmful behavior by certain fractions of participants or intermediaries well short of 100% (as measured by their computing power, stake-holding, or individuation and counting) can compromise the integrity of transactions or information flows between participants and thereby on balance harm the participants. The historically recent breakthroughs of computer science can reduce vulnerabilities, often dramatically so, but they are far from eliminating all kinds of vulnerabilities to the harmful behavior of any potential attacker.Matchmaking is facilitating the mutual discovery of mutually beneficial participants. Matchmaking is probably the kind of social scalability at which the Internet has most excelled. Social networks like Usenet News, Facebook, and Twitter facilitate the mutual discovery of like-minded or otherwise mutually entertaining or mutually informing people (and even future spouses!). After they have allowed people more likely to be of mutual benefit to discover each other, social networks then facilitate relationships at various levels of personal investment, from casual to frequent to obsessive. Christopher Allen among others has done some interesting and detailed analyses about group size and time spent mutually interacting in online games and associated social networks.eBay, Uber, AirBnB, and online financial exchanges have brought social scalability via often great improvements in commercial matchmaking: searching for, finding, bringing together, and facilitating the negotiation of mutually beneficial commercial or retail deals. These or related services also facilitate performances such as payment and shipping, as well as verification that other obligations undertaken by strangers in these deals have been performed and communication about the quality of such performances (as with \u201cstar rating\u201d systems, Yelp reviews, and the like).Whereas the main social scalability benefit of the Internet has been matchmaking, the predominant direct social scalability benefit of blockchains is trust minimization. A blockchain can reduce vulnerability by locking in the integrity of some important performances (such as the creation and payment of money) and some important information flows, and in the future may reduce the vulnerability of the integrity of some important matchmaking functions. Trust in the secret and arbitrarily mutable activities of a private computation can be replaced by verifiable confidence in the behavior of a generally immutable public computation. This essay will focus on such vulnerability reduction and its benefit in facilitating a standard performance beneficial to a wide variety of potential counterparties, namely trust-minimized money.Money and markets directly benefit the participants in each particular trade by the market matching a buyer with a mutually beneficial seller and by a widely acceptable and standardized counter-performance (money). I use markets here in the sense Adam Smith used the term: not as a specific place or service where buyers and sellers are brought together (although it might sometimes involve these), but rather the broad set of typically pairwise exchanges whereby the supply chain that makes a product is coordinated.Money and markets also incentivize creation of more accurate price signals that reduce negotiation costs and errors for participants in other similar exchanges. The potent combination of money and market thereby allowed a far higher number and variety of participants to coordinate their economic activities than previous exchange institutions, which more resembled bilateral monopolies than competitive markets.Markets and money involve matchmaking (bringing together buyer and seller), trust reduction (trusting in the self-interest rather than in the altruism of acquaintances and strangers), scalable performance (via money, a widely acceptable and reusable medium for counter-performance), and quality information flow (market prices).The greatest early thinker about money and markets was Adam Smith. At the dawn of the industrial revolution in Britain, Smith observed in The Wealth of Nations how making even the most humble of products depended, directly and indirectly, on the work of large numbers of a wide variety of people:Observe the accommodation of the most common artificer or day-laborer in a civilized and thriving country, and you will perceive that the number of people of whose industry a part, though but a small part, has been employed in procuring him this accommodation, exceeds all computation. The woolen coat, for example, which covers the day laborer, as coarse and rough as it may appear, is the produce of the joint labor of a great multitude of workmen. The shepherd, the sorter of the wool, the wool-comber or carder, the dyer, the scribbler, the spinner, the weaver, the fuller, the dresser, with many others, must all join their different arts in order to complete even this homely production. How many merchants and carriers, besides, must have been employed in transporting the materials from some of those workmen to others who often live in a very distant part of the country! How much commerce and navigation in particular, how many shipbuilders, sailors, sail makers, rope makers, must have been employed in order to bring together the different drugs made use of by the dyer, which often come from the remotest corners of the world! What a variety of labor, too, is necessary in order to produce the tools of the meanest of those workmen! To say nothing of such complicated machines as the ship of the sailor, the mill of the fuller, or even the loom of the weaver, let us consider only what a variety of labor is requisite in order to form that very simple machine, the shears with which the shepherd clips the wool. The miner, the builder of the furnace for smelting the ore, the feller of the timber, the burner of the charcoal to be made use of in the smelting-house, the brick maker, the brick layer, the workmen who attend the furnace, the millwright, the forger, the smith, must all of them join their different arts in order to produce them. Were we to examine, in the same manner, all the different parts of his dress and household furniture, the coarse linen shirt which he wears nest his skin, the shoes which cover his feet, the bed which he lies on, and all the different parts which compose it, the kitchen grate at which be prepares his victuals, the coals which he makes use of for that purpose, dug from the bowels of the earth, and brought to him perhaps by a long sea and a long land carriage, all the other utensils of his kitchen, all the furniture of his table, the knives and forks, the earthen or pewter plates upon which he serves up and divides his victuals, the different hands employed in preparing his bread and his beer, the glass window which lets in the heat and the light, and keeps out the wind and the rain, with all the knowledge and art requisite for preparing that beautiful and happy invention, without which these northern parts of the world could scarce have afforded a very comfortable habitation, together with the tools of all the different workmen employed in producing those different conveniences; if we examine, I say, all these things, and consider what a variety of labor is employed about each of them, we shall be sensible that without the assistance and co-operation of many thousands, the very meanest person in a civilized country could not be provided, even according to what we may falsely imagine the easy and simple manner in which he is commonly accommodated.And this was before the many successive waves of industrial revolution and globalization between 1776 and now that refined, elaborated, and extended the division of labor many times more. Rather than trusting in the unlikely altruism of so many strangers, markets and money create many pairings of mutual benefit and thus motivate this large network of mutually oblivious people to act in our interests:In civilized society man stands at all times in need of the cooperation and assistance of great multitudes, while his whole life is scarce sufficient to gain the friendship of a few persons\u2026[In contrast to other animals,] man has an almost constant occasion for the help of his brethren, and it is vain for him to expect it from their benevolence only\u2026 [Exchange is the] manner in which we obtain from another the far greater part of those good offices which we stand in need of. It is not from the benevolence of the butcher, the brewer, or the baker, that we expect our dinner, but from their regard for their own interest.Smith goes on to describe how division of labor, and thus labor productivity, depends on the extent of the network of pairwise exchanges: \u201cAs it is the power of exchanging that gives occasion to the division of labor, so the extent of this division must always be limited by the extent of that power, or, in other words, by the extent of the market\u201d. As the exchange network around a country and around the globe grows, involving a greater number and variety of producers, so grows the division of labor and thereby labor productivity.Money facilitates social scalability by increasing the opportunities for this exchange. By lowering coincidence problems (coincidence-of-wants in exchange and coincidence-of-want-and-event in unilateral transfers), via a widely acceptable and reusable form of wealth storage and transfer, money greatly lowered transaction costs, making possible more exchanges of a greater variety of goods and services involving exchanges and other wealth transfer relationships with a much larger number and much wider variety of people.A wide variety of media, from oral language itself, clay, paper, telegraph, radio, and computer networks, have served to communicate offers, acceptances, and the resulting deals and prices, as well as performance monitoring and other business communications.One of the most knowledgeable observations of the price network produced by markets and money can be found in Friedrich Hayek\u2019s essay, \u201cThe Use of Knowledge in Society\u201d:In a system in which the knowledge of the relevant facts is dispersed among many people, prices can act to coordinate the separate actions of different people\u2026in any society in which many people collaborate, this planning, whoever does it, will in some measure have to be based on knowledge which, in the first instance, is not given to the planner but to somebody else, which somehow will have to be conveyed to the planner. The various ways in which the knowledge on which people base their plans is communicated to them is the crucial problem for any theory explaining the economic process, and the problem of what is the best way of utilizing knowledge initially dispersed among all the people is at least one of the main problems of economic policy\u2014or of designing an efficient economic system\u2026 The mere fact that there is one price for any commodity\u2014or rather that local prices are connected in a manner determined by the cost of transport, etc.\u2014brings about the solution which (it is just conceptually possible) might have been arrived at by one single mind possessing all the information which is in fact dispersed among all the people involved in the process\u2026 The marvel is that in a case like that of a scarcity of one raw material, without an order being issued, without more than perhaps a handful of people knowing the cause, tens of thousands of people whose identity could not be ascertained by months of investigation, are made to use the material or its products more sparingly; i.e., they move in the right direction\u2026.The price system is just one of those formations which man has learned to use (though he is still very far from having learned to make the best use of it) after he had stumbled upon it without understanding it. Through it not only a division of labor but also a coordinated utilization of resources based on an equally divided knowledge has become possible\u2026a solution is produced by the interactions of people each of whom possesses only partial knowledge.Where long ago we used clay, and more recently paper, today programs and protocols running on our computers and data networks implement most of our commercial dealings. While this has greatly improved matchmaking and information flow, it has come at the cost of an increase in vulnerability to harmful behavior.As networks grow, more people with fewer mutually understood habits of and constraints on behavior are added. Security via root-trusting access control, designed for small and chummy offices like Bell Labs where co-workers were well known and income and expenditures well controlled by paper procedures rather than performed on these office computers, breaks down as an efficient and effective security mechanism as organizations become larger, as organizational boundaries are crossed, and as more valuable and concentrated resources such as money are put on or activated via the computers. The more strangers one receives emails from, the more likely one is likely to get a phishing attack or a malware-laced attachment. Traditional computer security is not very socially scalable. As I describe in \u201cThe Dawn of Trustworthy Computing\u201d:When we currently use a smart phone or a laptop on a cell network or the Internet, the other end of these interactions typically run on other solo computers, such as web servers. Practically all of these machines have architectures that were designed to be controlled by a single person or a hierarchy of people who know and trust each other. From the point of view of a remote web or app user, these architectures are based on full trust in an unknown \u201croot\u201d administrator, who can control everything that happens on the server: they can read, alter, delete, or block any data on that computer at will. Even data sent encrypted over a network is eventually unencrypted and ends up on a computer controlled in this total way. With current web services we are fully trusting, in other words we are fully vulnerable to, the computer, or more specifically the people who have access to that computer, both insiders and hackers, to faithfully execute our orders, secure our payments, and so on. If somebody on the other end wants to ignore or falsify what you've instructed the web server to do, no strong security is stopping them, only fallible and expensive human institutions, which often stop at national borders.Many server computers are not valuable enough for insiders or outsiders to attack. But an increasing number of others contain valuable concentrations of resources, motivating attack. Centralized root-trusting security scales poorly. As the resources controlled by computers become more valuable and more concentrated, traditional root-trusting security becomes more like the \u201ccall the cop\u201d security we are used to in the physical world. Fortunately, with blockchains we can do much better for many of our most important computations.Scalable markets and prices require scalable money. Scalable money requires scalable security, so that a greater number and variety of people can use the currency without losing its integrity against forgery, inflation, and theft.An individual or group communicating under the name \u201cSatoshi Nakamoto\u201d brought Bitcoin to the Internet in 2009. Satoshi\u2019s breakthrough with money was to provide social scalability via trust minimization: reducing vulnerability to counterparties and third parties alike. By substituting computationally expensive but automated security for computationally cheap but institutionally expensive traditional security, Satoshi gained a nice increase in social scalability. A set of partially trusted intermediaries replaces a single and fully trusted intermediary.Financial controls on computational steroids: a blockchain as an army of robots, each checking up on each other\u2019s work.When we can secure the most important functionality of a financial network by computer science rather than by the traditional accountants, regulators, investigators, police, and lawyers, we go from a system that is manual, local, and of inconsistent security to one that is automated, global, and much more secure. Cryptocurrencies, when implemented properly on public blockchains, can substitute an army of computers for a large number of traditional banking bureaucrats. \u201cThese block chain computers will allow us to put the most crucial parts of our online protocols on a far more reliable and secure footing, and make possible fiduciary interactions that we previously dared not do on a global network.\u201d (Source)The characteristics most distinctively valuable in blockchain technology in general, and Bitcoin in particular \u2014 for examplecome from the high levels of security and reliability a blockchain can maintain without human intervention. Without that high security it\u2019s just a gratuitously wasteful distributed database technology still tied to the local bureaucracies it would have to depend upon for its integrity.Since the mid-20th century computing has increased in efficiency by many orders of magnitude, but humans are using the same brains. This has created plenty of possibility for overcoming human limitations, and institutions based solely on human minds, with computational capabilities, including in security, doing what they do best, with human minds doing what they still do best. As a result, humans have no more raw mental ability to scale up our institutions than we ever have. But there is plenty of potential for improving social scalability by replacing some human functions with computational ones. (An important note\u2014this argument depends on the slope, not the absolute position, of the human ability line. The absolute position shown above is arbitrary and depends on what human \u201ccomputation\u201d we are measuring).A new centralized financial entity, a trusted third party without a \u201chuman blockchain\u201d of the kind employed by traditional finance, is at high risk of becoming the next Mt. Gox; it is not going to become a trustworthy financial intermediary without that bureaucracy.Computers and networks are cheap. Scaling computational resources requires cheap additional resources. Scaling human traditional institutions in a reliable and secure manner requires increasing amounts accountants, lawyers, regulators, and police, along with the increase in bureaucracy, risk, and stress that such institutions entail. Lawyers are costly. Regulation is to the moon. Computer science secures money far better than accountants, police, and lawyers.In computer science there are fundamental security versus performance tradeoffs. Bitcoin's automated integrity comes at high costs in its performance and resource usage. Nobody has discovered any way to greatly increase the computational scalability of the Bitcoin blockchain, for example its transaction throughput, and demonstrated that this improvement does not compromise Bitcoin\u2019s security.It is probable that no such big but integrity-preserving performance improvement is possible for the Bitcoin blockchain; this may be one of these unavoidable tradeoffs. Compared to existing financial IT, Satoshi made radical tradeoffs in favor of security and against performance. The seemingly wasteful process of mining is the most obvious of these tradeoffs, but Bitcoin also makes others. Among them is that it requires high redundancy in its messaging. Mathematically provable integrity would require full broadcast between all nodes. Bitcoin can\u2019t achieve that but to even get anywhere close to a good approximation of it requires a very high level of redundancy. So a 1 MB block consumes far more resources than a 1 MB web page, because it has to be transmitted, processed, and stored with high redundancy for Bitcoin to achieve its automated integrity.These necessary tradeoffs, sacrificing performance in order to achieve the security necessary for independent, seamlessly global, and automated integrity, mean that the Bitcoin blockchain itself cannot possibly come anywhere near Visa transaction-per-second numbers and maintain the automated integrity that creates its distinctive advantages versus these traditional financial systems. Instead, a less trust-minimized peripheral payment network (possibly Lightning) will be needed to bear a larger number of lower-value bitcoin-denominated transactions than Bitcoin blockchain is capable of, using the Bitcoin blockchain to periodically settle with one high-value transaction batches of peripheral network transactions.Bitcoin supports a lower rate transactions than Visa or PayPal, but due to its stronger automated security these can be much more important transactions. Anybody with a decent Internet connection and a smart phone who can pay $0.20-$2 transaction fees\u2014substantially lower than current remittance fees\u2014can access Bitcoin any where on the globe. Lower value transactions with lower fees will need to be implemented on peripheral bitcoin networks.When it comes to small-b bitcoin, the currency, there is nothing impossible about paying retail with bitcoin the way you\u2019d pay with a fiat currency \u2014 bitcoin-denominated credit and debt cards, for example, with all the chargeback and transactions-per-second capabilities of a credit or debit card. And there are also clever ways to do peripheral bitcoin retail payments in which small value payments happen off-chain and are only periodically bulk-settled on the Capital-B Bitcoin blockchain. That blockchain is going to evolve into a high-value settlement layer as bitcoin use grows, and we will see peripheral networks being used for small-b bitcoin retail transactions.When I designed bit gold I already knew consensus did not scale to large transaction throughputs securely, so I designed it with a two-tier architecture: (1) bit gold itself, the settlement layer, and (2) Chaumian digital cash, a peripheral payment network which would provide retail payments with high transactions-per-second performance and privacy (through Chaumian blinding), but would like Visa be a trusted third party and thus require a \u201chuman blockchain\u201d of accountants, etc. to operate with integrity. The peripheral payment network can involve only small value transactions, thereby requiring much less of a human army to avoid the fate of Mt. Gox.Ralph Merkle: pioneer of public-key cryptography and inventor of hierarchical hash-tree structures (Merkle trees).Money requires social scalability in its design, via security. For example it should be very hard for any participant or intermediary to forge money (to dilute the supply curve leading to undue or unexpected inflation). Gold can have value anywhere in the world and is immune from hyperinflation because its value doesn\u2019t depend on a central authority. Bitcoin excels at both these factors and runs online, enabling somebody in Albania to use Bitcoin to pay somebody in Zimbabwe with minimal trust in or and no payment of quasi-monopoly profits to intermediaries, and with minimum vulnerability to third parties.There are all sorts of definitions of \u201cblockchain\u201d out there, almost all of them just implicitly broad hand-waving amid the mountains of marketing hype. I suggest a clear definition that can be communicated to lay people. It is a blockchain if it has blocks and it has chains. The \u201cchains\u201d should be Merkle trees or other cryptographic structures with a similar integrity functionality of post-unforgeable integrity. Also the transactions and any other data whose integrity is protected by a blockchain should be replicated in a way objectively tolerant to worst-case malicious problems and actors to as high a degree as possible (typically the system can behave as previously specified up to a fraction of 1/3 to 1/2 of the servers maliciously trying to subvert it to behave differently).Bitcoin\u2019s socially scalable security, based on computer science rather than on police and lawyers, allows, for example, customers in Africa to pay suppliers in China seamlessly across borders. A private blockchain cannot accomplish this feat nearly as easily, since it would require an identification scheme, certificate authority, and PKI shared between these various jurisdictions. (Source)Because of this fraction, and because of the (hopefully very rare) need to update software in a manner that renders prior blocks invalid\u2014an even riskier situation called a hard fork\u2014blockchains also need a human governance layer that is vulnerable to fork politics. The most successful blockchain, Bitcoin, has maintained its immutable integrity via decentralized decision-making among experts in the technology combined with a strong dogma of immutability, under which only the most important and rare bug fixes and design improvements, that cannot be made any other way, justify a hard fork. Under this philosophy of governance accounting or legal decisions (such as altering an account balance or undoing a transaction) never justify a hard fork, but should be accomplished by traditional governance outside of (or on top of) the system (e.g. via a court injunction forcing a Bitcoin user to send a new transaction that effectively undoes the old one, or confiscating the particular keys and thus the particular holdings of a particular user).To say that data is post-unforgeable or immutable means that it can\u2019t be undetectably alteredafter being committed to the blockchain. Contrary to some hype this doesn\u2019t guarantee anything about a datum\u2019s provenance, or its truth or falsity, before it was committed to the blockchain. That requires additional protocols, often including expensive traditional controls. Blockchains don\u2019t guarantee truth; they just preserve truth and lies from later alteration, allowing one to later securely analyze them, and thus be more confident in uncovering the lies. Typical computers are computational etch-a-sketch, while blockchains are computational amber. Important data should be committed to blockchain amber as early as possible, ideally directly from and cryptographically signed by the device in which it was generated, to maximize the blockchain\u2019s benefit in securing its integrity.A Merkle tree of four transactions (tx0 through tx3). Combined with a proper replication and chains of transaction blocks protected by proof-of-work, Merkle trees can make data such as transactions post-unforgeable by consensus. In Bitcoin, a Merkle root hash securely summarizes and is used to verify the unaltered state of all the transactions in a block.My own 1998 \u201csecure property title\u201d architecture had Merkle trees and replication of data tolerant against an objective fraction of arbitrarily faulty software or malicious actors, but not blocks. It demonstrated my theory that you could protect the integrity of globally shared data and transactions, and use that ability to design a cryptocurrency (bit gold). It did not have the more efficient and computationally scalable blocks-and-ledger system that Bitcoin does. Also like today\u2019s private blockchains, secure property titles assumed and required securely distinguishable and countable nodes.Given the objective 51% hashrate attack limit to some important security goals of public blockchains like Bitcoin and Ethereum, we actually do care about the distinguishable identity of the most powerful miners to answer the question \u201ccan somebody convince and coordinate the 51%?Blockchain security is objectively limited and blockchain governance is heavily influenced by the potential for a 51% attack. An attack of course does not have to be called an \u201cattack\u201d by the attackers; instead they might call it \u201cenlightened governance\u201d or \u201cdemocracy in action\u201d. Indeed some kinds of software updates needed to fix bugs or otherwise improve the protocol require a soft fork. Some other kinds of software updates require hard forks, which in Bitcoin pose an even greater security and continuity risks than soft forks. Blockchains, although reducing trust far more than any other network protocols, are still far from trustless. Miners are partially trusted fiduciaries, and those who are not expert developers or computer scientists who have invested a great deal of time in learning the design principles and codebase of a blockchain must place a great deal of faith in the expert developer community, much as non-specialists who want to understand the results of a specialized science do of the corresponding scientists. During a hard fork exchanges can also be very influential by deciding which fork to support with their order books and trade symbol continuity.Public blockchains thus mostly but not entirely dodge the identity-is-hard bullet and take care of its remaining problem of identifying the most powerful miners at a higher \u201cwet\u201d/\u201csocial\u201d level, where it is probably more appropriate, rather than trying to securely map such an inherently wet (brain-based) concept onto the protocol, as PKI (public key infrastructure) rather awkwardly tries to do.So I think some of the \u201cprivate blockchains\u201d qualify as bona fide blockchains; others should go under the broader rubric of \u201cdistributed ledger\u201d or \u201cshared database\u201d or similar. They are all very different from and not nearly as socially scalable as public and permissionless blockchains like Bitcoin and Ethereum.All of the following are very similar in requiring an securely identified (distinguishable and countable) group of servers rather than the arbitrary anonymous membership of miners in public blockchains. In other words, they require some other, usually far less socially scalable, solution to the Sybil (sockpuppet) attack problem:The dominant, but usually not very socially scalable, way to identify a group of servers is with a PKI based on trusted certificate authorities (CAs). To avoid the problem that merely trusted third parties are security holes, reliable CAs themselves must be expensive, labor-intensive bureaucracies that often do extensive background checks themselves or rely on others (e.g. Dun and Bradstreet for businesses) to do so. (I once led a team that designed and built such a CA). CAs also act as a gatekeeper, rendering these permissioned systems. CAs can become singular points of political control and failure. \u201cPublic blockchains are automated, secure, and global, but identity is labor-intensive, insecure, and local.\u201dPKI-enabled private blockchains are a nice for banks and some other large enterprises because they already have mature in-house PKIs that cover the employees, partners, and private servers needed to approve important transactions. Bank PKIs are relatively reliable. We also have semi-reliable CAs for web servers, but not generally speaking for web clients, even though people have been working on the problem of client certificates since the invention of the web: for example advertisers would love to have a more secure alternative to phone numbers and cookies for tracking customer identities. Yet it hasn\u2019t happened.PKI can work well for some important things and people but it is not nearly so nice or so easy for lesser entities. Its social scalability is limited by the traditional wet identity bureaucracy on which it depends.Some significant thefts in the broader bitcoin ecosystem. Whereas the Bitcoin blockchain itself is probably the most secure financial network in existence (and indeed must remain far more secure than traditional payment networks in order to maintain its low governance costs and seamless cross-border capability), its peripheral services based on older centralized web servers are very insecure. (Source: author)We need more socially scalable ways to securely count nodes, or to put it another way to with as much robustness against corruption as possible, assess contributions to securing the integrity of a blockchain. That is what proof-of-work and broadcast-replication are about: greatly sacrificing computational scalability in order to improve social scalability. That is Satoshi\u2019s brilliant tradeoff. It is brilliant because humans are far more expensive than computers and that gap widens further each year. And it is brilliant because it allows one to seamlessly and securely work across human trust boundaries (e.g. national borders), in contrast to \u201ccall-the-cop\u201d architectures like PayPal and Visa that continually depend on expensive, error-prone, and sometimes corruptible bureaucracies to function with a reasonable amount of integrity.The rise of the Internet as seen the rise of a variety of online institutions, among them social networks, \u201clong-tail\u201d retail (e.g. Amazon), and a variety of services that allow small and dispersed buyers and sellers to find and do business with each other (eBay, Uber, AirBnB, etc.) These are just the initial attempts to take advantage of our new abilities. Due to the massive improvements in information technology over recent decades, the number and variety of people who can successfully participate in an online institution is far less often restricted by the objective limits of computers and networks than it is by limitations of mind and institution that have usually have not yet been sufficiently redesigned or further evolved to take advantage of those technological improvements.These initial Internet efforts have been very centralized. Blockchain technology, which implements data integrity via computer science rather than via \u201ccall the cops\u201d, has so far made possible trust-minimized money\u2014cryptocurrencies\u2014and will let us make progress in other financial areas as well as other areas where transactions can be based primarily on data available online.This is not to say that adapting our institutions to our new capabilities will be easy, or indeed in particular cases anything short of difficult and improbable. Utopian schemes are very popular in the blockchain community, but they are not viable options. Reverse-engineering our highly evolved traditional institutions, and even reviving in new form some old ones, will usually work better than designing from scratch, than grand planning and game theory. One important strategy for doing so was demonstrated by Satoshi\u2014sacrifice computational efficiency and scalability\u2014consume more cheap computational resources\u2014in order to reduce and better leverage the great expense in human resources needed to maintain the relationships between strangers involved modern institutions such as markets, large firms, and governments."}
{"prompt": "The Idea of Smart Contracts", "completion": "What is the meaning and purpose of \"security\"? How does it relate the the relationships we have? I argue that the formalizations of our relationships\u2014especially contracts\u2014provide the blueprint for ideal security.Many kinds of contractual clauses (such as collateral, bonding, delineation of property rights, etc.) can be embedded in the hardware and software we deal with, in such a way as to make breach of contract expensive (if desired, sometimes prohibitively so) for the breacher. A canonical real-life example, which we might consider to be the primitive ancestor of smart contracts, is the humble vending machine. Within a limited amount of potential loss (the amount in the till should be less than the cost of breaching the mechanism), the machine takes in coins, and via a simple mechanism, which makes a freshman computer science problem in design with finite automata, dispense change and product according to the displayed price. The vending machine is a contract with bearer: anybody with coins can participate in an exchange with the vendor. The lockbox and other security mechanisms protect the stored coins and contents from attackers, sufficiently to allow profitable deployment of vending machines in a wide variety of areas.Smart contracts go beyond the vending machine in proposing to embed contracts in all sorts of property that is valuable and controlled by digital means. Smart contracts reference that property in a dynamic, often proactively enforced form, and provide much better observation and verification where proactive measures must fall short.As another example, consider a hypothetical digital security system for automobiles. The smart contract design strategy suggests that we successively refine security protocols to more fully embed in a property the contractual terms which deal with it. These protocols would give control of the cryptographic keys for operating the property to the person who rightfully owns that property, based on the terms of the contract. In the most straightforward implementation, the car can be rendered inoperable unless the proper challenge-response protocol is completed with its rightful owner, preventing theft.If the car is being used to secure credit, strong security implemented in this traditional way would create a headache for the creditor - the repo man would no longer be able to confiscate a deadbeat's car. To redress this problem, we can create a smart lien protocol: if the owner fails to make payments, the smart contract invokes the lien protocol, which returns control of the car keys to the bank. This protocol might be much cheaper and more effective than a repo man. A further reification would provably remove the lien when the loan has been paid off, as well as account for hardship and operational exceptions. For example, it would be rude to revoke operation of the car while it's doing 75 down the freeway.In this process of successive refinement we've gone from a crude security system to a reified contract:Mature security systems will be undertaking different behavior for different contracts. To continue with our example, if the automobile contract were a lease, the final payment would switch off leasee access; for purchase on credit, it would switch off creditor access. A security system, by successive redesign, increasingly approaches the logic of the contract which governs the rights and obligations covering the object, information, or computation being secured. Qualitatively different contractual terms, as well as technological differences in the property, give rise to the need for different protocols.(Derived from \"Formalizing and Securing Relationships on Public Networks\", by Nick Szabo)A related article discusses a formal language for analyzing contracts and specifying smart contracts.Please send your comments to nszabo (at) law (dot) gwu (dot) eduCopyright \u00a9 1997 by Nick Szabo\nPermission to redistribute without alteration hereby granted"}
{"prompt": "Cyberspace, Crypto Anarchy, and Pushing Limits", "completion": "This messages touches on two topics of recent interest (to some) here:Setting up payment systems for message transmission, to handle the issues of \u201cmailbombing\u201d and \u201cflooding\u201d in a more natural way (locality of reference, user of a service pays, avoidance of the \u201cMorris Worm\u201d explosion effects which could\u2019ve happened with Detweiler bombed us, as Hal noted).The general issue of \u201cCyberspace.\u201d This lies at the root of some recent disagreements here, and is worthy of more discussion. Crypto will make this a very real cusp issue in the next several years.Why debate it now? What could possibly come out of such a debate?It happens that I\u2019m reading a wonderful new book by Kip Thorne, entitled \u201cBlack Holes and Space Warps.\u201d This is widely available in bookstores, in hardback only at this time. ($30, but it\u2019s a whopping big book, and I got it at Barnes and Noble for $24. Speaking of Barnes and Noble, the Santa Clara store is selling Li and Vitanyi\u2019s \u201cIntro. to Kolmogorov Complexity\u201d book for $44, before the 20% hardback discount, which may be a mispricingm, as I paid $60 for mine. Check it out if you\u2019re interested....I think there were two copies.)Thorne has spent 30 years studying gravitational collapse and black holes, and was a coauthor of the famed 1973 book on \u201cGravitation,\u201d which I got to use in a Xeroxed form for my general relativity class in 1973.The point? Thorne describes his involvement with Carl Sagan in working out the physics of time travel via wormholes. Thorne had an epiphany: however unlikely the engineering or financing of something is, there is something valuable to be gained in examining the absolute limits of what is possible without regard for engineering practicalities. Thus, he and his students looked into the implications of an extremely advanced civilization able to somehow hold open the mouth of a wormhole. The conclusions are fascinating and led to a new line of thinking about the structure of space-time.Pushing limits and seeing \u201cideal\u201d behavior is invigorating.The connection to crypto is this: Perhaps we should be thinking more about the implicaitons and effects of strong crypto, digital money, ideal remailers, etc., assuming that certain practical problems that bedevil us today are, or soon will be, solved. To some extent we already do this, as when we discuss Chaum\u2019s ideal mixes in the same way engineer\u2019s discuss ideal op amps--a useful abstraction of behavior in the limit that lesser, real world implementations can then be contrasted with.And of course many of us have found Vernor Vinge\u2019s \u201cTrue Names\u201d to be an excellent (and quickly readable) treatment of how things could work in a world of fast, cheap, and secure communication. Other writers have seen things differently (e.g., \u201cShockwave Rider,\u201d \u201c1984,\u201d \u201cSnow Crash\u201d).Here, to cut to the chase, are some brief statements of what I see as the \u201cbehavior in the limits.\u201d I won\u2019t elaborate on them right now.\u201cPay as you go\u201d is the natural way to handle most economic transactions. There are exceptions, of course, such as insurance, contracts for future perfomance, etc., but for the most part money is used to mediate immediate exchanges. For a timely example, why can your enemies not \u201cjunk mail bomb\u201d you with truly large (tons) of junk mail? Junk mail, as we call it, is in relatively small volumes (at most a mailbox full, except for celebrities perhaps) because of one simple thing: someone has to pay for the delivery! There is no possibility of a \u201cfree\u201d way to \u201cMake 19 copies of this ton of garbabe and mail them to your enemies.\u201d That there is with software--the remailer bombing by Detweiler, the 1988 Morris Worm, the \u201cDave Rhodes\u201d chain letters--is due to some flaws in the current Net model:costs of message trasnmission are not directly borne by senders (encourage overuse by some of scarce resources, a la the \u201ctragedy of the commons\u201d).sites and remailers will respond to \u201cinstructions\u201d to send the message on, to make copies of it, etc.I thus consider it imperative that we develop as quickly as we can the following:payment systems for message transmission (I\u2019ve argued for \u201cdigital postage\u201d as a first and comparatively easy application of digital money, others have as well, and Ray Cromwell just today issued his own proposal....time we get going on this. And lest you think I\u2019m calling for altruism here, I think some fortunes will be made in this area.)anonymous or identity-obscuring protocols, a la Chaum.a general move away from \u201ccommons\u201d-oriented systems, which breed the notions of \u201cfair access\u201d and such. If the \u201cproblem\u201d is that poor people cannot--it is alleged--afford a $17 a month Net connection (what Netcom charges, in about 25 cities and growing), then my solution would be to simply subsidize their bill. (I\u2019m not advocating this, nor do I think it wise to subsidize anyone\u2019s phone, Net, or dinner bills, but better this than \u201cnationalizing\u201d networks and thus creating more confusion and less efficiency for all.)Connectivity will be altered dramatically, The \u201cdistance\u201d in cyberspace is already uncorrelated to physical distance. (Hardly surprising, as this was apparent with the telephone. But a useful way of looking at cyberspace, as being a space of radically altered connectivities and distances.)Local access to service, the phone or cable lines that reach the home or office, is a potential bottleneck. But once a connection is made to a local node where multiple competitors exist (that is, once beyond the local government-granted monopoly), the possibility of \u201ccensorship\u201d decreases rapidly, for several reasons.thus, push for \u201cencrypted access\u201d lines from a terminal node (home, office) to a point with unlimited connectivity.this is the situation I now have with my PacBell line and Netcom: PacBell doesn\u2019t \u201ccare\u201d what I use the local line for, and once outside, I can dial a less-censorious Netcom rather than a Big Brotherish AOL or Prodigy.Cyberspace is infinitely colonizable. No limits to growth. (Assumption: realization of cyberspace is on various machines and networks, which are not free, nor infinite. But the \u201cno limits\u201d comes from ease with which those near a \u201cboundary\u201d can simply push out that boundary with more CPU resource, more networks, etc.).Crypto means access to \u201cregions\u201d can be controlled by \u201cowners\u201d:\u201cmy house, my rules\u201d enforced locally, without central State authorityessentially unbreakable security (in crypto sense)By the way, strong crypto is the \u201cbuilding material\u201d of cyberspace...the mortar, the bricks, the support beams, the walls. Nothing else can provide the \u201cpermanence\u201d...without crypto, the walls are subject to collapse at the first touch by a malicious person or agency. With crypto, not even a 100 megaton H-bomb can breach the walls.(If you think I\u2019m exaggerating, do some calculations on the energy to break a 1000-decimal-digit modulus.)No \u201czoning laws\u201d will be needed, or possible, in cyberspace. (Neil Stephenson\u2019s \u201cSnow Crash,\u201d while a wonderful and thought-provoking read, got it wrong here: cyberspace is too extensible and locally controllable.)Physical location of cyberspace locations will be increasingly hard to pin down. A vast \u201clabyrinth of rooms and corridors\u201d might be physically instantiated on a computer in Malaysia, while a \u201cvirtual gambling hall\u201d is being run via cryptographic cutouts (remailers) from someone\u2019s bedroom in Provo, Utah.The talk about \u201caccess rules\u201d is thus shown to be meaningless, unless the governments crack down on networks, crypto, and private systems in a way far beyond anything now being talked about.This is the \u201ccrypto anarchy\u201d I have been writing about since 1988. Cyberspace will turn out to be a far vaster frontier than anything we have seen so far. With \u201conly\u201d 10^70 or so particles in the entire universe, there\u2019s vastly more \u201cspace\u201d (address space, key space, etc.) in even a relatively small set of digits. Cyberspace is mathematical space, and its spaciousness is truly unlimited.And we\u2019ll be moving our trade, our entertainment, and much of our lives into cyberspace a whole lot faster than we\u2019ll be slowly moving into low Earth orbit and beyond. In fact, I consider that I\u2019m already half-way in. In a few years, with Mosaic-like one-touch connectivity, with a plethora of network choices, with secure remailers and similar tools to anonymize my transactions, I\u2019ll be so far in there\u2019ll be turning back.Enough for these remarks right now. I think it makes sense to take a slightly longer-range view of the inevitable trends, to see where we\u2019re going, to see what issues need more work.I hope some of you agree with me.--Tim May"}
{"prompt": "Confidential Auditing", "completion": "The auditing function is a vast and indispensable part of the modern economy. Auditing controls allow, among other things, employers to delegate resources and authority to employees, franchisors to delegate to franchisees, stockholders to delegate to management, advertisers to count eybeballs, marketers to gather more reliable data on customers, and make possible a wide variety of other such relationships. Auditing controls might fairly be called the security protocols of capitalism.A recent general survey showed that 83% of Americans are \"very concerned\" about their privacy on the Internet. One can expect even stronger figures from European customers, who have more first-hand experience with private data, much of it originally compiled for innocuous reasons, being used for political repression. Businesses recognize the shortcomings of NDAs and are looking for more reliable ways to protect confidential data. The vast majority of e-commerce customers are concerned about privacy.Auditing is in deep conflict with efforts towards greater privacy. Auditors have an ethic of recording, investigating, and reporting as much as possible, and often see privacy efforts as attempts to prevent auditing and potentially cover up fraud. Indeed, the recent multi-$billion failures of Baring's Bank and the Long Term Capital hedge fund, and more generally the recent problems with \"crony capitalism\" which have shorn stockholders and creditors of over $1 trillion, have been ascribed to such secrecy[3]. At the top of the list of current IMF reforms is \"openness\", a buzzword for the introduction of greater auditing controls and reporting requirements.Since auditing controls are used to secure trillions of dollars of transactions every year, they are not going away, and indeed will likely grow more effective and intrusive. On the other hand, we now have at our disposal the many breakthroughs achieved over the last two decades in modern cryptography. Can we use these to strike a better balance between auditing and privacy? I have come up with an architecture which uses such protocols to greatly improve this tradeoff: confidential auditing.We can achieve auditing logs unforgeable after commitment via secure timestamps[1]. We can then achieve to a great extent unforgeability prior to commitment, with segregation of duties via multiparty integrity constraints[2]. We then audit these commitments via multiparty private computations[4]. This combination allows a wide variety of transactions, conducted with normal efficiency, to be observed and verified by selected arbitrators or auditors, via more expensive private computations applied to randomly sampled commitments. This maintains a high degree of confidentiality for the inputs.The participants in this mutually confidential auditing protocol can verify that the books match the details of transactions stored in a previously committed transaction log, and that the numbers add up correctly. The participants can compute summary statistics on their confidentially shared transaction logs, including cross-checking of the logs against counterparties to a transaction, without revealing those logs. They only learn what can be inferred from the statistics, can't see the details of the transactions.Assuming many practical details I have glossed over in this sketch (such as the efficiency of auditing computations, the availability of digital transaction records in standard format, etc.), confidential auditing can bring a substantial improvement over current practices. Currently the details of all an organization's transactions, including for example medical records in an HMO and transactions in top-secret government programs, are either exposed directly to auditors, or are immune from auditing, allowing fraud.With mutually confidential auditing we will be able to gain high confidence in the factuality of counterparties' claims and reports without revealing identifying and other detailed information from the transactions underlying those reports. This will provide the basis for solid reputation systems, and other trusted third party systems, that maintain integrity across time, communications, summarization, and preserve confidentiality for transaction participants. With confidential auditing we will often be able to have both openness and privacy.BLLV98 A. Buldas, P. Laud, H. Lipmaa, J. Villemson, \"Time-Stamping with Binary Linking Schemes\", Crypto 98 \u21a9Szabo, in progress \u21a9See recent back issues of The Wall Street Journal and The Economist \u21a9Overview, http://szabo.best.vwh.net/msc.html; Quorum systems model, http://szabo.best.vwh.net/quorum.html \u21a9[B91] D. Beaver, \"Efficient Multiparty Protocols Using Circuit Randomization\", ACM STOC 91[RB89] T. Rabin & M. Ben-Or, \"Verifiable Secret Sharing and Multiparty Protocols with Honest Majority\", ACM STOC 89[GRR98] R. Gennaro, T. Rabin, & M. Rabin: \"Simplified VSS and Fast-Track Multiparty Computations\", PODC 98"}
{"prompt": "Proplets: Devices for Controlling Property", "completion": "Civilization has highly evolved practices for determining whether certain actions are allowable or not, or who should prevail in a dispute, namely law. Such a body of knowledge cannot be reinvented from scratch, so instead e-commerce security should draw heavily on it\u2014building property rights, contract and tort law into technology at a very basic level. Proplets define the basic security architecture for local evidence gathering, enforcement, and negotiation of such laws.Proplets do not rely on central planning, AI, or a single trusted third party for any function. Central planning is not able to account for the distributed and diverse knowledge and preferences of different people. A \"trusted third party\" is a nice-sounding synonym for a wide-open security hole that a designer chooses to overlook. Proplet design places strong emphasis on eliminating such exposures.The key is building in, at the most basic level of technology, code (in both the legal and software sense) that allows a widely distributed people, each person having his own unique information, circumstances, and preferences, to cooperate within well known, mutually agreeable, and strongly enforced constraints. With these constraints the risks and benefits of technology are balanced, weapons are monitored and securely restricted in their use to only very narrow, specific, lawful conditions, and for every person there is more profit from peace than from destruction.The goal of proplet design is to control physical objects with digital protocols. Proplets protect its structure and function from non-owners, and observe the environment for phenomena impinging on a region, on matter, or on its owner. A proplet is an electromechanical device (e.g. a MEMS device) with the following core abilities:A proplet may optionally also have the following abilities:No computational module can be read or controlled by physical tampering\u2014it will shut down, erase itself, or even self-destruct depending on the severity of tampering. Computational modules are \"transparent\" to their publically registered controller and opaque to other entities.Only protocols that are simple and composable with provable security govern the communications between the security kernel (private key operations), control box, sandbox, and other components of a computation modules. Similarly for communications between modules and between proplets.How does a proplet find out who owns it, or a guest module who controls it? There are two basic ways:A proplet's guest modules are publicly listed and transferred independently of each other and of the proplet's ownership module.With the home proplet alternative, biometric control of the home proplets may replace public ownership records.Proplets control electronics directly from ownership or guest modules. Proplets control machinery via entanglement. Entanglement can take at least two forms:Entanglment designs have in common that they make it too expensive for the attacker to steal the electronics or machinery by severing it from the controlling proplet.Deeds, in the context of replicated property titles and proplets, are smart contracts executed by a deed module. The current owner may add new deeds agreed to (but not remove old ones) by drafting signing and signing such a smart contract with other current property owners. The deed binds both properties (perhaps to different terms, depending on what the two current owners have negotiatied). The deed modules can be audited at any time by the contemporary owners of other proplets bound to the deeds. Founders of competing property title registries define master deeds, or tort laws, to govern disputes within registry properties. They also define tort law for disputes between their properties and properties defined by other registires, by coming to agreements with those registry founders. Founders also create the initial allocations.Founders are often the manufacturers of proplets. They build in a particular registry as authoratative for their proplets as well as designing an accompanying tort law.For example, the founder of registry of fixtures in a spatial region can sign an agreement with a movable property (chattel) registry, governing the behavior of chattel moving through space and interacting with fixtures. The manufacturers of chattel and fixtures program their proplets to respect the appropriate registries and constrain their sensors and effectors to follow the tort law that has been agreed to.Proplets combine our most highly evolved practices for cooperation on a large scale with a technology architecture suitable for advances well into the future, even well into posthuman civilization. Proplets provide a much sounder footing for solving the problems of high technology cooperation including problems such as privacy, weapons of mass destruction, and other abuses of the power of advanced technology.\"Computer Security as the Future of Law\", Mark Miller\n\"Formalizing and Securing Relationships on Public Networks\", Nick Szabo\n\"Secure Property Titles\", Nick SzaboMy thanks to Gregory Burch, J.D. for his helpful questions.Please send your comments to nszabo (at) law (dot) gwu (dot) edu"}
{"prompt": "Bitcoin: A Peer-to-Peer Electronic Cash System", "completion": "A purely peer-to-peer version of electronic cash would allow online payments to be sent directly from one party to another without going through a financial institution. Digital signatures provide part of the solution, but the main benefits are lost if a trusted third party is still required to prevent double-spending. We propose a solution to the double-spending problem using a peer-to-peer network. The network timestamps transactions by hashing them into an ongoing chain of hash-based proof-of-work, forming a record that cannot be changed without redoing the proof-of-work. The longest chain not only serves as proof of the sequence of events witnessed, but proof that it came from the largest pool of CPU power. As long as a majority of CPU power is controlled by nodes that are not cooperating to attack the network, they'll generate the longest chain and outpace attackers. The network itself requires minimal structure. Messages are broadcast on a best effort basis, and nodes can leave and rejoin the network at will, accepting the longest proof-of-work chain as proof of what happened while they were gone.Commerce on the Internet has come to rely almost exclusively on financial institutions serving as trusted third parties to process electronic payments. While the system works well enough for most transactions, it still suffers from the inherent weaknesses of the trust based model. Completely non-reversible transactions are not really possible, since financial institutions cannot avoid mediating disputes. The cost of mediation increases transaction costs, limiting the minimum practical transaction size and cutting off the possibility for small casual transactions, and there is a broader cost in the loss of ability to make non-reversible payments for non-reversible services. With the possibility of reversal, the need for trust spreads. Merchants must be wary of their customers, hassling them for more information than they would otherwise need. A certain percentage of fraud is accepted as unavoidable. These costs and payment uncertainties can be avoided in person by using physical currency, but no mechanism exists to make payments over a communications channel without a trusted party.What is needed is an electronic payment system based on cryptographic proof instead of trust, allowing any two willing parties to transact directly with each other without the need for a trusted third party. Transactions that are computationally impractical to reverse would protect sellers from fraud, and routine escrow mechanisms could easily be implemented to protect buyers. In this paper, we propose a solution to the double-spending problem using a peer-to-peer distributed timestamp server to generate computational proof of the chronological order of transactions. The system is secure as long as honest nodes collectively control more CPU power than any cooperating group of attacker nodes.We define an electronic coin as a chain of digital signatures. Each owner transfers the coin to the next by digitally signing a hash of the previous transaction and the public key of the next owner and adding these to the end of the coin. A payee can verify the signatures to verify the chain of ownership.The problem of course is the payee can't verify that one of the owners did not double-spend the coin. A common solution is to introduce a trusted central authority, or mint, that checks every transaction for double spending. After each transaction, the coin must be returned to the mint to issue a new coin, and only coins issued directly from the mint are trusted not to be double-spent. The problem with this solution is that the fate of the entire money system depends on the company running the mint, with every transaction having to go through them, just like a bank.We need a way for the payee to know that the previous owners did not sign any earlier transactions. For our purposes, the earliest transaction is the one that counts, so we don't care about later attempts to double-spend. The only way to confirm the absence of a transaction is to be aware of all transactions. In the mint based model, the mint was aware of all transactions and decided which arrived first. To accomplish this without a trusted party, transactions must be publicly announced[1], and we need a system for participants to agree on a single history of the order in which they were received. The payee needs proof that at the time of each transaction, the majority of nodes agreed it was the first received.The solution we propose begins with a timestamp server. A timestamp server works by taking a hash of a block of items to be timestamped and widely publishing the hash, such as in a newspaper or Usenet post[2-5]. The timestamp proves that the data must have existed at the time, obviously, in order to get into the hash. Each timestamp includes the previous timestamp in its hash, forming a chain, with each additional timestamp reinforcing the ones before it.To implement a distributed timestamp server on a peer-to-peer basis, we will need to use a proof-of-work system similar to Adam Back's Hashcash[6], rather than newspaper or Usenet posts. The proof-of-work involves scanning for a value that when hashed, such as with SHA-256, the hash begins with a number of zero bits. The average work required is exponential in the number of zero bits required and can be verified by executing a single hash.For our timestamp network, we implement the proof-of-work by incrementing a nonce in the block until a value is found that gives the block's hash the required zero bits. Once the CPU effort has been expended to make it satisfy the proof-of-work, the block cannot be changed without redoing the work. As later blocks are chained after it, the work to change the block would include redoing all the blocks after it.The proof-of-work also solves the problem of determining representation in majority decision making. If the majority were based on one-IP-address-one-vote, it could be subverted by anyone able to allocate many IPs. Proof-of-work is essentially one-CPU-one-vote. The majority decision is represented by the longest chain, which has the greatest proof-of-work effort invested in it. If a majority of CPU power is controlled by honest nodes, the honest chain will grow the fastest and outpace any competing chains. To modify a past block, an attacker would have to redo the proof-of-work of the block and all blocks after it and then catch up with and surpass the work of the honest nodes. We will show later that the probability of a slower attacker catching up diminishes exponentially as subsequent blocks are added.To compensate for increasing hardware speed and varying interest in running nodes over time, the proof-of-work difficulty is determined by a moving average targeting an average number of blocks per hour. If they're generated too fast, the difficulty increases.The steps to run the network are as follows:Nodes always consider the longest chain to be the correct one and will keep working on extending it. If two nodes broadcast different versions of the next block simultaneously, some nodes may receive one or the other first. In that case, they work on the first one they received, but save the other branch in case it becomes longer. The tie will be broken when the next proof-of-work is found and one branch becomes longer; the nodes that were working on the other branch will then switch to the longer one.New transaction broadcasts do not necessarily need to reach all nodes. As long as they reach many nodes, they will get into a block before long. Block broadcasts are also tolerant of dropped messages. If a node does not receive a block, it will request it when it receives the next block and realizes it missed one.By convention, the first transaction in a block is a special transaction that starts a new coin owned by the creator of the block. This adds an incentive for nodes to support the network, and provides a way to initially distribute coins into circulation, since there is no central authority to issue them. The steady addition of a constant of amount of new coins is analogous to gold miners expending resources to add gold to circulation. In our case, it is CPU time and electricity that is expended.The incentive can also be funded with transaction fees. If the output value of a transaction is less than its input value, the difference is a transaction fee that is added to the incentive value of the block containing the transaction. Once a predetermined number of coins have entered circulation, the incentive can transition entirely to transaction fees and be completely inflation free.The incentive may help encourage nodes to stay honest. If a greedy attacker is able to assemble more CPU power than all the honest nodes, he would have to choose between using it to defraud people by stealing back his payments, or using it to generate new coins. He ought to find it more profitable to play by the rules, such rules that favour him with more new coins than everyone else combined, than to undermine the system and the validity of his own wealth.Once the latest transaction in a coin is buried under enough blocks, the spent transactions before it can be discarded to save disk space. To facilitate this without breaking the block's hash, transactions are hashed in a Merkle Tree [7][2][5], with only the root included in the block's hash. Old blocks can then be compacted by stubbing off branches of the tree. The interior hashes do not need to be stored.A block header with no transactions would be about 80 bytes. If we suppose blocks are generated every 10 minutes, 80 bytes * 6 * 24 * 365 = 4.2MB per year. With computer systems typically selling with 2GB of RAM as of 2008, and Moore's Law predicting current growth of 1.2GB per year, storage should not be a problem even if the block headers must be kept in memory.It is possible to verify payments without running a full network node. A user only needs to keep a copy of the block headers of the longest proof-of-work chain, which he can get by querying network nodes until he's convinced he has the longest chain, and obtain the Merkle branch linking the transaction to the block it's timestamped in. He can't check the transaction for himself, but by linking it to a place in the chain, he can see that a network node has accepted it, and blocks added after it further confirm the network has accepted it.As such, the verification is reliable as long as honest nodes control the network, but is more vulnerable if the network is overpowered by an attacker. While network nodes can verify transactions for themselves, the simplified method can be fooled by an attacker's fabricated transactions for as long as the attacker can continue to overpower the network. One strategy to protect against this would be to accept alerts from network nodes when they detect an invalid block, prompting the user's software to download the full block and alerted transactions to confirm the inconsistency. Businesses that receive frequent payments will probably still want to run their own nodes for more independent security and quicker verification.Although it would be possible to handle coins individually, it would be unwieldy to make a separate transaction for every cent in a transfer. To allow value to be split and combined, transactions contain multiple inputs and outputs. Normally there will be either a single input from a larger previous transaction or multiple inputs combining smaller amounts, and at most two outputs: one for the payment, and one returning the change, if any, back to the sender.It should be noted that fan-out, where a transaction depends on several transactions, and those transactions depend on many more, is not a problem here. There is never the need to extract a complete standalone copy of a transaction's history.The traditional banking model achieves a level of privacy by limiting access to information to the parties involved and the trusted third party. The necessity to announce all transactions publicly precludes this method, but privacy can still be maintained by breaking the flow of information in another place: by keeping public keys anonymous. The public can see that someone is sending an amount to someone else, but without information linking the transaction to anyone. This is similar to the level of information released by stock exchanges, where the time and size of individual trades, the \"tape\", is made public, but without telling who the parties were.As an additional firewall, a new key pair should be used for each transaction to keep them from being linked to a common owner. Some linking is still unavoidable with multi-input transactions, which necessarily reveal that their inputs were owned by the same owner. The risk is that if the owner of a key is revealed, linking could reveal other transactions that belonged to the same owner.We consider the scenario of an attacker trying to generate an alternate chain faster than the honest chain. Even if this is accomplished, it does not throw the system open to arbitrary changes, such as creating value out of thin air or taking money that never belonged to the attacker. Nodes are not going to accept an invalid transaction as payment, and honest nodes will never accept a block containing them. An attacker can only try to change one of his own transactions to take back money he recently spent.The race between the honest chain and an attacker chain can be characterized as a Binomial Random Walk. The success event is the honest chain being extended by one block, increasing its lead by +1, and the failure event is the attacker's chain being extended by one block, reducing the gap by -1.The probability of an attacker catching up from a given deficit is analogous to a Gambler's Ruin problem. Suppose a gambler with unlimited credit starts at a deficit and plays potentially an infinite number of trials to try to reach breakeven. We can calculate the probability he ever reaches breakeven, or that an attacker ever catches up with the honest chain, as follows[8]:p\nq\nq\nz\n=\n=\n=\n probability an honest node finds the next block\n probability the attacker finds the next block\n probability the attacker will ever catch up from z blocks behindq\nz\n={\n1\n(q/p\n)\nz\nifp\u2264q\nifp>q\n}Given our assumption that\np>q\n, the probability drops exponentially as the number of blocks the attacker has to catch up with increases. With the odds against him, if he doesn't make a lucky lunge forward early on, his chances become vanishingly small as he falls further behind.We now consider how long the recipient of a new transaction needs to wait before being sufficiently certain the sender can't change the transaction. We assume the sender is an attacker who wants to make the recipient believe he paid him for a while, then switch it to pay back to himself after some time has passed. The receiver will be alerted when that happens, but the sender hopes it will be too late.The receiver generates a new key pair and gives the public key to the sender shortly before signing. This prevents the sender from preparing a chain of blocks ahead of time by working on it continuously until he is lucky enough to get far enough ahead, then executing the transaction at that moment. Once the transaction is sent, the dishonest sender starts working in secret on a parallel chain containing an alternate version of his transaction.The recipient waits until the transaction has been added to a block and\nz\nblocks have been linked after it. He doesn't know the exact amount of progress the attacker has made, but assuming the honest blocks took the average expected time per block, the attacker's potential progress will be a Poisson distribution with expected value:\u03bb=z\nq\npTo get the probability the attacker could still catch up now, we multiply the Poisson density for each amount of progress he could have made by the probability he could catch up from that point:\u2211\nk=0\n\u221e\n\u03bb\nk\ne\n\u2212\u03bb\nk!\n\u22c5{\n(q/p\n)\n(z\u2212k)\n1\nifk\u2264z\nifk>z\n}Rearranging to avoid summing the infinite tail of the distribution...1\u2212\n\u2211\nk=0\nz\n\u03bb\nk\ne\n\u2212\u03bb\nk!\n(1\u2212(q/p\n)\n(z\u2212k)\n)Converting to C code...Running some results, we can see the probability drop off exponentially with\nz\n.Solving for P less than 0.1%...We have proposed a system for electronic transactions without relying on trust. We started with the usual framework of coins made from digital signatures, which provides strong control of ownership, but is incomplete without a way to prevent double-spending. To solve this, we proposed a peer-to-peer network using proof-of-work to record a public history of transactions that quickly becomes computationally impractical for an attacker to change if honest nodes control a majority of CPU power. The network is robust in its unstructured simplicity. Nodes work all at once with little coordination. They do not need to be identified, since messages are not routed to any particular place and only need to be delivered on a best effort basis. Nodes can leave and rejoin the network at will, accepting the proof-of-work chain as proof of what happened while they were gone. They vote with their CPU power, expressing their acceptance of valid blocks by working on extending them and rejecting invalid blocks by refusing to work on them. Any needed rules and incentives can be enforced with this consensus mechanism.W. Dai, \"b-money,\" http://www.weidai.com/bmoney.txt, 1998. \u21a9H. Massias, X.S. Avila, and J.-J. Quisquater, \"Design of a secure timestamping service with minimal trust requirements,\" In 20th Symposium on Information Theory in the Benelux, May 1999. \u21a9 \u21a9S. Haber, W.S. Stornetta, \"How to time-stamp a digital document,\" In Journal of Cryptology, vol 3, no 2, pages 99-111, 1991. \u21a9D. Bayer, S. Haber, W.S. Stornetta, \"Improving the efficiency and reliability of digital time-stamping,\" In Sequences II: Methods in Communication, Security and Computer Science, pages 329-334, 1993. \u21a9S. Haber, W.S. Stornetta, \"Secure names for bit-strings,\" In Proceedings of the 4th ACM Conference on Computer and Communications Security, pages 28-35, April 1997. \u21a9 \u21a9A. Back, \"Hashcash - a denial of service counter-measure,\" http://www.hashcash.org/papers/hashcash.pdf, 2002. \u21a9R.C. Merkle, \"Protocols for public key cryptosystems,\" In Proc. 1980 Symposium on Security and Privacy, IEEE Computer Society, pages 122-133, April 1980. \u21a9W. Feller, \"An introduction to probability theory and its applications,\" 1957. \u21a9PDF available in English, Chinese (Simplified), Chinese (Traditional), Hebrew, Italian, Japanese, Russian, Spanish, and Vietnamese"}
{"prompt": "b-money", "completion": "I am fascinated by Tim May's crypto-anarchy. Unlike the communities traditionally associated with the word \"anarchy\", in a crypto-anarchy the government is not temporarily destroyed but permanently forbidden and permanently unnecessary. It's a community where the threat of violence is impotent because violence is impossible, and violence is impossible because its participants cannot be linked to their true names or physical locations.Until now it's not clear, even theoretically, how such a community could operate. A community is defined by the cooperation of its participants, and efficient cooperation requires a medium of exchange (money) and a way to enforce contracts. Traditionally these services have been provided by the government or government sponsored institutions and only to legal entities. In this article I describe a protocol by which these services can be provided to and by untraceable entities.I will actually describe two protocols. The first one is impractical, because it makes heavy use of a synchronous and unjammable anonymous broadcast channel. However it will motivate the second, more practical protocol. In both cases I will assume the existence of an untraceable network, where senders and receivers are identified only by digital pseudonyms (i.e. public keys) and every messages is signed by its sender and encrypted to its receiver.In the first protocol, every participant maintains a (seperate) database of how much money belongs to each pseudonym. These accounts collectively define the ownership of money, and how these accounts are updated is the subject of this protocol.The creation of money. Anyone can create money by broadcasting the solution to a previously unsolved computational problem. The only conditions are that it must be easy to determine how much computing effort it took to solve the problem and the solution must otherwise have no value, either practical or intellectual. The number of monetary units created is equal to the cost of the computing effort in terms of a standard basket of commodities. For example if a problem takes 100 hours to solve on the computer that solves it most economically, and it takes 3 standard baskets to purchase 100 hours of computing time on that computer on the open market, then upon the broadcast of the solution to that problem everyone credits the broadcaster's account by 3 units.The transfer of money. If Alice (owner of pseudonym KA) wishes to transfer X units of money to Bob (owner of pseudonym KB), she broadcasts the message \"I give X units of money to KB\" signed by KA. Upon the broadcast of this message, everyone debits KA's account by X units and credits KB's account by X units, unless this would create a negative balance in KA's account in which case the message is ignored.The effecting of contracts. A valid contract must include a maximum reparation in case of default for each participant party to it. It should also include a party who will perform arbitration should there be a dispute. All parties to a contract including the arbitrator must broadcast their signatures of it before it becomes effective. Upon the broadcast of the contract and all signatures, every participant debits the account of each party by the amount of his maximum reparation and credits a special account identified by a secure hash of the contract by the sum the maximum reparations. The contract becomes effective if the debits succeed for every party without producing a negative balance, otherwise the contract is ignored and the accounts are rolled back. A sample contract might look like this:KA agrees to send KB the solution to problem P before 0:0:0 1/1/2000. KB agrees to pay KA 100 MU (monetary units) before 0:0:0 1/1/2000. KC agrees to perform arbitration in case of dispute. KA agrees to pay a maximum of 1000 MU in case of default. KB agrees to pay a maximum of 200 MU in case of default. KC agrees to pay a maximum of 500 MU in case of default.The conclusion of contracts. If a contract concludes without dispute, each party broadcasts a signed message \"The contract with SHA-1 hash H concludes without reparations.\" or possibly \"The contract with SHA-1 hash H concludes with the following reparations: ...\" Upon the broadcast of all signatures, every participant credits the account of each party by the amount of his maximum reparation, removes the contract account, then credits or debits the account of each party according to the reparation schedule if there is one.The enforcement of contracts. If the parties to a contract cannot agree on an appropriate conclusion even with the help of the arbitrator, each party broadcasts a suggested reparation/fine schedule and any arguments or evidence in his favor. Each participant makes a determination as to the actual reparations and/or fines, and modifies his accounts accordingly.In the second protocol, the accounts of who has how much money are kept by a subset of the participants (called servers from now on) instead of everyone. These servers are linked by a Usenet-style broadcast channel. The format of transaction messages broadcasted on this channel remain the same as in the first protocol, but the affected participants of each transaction should verify that the message has been received and successfully processed by a randomly selected subset of the servers.Since the servers must be trusted to a degree, some mechanism is needed to keep them honest. Each server is required to deposit a certain amount of money in a special account to be used as potential fines or rewards for proof of misconduct. Also, each server must periodically publish and commit to its current money creation and money ownership databases. Each participant should verify that his own account balances are correct and that the sum of the account balances is not greater than the total amount of money created. This prevents the servers, even in total collusion, from permanently and costlessly expanding the money supply. New servers can also use the published databases to synchronize with existing servers.The protocol proposed in this article allows untraceable pseudonymous entities to cooperate with each other more efficiently, by providing them with a medium of exchange and a method of enforcing contracts. The protocol can probably be made more efficient and secure, but I hope this is a step toward making crypto-anarchy a practical as well as theoretical possibility.One of the more problematic parts in the b-money protocol is money creation. This part of the protocol requires that all of the account keepers decide and agree on the cost of particular computations. Unfortunately because computing technology tends to advance rapidly and not always publicly, this information may be unavailable, inaccurate, or outdated, all of which would cause serious problems for the protocol.So I propose an alternative money creation subprotocol, in which account keepers (everyone in the first protocol, or the servers in the second protocol) instead decide and agree on the amount of b-money to be created each period, with the cost of creating that money determined by an auction. Each money creation period is divided up into four phases, as follows:Planning. The account keepers compute and negotiate with each other to determine an optimal increase in the money supply for the next period. Whether or not the account keepers can reach a consensus, they each broadcast their money creation quota and any macroeconomic calculations done to support the figures.Bidding. Anyone who wants to create b-money broadcasts a bid in the form of <x, y> where x is the amount of b-money he wants to create, and y is an unsolved problem from a predetermined problem class. Each problem in this class should have a nominal cost (in MIPS-years say) which is publicly agreed on.Computation. After seeing the bids, the ones who placed bids in the bidding phase may now solve the problems in their bids and broadcast the solutions.Money creation. Each account keeper accepts the highest bids (among those who actually broadcasted solutions) in terms of nominal cost per unit of b-money created and credits the bidders' accounts accordingly."}
{"prompt": "The Crypto Anarchist Manifesto", "completion": "A specter is haunting the modern world, the specter of crypto anarchy.Computer technology is on the verge of providing the ability for individuals and groups to communicate and interact with each other in a totally anonymous manner. Two persons may exchange messages, conduct business, and negotiate electronic contracts without ever knowing the True Name, or legal identity, of the other. Interactions over networks will be untraceable, via extensive re- routing of encrypted packets and tamper-proof boxes which implement cryptographic protocols with nearly perfect assurance against any tampering. Reputations will be of central importance, far more important in dealings than even the credit ratings of today. These developments will alter completely the nature of government regulation, the ability to tax and control economic interactions, the ability to keep information secret, and will even alter the nature of trust and reputation.The technology for this revolution--and it surely will be both a social and economic revolution--has existed in theory for the past decade. The methods are based upon public-key encryption, zero-knowledge interactive proof systems, and various software protocols for interaction, authentication, and verification. The focus has until now been on academic conferences in Europe and the U.S., conferences monitored closely by the National Security Agency. But only recently have computer networks and personal computers attained sufficient speed to make the ideas practically realizable. And the next ten years will bring enough additional speed to make the ideas economically feasible and essentially unstoppable. High-speed networks, ISDN, tamper-proof boxes, smart cards, satellites, Ku-band transmitters, multi-MIPS personal computers, and encryption chips now under development will be some of the enabling technologies.The State will of course try to slow or halt the spread of this technology, citing national security concerns, use of the technology by drug dealers and tax evaders, and fears of societal disintegration. Many of these concerns will be valid; crypto anarchy will allow national secrets to be trade freely and will allow illicit and stolen materials to be traded. An anonymous computerized market will even make possible abhorrent markets for assassinations and extortion. Various criminal and foreign elements will be active users of CryptoNet. But this will not halt the spread of crypto anarchy.Just as the technology of printing altered and reduced the power of medieval guilds and the social power structure, so too will cryptologic methods fundamentally alter the nature of corporations and of government interference in economic transactions. Combined with emerging information markets, crypto anarchy will create a liquid market for any and all material which can be put into words and pictures. And just as a seemingly minor invention like barbed wire made possible the fencing-off of vast ranches and farms, thus altering forever the concepts of land and property rights in the frontier West, so too will the seemingly minor discovery out of an arcane branch of mathematics come to be the wire clippers which dismantle the barbed wire around intellectual property.Arise, you have nothing to lose but your barbed wire fences!"}
{"prompt": "Crypto Anarchy and Virtual Communities", "completion": "The combination of strong, unbreakable public key cryptography and virtual network communities in cyberspace will produce interesting and profound changes in the nature of economic and social systems. Crypto anarchy is the cyberspatial realization of anarcho-capitalism, transcending national boundaries and freeing individuals to make the economic arrangements they wish to make consensually.Strong cryptography, exemplified by RSA (a public key algorithm) and PGP (Pretty Good Privacy), provides encryption that essentially cannot be broken with all the computing power in the universe. This ensures security and privacy. Public key cryptography is rightly considered to be a revolution.Digital mixes, or anonymous remailers, use crypto to create untraceable e-mail, which has many uses. (Numerous anonymous remailers, in several countries, are now operating. Message traffic is growing exponentially.)Digital pseudonyms, the creation of persistent network personas that cannot be forged by others and yet which are unlinkable to the \"true names\" of their owners, are finding major uses in ensuring free speech, in allowing controversial opinions to be aired, and in providing for economic transactions that cannot be blocked by local governments. The technology being deployed by the Cypherpunks and others, means their identities, nationalities, and even which continents they are on are untraceable -- unless they choose to reveal this information. This alters the conventional \"relationship topology\" of the world, allowing diverse interactions without external governmental regulation, taxation, or interference.Digital cash, untraceable and anonymous (like real cash), is also coming, though various technical and practical hurdles remain. \"Swiss banks in cyberspace\" will make economic transactions much more liquid and much less subject to local rules and regulations. Tax avoidance is likely to be a major attraction for many. An example of local interest to Monte Carlo might be the work underway to develop anonymous, untraceable systems for \"cyberspace casinos.\" While not as attractive to many as elegant casinos, the popularity of \"numbers games\" and bookies in general suggests a opportunity to pursue.Data havens and information markets are already springing up, using the methods described to make information retrievable anonymously and untraceably.Governments see their powers eroded by these technologies, and are taking various well-known steps to try to limit the use of strong crypto by their subjects. The U.S. has several well-publicized efforts, including the Clipper chip, the Digital Telephony wiretap law, and proposals for \"voluntary\" escrow of cryptographic keys. Cypherpunks and others expect these efforts to be bypassed. Technology has let the genie out of the bottle. Crypto anarchy is liberating individuals from coercion by their physical neighbors\u2014who cannot know who they are on the Net\u2014and from governments. For libertarians, strong crypto provides the means by which government will be avoided.The presentation will describe how several of these systems work, briefly, and will outline the likely implications of this combination of crypto anarchy and virtual cyberspace communities.This paper describes the combination of two major technologies:This paper describes the combination of two major technologies:These areas have generally remained separate, at least in published papers. Certainly the developers of cyberspace systems, such as MUDs, MOOs, and Habitat-like systems, appreciate the importance of cryptography for user authentication, overall security, and certainly for (eventual) digital purchase of services. But for the most part the combination of these two areas has been the province of the science fiction writer, notably writers such as Vernor Vinge, William Gibson, Bruce Sterling, and Orson Scott Card.The \"Cypherpunks\" group, a loose, anarchic mailing list and group of hackers, was formed by several of us in 1992 as a group to make concrete some of the abstract ideas often presented at conferences. We've had some successes, and some failures.[1] The Cypherpunks group also appeared at a fortuitous time, as PGP was becoming popular, as Wired magazine appeared (they featured us on the cover of their second issue), and as the publicity (hype?) about the Information Superhighway and the World Wide Web reached a crescendo.The site ftp.csua.berkeley.edu has a number of essays and files, including crypto files, in the directory pub/cypherpunks. I have also written/ compiled a very large 1.3 MB FAQ on these issues, the Cyphernomicon, available at various sites, including my ftp directory, ftp.netcom.com, in the directory pub/tc/tcmay.The Cypherpunks group is also a pretty good example of a \"virtual community.\" Scattered around the world, communicating electronically in matters of minutes, and seeming oblivious to local laws, the Cypherpunks are indeed a community, and a virtual one. Many members use pseudonyms, and use anonymous remailers to communicate with the list. The list itself thus behaves as a \"message pool,\" a place where information of all sort may be anonymous deposited\u2014and anonymous received (since everyone sees the entire list, like a newspaper, the intended recipient is anonymized).Legal Caveat: Consult your local laws before applying any of the methods described here. In some jurisdictions, it may be illegal to even read papers like this (seriously). In particular, I generally won't be giving ftp site addresses for copies of PGP, remailer access, digital cash systems, etc. These are well-covered in more current forums, e.g., sci.crypt or talk.politics.crypto, and there are some unresolved issues about whether giving the address of such sites constitutes (or \"aids and abets\") violation of various export and munitions laws (crypto is considered a munition in the U.S. and probably elsewhere....some nations consider a laser printer to be a munitions item!).The past two decades have produced a revolution in cryptography (crypto, for short) the science of the making of ciphers and codes. Beyond just simple ciphers, useful mainly for keeping communications secret, modern crypto includes diverse tools for authentication of messages, for digital timestamping of documents, for hiding messages in other documents (steganography), and even for schemes for digital cash.Public key cryptography, the creation of Diffie and Hellman, has dramatically altered the role of crypto. Coming at the same time as the wholesale conversion to computer networks and worldwide communications, it has been a key element of security, confidence, and success. The role of crypto will only become more important over the coming decades.Pretty Good Privacy, PGP, is a popular version of the algorithm developed by Rivest, Shamir, and Adleman, known of course as RSA. The RSA algorithm was given a patent in the U.S., though not in any European countries, and is licensed commercially.[2]These tools are described in detail in various texts and Conference proceedings, and are not the subject of this paper.[3] The focus here is on the implications of strong crypto for cyberspace, especially on virtual communities.Mention should be made of the role of David Chaum in defining the key concepts here. In several seminal papers (for example,[4][5]), Chaum introduced the ideas of using public key cryptography methods for anonymous, untraceable electronic mail, for digital money systems in which spender identity is not revealed, and in schemes related to these. (I make no claims of course that Chaum agrees with my conclusions about the political and socioeconomic implications of these results.)Notes: cyberspace, Habitat, VR, Vinge, etc. Crypto holds up the \"walls\" of these cyberspatial realities. Access control, access rights, modification privileges.Virtual communities are the networks of individuals or groups which are not necessarily closely-connected geographically. The \"virtual\" is meant to imply a non-physical linking, but should not be taken to mean that these are any less community-like than are conventional physical communities.Examples include churches, service organizations, clubs, criminal gangs, cartels, fan groups, etc. The Catholic Church and the Boy Scouts are both examples of virtual communities which span the globe, transcend national borders, and create a sense of allegiance, of belonging, and a sense of \"community.\" Likewise, the Mafia is a virtual community (with its enforcement mechanisms, its own extra-legal rules, etc.) Lots of other examples: Masons, Triads, Red Cross, Interpol, Islam, Judaism, Mormons, Sindero Luminoso, the IRA, drug cartels, terrorist groups, Aryan Nation, Greenpeace, the Animal Liberation Front, and so on. There are undoubtedly many more such virtual communities than there are nation-states, and the ties that bind them are for the most part much stronger than are the chauvinist nationalism emotions. Any group in which the common interests of the group, be it a shared ideology or a particular interest, are enough to create a cohesive community.Corporations are another prime example of a virtual community, having scattered sites, private communication channels (generally inaccessible to the outside world, including the authorities), and their own goals and methods. In fact, many \"cyberpunk\" (not cypherpunk) fiction authors make a mistake, I think, in assuming the future world will be dominated by transnational megacorporate \"states.\" In fact, corporations are just one example\u2014of many\u2014of such virtual communities which will be effectively on a par with nation-states. (Note especially that any laws designed to limit use of crypto cause immediate and profound problems for corporations-countries like France and the Philippines, which have attempted to limit the use of crypto, have mostly been ignored by corporations. Any attempts to outlaw crypto will produce a surge of sudden \"incorporations,\" thus gaining for the new corporate members the aegis of corporate privacy.)In an academic setting, \"invisible colleges\" are the communities of researchers.These virtual communities typically are \"opaque\" to outsiders. Attempts to gain access to the internals of these communities are rarely successful. Law enforcement and intelligence agencies (such as the NSA in the U.S., Chobetsu in Japan, SDECE in France, and so on, in every country) may infiltrate such groups and use electronic surveillance (ELINT) to monitor these virtual communities. Not surprisingly, these communities are early adopters of encryption technology, ranging from scrambled cellphones to full-blown PGP encryption.[6]The use of encryption by \"evil\" groups, such as child pornographers, terrorists, abortionists, abortion protestors, etc., is cited by those who wish to limit civilian access to crypto tools. We call these the \"Four Horseman of the Infocalypse,\" as they are so often cited as the reason why ordinary citizen-units of the nation-state are not to have access to crypto.This is clearly a dangerous argument to make, for various good reasons. The basic right of free speech is the right to speak in a language one's neighbors or governing leaders may not find comprehensible: encrypted speech. There's not enough space here to go into the many good arguments against a limit on access to privacy, communications tools, and crypto.The advent of full-featured communications systems for computer-mediated virtual communities will have even more profound implications. MUDs and MOOs (multi-user domains, etc.) and 3D virtual realities are one avenue, and text-centric Net communications are another. (Someday, soon, they'll merge, as described in Vernor Vinge's prophetic 1980 novella, True Names.)An interesting way to view issues of network visibility is in terms of the \"transparency\" of nodes and links between nodes. Transparent means visible to outsiders, perhaps those in law enforcement or the intelligence community. Opaque mean not transparent, not visible. A postcard is transparent, a sealed letter is opaque. PGP inventor Phil Zimmermann has likened the requirement for transparency to being ordered to use postcards for all correspondence, with encryption the equivalent of an opaque envelope (envelopes can be opened, of course, and long have been).Transparent links and nodes are the norm in a police state, such as the U.S.S.R., Iraq, China, and so forth. Communications channels are tapped, and private use of computers is restricted. (This is becoming increasingly hard to do, even for police states; many cite the spread of communications options as a proximate cause of the collapse of communism in recent years.)There are interesting \"chemistries\" or \"algebras\" of transparent vs. opaque links and nodes. What happens if links must be transparent, but nodes are allowed to be opaque? (The answer: the result is as if opaque links and nodes were allowed, i.e., full implications of strong crypto. Hence, any attempt to ban communications crypto while still allowing private CPUs to exist....)If Alice and Bob are free to communicate, and to choose routing paths, then Alice can use \"crypto arbitrage\" (a variation on the term, \"regulatory arbitrage,\" the term Eric Hughes uses to capture this idea of moving transactions to other jurisdictions) to communicate with sites\u2014perhaps in other countries\u2014that will perform as she wishes. This can mean remailing, mixing, etc. As an example, Canadian citizens who are told they cannot access information on the Homolka-Teale murder case (a controversial case in which the judge has ordered the media in Canada, and entering Canada, not to discuss the gory details) nevertheless have a vast array of options, including using telnet, gopher, ftp, the Web, etc., to access sites in many other countries--or even in no country in particular.Most of the consequences described here arise from this chemistry of links and nodes: unless nearly all node and links are forced to be transparent, including links to other nations and the nodes in those nations, then the result is that private communication can still occur. Crypto anarchy results.\"The Net is an anarchy.\" This truism is the core of crypto anarchy. No central control, no ruler, no leader (except by example, reputation), no \"laws.\" No single nation controls the Net, no administrative body sets policy. The Ayatollah in Iran is as powerless to stop a newsgroup\u2014alt.wanted.moslem.women or alt.wanted.moslem.gay come to mind\u2014he doesn't like as the President of France is as powerless to stop, say, the abuse of French in soc.culture.french. Likewise, the CIA can't stop newsgroups, or sites, or Web pages, which give away their secrets. At least not in terms of the Net itself...what non-Net steps might be taken is left as an exercise for the paranoid and the cautious.This essential anarchy is much more common than many think. Anarchy\u2014the absence of a ruler telling one what to do\u2014is common in many walks of life: choice of books to read, movies to see, friends to socialize with, etc. Anarchy does not mean complete freedom\u2014one can, after all, only read the books which someone has written and had published\u2014but it does mean freedom from external coercion. Anarchy as a concept, though, has been tainted by other associations.First, the \"anarchy\" here is not the anarchy of popular conception: lawlessness, disorder, chaos, and \"anarchy.\" Nor is it the bomb-throwing anarchy of the 19th century \"black\" anarchists, usually associated with Russia and labor movements. Nor is it the \"black flag\" anarchy of anarcho-syndicalism and writers such as Proudhon. Rather, the anarchy being spoken of here is the anarchy of \"absence of government\" (literally, \"an arch,\" without a chief or head).This is the same sense of anarchy used in \"anarchocapitalism,\" the libertarian free market ideology which promotes voluntary, uncoerced economic transactions.[7] I devised the term crypto anarchy as a pun on crypto, meaning \"hidden,\" on the use of \"crypto\" in combination with political views (as in Gore Vidal's famous charge to William F. Buckley: \"You crypto fascist!\"), and of course because the technology of crypto makes this form of anarchy possible. The first presentation of this was in a 1988 \"Manifesto,\" whimsically patterned after another famous manifesto.[8] Perhaps a more popularly understandable term, such as \"cyber liberty,\" might have some advantages, but crypto anarchy has its own charm, I think.And anarchy in this sense does not mean local hierarchies don't exist, nor does it mean that no rulers exist. Groups outside the direct control of local governmental authorities may still have leaders, rulers, club presidents, elected bodies, etc. Many will not, though.Politically, virtual communities outside the scope of local governmental control may present problems of law enforcement and tax collection. (Some of us like this aspect.) Avoidance of coerced transactions can mean avoidance of taxes, avoidance of laws saying who one can sell to and who one can't, and so forth. It is likely that many will be unhappy that some are using cryptography to avoid laws designed to control behavior.National borders are becoming more transparent than ever to data. A flood of bits crosses the borders of most developed countries\u2014phone lines, cables, fibers, satellite up/downlinks, and millions of diskettes, tapes, CDs, etc. Stopping data at the borders is less than hopeless.Finally, the ability to move data around the world at will, the ability to communicate to remote sites at will, means that a kind of \"regulatory arbitrage\" can be used to avoid legal roadblocks. For example, remailing into the U.S. from a site in the Netherlands...whose laws apply? (If one thinks that U.S. laws should apply to sites in the Netherlands, does Iraqi law apply in the U.S.? And so on.)This regulatory arbitrage is also useful for avoiding the welter of laws and regulations which operations in one country may face, including the \"deep pockets\" lawsuits so many in the U.S. face. Moving operations on the Net outside a litigious jurisdiction is one step to reduce this business liability. Like Swiss banks, but different.Something needs to be said about the role of anonymity and digital pseudonyms. This is a topic for an essay unto itself, of course.Are true names really needed? Why are they asked for? Does the nation-state have any valid reason to demand they be used?People want to know who they are dealing with, for psychological/evolutionary reasons and to better ensure traceability should they need to locate a person to enforce the terms of a transaction. The purely anonymous person is perhaps justifiably viewed with suspicion.And yet pseudonyms are successful in many cases. And we rarely know whether someone who presents himself by some name is \"actually\" that person. Authors, artists, performers, etc., often use pseudonyms. What matters is persistence, and nonforgeability. Crypto provides this.On the Cypherpunks list, well-respected digital pseudonyms have appeared and are thought of no less highly than their \"real\" colleagues are.The whole area of digitally-authenticated reputations, and the \"reputation capital\" that accumulates or is affected by the opinions of others, is an area that combines economics, game theory, psychology, and expectations. A lot more study is needed.It is unclear if governments will move to a system of demanding \"Information Highway Driver's Licenses,\" figuratively speaking, or how systems like this could ever be enforced. (The chemistry of opaque nodes and links, again.)It surprises many people that some of these uses are already being intensively explored. Anonymous remailers are used by tens of thousands of persons-and perhaps abused.[9] And of course encryption, via RSA, PGP, etc., is very common in some communities. (Hackers, Net users, freedom fighters, white separatists, etc....I make no moral judgments here about those using these methods).Remailers are a good example to look at in more detail. There are two current main flavors of remailers:\"Cypherpunk\"-style remailers, which process text messages to redirect mail to another sites, using a command syntax that allows arbitrary nesting of remailing (as many sites as one wishes), with PGP encryption at each level of nesting.\"Julf\"-style remailer(s), based on the original work of Karl Kleinpaste and operated/maintained by Julf Helsingius, in Finland. No encryption, and only one such site at present. (This system has been used extensively for messages posted to the Usenet, and is basically successful. The model is based on operator trustworthiness, and his location in Finland, beyond the reach of court orders and subpoenas from most countries.)The Cypherpunks remailers currently number about 20, with more being added every month. There is no reason not to expect hundreds of such remailers in a few years.One experimental \"information market\" is BlackNet, a system which appeared in 1993 and which allows fully-anonymous, two-way exchanges of information of all sorts. There are reports that U.S. authorities have investigated this because of its presence on networks at Defense Department research labs. Not much they can do about it, of course, and more such entities are expected.(The implications for espionage are profound, and largely unstoppable. Anyone with a home computer and access to the Net or Web, in various forms, can use these methods to communicate securely, anonymously or pseudonymously, and with little fear of detection. \"Digital dead drops\" can be used to post information obtained, far more securely than the old physical dead drops...no more messages left in Coke cans at the bases of trees on remote roads.)Whistleblowing is another growing use of anonymous remailers, with folks fearing retaliation using remailers to publicly post information. (Of course, there's a fine line between whistleblowing, revenge, and espionage.)Data havens, for the storage and marketing of controversial information is another area of likely future growth. Nearly any kind of information, medical, religious, chemical, etc., is illegal or proscribed in one or more countries, so those seeking this illegal information will turn to anonymous messaging systems to access\u2014and perhaps purchase, with anonymous digital cash\u2014this information. This might include credit data bases, deadbeat renter files, organ bank markets, etc. (These are all things which have various restrictions on them in the U.S., for example....one cannot compile credit data bases, or lists of deadbeat renters, without meeting various restrictions. A good reason to move them into cyberspace, or at least outside the U.S., and then sell access through remailers.)Matching buyers and sellers of organs is another such market. A huge demand (life and death), but various laws tightly controlling such markets.Digital cash efforts. A lot has been written about digital cash.[10] [11] David Chaum's company, DigiCash, has the most interesting technology, and has recently begun market testing. Stefan Brands may or may not have a competing system which gets around some of Chaum's patents. (The attitude crypto anarchists might take about patents is another topic for discussion. Suffice it to say that patents and other intellectual property issues continue to have relevance in the practical world, despite erosion by technological trends.)Credit card-based systems, such as the First Virtual system, are not exactly digital cash, in the Chaumian sense of blinded notes, but offer some advantages the market may find useful until more advanced systems are available.I expect to see many more such experiments over the next several years, and some of them will likely be market successes.How will these ideas affect the development of cyberspace?\"You can't eat cyberspace\" is a criticism often levelled at argument about the role of cyberspace in everyday life. The argument made is that money and resources \"accumulated\" in some future (or near-future) cyberspatial system will not be able to be \"laundered\" into the real world. Even such a prescient thinker as Neal Stephenson, in Snow Crash, had his protagonist a vastly wealthy man in \"The Multiverse,\" but a near-pauper in the physical world.This is implausible for several reasons. First, we routinely see transfers of wealth from the abstract world of stock tips, arcane consulting knowledge, etc., to the real world. \"Consulting\" is the operative word. Second, a variety of means of laundering money, via phony invoices, uncollected loans, art objects, etc., are well-known to those who launder money...these methods, and more advanced ones to come, are likely to be used by those who wish their cyberspace profits moved into the real world.(Doing this anonymously, untraceably, is another complication. There may be methods of doing this--proposals have looked pretty solid, but more work is needed.)The World Wide Web is growing at an explosive pace. Combined with cryptographically-protected communication and digital cash of some form (and there are several being tried), this should produce the long-awaited colonization of cyberspace.Most Net and Web users already pay little attention to the putative laws of their local regions or nations, apparently seeing themselves more as members of various virtual communities than as members of locally-governed entities. This trend is accelerating.Most importantly, information can be bought and sold (anonymously, too) and then used in the real world. There is no reason to expect that this won't be a major reason to move into cyberspace.I've touched on the implications in several places. Many thoughtful people are worried about some of the possibilities made apparent by strong crypto and anonymous communication systems. Some are proposing restrictions on access to crypto tools. The recent debate in the U.S. over \"Clipper\" and other key escrow systems shows the strength of emotions on this issue.Abhorrent markets may arise. For example, anonymous systems and untraceable digital cash have some obvious implications for the arranging of contract killings and such. (The greatest risk in arranging such hits is that physical meetings expose the buyers and sellers of such services to stings. Crypto anarchy lessens, or even eliminates, this risk, thus lowering transaction costs. The risks to the actual triggermen are not lessened, but this is a risk the buyers need not worry about. Think of anonymous escrow services which hold the digital money until the deed is done. Lots of issues here. It is unfortunate that this area is so little-discussed....people seem to have an aversion for exploring the logical consequences in such areas.)The implications for corporate and national espionage have already been touched upon. Combined with liquid markets in information, this may make secrets much harder to keep. (Imagine a \"Digital Jane's,\" after the military weapons handbooks, anonymously compiled and sold for digital money, beyond the reach of various governments which don't want their secrets told.)New money-laundering approaches are of course another area to explore.Something that is inevitable is the increased role of individuals, leading to a new kind of elitism. Those who are comfortable with the tools described here can avoid the restrictions and taxes that others cannot. If local laws can be bypassed technologically, the implications are pretty clear.The implications for personal liberty are of course profound. No longer can nation-states tell their citizen-units what they can have access to, not if these citizens can access the cyberspace world through anonymous systems.I am making no bold predictions that these changes will sweep the world anytime soon. Most people are ignorant of these methods, and the methods themselves are still under development. A wholesale conversion to \"living in cyberspace\" is just not in the cards, at least not in the next few decades.But to an increasingly large group, the Net is reality. It is where friends are made, where business is negotiated, where intellectual stimulation is found. And many of these people are using crypto anarchy tools. Anonymous remailers, message pools, information markets. Consulting via pseudonyms has begun to appear, and should grow. (As usual, the lack of a robust digital cash system is slowing things down.Can crypto anarchy be stopped? Although the future evolution in unclear, as the future almost always is, it seems unlikely that present trends can be reversed:The Net is integrally tied to economic transactions, and no country can afford to \"disconnect\" itself from it. (The U.S.S.R. couldn't do it, and they were light-years behind the U.S., European, and Asian countries. And in a few more years, no hope of limiting these tools at all, something the U.S. F.B.I. has acknowledged.[13]Technological Inevitability: These tools are already in widespread use, and only draconian steps to limit access to computers and communications channels could significantly impact further use. (Scenarios for restrictions on private use of crypto.)As John Gilmore has noted, \"the Net tends to interpret censorship as damage, and routes around it.\" This applies as well to attempts to legislate behavior on the Net. (The utter impossibility of regulating the worldwide Net, with entry points in more than a hundred nations, with millions of machines, is not yet fully recognized by most national governments. They still speak in terms of \"controlling\" the Net, when in fact the laws of one nation generally have little use in other countries.)Digital money in its various forms is probably the weakest link at this point. Most of the other pieces are operational, at least in basic forms, but digital cash is (understandably) harder to deploy. Hobbyist or \"toy\" experiments have been cumbersome, and the \"toy\" nature is painfully obvious. It is not easy to use digital cash systems at this time (\"To use Magic Money, first create a client...\"), especially as compared to the easily understood alternatives.[14] People are understandably reluctant to entrust actual money to such systems. And it's not yet clear what can be bought with digital cash (a chicken or egg dilemma, likely to be resolved in the next several years).And digital cash, digital banks, etc., are a likely target for legislative moves to limit the deployment of crypto anarchy and digital economies. Whether through banking regulation or tax laws, it is not likely that digital money will be deployed easily. \"Kids, don't try this at home!\" Some of the current schemes may also incorporate methods for reporting transactions to the tax authorities, and may include \"software key escrow\" features which make transactions fully or partly visible to authorities.Strong crypto provides new levels of personal privacy, all the more important in an era of increased surveillance, monitoring, and the temptation to demand proofs of identity and permission slips. Some of the \"credentials without identity\" work of Chaum and others may lessen this move toward a surveillance society.The implications are, as I see it, that the power of nation-states will be lessened, tax collection policies will have to be changed, and economic interactions will be based more on personal calculations of value than on societal mandates.Is this a Good Thing? Mostly yes. Crypto anarchy has some messy aspects, of this there can be little doubt. From relatively unimportant things like price-fixing and insider trading to more serious things like economic espionage, the undermining of corporate knowledge ownership, to extremely dark things like anonymous markets for killings.But let's not forget that nation-states have, under the guise of protecting us from others, killed more than 100 million people in this century alone. Mao, Stalin, Hitler, and Pol Pot, just to name the most extreme examples. It is hard to imagine any level of digital contract killings ever coming close to nationstate barbarism. (But I agree that this is something we cannot accurately speak about; I don't think we have much of a choice in embracing crypto anarchy or not, so I choose to focus on the bright side.)It is hard to argue that the risks of anonymous markets and tax evasion are justification for worldwide suppression of communications and encryption tools. People have always killed each other, and governments have not stopped this (arguably, they make the problem much worse, as the wars of this century have shown).Also, there are various steps that can be taken to lessen the risks of crypto anarchy impinging on personal safety.[15]Strong crypto provides a technological means of ensuring the practical freedom to read and write what one wishes to. (Albeit perhaps not in one's true name, as the nation-state-democracy will likely still try to control behavior through majority votes on what can be said, not said, read, not read, etc.) And of course if speech is free, so are many classes of economic interaction that are essentially tied to free speech.A phase change is coming. Virtual communities are in their ascendancy, displacing conventional notions of nationhood. Geographic proximity is no longer as important as it once was.A lot of work remains. Technical cryptography still hasn't solved all problems, the role of reputations (both positive and negative) needs further study, and the practical issues surrounding many of these areas have barely been explored.We will be the colonizers of cyberspace.My thanks to my colleagues in the Cypherpunks group, all 700 of them, past or present. Well over 100 megabytes of list traffic has passed through he Cypherpunks mailing list, so there have been a lot of stimulating ideas. But especially my appreciation goes to Eric Hughes, Sandy Sandfort, Duncan Frissell, Hal Finney, Perry Metzger, Nick Szabo, John Gilmore, Whit Diffie, Carl Ellison, Bill Stewart, and Harry Bartholomew. Thanks as well to Robin Hanson, Ted Kaehler, Keith Henson, Chip Morningstar, Eric Dean Tribble, Mark Miller, Bob Fleming, Cherie Kushner, Michael Korns, George Gottlieb, Jim Bennett, Dave Ross, Gayle Pergamit, and\u2014especially\u2014the late Phil Salin. Finally, thanks for valuable discussions, sometimes brief, sometimes long, with Vernor Vinge, David Friedman, Rudy Rucker, David Chaum, Kevin Kelly, and Steven Levy.The Cypherpunks group was mainly formed by Eric Hughes, Tim May, and John Gilmore. It began both physical meetings, in the Bay Area and elsewhere, and virtual meetings on an unmoderated mailing list. The name was provided by Judith Milhon, as a play on the \"cyberpunk\" genre and the British spelling of cipher. The mailing list can be subscribed to by sending the single message subscribe cypherpunks in the body of a message to majordomo@toad.com. Expect at least 50 messages a day. About 600 subscribers in many countries are presently on the list. Some are pseudonyms. \u21a9RSA Data Security Inc., Redwood Shores, California, is the license administrator. Contact them for details. \u21a9Many crypto texts exist. A good introduction is Bruce Schneier's Applied Cryptography, John Wiley and Sons, 1994. This text includes pointers to many other sources. The \"Crypto\" Proceedings (Advances in Cryptology, Springer-Verlag, annually) are essential references. The annual Crypto conference in Santa Barbara, and the Eurocrypt and Auscrypt conferences, are where most crypto results are presented. \u21a9David Chaum, \"Untraceable Electronic Mail, Return Addresses, and Digital Pseudonyms,\" Comm. ACM 24, 2, February 1981, pp. 84-88. Cypherpunks-style remailers are a form of Chaum's \"digital mixes,\" albeit far from ideal. \u21a9David Chaum, \"Security without Identification: Transaction Systems to make Big Brother Obsolete,\" Comm. ACM 28, 10, October 1985. This is an early paper on digital cash...be sure to consult more recent papers. \u21a9The political opposition in Myan Mar\u2014formerly Burma\u2014is using Pretty Good Privacy running on DOS laptops in the jungles for communications amongst the rebels, according to Phil Zimmermann, author of PGP. This life-and-death usage underscores the role of crypto. \u21a9David Friedman, The Machinery of Freedom, 2nd edition. A leading theoretician of anarcho-capitalism. (Hayek was another.) \u21a9Tim May, The Crypto Anarchist Manifesto, July 1988, distributed on the Usenet and on various mailing lists. \u21a9Abuse, according to some views, of remailers is already occurring. A Cypherpunks-type remailer was used to post a proprietary hash function of RSA Data Security, Inc. to the Usenet. (Let me hasten to add that it was not a remailer I operate, or have control over, etc.) \u21a9article on digital cash, The Economist, 26 November 1994. pp. 21-23. \u21a9article on digital cash, Steven Levy, Wired. December 1994. \u21a9See Kevin Kelly's Out of Control, 1994, for a discussion of how central control is failing, and how the modern paradigm is one of market mechanisms, personal choice, and technological empowerment. \u21a9During the \"Digital Telephony Bill\" debate, an FBI official said that failure to mandate wiretap capabilities within the next 18 months would make it all moot, as the cost would rise beyond any reasonable budget (currently $500 million for retrofit costs). \u21a9\"Magic Money\" was an experimental implementation of Chaum's digital cash system. It was coded by \"Pr0duct Cypher,\" a pseudonymous member of the Cypherpunks list\u2014none of us knows his real identity, as he used remailers to communicate with the list, and digitally signed his posts. Many of us found it too difficult to use, which is more a measure of the deep issues involved in using digital analogs (no pun intended) to real, physical money. \u21a9Robin Hanson and David Friedman have written extensively about scenarios for dealing with the threats of extortionists, would-be assassins, etc. I am hoping some of their work gets published someday. (Much of the discussion was in 1992-3, on the \"Extropians\" mailing list.) \u21a9"}
{"prompt": "Formalizing and Securing Relationships on Public Networks", "completion": "History has seen successive revolutions in the costs of doing global business. First transportation, then manufacturing, and recently communications costs have fallen dramatically. Yet there are still major barriers to doing business internationally. The cost of doing business globally is increasingly dominated by issues of jurisdiction, security, and trust: the costs of developing, maintaining, and securing our relationships.Despite the recent rise of global computer networks, our institutions still take for granted that we live in a world of paper. We formalize our relationships with written contracts, written laws, and forms designed for paper. Our attitudes and laws regarding intellectual property and privacy have assumed a world of paper which is costly to copy. Increasingly, we can no longer take these deeply embedded, highly evolved paper institutions for granted. Nor, since these institutions involve complex human relationships, can we redesign them overnight. We are entering a period where civilization must once again adapt to a radical new media.Over the long stretch civilization, paper represents only one of many technologies used to mediate commercial relationships. The Inca used quipu \u2013 accounts encoded on strings, a system with interesting tamper-resistance properties. Early Middle Eastern civilizations used clay tokens for thousands of years. These combined the function of, and were a precursor to, both cuneiform writing and coins. Coins started out as lumps of standardize metal and weight. Since these were too expensive to test during a normal business transaction, they came to be stamped by reputable or powerful authorities. Coins played a major role in commerce for thousands of years, but that era is now over.Business is now dominated by paper and institutions of written literacy. Security measures have included chops, seals, and written signatures. Value has been transered via bills of exchange (which evolved into checks), bearer certificates, and accounts using the double-entry bookeeping system. Most importantly, we take for granted that contracts and law are written on this static medium, to be interpreted and enforced by human authorities.We are now entering an era of online communications and software \"literacy\". The \"physics of cyberspace\", studied by computer scientists, are radically different from the properties of paper, to an even greater degree than paper was different from string, clay, and metal. Not only written but also aural, visual, and other sensory media can be combined. Most importantly, digital media are dynamic \u2013 they not only transmit information, but can also make some kinds of decisions. Digital media can perform calculations, directly operate machinery, and work through some kinds of reasoning much more efficiently than humans.The movement from static to dynamic media promises to bring about a fourth cost revolution in the related areas of jurisdiction, trust, and security. Impacts on business will be felt in law, accounting, auditing, billing, collections, contracts, confidentiality, and so on: in short, the entire nature of our business relationships will be altered in ways only partially foreseeable.The main traditional way to formalize a business relationship is the contract, a set of promises agreed to in a \"meeting of the minds\". We naturally think of contracts as written, but oral agreements are also considered contracts, and have been around since prehistory. The contract is the basic building block of a market economy. Over many centuries of cultural evolution has emerged both the concept of contract and principles related to it, encoded into common law. Such evolved structures are often prohibitively costly to rederive. If we started from scratch, using reason and experience, it could take many centuries to redevelop sophisticated ideas like contract law and property rights that make the modern market work. But the digital revolution challenges us to develop new institutions in a much shorter period of time. By extracting from our current laws, procedures, and theories those principles which remain applicable in cyberspace, we can retain much of this deep tradition, and greatly shorten the time needed to develop useful digital institutions.Computers make possible the running of algorithms heretofore prohibitively costly, and networks the quicker transmission of larger and more sophisticated messages. Furthermore, computer scientists and cryptographers have recently discovered many new and quite interesting algorithms. Combining these messages and algorithms makes possible a wide variety of new protocols. These protocols, running on public networks such as the Internet, both challenge and enable us to formalize and secure new kinds of relationships in this new environment, just as contract law, business forms, and accounting controls have long formalized and secured business relationships in the paper-based world.In electronic commerce so far, the design criteria important for automating contract execution have come from disparate fields like economics and cryptography, with little cross-communication: little awareness of the technology on the one hand, and little awareness of its best business uses other. These efforts are striving after common objectives, and converge on the concept of smart contracts[1].Smart contracts reduce mental and computational transaction costs imposed by either principals, third parties, or their tools. The contractual phases of search, negotiation, commitment, performance, and adjudication constitute the realm of smart contracts. This article covers all phases, with an emphasis on performance. Smart contracts utilize protocols and user interfaces to facilitate all steps of the contracting process. This gives us new ways to formalize and secure digital relationships which are far more functional than their inanimate paper-based ancestors.The basic idea behind smart contracts is that many kinds of contractual clauses (such as collateral, bonding, delineation of property rights, etc.) can be embedded in the hardware and software we deal with, in such a way as to make breach of contract expensive (if desired, sometimes prohibitively so) for the breacher. A canonical real-life example, which we might consider to be the primitive ancestor of smart contracts, is the humble vending machine. Within a limited amount of potential loss (the amount in the till should be less than the cost of breaching the mechanism), the machine takes in coins, and via a simple mechanism, which makes a freshman computer science problem in design with finite automata, dispense change and product according to the displayed price. The vending machine is a contract with bearer: anybody with coins can participate in an exchange with the vendor. The lockbox and other security mechanisms protect the stored coins and contents from attackers, sufficiently to allow profitable deployment of vending machines in a wide variety of areas.Smart contracts go beyond the vending machine in proposing to embed contracts in all sorts of property that is valuable and controlled by digital means. Smart contracts reference that property in a dynamic, often proactively enforced form, and provide much better observation and verification where proactive measures must fall short.As another example, consider a hypothetical digital security system for automobiles. The smart contract design strategy suggests that we successively refine security protocols to more fully embed in a property the contractual terms which deal with it. These protocols would give control of the cryptographic keys for operating the property to the person who rightfully owns that property, based on the terms of the contract. In the most straightforward implementation, the car can be rendered inoperable unless the proper challenge-response protocol is completed with its rightful owner, preventing theft. But if the car is being used to secure credit, strong security implemented in this traditional way would create a headache for the creditor \u2013 the repo man would no longer be able to confiscate a deadbeat's car. To redress this problem, we can create a smart lien protocol: if the owner fails to make payments, the smart contract invokes the lien protocol, which returns control of the car keys to the bank. This protocol might be much cheaper and more effective than a repo man. A further reification would provably remove the lien when the loan has been paid off, as well as account for hardship and operational exceptions. For example, it would be rude to revoke operation of the car while it's doing 75 down the freeway.In this process of successive refinement we've gone from a crude security system to a reified contract:Mature security systems will be undertaking different behavior for different contracts. To continue with our example, if the automobile contract were a lease, the final payment would switch off leasee access; for purchase on credit, it would switch off creditor access. A security system, by successive redesign, increasingly approaches the logic of the contract which governs the rights and obligations covering the object, information, or computation being secured. Qualitatively different contractual terms, as well as technological differences in the property, give rise to the need for different protocols.Outside of the financial cryptography community, and long predating it, there is a deep tradition of protocols used in the course of performing contracts. These protocols consist of a flow of forms (\"data flow\", canonically displayed in data flow diagrams), along with checks and procedures called \"controls\". Controls serve many of the same functions as cryptographic protocols: integrity, authorization, and so on. This article uses \"control protocols\" or simply \"controls\" to refer to this combination of data flow and controls.Control protocols, and the professions of auditing and accounting[2] based on them, play a critical but ill-analyzed role in our economy. Economists lump them, along with other costs of negotiating and ensuring the performance of contracts, under their catch-all rubric of \"transaction costs\". But without controls, large corporations and the economies of scale they create would not be possible. Controls allow a quarrelsome species ill-suited to organizations larger than small tribes to work together on vast projects like manufacturing jumbo jets and running hospitals. These control protocols are the result of many centuries of business experience and have a long future ahead of them, but the digital revolution will soon cause these paper-era techniques to be dramatically augmented by, and eventually integrate into, smart contracts.Controls enable auditing of contract performances, allowing more precise inference of the behavior of an agent. Auditing is costly, so it is undertaken by random sampling. Economists study the substitutability between the probability of verifying a breach and the magnitude of legal fines, where physical enforcement is used. Conceivably, one could substitute increasingly high penalties for increasingly rarer and less expensive auditing. However, this is not robust to real-world conditions of imperfect information.Since controls primarily address the implicit contracts between employees and employer, there is little mapping from contract to control. A secondary function of controls to to monitor contracts with other organizations. Here there is some mapping, but it is confounded by the integration of the two functions in most controls. Rather than based on contractual terms, controls are typically based on managerial authorization.Controls are typically based around amounts of money and quantities of goods. A canonical control is double entry bookkeeping, where two books are kept, and there must be arithmetic reconciliation between the books. To conceal an irregularity, necessary to omit from both sides, or to record entries offsetting the irregularity. Notice that there is a problem distinguishing error from fraud. This problem crops up in many areas in both auditing and smart contracts. To illustrate, here are two common control techniques:Imprest: this is a family of controls involving the receipt or disbursement of bearer certificates (usually notes and coins). One example is the protocol used at most movie theaters. Entry is segregated from payment by introducing tickets and establishing two employee roles, the ticket seller in a booth, and the ticket stub salesman at the entrance. Periodically, a bookkeeper reconciles the number of tickets with the total paid. Discrepancy again indicates fraud or error.Customer audit: Techniques to get the customer to generate initial documentation of a transaction. For example, pricing goods at $.99 forces the employee to open the cash register to make change, generating a receipt.A complete control protocol typically features the generation of initial documentation, segregation of duties, and arithmetic reconciliation of quantities of goods, standard service events, and money.Of these, the segregation of duties deserves special comment.In a large business, transactions are divided up so that no single person can commit fraud. Segregation of duties is an instance of the principle of required conspiracy. For example, the functions of warehouse/delivery, sales, and receipt of payments are each performed by different parties, with a policy that each party reports every transaction to a fourth function, accounting. Any singular reported activity (e.g., delivery without receipt of payment) indicates potential fraud (e.g., a delivery was made to a customer and the payment pocketed instead of being put into the corporate treasury). Segregation of duties is the auditor's favorite tool. Where it is absent the auditor cries \"foul\", just as a good engineer would react to a single point of failure. Many cryptographic systems have rightfully gone down to commercial failure because they ground down to trust in a single entity rather than segregating functions so as to require conspiracy.There are least three significant differences between the scope and emphasis of smart contracts and controls. Controls are paper-era protocols designed around static forms, place little emphasis on confidentiality, and are based on management authorizations rather than one-to-one relationships.Smart contracts can be based on a wide variety of interactive protocols and user interfaces, and can be involved in a wide variety of kinds of contractual performance. Control protocols, developed in the era of paper, are based on static forms passed as messages and processed in tables and spreadsheets. Controls focus on money and counts of standardized goods and service events, easily recorded by numbers and manipulated by arithmetic, while mostly ignoring other kinds or aspects of contractual performance. Checksums on numbers, the basis of reconciliation, are crude and forgeable compared to cryptographic hashes. Electronic Data Interchange (EDI) keeps these static forms and maintains reliance on controls. It uses cryptographic hashes for nothing more sophisticated than integrity checks on individual messages.Controls place little emphasis on confidentiality, at least in the modern accounting literature. The emphasis on confidentiality in paper-era protocols is lacking because violation of often implicit confidences, via replication of data, was much more difficult with paper. Furthermore, technologies for protecting confidentiality while auditing were not feasible. Businesses traditionally trusted accounting firms with confidences, a trust that has eroded over the last century, and will erode still further as accounting firms start taking advantage of the vast amounts of inside and marketing information they are collecting from their customers' databases during audits. Using paper-based protocols in a digital world, there are few effective controls against the auditors themselves. Post-unforgeable transaction logs and multiparty secure computation, discussed below, indicate the possibility of cryptographic protocols to implement less relavatory but more effective auditing trails and controls; their use may be able to ameliorate the growing problems with data mining and breach of confidentiality.Auditors place quite a bit of trust in management to authorize transactions in a secure and productive manner. Objecting to this dual trust in management and distrust of employees inherent in the accounting tradition, there has been a trend in the last two decades towards a loosening of controls as a part of hierarchy flattening and empowerment of professional employees. Unfortunately, loose controls have led to several recent scandals in the banking and investment trade. The most recent view is that there must be a learned tradeoff between controls and empowerment. The smart contract view is that we need smarter controls, originating at the ownership of the company, and entailing less asymmetry between management and other professional employees. This means converting many implicit employee contracts to more explicit smart contracts based on more direct relationships between owners (or at least their directors) and employees, and symmetric formalizations between employees.Although most of these differences are biased against controls, these traditional protocols have a long future ahead of them, simply because they have a long past. They are highly evolved, hundreds of years old (double-entry bookkeeping, for example, predates the Renaissance). Smart contracts will incorporate many techniques and strategies from control protocols, such as generation of an initial record, segregation of duties, and reconciliation. It will not be long, however, before smart contracts start augmenting and transforming traditional business procedures, making a wide variety of new business structures possible and in the long run replacing traditional controls.Electronic Data Interchange (EDI) is the computer-to-computer communication of standardized business transactions between organizations, in a standard format that permits the receiver to perform the intended transaction. It renders traditional static business forms in cyberspace, and maintains the dependence on traditional controls. Beyond simple encryption and integrity checks, EDI does not take advantage of algorithms and protocols to add security and \"smarts\" to business relationships. It enables more rapid execution of traditional negotiation and performance monitoring procedures.EDI loses some security features provided by physical paper (such as difficulty of copying) while not gaining advantages from the wide variety of protocols possible beyond simple message-passing of static forms. This article examples a much richer set of protocols.EDI contracts tend to be merely reiterations of existing terms and conditions, with only some timing expectations changed for the electronic environment. By redesigning our business relationships to take advantage of a richer set of protocols, smart contracts can take us far beyond the paper-based paradigm of shipping around forms in a secure manner.The following classification, derived from Sokol[3], illustrates the variety of business forms that have been rendered in electronic form:Focal (or Schelling) points are often designed and submitted into negotiations by one side or another, both to bias the negotiations and to reduce their cost. The fixed price at the supermarket (instead of haggling), the prewritten contract the appliance salesman presents you, etc. are examples of hard focal points. They are simply agreed to right away; they serve as the end as well as the beginning of negotiations, because haggling over whether the nearest neighbor focal point is better is too expensive for both parties.There are many weak enforcement mechanisms which also serve a similar purpose, like the little arms in parking garages that prevent you from leaving without paying, the sawhorses and tape around construction sites, most fences, etc. Civilization is filled with contracts embedded in the world.More subtle examples include taxi meters, cash register readouts, computer displays, and so on. As with hard focal points, the cost of haggling can often be reduced by invoking technology as authority. \"I'm sorry, but that's what the computer says\", argue clerks around the world. \"I know I estimated $50 to get to Manhattan, but the meter reads $75\", says the taxi driver.Economists stress two properties important to good contract design: observability by principals and verifiability by third parties such as auditors and adjudicators. From the traditions behind contract law and the objectives of data security, we derive a third objective, privity. We flesh out the dimensions of contract design by disentangling mental from computational transaction costs, classifying the kinds of enforceability, characterizing the temporal phases of contracting, and discussing the nature of tradeoffs between the three design objectives.The costs that smart contracts address are lumped by economists under the catch-all rubric of \"transaction costs\". We can divide these into mental and computational transaction costs.One major category of costs include the cost of anticipating, agreeing to, and clearly writing down the various eventualities. These are largely mental transaction costs, although online research tools, for example, may bring more information about eventualities.Most contractual dispute involves an unforeseen or unspecified eventuality. We lack a good model for this. Such a model would account for the computational costs of foreseeing these eventualities, some of which may be uncomputable (and therefore of infinite cost). Where eventualities remain unspecified, contracts remain incomplete.Where counterparties lack focal points, they lack a meeting of minds. Negotiation addresses this gap; the farther apart the focal points (in terms of value), the more expensive the negotiations. There are a variety of institutions of negotiation, which economists study under the rubric of \"mechanisms\". These range from simple haggling to sophisticated auctions and exchanges.For the temporal phases of contracting we use the following schema, classified according to the two-phase model used in economics:Smart contracts often involve trusted third parties, exemplified by an intermediary, who is involved in the performance, and an adjudicator, who is invoked to resolve disputes arising out of performance (or lack thereof). Intermediaries can operate during search, negotiation, commitment, and/or performance. Hidden knowledge, or adverse selection, occurs ex-ante; hidden actions (moral hazards) occur ex-post.Here are some examples of contemporary electronic commerce activities and the phases of contracting they deal with:This article covers all phases, with a particular emphasis on performance.The first objective of smart contract design is observability, the ability of the principals to observe each others' performance of the contract, or to prove their performance to other principals. The field of accounting is, roughly speaking, primarily concerned with making contracts an organization is involved in more observable.Economists discuss \"hidden knowledge\", also known as \"adverse selection\", which can occur due to lack of ability to observe potential counterparties during the search and negotiation phases. Another major problem is \"hidden actions\", also known as \"moral hazard\", which can occur due to the lack of observability and ability to drop out of contract during the performance phase of a contract.One important task of smart contracts, that has been largely overlooked by traditional EDI, is critical to \"the meeting of the minds\" that is at the heart of a contract: communicating the semantics of the protocols to the parties involved. There is ample opportunity in smart contracts for \"smart fine print\": actions taken by the software hidden from a party to the transaction.Here's a small example of smart fine print:Without user interfaces smart contracts are largely invisible, like the electronics in newer car engines. This is both a blessing \u2013 counterparties don't have to feel like they're dealing with user-hostile computers \u2013 and a curse \u2013 the \"smart fine print\" problem of hidden actions.To properly communicate transaction semantics, we need good visual metaphors for the elements of the contract. These would hide the details of the protocol without surrendering control over the knowledge and execution of contract terms. For example, encryption can be shown by putting the document in an envelope, and a digital signature by affixing a seal onto the document or envelope.Amid all the hype about \"information warfare\", lost in the noise is the fact that it is impossible to commit an act of physical violence over the Net. That includes not only all physical crimes of coercion, but also arrest, incarceration, and other traditional methods of law enforcement. Because of this fact, and the jurisdictional swamp that is the multinational Internet, this article concentrates on means of protecting against breach and third parties that do not rely on law enforcement.We can categorize the security measures against breach, eavesdropping, and interference in the following manner:Currently, the most prevalent forms of security software are not proactive cryptography, but reactive and panoptic methods like virus scanning software, filtering firewalls, traceroutes of attackers, etc. Once modern cryptographic protocols are more widely deployed, the balance will likely shift towards preventative security.Reactive measures rely upon two areas: verifiability and penalties. As discussed in the section on accounting controls, under ideal economic conditions, the statistical distribution of verification failures is known, so that verification costs and penalties are can be traded off neatly. But with imperfect information, the jurisdictional swamp, and lack of collateral or other security, collection of damage awards is even more severely limited than in contracts confined to traditional geographic jurisdictions. Reputation costs may be the only practical source of penalties in many cases. For reactive measures to work, high verifiability is critical.So our second objective is verifiability, the ability of a principal to prove to an adjudicator that a contract has been performed or breached, or the ability of the adjudicator to find this out by other means. The disciplines of auditing and investigation roughly correspond with verification of contract performance.Our third objective of smart contract design is privity, the principle that knowledge and control over the contents and performance of a contract should be distributed among parties only as much as is necessary for the performance of that contract. This is a generalization of the common law principle of contract privity, which states that third parties, other than the designated adjudicators and intermediaries, should have no say in the enforcement of a contract. To maintain knowledge and control, performance must be encapsulated: protected from outside influences, especially sophisticated attacks. This is the idea behind both the legal doctrine of privity, which restricts redress to the parties to a contract, and the idea of property rights.Attacks against privity are epitomized by third parties Eve the eavesdropper, a passive observer of contents or performance, and malicious Mallet, who actively interferes with performance or steals service. Under this model privacy and confidentiality, or protecting the value of information about a contract, its parties, and its performance from Eve, is subsumed under privity, as are property rights. The most common definitions of \"security\" in the online world roughly correspond to the goal of privity.Our generalized privity thus encompasses property rights as stable objects linked to particular contracts (and thereby the parties in privity to such contracts, the \"owners\"). Privity creates a clear boundary within which operate a coherent set of rights, responsibilities, and the knowledge with which to carry out those responsibilities and protect those rights. Clarified boundaries also allow accountability. Protection from extraneous interference allows us to focus responsibility for the consequences of contract-related activity onto the parties to the contract.Privity says that we want to minimize vulnerability to third parties. Verifiability and observability often require that we invoke them. An intermediary must be trusted with some of the contents and/or performance of the contract. An adjudicator must be trusted with some of the contents, and some of the history of performance, and to resolve disputes and invoke penalties fairly. In smart contract design we want to get the most out of intermediaries and adjudicator, while minimizing exposure to them. One common outcome is that confidentiality is violated only in case of dispute.Many kinds of specific performance are often entrusted to intermediaries. We must be able to trust the intermediary (credit agency, anti-virus software vendor, certificate intermediary, digital cash mint, etc.) with their particular claims (about creditworthiness, dangerous byte patterns, identity, conservation of the money supply, etc.) As Ronald Reagan remarked in a slightly different context, \"trust but verify\". To deserve our trust, intermediaries must convince us that their claims are true. We need to be able to \"ping\" their veracity, verifying that certain claimed transactions in fact occurred. An entire profession exists in market economies to perform this function: auditing.Ideally, observability and verifiability can also include the ability to differentiate between intentional violations of the contract and good faith errors, but this is difficult in practice, since the difference is often largely one of subjective, unrevealed intent.A protocol[5] in computer science is a sequence of messages between at least two computers. At a higher level of abstraction, a protocol consists of algorithms communicating via messages. These programs act as proxies, or agents, for human users, who communicate their preferences via users interfaces. We distinguish protocol endpoints by names such as \"Alice\" and \"Bob\", but it should be kept in mind that the end points are really computer processing units, which may or may not be under the control of, or taking actions contrary to the intent of, the human user. Human users typically do not have full knowledge of the protocol in question, but rather a metaphorical understanding obtained via user interface, manuals, and so on. Unlike most real-world contracts, protocols must be unambiguous and complete.Protocols come in three basic types. I have modified the terminology of Schneier[6] to match more closely to the corresponding business terminology:The corresponding smart contracts elaborate on \"Alice\" to distinguish between the software (in two components, the endpoint of protocol and the user interface), and Alice herself. Cryptographic and other computer security mechanisms give us a kit of tools and parts from which we can build protocols, which form the basis of smart contracts.The security properties of physical media are based on physical properties we often take for granted, for example the unforgeability of an atom of gold. The structural constraints (\"physics\") of cyberspace relevant to security are described by the mathematical theories studied by computer scientists, especially in the specialty called cryptography. Here are the important \"fundamental particles\" of the cryptographic universe:These \"particles\" are potent building blocks for engineering secure protocols. Imagine a material so tough, it is completely impervious to a supernova, and so cheap you could use it to make walls, locks, safes, and envelopes to protect everyday items. This is not just a metaphor: cracking a 4,096 bit RSA key with best known algorithm really would require more electrical power for the computers than the power produced by a supernova. These cryptographic primitives promise to be a main driving force of the fourth cost revolution for global business.A family of protocols, called cryptographic protocols because their first application was computerized \"secret writing\", provide many of the basic building blocks that implement the improved tradeoffs between observability, verifiability, privity, and enforceability in smart contracts. Contrary to the common wisdom, obscurity is often critical to security. Cryptographic protocols are built around foci of obscurity called keys. A key's immense unknown randomness allows the rest of the system to be simple and public. The obscurity of a large random number, so vast that a lucky guess is astronomically unlikely, is the foundation upon which cryptographic protocols, and smart contracts based on them, are built.Two significant cautions are in order when thinking about how cryptographic protocols can be used in online relationships. The first is that protocols usually provide security \"up to\" some assumption. This assumption is a remaining weak point which a complete working system must address in some reasonable manner. One common endpoint is is assumptions about trusted third parties. Often the degree or function of the trust is not well specified, and it is up to the real-world systems analyst to characterize and ameliorate these exposures. The best mediated protocols only trust the intermediary or counterparty with a well limited function.Even without trusted third parties, cryptographic protocols often ground out in trust of the counterparty. For example, encryption of a message provides confidentiality up to the actions of parties with decrypting keys. Encryption does not stop key holders from posting plain text to Usenet. We cannot just say that encryption provides \"confidentiality\" and leave our concern for confidentiality at that.The second caution is that much of the terminology used in the cryptographic literature to name protocols (\"signatures\", \"cash\", etc.) is misleading. Sometimes the terminology falls short on substantial matters: a \"digital signature\", for example, is not biometric and is based on a key that can easily be copied if not protected by another mechanism. Often cryptographic protocols can be generalized to much wider purposes than implied by the label. For example, \"digital cash\" is a very general protocol which can implement a wide variety of bearer certificates and conservation wrappers for distributed objects.Protocols for smart contracts should be structured in such a way as to make their contractsA vandal can be a strategy or sub-strategy of a game whose utility is at least partially a function of one's own negative utility; or it can be a mistake by a contracting party to the same effect. \"Naive\" simply refers to both lack of forethought as to the consequences of an attack , as well as the relatively low amount of resources expended to enable that attack. Naive vandalism is common enough that it must be taken into consideration. A third category, (c) sophisticated vandalism (where the vandals can and are willing to sacrifice substantial resources), for example a military attack by third parties, is of a special and difficult kind that doesn't often arise in typical contracting, so that we can place it in a separate category and ignore it here. The distinction between naive and sophisticated strategies has been computationally formalized in algorithmic information theory.The expected loss due to third party attack is called the exposure. The cost of third parties to defeat the security mechanism is the disruption cost. If the disruption cost is greater than the expected benefit, we can expect an incentive compatible attacker to disrupt the security.One of the drivers of the trust cost revolution will likely be the wide variety of new cryptographic protocols that have emerged in recent years. The most traditional kind of cryptography is secret key cryptography, in which Alice and Bob (our exemplar parties to a smart contract) use a single shared, prearranged key to encrypt messages between them. A fundamental problem we will see throughout these protocols is the need to keep keys secret, and public key cryptography helps solve this. In this technique, Alice generates two keys, called the private and public keys. She keeps the private key secret and well protected, and publishes the public key. When Bob wishes to send a message to Alice, he encrypts a message with her public key, sends the encrypted message, and she decrypts the message with her private key. The private key provides a \"trapdoor\" that allows Alice to compute an easy inverse of the encryption function that used the public key. The public key provides no clue as to what the private key is, even though they are mathematically related. The RSA algorithm is the most widely used method of public key cryptography.Public key cryptography also makes possible a wide variety of digital signatures. These proves that a piece of data (hereafter referred to as just an \"object\") was in active contact with the private key corresponding to the signature: the object was actively \"signed\" with that key. There are two steps to an authentication protocol: signing and verification. These may occur synchronously, or, in many public protocols, a signature may be verified at some distant time in the future.The digital signature probably should have been called a \"digital stamp\" or \"digital seal\" since its function resembles more those methods than an autograph. In particular, it is not biometric like an autograph, although incorporation of a typed-in password as part of the private key used to sign can sometimes substitute for an autograph. In many Asian countries, a hand-carved wooden block, called a \"chop\", is often used instead of autographs. Every chop is unique, and because of the unique carving and wood grain cannot be copied. A digital signature is similar to the chop, since every newly generated key is unique, but it is trivial to copy the key if obtained from the holder. A digital signature relies on the assumption that the holder will keep the private key secret.A blind signature publically authenticates privy information (but can we use non-privy signatures blindly as well?). This is a digital signature and secret-key encryption protocol that together have the mathematical property of commutativity, so that they can be stripped in reverse of the order they were applied. It's like stamping an unknown document through carbon paper (without having to worry about smudging). The effect is that Bob \"signs\" an object, for which he can verify its general form, but cannot see its specific content. Typically the key of the signature defines the meaning of the signed object, rather than the contents of the object signed, so that Bob doesn't sign a blank check. Blind signatures used in digital bearer certificates, where Bob is the clearing agent, and in Chaumian credentials, where Bob is the credential issuer.The blind signature is one example of the many \"magic ink signatures\" cryptographers have invented. Another class of these protocols are used to limit the parties allowed to either verify the signature or to learn the identity of the signer. The most privy are the zero-knowledge proofs, where only the counterparty can authenticate the prover. Designated confirmer signatures allow the signer to designate particular counterparties as verifiers. For example, a business could give particular auditors, investigators, or adjudicators the authority to verify signed objects, while other third parties, such as competitors, can learn nothing from the signature. Group signatures allow members to sign as an authentic member of a group, without revealing which member made the signature.So far, we've assumed parties like Alice and Bob are monolithic. But in the world of smart contracts, they will use computer-based software agents and smart cards to do their electronic bidding. Keys are not necessarily tied to identities, and the task of doing such binding turns out to be more difficult than at first glance. Once keys are bound, they need to be well protected, but wide area network connections are notoriously vulnerable to hacking.If we assume that the attacker has the ability to intercept and redirect any messages in the network protocol, as is the case on wide area networks such as the Internet, then we must also assume, for practical all commercial operating systems, that they would also be able to invade client if not merchant computers and find any keys lying on the disk.There's no completely satisfactory solution to end point operations security from network-based attacks, but here's a strategy for practically defanging this problem for public-key based systems:All public key operation can be performed inside an unreadable hardware board or smart card on a machine with a very narrow serial-line connection (ie, it carries only a simple single-use protocol with well-verified security) to a dedicated firewall. This is economical for high traffic servers, but may be less practical for individual users. Besides better security, it has the added advantage that hardware speeds up the public key computations.If Mallet's capability is to physically seize the machine, a weaker form of key protection will suffice. The trick is to hold the keys in volatile memory. This makes the PC proof from physical attacks \u2013 all that needed to destroy the keys is to turn off the PC. If the key backups can be hidden in a different, secure physical location, this allows the user of this PC to encrypt large amounts of data both on the PC itself and on public computer networks, without fear that physical attack against the PC will compromise that data. The data is still vulnerable to a \"rubber hose attack\" where the owner is coerced into revealing the hidden keys.Object-oriented, or capability, security is a deep and promising area, but beyond the scope of this article. Capabilities can potentially simplify the design of many distributed security protocols. Instead of developing a new or modified cryptographic protocol for each contracting problem, capabilities may allow us to design a rich variety of distributed security protocols over a common cryptographic framework.For more information see Introduction to Capability Based Security.Quorum distribution of performance or control over resources can be based on the secret sharing of keys needed to perform or control a resource. These are also known as threshold techniques. These are methods of splitting a key (and thus control over any object encrypted with that key) into N parts, of which only M are needed to recreate the key, but less than M of the parts provide no information about the key. Secret sharing is a potent tool for distributing control over objects between principals.Markus Jacobsson has designed a quorum of mints for signing digital coins, for example. Quorum establishes a \"required conspiracy\" of M out of N to perform a function, providing an option for stronger protection than the typical 2 out of N used in segregation of duties, and greater confidence in the security underlying the segregation.Traditionally, auditors have contacted counterparties in order to verify that a transaction actually took place (The \"principle of required conspiracy\" at work again). With post-unforgeable logs, via a hierarchical system of one-way hash functions, a party can publically commit to transactions as they are completed by publishing signed cumulative hashes of the transaction stream. The confidentiality of the transaction is fully maintained until an auditor \"pings\" the transaction to determine its actual nature. The counterparty identity can remain confidential, because it is not required to establish the other facts of the transaction. The only attack is to forge transactions in real time, as the transaction itself takes place, which in most practical cases will be unfeasible. Most accounting fraud involves analyzing sets of completed transactions and then forging them to make them compute to a desired counterfactual result.Cryptographers have developed protocols which create virtual machines between two or more parties. Multiparty secure computation allows any number of parties to share a computation, each learning only what can be inferred from their own inputs and the output of the computation. These virtual machines have the exciting property that each party's input is strongly confidential from the other parties. The program and the output are shared by the parties. So, for example, we could run a spreadsheet across the Internet on this virtual computer. We would agree on a set of formulas, set up the virtual computer with these formulas, and each input our own private data. We could only learn only as much about the other participants' inputs as we could infer from our own inputs and the output.There are two major complications. The first is that this virtual computer is very slow: one machine instruction per network message. The second is that some parties learn the results before others. Several papers have disussed the fraction of parties one must trust in order to be assured of learning the correct output. The mechanism must be constructed so that a sufficient number of parties have an incentive to pass on the correct result, or reputation, side contracts, etc. used to the same effect.With these caveats, any algorithmic intermediary can, in principle, be replaced by a trustworthy virtual computer. In practice, because of the two complications, we usually construct more limited protocols out of more efficient elements.Trusted Third Party:Mathematically Trustworthy Protocol:Multiparty secure computer theory, by making possible privy virtual intermediation, has major implications for all phases of contracting. This can be seen most clearly in the area of negotiations. A \"mechanism\" in economics is an abstract model of an institution which communicates with its participants via messages, and whose rules can be specified algorithmically. These institutions can be auctions, exchanges, voting, and so on. They typically implement some kind of negotiation or decision making process.Economists assume a trusted intermediary operates the mechanism. Here's a simple example of using this virtual computer for a mechanism. Alice can submit a bid price, and Bob an ask price, to their shared virtual computer which has one instruction, \"A greater than B?\". The computer then returns \"true\" if Alice's bid is greater than Bob's offer. A slightly more sophisticated computer may then decide the settlement price according to a number of different algorithms (Alice's bid, Bob's ask, split the difference, etc.) This implements the mechanism \"blind bargaining\" with no trusted intermediary.In principle, since any computable problem can be solved on this virtual computer (they are \"Turing complete\"), any computable economic mechanism can be implemented without a trusted intermediary. In practice, these secure virtual computers run very slowly (one virtual machine instruction per network message), and the order in which participants learn results often matters. But the existence proof, that any economic mechanism can be run without a trusted intermediary, up to temporal issues, is very exciting. This means that, in principle, any contract which can be negotiated through a trusted third party (such as an auction or exchange) can be negotiated directly. So, in some abstract sense, the only remaining \"hard\" problems in smart contract negotiations are (a) problems considered hard even with a trusted intermediary (for the standard economic reasons), (b) nonsimultaneity problems in learning the decision, and (c) the task of algorithmically specifying the negotiating rules and output contract terms (This includes cases where an intermediary adds knowledge unavailable to the participants, such as a lawyer giving advice on how to draft a contract).Applying this kind of analysis to the performance phase of contracts is less straightforward. For starters, economic theories of the performance phase are not as well developed or simple as the mechanism theory of negotiations. Indeed, most economic theory simply assumes that all contracts can be perfectly and costlessly enforced. Some of the \"transaction cost\" literature has started to move beyond this assumption, but there are few compelling results or consensus theories in the area of techniques and costs of contract enforcement.Performance phase analysis with multiparty secure computer theory would seem to apply only to those contracts which can be performed inside the virtual computer. But the use of post-unforgeable auditing logs, combined with running auditing protocols inside the shared virtual computer, allows a wide variety of performances outside the virtual computer to at least be observed and verified by selected arbitrators, albeit not proactively self-enforced.The participants in this mutually confidential auditing protocol can verify that the books match the details of transactions stored in a previously committed transaction log, and that the numbers add up correctly. The participants can compute summary statistics on their confidentially shared transaction logs, including cross-checking of the logs against counterparties to a transaction, without revealing those logs. They only learn what can be inferred from the statistics, can't see the details of the transactions. Another intriguing possibility is that the virtual computer can keep state over long periods of time, allowing sophisticated forms of privy and self-enforcing secured credit.With mutually confidential auditing we will be able to gain high confidence in the factuality of counterparties' claims and reports without revealing identifying and other detailed information from the transactions underlying those reports. These provide the basis for solid reputation systems, and other trusted third party systems, that maintain integrity across time, communications, and summarization, and preserve confidentiality for transaction participants. Knowing that mutually confidential auditing can be accomplished in principle may lead us to practical solutions.Bearer certificates implement transferable rights on standardized contracts. Each kind of contract (for example, each denomination of \"coin\" in digital cash) corresponds to a digital signature, just as each issue of Federal Reserve Notes or stock certificates corresponds to a particular plate.In the most straightforward bearer certificate protocol, the issuer and transfer agent (the same entity, for our purposes, though they can easily be unbundled) create a serial number (really a large unguessable random number, rather than a sequence), and add it to a list of issued certificates. The transfer agent clears a transfer by checking the signature to identify and nature of the bearer contract and verify that it was made, then looking on that contract's issued list to make sure the serial number is there, then removing the serial number. Alternatively, the issuer can let the issuee make up the serial number, then, when cleared, check the signature and put the number on the list of cleared certificates. The signature provides the assurance that the certificate is indeed the the particular kind of contract with bearer, while the serial number assures that the same instance of that contract is not cleared or redeemed more than once. In these simple versions, the transfer agent can link the transferee to the transferor for all transfers. To implement the privacy characteristics of coins and physical bearer certificates, we need to add unlinkability features.Unlinkability can be provided by combining the second variation above, a list of cleared certificates, with blind signatures and a mixing effect. Enough instances of a standardized contract are issued over a period of time to create a mix. Between the issuing and clearing of a certificate, many other certificates with the same signature will be cleared, making it highly improbable that a particular clearing can be linked to a particular issue via the signature. There is a tradeoff between the mixing effect and the exposure to the theft of a \"plate\" for a particular issue: the smaller the issue, the smaller the exposure but the greater the linkability; a larger issue has both greater exposure and greater confidentiality.Blind signatures can be used to make certificate transfers unlinkable via serial number. Privacy from the transfer agent can take the form of transferee-unlinkability, transferor-unlinkability, or \"double blinded\" where both transferor and transferee are unlinkable by the transfer agent or a collusion of a transfer agent and counterparty.Bearer certificates come in an \"online\" variety, cleared during every transfer, and thus both verifiable and observable, and an \"offline\" variety, which can be transferred without being cleared, but is only verifiable when finally cleared, by revealing any the clearing name of any intermediate holder who transferred the object multiple times (a breach of contract).This unlinkability is often called \"anonymity\", but the issue of whether accounts are issued to real names or pseudonyms, and whether transferor and transferee identify themselves to each other, is orthogonal to unlinkability by the transfer agent in the online model. In the off-line model, account identification (or at least a highly reputable and/or secured pseudonym) is required: passing an offline certificate a second time reveals this identity. Furthermore, communications channels can allow Eve to link transferor and transferee, unless they take the precaution of using an anonymous remailer. Online clearing does make lack of identification a reasonable option for many kinds of transactions, although common credit and warrantee situations often benefit from or even require identification.When confronting an attempted clearing of a cleared serial number, we face an error-or-fraud dilemma similar to the one we encountered above in double entry bookkeeping. The ecash\u2122 protocol from DigiCash actually takes advantage of this ambiguity, second-transferring certificates on purpose to recover from a network failure. When certificates are lost over the net it is not clear to the transferor whether they have been received and cleared by the transferee or not. Second-transferring directly with the transfer agent resolves the ambiguity. This only works with the online protocol. The issue of distinguishing error from fraud is urgent in the offline protocol, but there is as yet no highly satisfactory solution. This problem is often intractable due to the subjectivity of intent.Issuance and cleared transfer of references to a distributed object conserves the usage of that object. This object becomes \"scarce\" in economic terms, just as use of physical objects is finite. Conserved objects provide the basis for a software economics that more closely resembles economics of scarce physical objects. Conserved objects can be used to selectively exclude not only scarce physical resources (such as CPU time, network bandwidth and response time, etc.), but also fruits of intellectual labor \u2013 as long as one is willing to pay the price to interact with that information over the network rather than locally (cf. content rights management). Conservation immunizes objects and the resources they encapsulate to denial of service attacks. Bearer certificate protocols can be used to transfer references to a particular instance or set of instances of an object, just as they can be used to transfer other kinds of standardized rights.Digital cash is the premier example of a digital bearer certificate. The issue and transfer agent is called a \"mint\". Bearer certificate protocols enable online payment while honoring the characteristics desired of bearer notes, especially unforgeability (via the clearing mechanism) and transfer confidentiality (via mixing and blinding).To implement a full transaction of payment for services, we often need need more than just the digital cash protocol; we need a protocol that guarantees that service will be rendered if payment is made, and vice versa. Current commercial systems use a wide variety of techniques to accomplish this, such as certified mail, face to face exchange, reliance on credit history and collection agencies to extend credit, etc. Potential smart contract protocols in this area are discussed under Credit.Content protection contracts are valuable in that they incentive publishers to allow users to view content directly, rather than indirectly and partially via queries to remote servers. Content protection of software distributed online would allow it to be run locally rather than remotely, while enforcing the contract rights and copyrights of the publisher against the user. This local usage billing of software often goes under the rubric of \"superdistribution\"[11].Watermark schemes work by altering less significant bits of content \u2013 usually a picture; sound works less well and text is difficult. These altered bits typically contain the identities of the publisher and viewer, and perhaps other information related to the contract. The idea is that, when investigators scan released content, the watermark will finger the breacher of the contract (or violator of copyright law).Watermark investigation can be assisted by a quite inexpensive technique, Web spiders. These spiders look for redistributed watermarked material on the Web. The customer originating the copy can then be fingered.One attack against watermarks is to overwrite likely watermark bits with other patterns legitimate to viewing software. The entanglement of watermark bits with bits important to the picture can be made rather obscure, but not strongly so by the standards of cryptography. Another attack is to steal content from a customer and distribute it as is. The watermark will finger the victim, rather than the thief.All watermark schemes can be defeated with sufficient effort. These schemes can then be distributed as software worldwide. Once the initial effort is put into breaking a scheme, the marginal cost of breaking it is minimal. Furthermore, once the watermark is removed, the content can be distributed and even published[12] with secure anonymity.In sum, watermark schemes can add significant risk to the copying of of low value or ephemeral information. This will be sufficient for many kinds of content, such as news or product updates. It won't stop, for long, the redistribution of high-value content. Since watermarks require traceable identification, they reduce customer privacy and require the inconvenience of registration and authentication, adding to the transaction costs of content purchase.Contrary to the hype, there is no strong content protection software. Watermarks are as close as we've come, and they fall far short of the standards of computer security. Large sums have gone into attempts to develop such technology, resulting in hundreds of patents but no substantial results.As a result, some publishers have begun putting their research dollars into a radical alternative, innocuously dubbed the \"secure CPU\" (SPU)[13]. This is a CPU that is \"secure\" against the owner of the computer! To enforce copyright or content contracts, the SPU monitors all content-related activity. Some marketing literature even lists, alongside the traditional copyright, a new \"right\" of publishers to monitor the usage of their content. Remarkably enough, these panoptic non-personal computers are the focus of major R&D efforts.The radical SPU projects demonstrate both the high value of content contracts to publishers and the high price we have to pay to maintain the paper-era intellectual property model online. Strong content protection would be valuable in going beyond indirect and partial viewing of content on servers, to viewing content directly and locally. The price is the loss of control over our own computers, and loss of privacy over our activities on those computers.The online content market is squeezed from above and below. From above, by the ease of redistributing high-value content. From below, by the mental transaction costs of charging for low value content \u2013 costs to which the requirements of registration and traceable identification add substantially. The size of the market in between is an open question. \"Information wants to be free\", but authors and publishers want to be paid for it. The current content market for more difficult to copy media, such as books, films, CD-ROM, and so forth is large, in the hundreds of billions of dollars per year. But on the Internet, free content dominates. Distributing ephemeral content in the form of service subscriptions is in most cases a more viable way to go. It remains to be seen how large the Internet content market will become, and to what extent customers will tolerate impositions on privacy and control of their computers in order to obtain legal content.Reputation can be viewed as the amount of trust an agent has created for himself[14]. Reputation systems ultimately need to be based on fact rather than mere opinion or faith to be effective. For example, if we are to have a good credit rating system, we need to be confident that the credit record assembled by the agency is sufficiently accurate. Reputation information is typical gathered and distributed by intermediaries trusted to perform this task. Reputation can take the form of a public database (such as credit rating services) or credentials issued by the tracking agency and carried by the user. A bearer doesn't want to show his negative credentials, so credentials are often only positive. But we want to protect ourselves against negative behavior sources well as search out positive sources.Tags that bundle the results of a wide variety of transactions - global names, or universal IDs, or \"True Names\" \u2013 may provide the most incentive for parties to carry their negative credentials. Most people have accumulated enough positive reputation is some areas that it is well-nigh impossible for them to start over their entire lives as newcomers.Robin Hanson[15] has observed that in a world of global names, the use of a local name may signal the hiding of negative credentials, so that the use of global names is in equilibrium. A further problem with local names is that our relationships are often not neatly compartmentalizable into standard service types, and even where they are we might like to expand them into new areas. On the other hand, local names are essential for privacy. I suggest that we will want to reveal progressively more local names to our counterparties as our relationships with them become closer and more co-exposed.While the global name equilibrium may hold for many of our relationships, there may be plenty of areas where the privity benefits of localizing names outweigh the costs of being less or unable to differentiate newcomers from hostiles. For example, the preference-tracking service at www.firefly.com increases participation via the use of pseudonyms, thereby protecting customers from exposure to strangers who might abuse that information. On the other hand, credit transactions typically demand identifying information, because the contractual exposure typically outweighs benefits of privity.Global name public keys, which have many drawbacks in terms of privity, may be the best way to track negative reputation, but they are no panacea. There is an important conundrum in an ID-based key system: the conflict between the ability to get a new key when the old one is or could be abused by another (key revocation), and the ability of another to be sure they are dealing with the same person again. This may also provide an opportunity for parties to selectively reveal positive credentials and hide negative ones. For example, a person with a bad credit rating could revoke the key under which that rating is distributed and create a new one, while selectively updating their positive credentials to the new key (e.g., have their alma mater create a new diploma).The current universal (non-cryptographic) key in the U.S., the social security number (SSN), is very difficult to revoke; it's much easier to change your name. This policy is probably no accident, since the biggest economic win of global name identification is the tracking of negative reputations, which revocation can defeat. As long as the SSN is a shared database key, not used for the purpose of securely identifying a faceless transaction, there is little need for revocation beyond the undesired erasure of negative history. Combining a secret authentication key, which must be revocable, with a public universal ID is quite problematic.One of the basic outstanding problems in smart contracts is the ensurement of credit. This comes up not only in loans, but in any other contract which involves a temporal lag between performance and reciprocal performance of the contractual terms.In current practice, there are several partially effective processes for ensuring future performance:These processes have a fundamental property in common \u2013 they violate the privity of credit transactions \u2013 in other words, they bring in third parties to track reputations or enforce repayment. Do credit transactions entail a fundamental imbalance in incentives that can only be redressed by bringing in third parties, or can the security protocols be discovered which allow credit with minimal or no third party involvement?Three important variables have been proposed for reputation economics:In turn, Peter Swire[16] describes two problems facing inadequately secured or unsecured loans to \"credit names\":Adverse selection: Prior deadbeats can start fresh by signing up for the new service. Going in, it will be biased in favor of deadbeats. This problem may be addressed by using Chaumian credentials. These allow the established positive reputations of previous names to be carried over to the credit name, without allowing anyone to link the two names. Entrants without positive reputations can be rejected.The endgame problem: A credit name can establish a good credit rating over time. When the limit is high enough, the borrower can quickly spend it all. A malicious borrower, with a good rating established under a previous name, can systematically profit at the expense of the lender, if the throw-away value is greater than the replacement cost. To address this problem, creditors will have to charge higher rates to new credit names and raise credit limits more slowly than for traceable names. Honest borrowers will subsidize the dishonest, to an even greater extent than they do in the current credit card system.Secured credit need not violate privity if the physical control over the securing property can be shared. So that, for example, automobile credit can be secured as long as repossession is possible, as described in the example above.A standard mechanism of secured credit applicable online is the escrow. An escrow is an intermediary trusted to hold messages until messages from both sides are received, and, optionally, their contents verified - to extent the content is verifiable, and at the expense of some privity. The escrow then sends the messages off to their recipients, along with receipts. Messages can contain any sort of data: content, a bearer certificate, etc.Alice wants a New York City cab ride for which she's willing to pay $100, but she doesn't trust Bob the taxi driver to get her there on time if she pays up front. Bob in turn doesn't trust Alice to pay at the end of the trip. Commerce can be consummated by Alice tearing a $100 bill and giving half to Bob. After the trip she gives the other half to Bob, which he can then reassemble into a negotiable $100 bill. Alice loses her incentive to not pay. Bob gains incentive to get her there on time as promised. Both have made what economists call a \"credible commitment\" to perform their respective parts of the contract. Markus Jacobsson has digitized this idea, coming up with a protocol for ripped digital cash. As with many other aspects of digital cash, the idea can be further generalized to rip some other kinds of bearer instruments \u2013 specifically, those whose value can be divided roughly in half. If the transfer is double-blinded the transfer agent has no knowledge of the participants and therefore no bias to favor one over the other. The transfer agent must, however, be able to assess proof of performance, and the protocol is only workable where such proof (in the form of proof of receipt of a message, for example) is available.The ripped bill is similar to using the transfer agent as an escrow agent. An advantage over using an escrow agent is that the need for extra anonymous channels between the parties and the escrow is avoided. A disadvantage is that the transfer agent now has taken on the major additional job of acting as an adjudicator, assessing proofs of performance (or at the very least, must be responsible for subcontracting out this job and implementing the adjudicator's judgement).Credit cards provide relatively little protection from third parties, especially in the area of privacy, but they do have an interesting contractual feature worth noting, the chargeback. With chargebacks customers can get refunds on allegedly unwanted merchandise. The issuer tracks the number of chargebacks both for customers and merchants; too many chargebacks can get you booted out of the system. This provides an efficient mechanism for refunds without resorting to expensive tort proceedings. Many customers who read the fine print or otherwise learn about chargeback limits often do chargebacks despite receiving and enjoying the merchandise; there is no practical way for the issuer to detect such fraud, and so it can only be pruned by limiting the number of chargebacks per customer. Some merchants complain vociferously about such customer \"theft\", and it seems to make possible coordinated attacks to put merchants out of business, but nevertheless merchants sign up for credit cards, because that's what their customers have signed up for. The chargeback feature makes customers more comfortable purchasing goods of unknown quality, especially mail-order and over the Internet. Chargeback provides a crude but effective partial solution to the information asymmetry problem between retailers and consumers.\"Time release\" money that becomes good only after a certain date, and \"interval money\", that would expire after a certain date have been proposed. These can be implemented by a digital mint expiring or activating special issues of digital cash, or by a third party issuing escrowed keys at specific times. Since these keys are encrypted against the escrow agent, and that agent doesn't know what they will be used for, the escrow agent has no incentive to cheat. A generalization of this is that transfer and redeemability are each associated with interval sets, or validity periods when each can and cannot be performed. This is analogous to clipping coupons on bonds.Hal Finney[17] has described a loan mix, to unlink borrowers from amount borrowed. The identity of the potential borrowers is still public, as well as the system for enforcing payment, but the actual amount loaned or borrowed remains unknown. The system starts with participants putting unknown amounts into a pot and getting receipts (bearer bonds) for these amount. All participants then borrow a standard amount. Whether a participant is a net borrower or a net creditor, and of what amount, remains private. When the loan is due all participants repay the standard amount, and the creditors reclaim the amounts on their bearer bonds. The amount actually borrowed (or, if negative, loaned) is the public amount borrowed minus the amount put into the pot. One consequence is that while negative reputations can still be accumulated when participants fail to pay back the standard amount, positive reputations are minimal, since participants who borrow and loan are indistinguishable. If future creditors put stock in positive participation, one could gain a credit rating by perpetually participating as a net borrower of zero, by loaning and borrowing the same amounts.Smart contracts combine protocols, users interfaces, and promises expressed via those interfaces, to formalize and secure relationships over public networks. This gives us new ways to formalize the digital relationships which are far more functional than their inanimate paper-based ancestors. Smart contracts reduce mental and computational transaction costs, imposed by either principals, third parties, or their tools.Mark Miller[18] foresees that the law of the Internet, and the devices attached to it, will be provided by a grand merger of law and computer security. If so, smart contracts will be a major force behind this merger.A previous version of this paper appeared in the peer-reviewed journal First Monday, at http://www.firstmonday.dk/issues/issue2_9/szabo/index.htmlMany of the links above and references here rely on URLs that can be found in the online edition of this paper, at http://szabo.best.vwh.net/caymanpaper.html.The author has been refining these ideas since the early 1990's. A variety of earlier articles on this topic can be found at http://szabo.best.vwh.net \u21a9George H. Bodnar and William S. Hopwood, 1987.Accounting Information Systems. 3rd ed. Boston: Allyn and Bacon. \u21a9Phyllis K. Sokol, 1995. From EDI to Electronic Commerce: a business initiative. New York: McGraw-Hill. \u21a9Oliver Hart, 1989. \"Incomplete Contracts,\" In: John Eatwell, Murray Milgate, and Peter Newman (eds.), The New Palgrave: Allocation, Information, and Markets. New York: Norton.Bruce Schneier,1996. Applied Cryptography. 2nd ed. New York: Wiley. \u21a9John Bouvier, 1856. A Law Dictionary: Adapted to the Constitution and Laws of the United States of American and of the Several States of the American Union. Rev. 6th ed. \u21a9Michael Polanyi, Personal knowledge: Towards a post-critical philosophy. Chicago: University of Chicago Press.The economics of distributed knowledge is studied by the Austrian school; in particular see Friedrich Hayek, \"On the Use of Knowledge in Society.\"Vernon V. Palmer, 1992. The Paths to Privity: The History of Third-Party Beneficiary Contracts at English Law. San Francisco: Austin and Winfield.Lance Cotrell, 1995. \"Mixmaster & Remailer Attacks.\"Brad Cox, 1995. Superdistribution:: Objects as Property on the Electronic Frontier. Reading, Mass.: Addison-Wesley. \u21a9Ian Goldberg and David Wagner, 1997. \"Enabling Anonymous Publishing on the World Wide Web.\" \u21a9Olin Silbert, David Bernstein, and David Van Wie, 1996. \"Securing the Content, Not the Wire for Information Commerce.\" \u21a9Joseph M. Reagle Jr., 1996. \"Trust in Electronic Markets,\" First Monday, Volume 2, number 2 (August). \u21a9Robin Hanson, personal communication. \u21a9Peter Swire, 1997. \"The Uses and Limits of Financial Cryptography: A Law Professor's Perspective.\" \u21a9Hal Finney, 1997. \"Anonymous Credit\" posts. \u21a9Mark Miller, 1997. \"The Future of Law,\" paper delivered at the Extro 3 Conference (August 9). \u21a9Please send your comments to nszabo (at) law (dot) gwu (dot) edu"}
{"prompt": "A Formal Language for Analyzing Contracts", "completion": "The author presents a mini-language for professionals and researchers interested in drafting and analyzing contracts. It is intended for computers to read, too. The main purpose of this language is to specify, as unambiguously and completely and succinctly as possible, common contracts or contractual terms. These include financial contracts, liens and other kinds of security, transfer of ownership, performance of online services, and supply chain workflow.The following problems may be addressed by the language when interpreted by computer:The process of designing this language is also a great way to explore the basic nature of contracts (what are the \"elements\" out of which a wide variety of useful contracts can be drafted?) and their composibility (what rules for composing these atoms rule out impossible contracts?) The language is also a creative tool for thinking up and \"sketching\" new kinds of contracts. I welcome your participation.The words in our language follow legal terminology as much as possible \u2013 thus for example performance means execution to satisfy the terms of the contract (as in the legal field), rather than measured quantities like speed, memory usage, bandwidth, etc. (as programmers use the term). A law degree is not required to use the language, but some familiarity with contract law and the drafting of contracts is recommended. A lawyer who did reasonably well on the analytical and logical sections of the U.S. LSAT or its overseas equivalent, will, I suspect, have better luck drafting contracts in this language than than a programmer whose sole experience lies in traditional procedural language. That is why I call this a drafting language not a programming language.Our language can specify the output of a negotiation (which could be an auction, an exchange, or two parties drafting the contract, or one party drafting and the other agreeing to it, etc. ). It also can define the input to an engine that drives and monitors the transactions that perform the contract:Performance of the contract, i.e. its reification as a smart contract, can thus be seen as (hypothetical, at this point) execution of a program written in our language. Furthermore, our language incorporates a wide variety of contractual terms, not just abstract monetary terms and their derivatives. These two characteristics make our language very different from special purpose financial contract languages such as[4]. While we use several financial contract examples to introduce our language and demonstrate its flexibility, its scope both in functionality and the kinds of contracts and transaction protocols it can represent is far broader.Each word and phrase in our language has a clear standard meaning. As a result, contracts can be drafted that will be far less subject to disputes over interpretation. On the other hand, the language is not very good at expressing many subjective and ambiguous concepts that are often necessary in contracts. Nor is it any good, in its present state, in referring to jurisdictions or doctrines of law. The language is nevertheless very different from a traditional programming language. Contractual terms are defined in terms of events that trigger their performance. Such events include dates and times, choices made by the parties, observable breaches of contract, and so on.Our language is not a markup language. It is not about manipulating text for the purposes of drafting contracts. It is not about structuring text, specifying fill-out forms, defining static data formats, or similar tasks of languages such as HTML or XML. For those tasks one should use a markup language, or a text-manipulating programming language (e.g. Perl), not this language. Our language does something very different. It models the dynamics of contract performance \u2013 when and under what conditions obligations should be performed.The words and sentences of the language do not consist of instructions followed down the page from one step to the next. Instead, a contract is read (both by human and computer) by following nested definitions of contractual terms as they expand, and by looking at events in when statements and seeing what they trigger. If the drafter does need to explicitly construct a step by step calendar schedule, this can be done by using calendar-driven events or words like for and then.The language encourages composition of contracts. Contracts, rights, and obligations can be nested. We call these nested structures clauses. Contracts and clauses involve two parties, the Holder, from whose point of view we read the contract, and a Counterparty. Multi-party agreements can be drafted by composing several two-party contracts.Our first example is a well-known financial contract, the future. A future is an obligation on the part of the Holder of the futures contract to purchase a certain amount of a certain commodity in a certain month, and the obligation on the part of the future contract writer, the Counterparty, to deliver these goods. For the purposes of introducing this contract, we give it in the abstract form in which financial analysts usually deal with it, leaving out important details that describe the third parties who act as trusted intermediaries to define \"fair bundles\" of commodities, and we also leave out many details about the actual delivery.Since this language is not yet being computer interpreted, the syntax is designed more for human than computer readability. I will be a bit fast and loose with the syntax, and you can be too. I mostly use tabs instead of brackets {} to structure clauses in a way that seems natural and readable to me \u2013 and I hope to you \u2013 but might confuse a computer. Feel free to develop your own style.The top three lines in the contract, in the form name(parameters) = tells us that we are defining a named clause. The named clause can define an entire contract or just a clause in a larger contract. We can pass the names of other named clauses, lists of events, and other kinds of information that the named clause needs \u2013 these are the parameters.when withinPeriod(p) means \"when the first calendar or clock event generated during period p\". The drafter can elsewhere set how often this regular \"clock tick\" event occurs. The first such clock tick after the start of the period, in this case the first scheduled delivery day in the month of July, triggers the clause with the brackets {}. More sophisticated schedules are possible, such as those that minimize delivery costs for the Counterparty by delivering to different Holders on different days in July. Fortunately, we can hide these scheduling details within the calendar event and schedule iterator mechanisms, leaving the drafter free from worrying about exactly when markets are open, which days are weekends or holidays or leap days, and the like. The Counterparty's delivery schedule can be negotiated or this detail can be left up to the Counterparty. In the contract above, the constraints on delivery are that it occur within July and only in conjunction with payment from the Holder.The innermost clause says to swap rightA for rightB. This clause is split into a Holder right and a Counterparty right. The right clause Holder rightA means \"Holder has the right to performance of rightA\", in this case delivery of the pork bellies. The clause Counterparty rightB means \"Counterparty has the right to performance of rightB\", which here is the payment of 1,500 dollars. with indicates a simultaneous swap \u2013 the two transactions should occur together, perhaps intermediated by an escrow agent to enforce both the delivery and payment terms.A then statement allows us to proceed step by step. If we had two clauses written thus:They could be performed in any order \u2013 right2 might be performed first, or right1 might be, or (most likely) performance on both might proceed at the sime time. Several when statements nested together at the same level have any implicit also as they can be triggered in any order.Envision a dancing elf that follows nesting of clauses as they are performed and of events as they are caught. (Programmers call this dancing elf by the boring name \"instruction pointer\"). There can be more than one dancing elf if there is an also or if more than one when statement is triggered while another is active, but usually we only need to think about one at a time.If we wish to add the constraint that right2 cannot be performed until right1 has been, we use then:Traditional programmers will be sorely tempted to fill their contracts with then statements, mimicking the style of procedural programming. Do not! Those experienced with drafting contracts know that in some cases such a constraint is clearly appropriate and in some cases it clearly isn't, and it is important when adding constraints to be explicit. Therefore the following statement is illegal, and will be rejected both by the computer and by any right-thinking drafters working without a computer:Finally, we have already seen this kind of clause:This means that right1 and right2 should be performed simultaneously \u2013 and either both of them should be performed, or neither of them. In the lingo of computer scientists, it should be an \"atomic\" transaction.The then terminate at the end of the named clause ensures that all rights and obligations under the contract are terminated once it has been performed. It is not triggered until the one-line body of the future contract has been completed. as well as any outstanding subordinate clauses with their rights and obligations. This clause is implicit at the end of every named clause, but for this one time we make it explicit. This clause is often used explicitly when the drafter wants to ensure the proper termination of non-named clauses nested within a named clause.Let's now proceed through the futures contract step by step, as clauses are activated and then performed. A normal font indicates the clause is inactive. A bold font indicates an active state \u2013 the clauses is being performed.When the parties commit to the contract its first clauses (the clauses at the highest level of indentation) are awoken. In our futures contract we have only one such clause, and so the when (but not the clauses nested underneath it) go to in an active state, waiting for the withinPeriod() event:When the calendar has advanced to the end of trading on the last trading day of August, the withinPeriod(p) event occurs and the when activates the clauses nested at the next level inside. The when itself becomes inactive \u2013 it is no longer waiting for an event:The then has cause the terminate to wait for the when and its subclauses to be performed. Once the swap of rights has been performed, the performed clauses convert to inactivity and the terminate fires:It is easy to generalize in our language. The generic futures contract looks like this:Instead of pork bellies, we can swap any other rightA for rightB, which can be a wide variety of things beside money. Drafters can specify very general boilerplate and fill in details for specific contracts later.We now present another kind of financial contract. In this American option, the Holder has the right to buy for $20 (the option strike price) per share one round lot (100 shares) of XYZ Corp on or before the last trading day of August. These kinds of contracts are called \"derivatives\" because the call option is derived from the underlying right (here a stock).Think about that dancing elf again. (When reading or writing in our language it's important to follow these dancing elves. If the elves become annoying, think of some other dynamic character or process for a metaphor that suits). As it goes around it wakes up clauses, making them active, causing them to be performed. Sometimes there can be more than one elf dancing through the code at the same time, for example if more than one when statement is triggered while another is active, but usually we only need to think about one at a time.The contract starts out with dancing elves in the two top-level clauses:These when statements are now waiting for their respective events. Since the events are mutually exclusive (it is first beforeTime(time), then afterTime(time), but never both) we only need to worry about the first to be executed. Note that, unless separated by a then, the order of the clauses at the same level is not important. The following code is identical to the code in our example:The beforeTime(time) is immediately activiated, so that we start with the nested clause(s) at the level immediate below it active as well \u2013 in this case, when choiceOf(Holder).A series of whenes at the same level in that clause all start waiting for any of them to be triggered. When a when receives an event thrown below it or at it, the nested clause below it becomes active. Then the clauses below it become active and are performed down to the wheness one level below. The whenes at that level go from inactive to active, now waiting for their events to occur.The when beforeTime(time) becomes active when the option itself is first activated, and remains active until time. Being active it wakes up the when choiceOf(Holder). This when specifies the event that gives the contract its nature as an option -- the choice of its holder to exercise it or not. If the Holder chooses to do so, the Holder gets the stock (rightA) from the Counterparty (the writer of the call option) in exchange for the money (rightB). The dancing elves then move from the when clause to the swap clause:When code gets complicated, we might not be able to easily tell whether the implicit then terminate on the last line will get executed. So it's a good idea to terminate the contract explicitly when the option expires.We will see examples where more than one kind of event, and even sequences of events (such as a calender schedule of payment dates) trigger the execution of contractual terms.Remember that the language does not proceed by default step by step \u2013 instead the reader (human or computer) should follow down the nested contract definitions as they expand, and look at events in when statements to see what they trigger. Explicit step by step calendar schedules can be built using for, then, and calendar events.Here's an example that uses such explicit steps. A bond makes a sequence of fixed payments, called coupons, on a regular schedule, and then makes a final payment, the principal. We don't show here the details of the schedule itself, but in general a schedule could be defined to be any kind of temporal sequence \u2013 we could pay out coupons on the last day of every month, on every Japanese holiday, according to the computation of Easter (don't laugh \u2013 schedulers of medieval fairs had to face this problem), or however we choose. When implemented the calendar events and schedule iterator will contain a very thorough implementation that solves many of the nasty calendar problems that often appear in transaction processing systems.for iterates through the events in the schedule one by one, with the nested when handling them. When it appears after a for clause, a then advances the iterator one more step.Next we sketch a contract to sell a car on credit. Being a sketch rather than a full-fledged design, this is an oversimplified or \"toy\" example \u2013 we leave out fees, any references to a related insurance contract, warrantees, waivers, etc. We also for simplicity have the bank (here the Holder) be the same as the car dealer. Finally, we don't show here any lien on the car to secure the loan. We will make a stab at a lien-like mechanism in an example below.If we want to allow prepayment, our schedule would contain single times rather than periods with a begin time and an end time. And our loan payments would look as follows:We could compute the above payment from other information we are more likely to see in the contract, but this involves just normal programming. We can use a function to perform the computation in the first place:\"=\" sets, for all time (thus constant), the number payment.amount to the value returned by the function computeInterest. We could also do more complicated things \u2013 deduct interest for prepayment, or conversely add prepayment penalties, or a wide variety of other conditions.We can also structure the car purchase contract so that the new owner doesn't get the title until after the downPayment has been received:Let's use our language to analyze some important advances in the history of economic institutions. Genoa was an independent and rather libertarian (for its time) city heavily involved in the Mediterranean sea trade. During its height in the twelth through fifteenth centuries it developed many commercial innovations, including two we will examine here, the \"dry exchange\" loan and pooled-risk insurance.Here is a clause from a contract made in Genoa on June 23 in 1271 A.D. A man is co-signing an obligation being made by his son:Wherefore and for which we promise, both of us [liable] for the whole amount, to give and to pay to you or to your accredited messenger 53 gold hyperpers, good and of correct weight, in Romania [Byzantium], by the Kalends of September. If, however, we do not give you these [hyperpers] within the said time limit, [we promise] for each of the said hyperpers 11 shillings Genoese in Genoa whenever you wish. Otherwise we promise, both of us [liable] for the whole amount, to give to you, making the stipulation, the penalty of the double of the said amount, the aforesaid [conditions] remaining as settled. And we pledge to you as security for the aforesaid [promises] all our goods, existing and future...[5]Now, this is a very clever contract, called by scholars a \"dry exchange\". The Catholic Church forbad the charging of interest, so a loan contract that came right out and charged interest would be unenforceable and expose the drafters to further Church sanctions. But both long-distance exchange (making a trade at a distant market at a later date -- often via a sea voyage, thus a \"wet\" exchange) and currency exchange were quite legal, enforceable, and common. The above contract combined these two, along with damage clauses, in a clever way. None of the above parties had any intention of travelling to Byzantium, or even outside Genoa, to perform on this contract. Its logic can be analyzed as follows (the Holder is the creditor). We've added the statements \"in (geographic location)\", security, and foreclose to highlight important aspects of this contract. The latter sells enough of the goods at auction to satisfy penalty (if there was not enough to satisfy the creditors there was a bankruptcy procedure to fairly allocate the remain security among the creditors, but this is not shown):Neither party expected payment1 to be performed. The amounts of hyperpers and shillings probably reflected accurately the exchange rate between the two coins at the time \u2013 there's no sense being too obvious. But it would have been far too expensive to travel to Byzantium just to do this exchange. So in fact both parties expected payment2, a fake damage clause, to normally be performed. If it wasn't, then we have two real damage clauses \u2013 the somewhat reasonable \"penalty of the double\" and the lethal \"all our goods, existing and future\". Another interpretation of the latter clause is that it would only refer to a value of goods up to the double penalty amount, but the goods could be chosen from among all the goods of the debtor and the co-signer. Certainly a modern court would consider the interpretation I have placed on it in our language to be unconscionable, therefore unenforceable.Above the part we quoted, the contract does not specify how much the original loan amount was \u2013 the debtors simply acknowledge that they have received from the creditor \"a number of Genoese deniers\" and then promise other currencies in return as quoted above. So a Church investigator couldn't prove just from reading the contract that any interest was charged. As for the Genoese judge arbitrating a dispute, he would likely be in favor of loans at interest, and happy to wink and nod and interpret the contract literally.Modern derivatives traders do this all the time, creating synthetic assets or combinations that mimic the financial functionality of some other contract while avoiding its legal limitations. Our language is ideal for drafting and analyzing such contracts.The earliest risk-pooling insurance contracts were structured similarly to, and enforced under the same legal principals as, loans. Indeed, let's start with a simple loan for a purchase of goods with no interest where the Holder (the creditor) can call in the loan any time between days t1 and t2:Let's add to our language a safeArrival(goods) event \u2013 the event that a ship carrying goods arrives safely in port and that goods are offloaded and accounted for. Now by adding to this loan contract only one extra line, whening safeArrival(), and slightly modifying a few others we can transform it into a marine insurance contract. The insured is the Holder, the insurer is the Counterparty. For this simple version damages are paid in a fixed amount (principal) if safeArrival does not occur:Here's an example of an early insurance contract of this kind \u2013 again from Genoa, the birthplace of modern commercial institutions. For the first time we see a pool of insurers \u2013 not one but many counterparties, each pledging their entire property as security. Often these were feudal lords with large landholdings, so the value that could be brought to bear to back these insurance contracts was vast. This is how Lloyds Names still work today. Since several Names back a single contract (e.g. covering a single shipment of goods, as here), each Name puts only a tiny fraction of their estate at risk in that voyage. An insurance exchange like Lloyds allows the agents of goods owners, shippers, and Names to meet and mass-produce these kinds of contracts....Geri, [son] of the late Ser Lapo of Florence, Simone Guascone, [9 more Names listed], each of them [liable] for the amount written below, have acknowledged and in truth have declared to me, notary undersigned, as a public official [holding] a public office, making the stipulation and receiving in the name and stead of Federico Vivaldi, citizen of Genoa, that they have bought, have had, and have received from him a certain amount of goods of the said Frederico...And for these goods and in consideration of their price each of them has promised to give and to pay to said Frederico or to his accredited messenger: [from] the said Geri, 150 gold florins, the said Simone, 50 florins, [100 florins each from the other Names] within the next five months from now. Otherwise they have promised to give and to pay to the said Frederico the penalty of the double of it and of the entire amount to which and to the extent of which [this agreement] is violated or is not observed as above, together with restitution of all losses, unrealized profits, and expenses which might be incurred because of it in court or outside \u2013 the aforesaid remaining as settled, and under hypothecation and pledge of their goods and [the goods] of any one of them, existing and future.[The above is binding] with the exception and special reservation that if the amount of goods, property, and merchandise which was loaded or is to be loaded by Frederico Imperiale or by another in his behalf for the account of the said Frederico Vivaldi in Aigues-Mortes \u2013 to be transported to Ayassoluk and Rhodes or to either of these two localities in a certain ship...and which departed from Aigues-Mortes or is about to depart in order to sail to aforesaid regions \u2013 is brought and unloaded in the said localities of Ayasoluk and Rhodes or in either of them, in safety, then and in such a case the present intrument is cancelled, void, and of no value and pro rata. And be it understood that such a risk begins when the said ship departs and sets sail from Aigues-Mortes, and it remains and lasts, while the captain goes, stays [in port], sails, loads and unloads, from the said locality of Aigues-Mortres up to the said localities of Ayassoluk and Rhodes, in whatever manner and way he wishes, until said amount of goods, property, and merchandise has been brought and unloaded in Ayassoluk and Rhodes or in either of these two localities in safety, and pro rata. Let the present instrument also be cancelled if the said Frederico refrains from asking payments of the aforesaid amounts of money for the space of one year after the time or the time limit has elapsed for asking or obtaining their payment....Done as above, September 15th, around nones. [1393 A.D.][5]Ignoring the pro rata language, the specific definition of the risks that prevent generation or not of the safeArrival() event, and ignoring the multiple Names (i.e. treating them as one Counterparty), the contract can be modelled by the insurance contract we drafted above with its parameters filled in as follows, and with Frederico Vivaldi as the insured (the Holder):This contract was still, legally speaking, a loan. This had at least two interesting consequences on what we now call the insurance premium. Firstly, the premium was treated as goods purchases by the insurer on credit. Secondly, even at this late date, contracts were coy about the actual value of such goods. Leaving the value of those goods unspecified made usury difficult to prove in this \"loan\".Events in a when clause can be combined in logical conditions which must evaluate to true in order to trigger the subclause. This can be used to model conditional clauses in contracts, and, more broadly, procedural and substantive rules of law. When constructing rules we call the primitive events elements. For example, here is, roughly following the Restatement(Second) of Contracts, a legal rule for promissory estoppel:We include a gratuitous \"then\" here for readability. Computer programmers should note that we are following a shorthand here used by lawyers \u2013 we write the logical phrase (A and B and C and D) as (A B C and D). When mixing and and or, write out the complete logic, and use parentheses where appropriate.The rule elements, such as \"there is a promise\", exist in a superimposed state. By default, the logic is ignorant of the facts, and each element is genuinely at issue. As a result, \"there is a promise\" and the other elements of the above rule are both true and false, at the same time. (Those familiar with quantum mechanics or legal reasoning know what I'm talking about here). In the initial state, where every element is genuinely at issue, nontrivial rules will always evaluate to both true and false. Thus, both \"promise will be enforced\" and \"promise will not be enforced\" clauses will be triggered. When the clauses are incompatible, as these appear to be by their label, it is up to the implementor of the clause to deal with this properly. In this case, such a clause should only be treated as advisory until all material elements have been decided \u2013 i.e., they are no longer genuinely at issue, at which point the rule can be used to make a decision, i.e. trigger a single clause which takes a consistent action. A future version of this document will describe how to resolve elements genuinely at issue into elements not genuinely at issue, and thus decide on a single outcome or course of action. It will also describe how to deal with advisory clauses; for example, to analyze which elements are most favorable to one outcome or another. Finally, another future feature will include elements that cover a range of numerical values, rather than just true or false, and a formalized \"balancing test\" that determines outcomes based on underlying numerical estimates.Our rule language is ideal for specifying estates and future interests in real estate deeds. One can also apply these patterns to other kinds of property where appropriate. Here are some examples:Lease for Term: (n.b. \u2013 Grantor = self). This is an old common law lease that actually transfers title for a certain period of time.Life Estate with Reverter: (n.b. \u2013 Grantor = self)Assignable Reverter for Lease. To make future interests assignable, define them separately. Note to make the Grantor explicit. (As usual we are looking at things from the obligor's side):We can now redefine the Life Estate with Reverter in terms of the separately defined future interest:Life Estate with Remainder. The only difference here is that the property is remaindered to a third party instead of reverting to the grantor.Fee Simple Determinable. The Condition can be any verifiable event or change of state of the property or its title. A common real estate condition, for example, is \"used for commercial purposes\" \u2013 i.e., a restriction that the property may not be used for commercial purposes, otherwise the grantee is penalized by losing title to the grantor.Fee Simple Subject to Executory Limitation. Same as Fee Simple Determinable, except the property gets remaindered to a third party instead of revertin to the grantor.Fee Simple Subject to Condition Subsequent. Here title is not automatically transferred upon occurence of the condtion. Instead the Grantor must do some affirmative and verifiable act (in this example \"entering\" the property), to reclaim the title.In this section we will look at ways to construct multiparty agreements, distinguish ambient from thrown events, and examine a number of other more advanced features of or ways to use our language.We will complete the life cycle of the American option we drafted above by \"writing\" the option \u2013 creating it from an underlying security rightA and selling it for rightX. Here the Holder (same party as the Holder above, in this case the person who will buy the written option) first verifies that the Counterparty indeed holds the underlying security (rightA) with Broker. The Broker is trusted by the Holder to make sure Counterparty continues to hold the security until the option is exercised or expired. The contract between the Broker and Holder is escrowRight().)Since Counterparty, the option writer, is not paying anything up front for an option on rightB, this right does not need to be escrowed.We now redraft the option itself to take advantage of the escrow. rightA is transferred to Holder by the throw upon excercise, or back to Counterparty if the option expires.We can think of events as coming in two kinds. The first, ambient events, occur spontaneously in the environment, or are generated by an entity external to our specification such as a user or a schedule. The second, thrown events, are events we explicitly throw as above.In this manual I have expressed contract clauses in terms of rights. Often contract language is expressed in terms of obligations, which can be done as a mirror image \u2013 to Holder right is the same as from Counterparty obligation and vice versa. Use from to distinguish an obligation.Further showing the flexibility of our language we can add sensors and effectors, adding \"smarts\" to our contracts and augmenting legal enforcement with technological constraints.First we draft a specification for the contract-like bevavior of a vending machine:We have here introduced a new language feature, a state variable. Our state variable moneyAmount generates an event upon surpassing the candy price threshold of $0.90. Note that nickels, dimes, etc. are actual physical objects that the sensors (generating events \"nickel\", \"dime\", etc.) detect and treat separately \u2013 they are not merely abstract amounts of money.State variables can be troublesome, and should be avoided unless utterly necessary as here. This one is relatively harmless because the coin slot tends to force the coins to come in one at a time, so that no two clauses are trying to change the state variable at the same time. Even if they were, the addition operation is what mathematicians call \"commutative\", meaning it doesn't matter what order it's done in. But if the operation on the state variable were more complicated or involved certain other kinds of operations, we wouldn't know whether it was commutative. The order in which events occured and changed the state variable might matter very much, and we could get into big trouble. So avoid state variables whenever possible.To simplify things, we've left out making change \u2013 our machine has to have one of those signs you sometimes see, \"exact change only\". If the customer puts in a coin that pushes the amount from, say, $.80 to $1.05 \u2013 too bad, the machine eats it. If the customer puts in $0.90 (or more) and then adds more coins, however, the machine automatically returns the extra coins. The machine will also return whatever has been put in the till, if the customer changes her mind and decides not to buy the candy. Exercise for the reader: verify for yourself that the above behavior descriptions are correct as the code is written.RedirectNewCoinsTo(returnTill) causes any further coins to drop into the return chute instead of onto the sensor that triggers the above events. The reader must here imagine what the mechanism looks like, as part of the behavior is \"encoded\" in its mechaninism rather than explitly in this statement.Think of the nested contracts and rights as an upside-down tree \u2013 a hierarchy of nested clauses. Events propagate from up from the \"leaves\" of the tree towards the \"root\" at the top. They are caught by the first when event they encounter for that event. In this case, once we enter the when threshold() clause, the when (nickel | dime | quarter) clause overrides the when(nickel) and so on clauses above them.Like a perpetuity, our vending machine has no scheduled time or condition where it stops performing \u2013 therefore we have a continue statement to overrid the implicit then terminate on the last line.Alas, neither I nor real world candy machine makers have any code to solve the case where the candy gets stuck in the machine.The above is a transcription of machine behavior. Now we make it even more like a contract. Here we incorporate the customer and his choices, which implicitly generated the coin events in the code above \u2013 here the coins are rights of the Holder. Thinking more about the party, rather than the machine, allows us to recognize that at each step the customer wants feedback on how much money they have put in, thus to Counterparty display(moneyAmount). This display is done by the Holder (the vending machine as an agent of the vendor) as a right of the Counterparty (the customer). To enable better customer choice, we add a new construct to our language: choiceOf(agent, right) which allows the customer multiple choice, based on which right they wish to transfer to the agent's counterparty (here the vending machine, the Holder).How is it that we have specified the behavior of a vending machine in a language designed for drafting contracts? Can nickels, dimes, quarters, and operations like dropping coins from one till to another be thought of as rights and obligations? I think so. They are not legal rights and obligations, to be sure. There is no explicit contract between the vendor and candy machine customers, and if their were it would probably waive liability for violating most of the clauses in our code. What this code describes is the logical and typical behavior of a vending machine. It also reifies the implicit understanding most customers have when using a vending machine. Thus it models a contract-like \"meeting of the minds\" between the customer and the vendor that is mediated by the machine.Here is a stab at formally describing the hypothetical \"auto repo auto\". The car is controlled by a proplet and the proplet looks to property titles to determine ownership authority. The proplet lets only the titled owner enter and drive the car. \"Holder\" is the bank that made the loan and \"Counterparty\" is the new owner. As above we ignore the car dealer; the bank originally owning the car. This example highlights the ability of the language to very succinctly describe contracts but also its inability to describe the actual security that will enforce the contract. There is of course a lot missing here, including the items missing from the above car loan contract. From a smart contracts viewpoint, the biggest thing missing is that there is nothing to motivate the \"Holder getTitle(car)\" in the last when, nor any way specified here to enforce it. And of course all connection between ownership and authority to enter, start, and drive the car is here implicit \u2013 the actual proplet behavior in this regard would have to account for safety, emergency use, etc.For all that work-up, we've only actually added one clause to our car purchase contract above. The clause forfeits the title and is structured much like the damage clauses we have seen. A breachedPerformance() event is generated if it is detected (by the Holder, a third party auditor, or the proplet itself) that the Countparty failed to make a payment according to the schedule specified by loan.Here is a formal specification of the language's grammar in \"Backus-Naur Form\"(BNF). The specification is for a planned computer-readable version of the language and there are a few minor differences, such as the use of brackets {} instead of tabs to denote nesting. BNF is used to define what linguists call \"context-free grammars\". It is also used, as here, to define the syntax of languages that computers can also interpret and execute. I also include some more discussion of the meanings of the words and structures, especially how the computer might interpret them. As you can see, this is an evolving language, a work in progress with many unresolved issues. Your suggestions for changing or adding more kinds of contractual terms to our language are quite welcome.Q: There are already languages for specifying financial contracts[3], what is the novelty here?A: This the first specification language to generalize contractual structures to any kind of exclusive rights, not just money. This is also the first language that incorporates the dynamic nature of many contracts, (their dependence on time or events) in a succinct, complete, and potentially executable manner. Surprisingly, this often makes the specification more not less succinct.Where's the money?A: This language is targeted toward an economy of distributed software and devices performing services for each other. A money economy can be constructed out of a barter economy but not vice versa. Real online money is far more subtle than a mere shared variable (or even the specification of \"bank notes\" in this language). Money is just one kind of fungible exclusive right, and the structure of financial contracts are generalized by converting money terms into any fungible exclusive right.Q: What assumptions are you making?A: This is the most important question to ask of any novel scheme! I have identified at least the following:Q: What are some problems with this language you'd like to see solved?A: Implementations that satisfy the above assumptions for the particular language atoms, and also for compositions of the atoms. (Of course, various protocols in the \"financial cryptography\" field, in my own proposals, in the E language, etc. provide many valuable building blocks for such solutions).There are many instances of deals gone sour at the last minute when the salesfolk check with legal and discover that the deal is not possible due to a clause in another contract \u2013 for example a promise not to sell to a customer's competitors in an industry for a certain period of time. Worse, such a conflict might not be discovered until the contraditory commitment has been made. \u21a9The E programming language \u21a9Proceedings of the Financial Cryptography Conferences, Springer-Verlag \u21a9Composing contracts: an adventure in financial engineering \u2013 A different kind of language for specifying financial contracts in order to compute their risk and value. \u21a9Lopez and Raymond, Medieval Trade in the Mediterranean World: Illustrative Documents, Columbia University Press 2001. \u21a9 \u21a9Please send your comments to nszabo (at) law (dot) gwu (dot) eduCopyright \u00a9 2002 by Nick Szabo\nPreliminary draft -- Redistribution only with written permission of author.Editor's note: Some links may be broken."}
{"prompt": "Secure Property Titles with Owner Authority", "completion": "The advent of writing greatly improved the tracking of property rights, and indeed gave rise to our modern systems of property rights and law. However, written records have proven to be quite vulnerable to abuse. A common pattern during eras of political instability or oppression has been the confiscation of land via the forgery or destruction of public records. Reconstruction from informal records, such as residency recorded in phone books, even when possible is costly and fraught with error and potential for fraud[1]. Large amounts of, in some areas most, property in developing countries is not formally titled[2]. Even during eras of political stability in developed countries, there occur many expensive problems with titles.[3] Straightforward transcription of written records into a centralized online repository would make many of these problems even worse \u2013 electronic records can be highly vulnerable to loss and forgery, and insiders are the most common source of such attacks. This paper proposes a secure, distributed title database to prevent such attacks against property rights in the future.Many kinds of Internet resources have a basic characteristic: users must agree on their control across trust boundaries. A big example is names. The article \"Names: Decentralized, Secure, Human-Meaningful: Choose Two\" dismisses not only the ubiquity and importance of this problem, but also the possibility of solution.[4] Instead petnames are proposed. These are at best mere mnemonics to translate human-readable into cryptographic names; petnames don't do anything to secure naming across trust boundaries. All three attributes \u2013 decentralized, secure, and human-meaningful \u2013 must be provided if people are to communicate and be communicated about securely over the Internet, and this paper along with the article Advances in Distributed Security shows how to provide all three.More generally, we show how to implement transferable global rights, enforced entirely by protocol, to names, attributions, bit gold, and similar purely informatic property owned by a particular entity but possessed and relied upon by the public, and how to implement a secure title database for other kinds of property. For a particular example of cross-trust-boundary rights enforced entirely by protocol, see my proposal for name integrity in cross-trust-boundary file systems.In all cases of property rights there is a defined space, whether a namespace or physical space, and the task is to agree on simple attributes of or rights to control subdivisions of that space. In some cases a name or other symbol corresponds to a person or object owned or controlled by that person. For example, Internet users must agree on which domain name corresponds to which web site operator. In other cases we are simply concerned with control over a subdivision of the space. With real estate we must agree on who owns various rights (to occupy the surface, to mine the minerals under, etc.) to a piece of land. With radio spectrum we must agree on who owns what range of frequencies and in what physical space (or transmitting power as an easily observed approximation of physical space used).It is the author's hypothesis that all such agreements of control, including control over the semantics of symbols, to be made and respected across trust boundaries are problems of agreeing on and maintaining property rights. Thus the results of this paper are far more general than they might first appear \u2013 I believe this paper provides a solution to secure namespaces and similar problems as well as the problem of securely recording agreements on traditional property rights. Highlighting the property rights nature of public directories also highlights the limitations of these mappings \u2013 for example that names, addresses, and other symbols whose semantics are controlled by a person can often be delegated, just as property can be given or rented.New advances in replicated database technology will give us the ability to securely maintain and transfer ownership for a wide variety of kinds of property, including not only land but chattels, securities, names, and addresses. This technology will give us public records which can \"survive a nuclear war\", along the lines of the original design goal of the Internet. While thugs can still take physical property by force, the continued existence of correct ownership records will remain a thorn in the side of usurping claimants.I use political words in this essay as metaphors to describe how our hypothetical property title software, and especially its protocol for distributing the title database across a public network, could work. A group, called a property club, gets together on the Internet[5] and decides to keep track of the ownership of some kind of property. The property is represented by titles: names referring to the property, and the public key corresponding to a private key held by its current owner, signed by the previous owner, along with a chain of previous such titles. Title names may \"completely\" describe the property, for example allocations in a namspace. (Of course, names always refer to something, the semantics, so such a description is not really complete). Or the title names might simply be labels referring to the property. Various descriptions and rules \u2013 maps, deeds, and so on \u2013 may be included.The property club can be thought of as a \"microgovernment\", an entity that performs globally and independently one narrow function normally associated with government. In particular it is a \"constitutional microdemocracy\" with low entry and exit costs. After the rules of property transfer have been decided, each vote should stay within this constitution \u2013 so that normally the vote will simply implement a distributed operation according to the property rules. The voting is necessary not due to a democratic political ideology but because it is the optimal result in analysis of distributed databases with malicious attackers.[6] If the rules are violated by the winning voters, the correct losers can exit the group and reform a new group, inheriting the old titles. Users of the titles (relying parties) who wish to maintain correct titles can securely verify for themselves which splinter group has correctly followed the rules and switch to the correct group. If the rules are violated by losing voters, they can be excluded from further participation both by correct winners and rule-following relying parties.This voting-or-reformation method works well where exit costs are low. Thus in practice users should not \"put all their eggs in one basket\", but different title clubs should be used for different kinds of property. Note that the key security feature of the club is not the voting, but a set of objective, often automated, rules and an unforgeable audit trail that allows both club members and relying parties to check whether each vote followed the rules. So, to go further with the political metaphor, a property club is a \"constitutional microdemocracy\" with most of the emphasis on the \"constitutional\". The voting is necessary, but is quite regulated.To implement a property club, we set up a replicated database so that the club members, hereafter \"servers\", can securely maintain titles of ownership, and securely transfer them upon the request of current owners. Actually getting end users to respect the property rights agreed upon by this system will be dependent on the specific nature of the property, and is beyond the scope of the current inquiry. The purpose of the replicated database is simply to securely agree on who owns what. The entire database is public.The ideal title database would have the following properties:We cannot achieve ideals (1) and (3), so we introduce \"voting\" as follows. A good model of secure replicated databases is the \"Byzantine Quorum System\" of Malkhi & Reiter[6]. In contrast to most recent work in peer-to-peer software, our design is based on mathematical proofs of security rather than hand-waving. For a short discussion of such threshold-of-servers approaches, see my essay \"Coalition Design for Secure Protocols\". The database is replicated across a universe of servers U, |U|=n. The \"quorum system\" is a collection of subsets (quora) of these servers, each pair of which intersect. Each quorum can operate on behalf of the system; intersection guarantees that operations done on distinct quora preserve consistency. A quorum system tolerant of Byzantine (unconditionally malicious) server failures is a collection of subsets of servers, each pair of which intersect in a set containing sufficiently many correct servers to guarantee the consistency of the replicated data. The authors construct a protocol such that any intersection contains at least 2f+1 servers, thus providing resilience against up to f malicious servers, n > 4f.Using these results it looks like we can approach our ideal title database as follows:Sharing control over property, for example as security for a loan, could be accomplished by sharing the private key corresponding to the current owner's public key. Possession of this private key is required to sign over title; multiparty threshold signatures could also be handled. So it may be a good idea to use one keypair for each combination of title and current owner, rather than keypairs representing the identities of owners. When certain contractual conditions are met, such as the last payment on a loan, this could trigger the generation of a new keypair held solely by the owner, and transfer of title from the shared keypair to the new keypair.The initial allocations might occur by mapping existing property rights from their current institutional incarnation, or by using traditional methods of staking and negotiating mutual recognition of claims. Some methods less dependent on an existing legal regime for the rights will be discussed in this section.For some kinds of allocation, such as spatial regions or a hierarchical namespace, we wish to be able to subdivided and re-merge properties. Current owner Alice should be able to transfer various fractional portions of her title to multiple single relying counterparties. One possibility is to have \"divide\" or \"merge\" messages whereby the current owner of a property can retire the old property specifications(s) and link them to new property spec(s), the whole message being signed by the owner. Then the new property spec(s) are introduced and considered active, and the old ones considered deactivated. It would be the responsibility subsequent transferees to ensure that the new specifications do not intersect, and are otherwise in good order.One way to approach the homesteading, or initial allocation, problem, I call the \"emergent respect\" style: Alice claims the entire unallocated universe. Bob also claims it, the same property spec under a different digital signature. They then may choose to subdivide, sell, give away, etc. property. Each conflicting root grows like a tree into an allocation of all property.How to resolve trees with conflicting roots? Eventually, the thugs, mechanisms, or informal agreements which enforce property rights converge on a particular tree as the standard, proper allocation. Roots who give away more property to more people, or who actually deploy mechanisms to protect their property, will gain more respect for the tree they started.In a namespace, conflicts may be resolved by giving names to the conflicting roots, and keeping track of those name-subtree mappings as property.Usurpers may be able to steal property by setting up their own root and enforcing it, but they can't delete the alternative allocations. The history is always there as evidence for claims.Those with no firsthand knowledge of conflicting claims may resolve them by consulting authorities, and weighing the opinions of these authorities according to trust metrics, similar to trust metrics sometimes used for public key certificates.With secure timestamps, homesteading could be done on a first-come rather than emergent respect basis.For some kinds of property we might want to add the right of adverse possession, or formalized squatting. Here's one general way to implement a kind of adverse possession:This method doesn't attempt to define or utilize a state of \"disuse\". Instead it equates activity of the property with the ongoing active online presence of an owner who knows about the title and wishes to continue ownership. Cost of maintaining the title might be made high by requiring a periodic registry fee from owners. However, this introduces the problem of who obtains the benefit, by property club rules, of the profits from this fee, and the problem of that the fee lowers the profit of owning the property, even perhaps making it negative. One possibility, where costs of protecting the property are high, is to charge a \"Georgian tax\" based on some imprecise but objective estimate of the value potential of the property, and allocate the fees to the task of securing the property. To come up with this estimate, or to account for usage of the property itself, would involve mechanisms or observation of characteristics specific to the kind of property, to which subject we now turn.Largely unaddressed above is the problem of divergence between actual conditions and directory rights. For example, squatters might legitimately, in the eyes of most property rights enforcers, occupy and improve unused land which a title registry indicates is owned by others. De Soto[2] describes squatters and emergent property rights on the American frontier and today's developing world. When names are property, a name may violate a pre-existing trademark, causing the confusion that both the new namespace and the old trademark namespace were designed to solve.When divergence becomes too great, a solution to address the unreality of the title registry is needed. One such solution is for the squatters to set up their own rival registry, and then prove the superior correspondence of their registry to actual reality over control and use of the resources. Another solution for squatters is to use the adverse possession mechanism described above \u2013 but this works only if the cost of maintaining the title is sufficiently high.Another solution is to examine the incentives of the titled owner, to see if they correspond to truthfully claiming control over a resource. In most cases there may be incentive to lie, and we can't use this method. In some cases there is incentive to tell the truth and we can, with caveats, rely on it. Any such incentive assumption in the property rules should be explicated, so that relying parties can examine whether the conditions creating the incentive still hold.Another solution is for property club rules and the registry to originally incorporate rich information about the actual state of property, and modify the actual ownership and transfer on this property based on that state, in a way that leaves few ambiguities so it can be fully audited by club members and third parties. It is most advantageous when this auditing can remain automated, as envisioned above. However the introduction as rule criteria of unrecorded (or unsecurely recorded) transient states common in physical property causes auditing, and thus the titles, to become both less secure and more expensive.My thanks to Gregory Burch, J.D., Eileen O'Connor, J.D., Melora Svoboda, and many others for their helpful comments.Kelly McCollum, \"Using Phone Books, Scholars Build a Data Base for Resettling Kosovars\" \u21a9Hernando de Soto, The Mystery of Capital \u21a9 \u21a9Reasons to buy title insurance \u21a9Bryce \"Zooko\" Wilcox, Names: Decentralized, Secure, Human-Meaningful: Choose Two \u21a9Property on the Internet may take all kinds of new forms. For analysis one recently emerged form, the ownership of open source software projects, see Eric Raymond, \"Homesteading the Noosphere\". \u21a9Malkhi & Reiter, \"Byzantine Quorum Systems\", STOC97 \u21a9 \u21a9Please send your comments to nszabo (at) law (dot) gwu (dot) eduCopyright \u00a9 1998,1999,2002,2005 by Nick Szabo\nPermission to redistribute without alteration hereby granted"}
{"prompt": "Trusted Third Parties are Security Holes", "completion": "Commercial security is a matter of solving the practical problems of business relationships such as privacy, integrity, protecting property, or detecting breach of contract. A security hole is any weakness that increases the risk of violating these goals. In this real world view of security, a problem does not dissapear because a designer assumes it away. The invocation or assumption in a security protocol design of a \"trusted third party\" (TTP) or a \"trusted computing base\" (TCB) controlled by a third party constitutes the introduction of a security hole into that design. The security hole will then need to be plugged by other means.If the risks and costs of TTP institutional alternatives were not accounted for in the protocol design, the resulting protocol will in most cases be too costly or risky to be practical. If the protocol beats these odds and proves practical, it will only succeed after extensive effort has gone into plugging the TTP security hole(s). TTP assumptions cause most of the costs and risks in a security protocol, and plugging TTP security holes produces the most benefit and profit.As a result, we propose a security protocol design methodology whereby the most risky and expensive part(s) of a security protocol, the trusted third partie(s), are designed in parallel with security protocol(s) using those parties. The objectives of cost and risk minimization are focused on the TTPs rather than the security protocols themselves, which should be designed to suit the cost and risk minimized TTPs.We also briefly discuss and reference research and implementation in security mechanisms that radically reduce trusted third party costs and risks by distributing automated TTPs across several parties, only a portion of which need to act in a reliable or trustworthy matter for the protocol to be reliable or trustworthy.This author has professional experience implementing a TTP that was assumed by early advocates of public key cryptography. This TTP has come to be called a \"certificate authority\" (CA). It has been given the responsibility of vouching for the \"identity\" of participants. (Here I focus on the costs imposed by the TTP; alternatives such as PGP's Web of Trust and SPKI have been discussed amply elsewhere).The certificate authority has proved to be by far the most expensive component of this centralized public key infrastructure (PKI). This is exacerbated when the necessity for a TTP deemed by protocol designers is translated, in PKI standards such as SSL and S/MIME, into a requirement for a TTP. A TTP that must be trusted by all users of a protocol becomes an arbiter of who may and may not use the protocol. So that, for example, to run a secure SSL web server, or to participate in S/MIME, one must obtain a certifcate from a mutually trusted certificate authority. The earliest and most popular of these has been Verisign. It has been able to charge several hundred dollars for end user certificates \u2013 far outstripping the few dollars charged (implicitly in the cost of end user software) for the security protocol code itself. The bureaucratic process of applying for and renewing certificates takes up far more time than configuring the SSL options, and the CA's identification process is subject to far greater exposure than the SSL protocol itself. Verisign amassed a stock market valuation in the 10's of billions of U.S. dollars (even before it went into another TTP business, the Internet Domain Name System(DNS) by acquiring Network Solutions). How? By coming up with a solution \u2013 any solution, almost, as its security is quite crude and costly compared to the cryptographic components of a PKI \u2013 to the seemingly innocuous assumption of a \"trusted third party\" made by the designers of public key protocols for e-mail and the Web.Some more problems with CAs are dealt with here.The Internet DNS is another example of the high costs and risks imposed by a TTP. This one tiny part of the TCP/IP protocol stack has accounted for a majority of the disputes and handwringing involving that protocol. Why? Because it is one of the few areas of the TCP/IP stack that depends on a centralized hieararchy of TTPs rather than on protocol negotiations between individual Internet nodes. The DNS is also the single component of the Internet most likely to fail even when its names are not being disputed or spoofed.The high costs of implementing a TTP come about mainly because traditional security solutions, which must be invoked where the protocol itself leaves off, involve high personnel costs. For more information on the necessity and security benefits of these traditional security solutions, especially personnel controls, when implementing TTP organizations, see this author's essay on group controls. The risks and costs borne by protocol users also come to be dominated by the unreliability of the TTP \u2013 the DNS and certificate authorities being two quite commom sources of unreliability and frustration with the Internet and PKIs respectively.Companies like Visa, Dun and Bradstreet, Underwriter's Laboratories, and so forth connect untrusting strangers into a common trust network. Our economy depends on them. Many developing countries lack these trust hubs and would benefit greatly from integrating with developed world hubs like these. While these organizations often have many flaws and weaknesses \u2013 credit card companies, for example, have growing problems with fraud, identity theft, and innacurate reports, and Barings recently went belly up because their control systems had not properly adapted to digital securities trading \u2013 by and large these institutions will be with us for a long time.This doesn't help us get TTPs for new protocols. These institutions have a particular way of doing business that is highly evolved and specialized. They usually cannot \"hill climb\" to a substantially different way of doing business. Substantial innovations in new areas, e.g. e-commerce and digital security, must come from elsewhere. Any new protocol design, especially paradigmatically different areas such as capabilities or cryptographic computations, will be a mismatch to the existing institutions. Since building new TTPs from scratch is so costly, it is far cheaper when introducing protocols from these institutionally novel security technologies to minimize their dependencies on TTPs.Many are the reasons why organizations may come to favor costly TTP based security over more efficient and effective security that minimizes the use of TTPs:Limitations of imagination, effort, knowledge, or time amongst protocol designers \u2013 it is far easier to design security protocols that rely on TTPs than those that do not (i.e. to fob off the problem rather than solve it). Naturally design costs are an important factor limiting progress towards minimizing TTPs in security protocols. A bigger factor is lack of awareness of the importance of the problem among many security architects, especially the corporate architects who draft Internet and wireless security standards.The temptation to claim the \"high ground\" as a TTP of choice are great. The ambition to become the next Visa or Verisign is a power trip that's hard to refuse. The barriers to actually building a successful TTP business are, however, often severe \u2013 the startup costs are substantial, ongoing costs remain high, liability risks are great, and unless there is a substantial \"first mover\" advantage barriers to entry for competitors are few. Still, if nobody solves the TTP problems in the protocol this can be a lucrative business, and it's easy to envy big winners like Verisign rather than remembering all the now obscure companies that tried but lost. It's also easy to imagine oneself as the successful TTP, and come to advocate the security protocol that requires the TTP, rather than trying harder to actually solve the security problem.Entrenched interests. Large numbers of articulate professionals make their living using the skills necessary in TTP organizations. For example, the legions of auditors and lawyers who create and operate traditional control structures and legal protections. They naturally favor security models that assume they must step in and implement the real security. In new areas like e-commerce they favor new business models based on TTPs (e.g. Application Service Providers) rather than taking the time to learn new practices that may threaten their old skills.Mental transaction costs. Trust, like taste, is a subjective judgment. Making such judgement requires mental effort. A third party with a good reputation, and that is actually trustworthy, can save its customers from having to do so much research or bear other costs associated with making these judgments. However, entities that claim to be trusted but end up not being trustworthy impose costs not only of a direct nature, when they breach the trust, but increase the general cost of trying to choose between trustworthy and treacherous trusted third parties.For most of human history the dominant form of property has been personal property. The functionality of personal property has not under normal conditions ever depended on trusted third parties. Security properties of simple goods could be verified at sale or first use, and there was no need for continued interaction with the manufacturer or other third parties (other than on occasion repair personel after exceptional use and on a voluntary and temporary basis). Property rights for many kinds of chattel (portable property) were only minimally dependent on third parties \u2013 the only problem where TTPs were neededwas to defend against the depredations of other third parties. The main security property of personal chattel was often not other TTPs as protectors but rather its portability and intimacy.Here are some examples of the ubiquity of personal property in which there was a reality or at least a strong desire on the part of owners to be free of dependence on TTPs for functionality or security:This desire is instinctive and remains today. It manifests in consumer resistance when they discover unexpected dependence on and vulnerability to third parties in the devices they use. Suggestions that the functionality of personal property be dependent on third parties, even agreed to ones under strict conditions such as creditors until a chattel loan is paid off (a smart lien) are met with strong resistance. Making personal property functionality dependent on trusted third parties (i.e. trusted rather than forced by the protocol to keep to the agreement governing the security protocol and property) is in most cases quite unacceptable.We now propose a security protocol design methodology whereby protocol(s) are designed to minimize these costs and risks of the TTPs. Minimizing the costs and risks of the security protocol(s) themselves is an important but secondary priority.Currently, security designers usually invoke or assume TTPs to suit the most elegant and secure or least computationally costly security protocol. These naive TTPs are then used in a proof of concept of an overall protocol architecture. But this does not discover the important things that need to be discovered. Once a security protocol is implemented the code itself costs very little, and exponential cost functions such as Moore's law keep reducing computational, bandwidth, and many other technological costs. The costs of the security protocol itself (except for the costs of message rounds, limited by the speed of light, and the costs of the user interface, limited by mental transaction costs) approach zero. By far the largest long-term cost of the system (as we learned with PKI) is the cost of implementing the TTPs.It's far more fruitful to estimate from the beginning what the TTPs will cost, rather than try to design the security protocols to minimize the costs of the TTPs. This will likely bring the designer to quite different trust assumptions and thus security protocols than if (s)he assumes pure, unanalyzed TTPs in certain places in order to simplify the security protocol. A natural corrolary is if that there exists a security protocol that can eliminate or greatly reduce the costs of a TTP, then it pays greatly to implement it rather than one which assumes a costly TTP. Even if the latter security protocol is simpler and much more computationally efficient.A corollary of \"trusted third parties are security holes\" is \"all security protocols have security holes\", since no protocol is fully free of such assumptions. The key steps in estimating TTP costs and risk are to (1) examine one's assumptions thoroughly to uncover all TTP assumptions and characterize specifically what each TTP is and is not expected to do, (2) observe that each such specific hole and task has an associated cost and risk.There are several other important considerations, including:If for a new context like e-commerce we can find a security protocol which replaces a TTP organization (a complex set of traditions quite unproven in the new context) with mathematics (which at least in itself is quite clear and provable) it will often be a very big win to do so. More often we will replace a complex costly TTP with one or more much simpler TTPs plus mathematics. That too is a big win. We can only tell if and by how much it is a win by focusing on the trust assumptions and the resulting costs of the TTPs rather than focusing on the efficiency of the security protocol. The key is to focus on the cost of the TTPs and design the security protocol to minimize them, rather than assuming TTPs in order to simplify or optimize the efficiency of the security protocol.A good digital security protocol designer is not only an expert in computer science and cryptography, but also very knowledgeable about the traditional costly techniques of physical security, auditing, law, and the business relationships to be secured. This knowledge is not used to substitute these costly security methods for more cost effective digital security, but in order to minimize hidden dependence on costly methods for the real security. A good protocol designer also designs, rather than merely assumes, TTPs that work with minimal use of costly techniques.We saw above that the keys to minimizing TTPs are to identify them, characterize them, estimate their costs and risks, and then design protocols around TTPs of minimal cost and risk. When the risk is mitigated with techniques like those in this session, it can be very substantially reduced.Three areas of research and implementation show special promise in improving trust. Two of these involve the particularly thorny area of privacy, where breach of trust is often irreversible \u2013 once data gets out it can be impossible to put back.The first protocol family in which trust can be distributed to preserve privacy is the Chaum mixes. Mixes allow communications immune from third party tracing. Only any one out of N proxies in a proxy chain need be trustworthy for the privacy to be preserved. Unfortunately, all N of the proxies need to be reliable or the message will be lost and must be resent. The digital mix protocol's tradeoff is to increase messaging delays (resends) in order to minimizes the risk of irreversible privacy loss.Another protocol family in which trust can be distributed to preserve privacy is the multiparty private computations. Here a virtual computer is distributed across the N parties who provide specially encrypted input to each other rather than to a trusted third party. The distributed computer takes inputs from each of the N parties, computes an agreed to algorithm, then outputs the answer. Each party learns only the answer not the inputs of any other party. The threshold of parties that that must collude to violate privacy or threaten reliability can be traded off and have been studied in detail in the ample literature on this topic. Multiparty private computations can be used for confidential auditing, confidential preference gathering and data mining, auctions and exchanges with confidential bids, and so on.A protocol family that replicates data, and distributes operations on that data, while preserving the integrity of that data, are the Byzantine resilient replicated databases. Implementations of Byzantine resilient replicated databases include Fleet and Phalanx. Fleet implements replicated persistence of general purpose objects. Some open source implementations, which approach but do not achieve Byzantine resilience, general purpose, or complete decentralization include Mojo Nation and Freenet. Applications include secure name registries and property titles as well as securely published content in Mojo Nation and Freenet. The most advace work in this area involves Byzantine fault tolerant quorum systems and other recent advanced in distributed security.It is important to note that these threshold techniques are only meant to enhance the integrity of a single step or run of the protocol. Practical systems, such as Mojo Nation, combine a majority or super-majority within a particular run with failure detection and choice by clients of servers between runs. So we can add back all the reputation systems, auditing, and so on that add robustness in the long term to distributed systems. The majorities or super-majorities within an invocation create a very good short-term robustness that is missing from current systems like Freenet and Mojo Nation. (It's only party missing from Mojo, which has a 4-of-8 voting scheme but this has not been shown to be Byzantine resilient up to 4-of-8).Remote attestation has been proposed for verifying the state of software running on clients to protect intellectual property. A more valuable use for remote attestation is for verifying the behavior of servers. This is also called the transparent server approach. Through remote attestation, clients can verify that the specific desired code is running on a server. Combined with the ability to audit that code as open source, remote attestation of servers can greatly decrease the vulnerability of clients and users to the server. Given the importance of the trusted third party problem we have discussed here, this approach has vast potential to convert trusted third party protocols into secure protocols, and to make possible a wide variety of secure protocols that were heretofore impossible. For example, Hal Finney has implemented a version of bit gold called reusable proofs of work, based on a secure coprrocessor board that allows users to remotely attest the code running on the card. While one still needs to trust the manufacturer of the card, this manufacturer is separated from the installation of server code onto and the operation of the server on the card.Often the protocol designer can't figure out how to fix a vulnerability. If the attack one needs a TTP to protect against is not a serious real-world threat in the context of the application the designer is trying to secure, it is better to simply leave the small hole unplugged than to assign the task to a TTP. In the case of public key cryptography, for example, protocol designers haven't figured out how to prevent a \"man-in-the-middle\" (MITM) attack during the initial key exchange. SSL tried to prevent this by requiring CAs as trusted third parties, as described above, and this solution cost the web community billions of dollars in certificate fees and lost opportunities to secure communications. SSH, on the other hand, decided to simply leave this small hole unplugged. The MITM hole has, to the best of my knowledge, never even once been exploited to compromise the privacy of an SSH user, yet SSH is far more widely used to protect privacy than SSL, at a tiny fraction of the cost. This economical approach to security has been looked at at greater length by Ian Grigg.Alan Karp, Mark Miller, and others have observed the confusion over words like \"trust\" and \"trusted\" as used in the security community, and proposed replacing the verb \"trusts\" with \"is vulnerable to\". This substitution is a great way to radically clarify security protocol designs. \"Trusted third party\" as used in this essay becomes \"vulnerable to a third party\", and the point of this paper, that this is a security hole, becomes obvious.In the context of protocol designs, instead of saying the protocol designer trusts some little-known generic class of parties (referred to in the singular as \"a trusted third party\") with a given authorization (which probably really means the protocol designer just can't figure out how to plug a security hole), an honest protocol designer will admit that there is a vulnerability here \u2013 and that it is up to \"out of band\" mechanisms to plug or minimize, or up to users to knowledgeably ignore, that hole. The class of parties is little-known because security protocol designers typically don't know much about the traditional non-digital security, legal, and institutional solutions needed to make such a party trustworthy. The substitution of \"vulnerable to\" for \"trusted\" works well in protocol design, and in communicating honestly about the security of a protocol.Alas, are security designers and sellers of security systems who invoke \"trusted third parties\", \"trusted computing\", and the like really going to come out and admit that their protocols are \"vulnerable\"? Security designs sound so much more secure when they use the euphemism \"trust\".In the real world, beyond the technical context of security protocol design, \"trust\" has a variety of meanings. One different use of \"trust\" is well-informed trust, for example \"I trust this armor to protect me from normal bullets, because it's been very well tested\", \"I trust this site with this authorization because we're using a strong security protocol to protect me when I grant this authorization\", or \"I trust my wife with the kids\", in which cases translating \"trust\" to \"am vulnerable to\" would be to reverse its meaning. That \"trust\" can take on practically opposite meanings, depending upon the context, is another strong argument for avoiding use of the word when describing the vulnerabilities, or lack thereof, of security protocols. Whether a designer thinks he does or must trust some generic class of parties is one thing. Whether a particular user will actually trust a particular entity in that class when the protocol actually runs is quite another matter. Whether either the user's trust or the designer's trust is well informed is yet another matter still.Traditional security is costly and risky. Digital security when designed well diminishes dramatically in cost over time. When a protocol designer invokes or assumes a TTP, (s)he is creating the need for a novel organization to try to solve an unsolved security problem via traditional security and control methods. Especially in a digital context these methods require continuing high expenditures by the TTP and the TTP creates a bottleneck which imposes continuing high costs and risks on the end user.A far better methodology is to work starting from TTPs that either well known, or easy to characterize, and of minimal cost. The best \"TTP\" of all is one that does not exist, but the necessity for which has been eliminated by the protocol design, or which has been automated and distributed amongst the parties to a protocol. The latter strategy has given rise to the most promising areas of security protocol research including digital mixes, multiparty private computations, and Byzantine resiliant databases. These and similar implementations will be used to radically reduce the cost of current TTPs and to solve the many outstanding problems in privacy, integrity, property rights, and contract enforcement while minimizing the very high costs of creating and operating new TTP institutions.Links in the text.My thanks to Mark Miller who encouraged me to write down these thoughts and provided many good comments. My thanks also to Hal Finney, Marc Stiegler, David Wager, and Ian Grigg for their comments.Please send your comments to nszabo (at) law (dot) gwu (dot) eduCopyright \u00a9 2001, 2004, 2005 by Nick Szabo\nPermission to redistribute without alteration hereby granted"}
{"prompt": "Contracts with Bearer", "completion": "\"Digital bearer certificate\" is a broad term developed by this author[1] incorporating at least two emerging technologies: digital cash and distributed capabilities (secure distributed object references). I will first describe the Chaumian protocol and its innovative privacy feature. I will then discuss how these ideas map to the world of capabilities in the section on generic vs. specific rights. I have altered digital cash terminology from digital cash to bearer certificate or token, from mint to issuer or transfer agent, and so on to reflect the ability of Chaum's protocols to generalize. Chaumian bearer certificates implement standardized rights transferable regardless of the identity of the holder. Each kind of contract (for example, each denomination of \"coin\" in digital cash) corresponds to a digital signature, just as each issue of Federal Reserve Notes or stock certificates corresponds to a particular plate.In the most straightforward Chaumian protocol, the issuer and transfer agent (the same entity, for our purposes, though they can easily be unbundled) create a serial number (really a large unguessable random number, rather than a sequence), and append it to a list of issued certificates. The transfer agent clears a transfer (i.e., redeems the certificate) by checking the signature to identify the class of bearer contract and verify that it was made, then looking on that contract's issued list to make sure the serial number is there, then removing the serial number. Alternatively, the issuer can let the issuee make up the serial number, then, when cleared, check the signature and put the number on the list of cleared certificates. The signature provides the assurance that the certificate is indeed the the particular kind of contract with bearer, while the serial number assures that the same instance of that contract is not cleared or redeemed more than once. In these simple versions, the transfer agent can link the transferee to the transferor for all transfers. To implement the privacy characteristics of coins and physical bearer certificates, we need to add unlinkability features.Meet the greatest simple equation since e=mc2:S is a digital signature. f is the blinding function, and g an unblinding function. The blinding functions are usually based on a secret random number called the \"blinding factor\". m is another random number, a unique identifier which can, for example, refer to an instance of some object.The idea is very clever but very simple. It may be counterintuitive because the simplest physical world metaphor of this highly useful e-commerce primitive sounds worse than useless: Alice can get Carol to sign a blank check! Here's how:The genius behind this discovery: cryptography guru David Chaum. The brilliance lies in step 3: Chaum discovered that some signatures have the property of being \"commutative\" with the blinding functions: Alice can strip off the blinding in the reverse order which the blinding and signature were applied, leaving just Alice's signature of n. It is as if Alice put a piece of carbon paper inside the envelope!In particular for RSA signatures, with public key (pq, e) and private key d, the blind signature functions are the following modulo pq:We can check that the blind signature property holds: gSf(m) = (m(ke))d * k-1 = md * k * k-1 = md, which is the valid RSA signature of private key d on m.Distinguish between either a counter or third party tracing one person's true name, via lack of or weak communications mix, and a third party linking two entities (whether nyms, use-more-than-once-addresses, account numbers, or true names) as being involved in the same transaction. By unlinkability herein we mean the latter. The goal where true names are used (this occurs, for example, when using true name accounts or not using good communications mixes), is to prevent third party linking of two people doing business with each other. Where nyms are used the goal is to minimize the release of traffic information, to prevent the unwanted accumulation of unique behavior patterns, which could be used to link nyms (including to their true names), or could augment other means of breaching privacy. Blinding especially helps where rights holders want to keep third party or public accounts denominated in generic rights. In that case a communications mix doesn't even in principle give us what blinding does.Besides protecting against the transfer agent, Chaum's transferor-, transferee-, and double-blinding protocols protect against collusion of a party with a transfer agent to identify the countparty account or nym.Unlinkability can be provided by combining a list of cleared certificates with blind signatures and a delay-mixing effect. Enough instances of a standardized contract are issued over a period of time to create a mix. Between the issuing and clearing of a certificate, many other certificates with the same signature will be cleared, making it highly improbable that a particular clearing can be linked to a particular issue via the signature. There is a tradeoff between the mixing effect and the exposure to the theft of a \"plate\" for a particular issue: the smaller the issue, the smaller the exposure but the greater the linkability; a larger issue has both greater exposure and greater confidentiality.Blind signatures can be used to make certificate transfers unlinkable via serial number. Privacy from the transfer agent can take the form of transferee-unlinkability, transferor-unlinkability, or \"double blinded\" where both transferor and transferee are unlinkable by the transfer agent or a collusion of a transfer agent and counterparty.A use-once-address communications mix plus foreswearing any reputation gain from keeping accounts, in theory also buys us unlinkability, but a communications mix is weak and very expensive.Bearer certificates come in an \"online\" variety, cleared during every transfer, and thus both verifiable and observable, and an \"offline\" variety, which can be transferred without being cleared, but is only verifiable when finally cleared, by revealing any the clearing name of any intermediate holder who transferred the object multiple times (a breach of contract).This unlinkability is often called \"anonymity\", but the issue of whether accounts are issued to real names or pseudonyms, and whether transferor and transferee identify themselves to each other, is orthogonal to unlinkability by the transfer agent in the online model. In the off-line model, account identification (or at least a highly reputable and/or secured pseudonym) is required: passing an offline certificate a second time reveals this identity. Furthermore, communications channels can allow Eve to link transferor and transferee, unless they take the precaution of using an anonymous remailer. Online clearing does make lack of identification a reasonable option for many kinds of transactions, although common credit and warrantee situations often benefit from or even require identification.When confronting an attempted clearing of a cleared serial number, we face an error-or-fraud dilemma similar to the one we encountered above in double entry bookkeeping. The ecash\u2122 protocol from DigiCash actually takes advantage of on purpose to recover from a network failure. When certificates are lost over the net it is not clear to the transferor whether they have been received and cleared by the transferee or not. Second-transferring directly with the transfer agent resolves the ambiguity. This only works with the online protocol. The issue of distinguishing error from fraud is urgent in the offline protocol, but there is as yet no highly satisfactory solution. This problem is often intractable due to the subjectivity of intent.With ideal two-way anonymous communications between use-once keys, and completely accountless clearing, unlinkability via blind signatures becomes redundant. This ideal case has yet to be even closely approached with implemented technology, and necessarily involves long communications delays which are often intolerable. Real imperfect communications mixes and less expensive blinded tokens complement each other.Issuance and cleared transfer of references to a distributed object conserves the usage of that object. This object becomes \"scarce\" in economic terms, just as use of physical objects is finite. Conserved objects provide the basis for a software economics that more closely resembles economics of scarce physical objects. Conserved objects can be used to selectively exclude not only scarce physical resources (such as CPU time, network bandwidth and response time, etc.), but also fruits of intellectual labor \u2013 as long as one is willing to pay the price to interact with that information over the network rather than locally (cf. content rights management). Conservation immunizes objects and the resources they encapsulate to denial of service attacks. Bearer certificate protocols can be used to transfer references to a particular instance or set of instances of an object, just as they can be used to transfer other kinds of standardized rights.To implement a full transaction of payment for services, we often need need more than just the digital cash protocol; we need a protocol that guarantees that service will be rendered if payment is made, and vice versa. Current commercial systems use a wide variety of techniques to accomplish this, such as certified mail, face to face exchange, reliance on credit history and collection agencies to extend credit, etc. I discuss such issues in my article on smart contracts.To discuss the mapping between Chaumian certificates and distributed capabilities as implemented in for example E I introduce some different, partly overlapping terminology: generic vs. specific, exclusive vs. non-, Transfer Agent vs. Provider, token vs. Swiss number.Rights can be generic or specific. Generic rights correspond to a class of objects, specific rights to an instance. So a specific right is implemented with a Swiss number, a large random number. The signed numbers corresponding to generic rights I will call \"tokens\".Rights can also be exclusive or non-exlusive. Any object which must be conserved, or finally allocated to a specific user, is \"exclusive\".Simple example: the right to an exclusive lock on some 1 MB of memory is generic and exclusive. The right to an exclusive lock on the specific address space 100-101 is specific and exclusive. The right to two dozen particular stock quotes at 12:22 p.m. today is specific and non-exclusive.The main motivation for these distinctions are different mechanisms of unlinkable transfer of these rights, set out below.For simplicity generic rights are all \"use-once\": the life cycle of a token consists of issuance, followed by a series of transfers, followed by consumption. More sophisticated life cycles, such as alternating transfer and consumption, are likely possible with some extra protocol.With a perfect communications mix, including use-once return addresses, and no reputation building, we wouldn't need blinded tokens. However, communications mixes are expensive, and we want the option of having certain public records by which to build reputations, yet do certain rights transfers privately. For these reasons, we should allow clients to blind token transfers in addition to providing a communications mix.For inexpensive, unlinkable, and verifiable transfer of exclusive generic rights, using blinded tokens, there must be a signficant population of interchangable generic rights. Such rights bundled with nonexlusive specific rights can also be cheaply transferred since online clearing is not required for the latter. Unlinkable and verifiable transfer of exclusive specific rights seems to require online clearing via an expensive communications mix.Two kinds of TTPs: a Transfer Agent (TA) and a Provider. The TA operates like an accountless digital cash mint, clearing the transfer of tokens for generic rights. Digital cash is a special case: money is the most generic of rights.The Provider is responsible for actually holding the object, which can contain unique state. The Provider issues a Swiss number, or better a signed description of the specific right and its Swiss number. This signature allows offline verification of the nonexlusive right where the Provider is reputable. The TA issues a token for the corresponding generic rights.Chaum has also developed other means for dealing with unique state[2].I'm assuming the TA and Provider have known reputable signatures. The trust or reputation needed to ensure correctness of transfer between Provider, TA, and users is partly left for later analysis. The two main goals here are to assure that users can verify their rights (including exclusivity from transferors where promised) and retain full privacy from TAs and Providers. Some other trust assumptions are likely made here which need to be explicated and analyzed.To implement exclusive transfers, the TA keeps a list of cleared (cancelled) token numbers. The TA corresponds to a \"mint\" in the Chaumian online digital cash protocol (see above). A class of generic rights corresponds to a \"denomination\" of coin. The Provider may also keep a list of outstanding or used Swiss numbers, like an E Registrar.Here is another example of a generic right, or class of fungible objects: \"A queriable SQL database with up to 10 MB of storage, and certain standard response time guarantees\".The TA sees only classes of fungible objects. The Provider and users see particular instances with unique state, for example a database filled with unique information.The Provider acts analogously to a \"shop\". It is just another token client to the TA, which like other clients can transfer or receive tokens. Its special role is that it is responsible for issuance, where it tells the TA about a new instance, obtains a new token, and transfers it to the client to whom the new generic right is being issued. The TA generates and destroys token supply only at the behest of the Provider; otherwise all its transfers conserve the supply of a particular generic right. The Provider is also responsible for the delivery of service to the client bearing the promised right(s), at which time the Provider \"deposits\" the generic token(s), instructing the TA to decrement the token supply. In digital cash terminology, the Provider is the only entity which has to keep something like a bank account. Rights holders can also keep an account, if they wish to use it to help build reputation, or they can just use the TA for accountless conserved rights transfer.The Provider issues along with the initial generic rights token a signed affadavit, machine or human readable, describing aspects of the object which may be non-exlusive and unique, along with that instance's Swiss number and the public key(s) of the generic right(s) for which it is valid. For example, it might say \"a database containing quotes of these two dozen listed stocks as of 12:22 pm Monday\", without actually containing those quotes. Often such description is worth more when bundled with generic exclusive rights, such as the right to a fast response time. The specific rights can elaborate in unique ways upon the generic rights, as long as these elaborations are not taken to define exclusive rights. The generic rights let the TAs garuntee exclusivity to users and conservation of resources to Providers, while the specific rights describe the unique state to any desired degree of elaboration. The Provider must be prepared to service any specific promise it has issued, as long as it is accompanied by the proper conserved generic tokens.This method of composing specific and generic rights, transferred as a bundle but with exlusive generic atoms cleared by different TAs, allows arbitrarily sophisticated rights bundles, referring to objects with arbitrarily unique state, to be transferred unlinkably. A wide variety of derivatives and combinations are possible. The only restriction is that obtaining rights to specific exclusive resources must either be deferred to the consumption phase, or transferred with online clearing via expensive communications mix.If the Provider wished to guarantee exclusivity to a specific right, transfer seems to require an expensive communications mix between Provider and transferee, rather than a cheap blinded token. For example, \"Deep Space Station 60 from 0500-0900 Sunday\" or \"a lock on autoexec.bat now\" demands exclusivity to a specific right, and thus seems to require a communications mix to unlinkably transfer. On the other hand, \"A one hour block on DSS-60 in May\" and \"the right to lock autoexec.bat at some point\" are generic and can be transferred privately with the much less expensive blinding, given a sufficient population of other tokens for this class of generic right transfered between the issuance and consumption of a given token.Clients can deal with the TA without a communications mix. They deal with the Provider via a communications mix. If both the initial and final holders failed to do this, the Provider could link them. If just the final holder failed to do so, the Provider could identify him as the actual user of the resource. Thus for full privacy generic transfers are cheap, and nonexclusive transfers are cheap, while specific exsclusive transfers and actually using the object seem to require the expensive communications mix.My thanks to David Chaum, Mark Miller, Bill Frantz, Norm Hardy, and many others for taking the time to give me their valuable insights into these issues.The first public references to this idea can be found here, here. I also referred to this idea during this period in many personal communications, using the phrases \"digital bearer instrument\", \"digital bearer certificate\", \"scarce object\", and \"conserved object\". The idea of digital bearer certificates as a serious proposal for the financial industry has been popularized, with many intruiging additional ideas, by Bob Hettinga. \u21a9David Chaum, Online Cash Checks \u21a9\"Blind Signatures for Untraceable Payments,\" D. Chaum,\nAdvances in Cryptology Proceedings of Crypto 82,\nD. Chaum, R.L. Rivest, & A.T. Sherman (Eds.), Plenum, pp. 199-203.The E distributed object languagePlease send your comments to nszabo (at) law (dot) gwu (dot) eduCopyright \u00a9 1997, 1999 by Nick Szabo\nPermission to redistribute without alteration hereby granted"}
{"prompt": "The God Protocols", "completion": "Imagine the ideal protocol. It would have the most trustworthy third party imaginable \u2013 a diety who is on everybody's side. All the parties would send their inputs to God. God would reliably determine the results and return the outputs. God being the ultimate in confessional discretion, no party would learn anything more about the other parties' inputs than they could learn from their own inputs and the output.Alas, in the our temporal world we deal with humans rather than deities. Yet, too often we are forced to treat people in a nearly theological manner, because our infrastructure lacks the security needed to protect ourselves.Network security theorists have recently solved this problem to an astonishing extent. They have developed protocols which create virtual machines between two or more parties. Multiparty secure computation allows any number of parties to share a computation, each learning only what can be inferred from their own inputs and the output of the computation. These virtual machines have the exciting property that each party's input is strongly confidential from the other parties. The program and the output are shared by the parties.For example, we could run a spreadsheet across the Internet on this virtual computer. We would agree on a set of formulas and set up the virtual computer with these formulas. Each participant would have their own input cells, which remain blank on the other participants' computers. The participants share output cell(s). Each input our own private data into our input cells. Alice could only learn only as much about the other participants' input cells as she could infer from her own inputs and the output cells.There are three major limitations. The first is that this virtual computer is very slow: in some cases, one arithmetic calculation per network message. Currently it is at best practical only for small logic or arithmetic calculations used as an adjunct to or component of more efficient computations and protocols.The second is that there is a tradeoff between privacy, fairness, and fault tolerance. Fairness means everybody learning the results in such a way that nobody can gain an advantage by learning first. Fault tolerance can provide robustness against a minority, so that it takes a majority dropping out to halt the protocol, or it can be nonrobust but fail-stop, so that a single participant can terminate the protocol. Many papers have discussed the fraction of parties one must trust in order to be assured of learning the correct output. In traditional results, fairness and privacy could not both be achieved with a faulty majority. Recent papers[3][4][5][6] have produced fair and private protocols even with faulty majorities. They trade robustness for privacy and fairness against any proportion of faulty parties. The advantage of this fail-stop approach is that one can usually find new partners and start over again, but one does not want to suffer irreversible losses such as leaking information, being left holding the bag, or being convinced of an incorrect result.The third limitation is that, far from being omniscient or omnipotent, the protocol will accomplish only what is specified in the algorithm and the inputs. It won't be able to replace human trusted third parties where those parties provide insight or knowledge that cannot be provided by a computer.With these caveats, any algorithmic intermediary can, in principle, be replaced by a trustworthy virtual computer. In practice, because of the three complications, we usually construct more limited protocols out of more efficient elements.Multiparty computation theory, by making possible privy virtual intermediation, has major implications, in theory, for all kinds of contractual relationships. This can be seen most clearly in the area of negotiations. A \"mechanism\" in economics is an abstract model of an institution which communicates with its participants via messages, and whose rules can be specified algorithmically. These institutions can be auctions, exchanges, voting, and so on. They typically implement some kind of negotiation or decision making process.Economists assume a trusted intermediary operates the mechanism. Here's a simple example of using this virtual computer for a mechanism. Alice can submit a bid price, and Bob an ask price, then their shared virtual program which has one instruction, \"A greater than B?\". The computer then returns \"true\" if Alice's bid is greater than Bob's offer. A slightly more sophisticated computer may then decide the settlement price according to a number of different algorithms (Alice's bid, Bob's ask, split the difference, etc.) This implements the mechanism \"blind bargaining\" with no trusted intermediary.In principle, since any computable problem can be solved on this virtual computer (they are \"Turing complete\"), any computable economic mechanism can be implemented without a trusted intermediary. In practice, we face the three limitations discussed above. But the existence proof, that any economic mechanism can be run without a trusted intermediary, is very exciting. This means that, in principle, any contract which can be negotiated through a trusted third party (such as an auction or exchange) can be negotiated directly. So, in some abstract sense, the only remaining \"hard\" problems in smart contract negotiations are (a) problems considered hard even with a trusted intermediary (for the standard economic reasons), and (b) the task of algorithmically specifying the negotiating rules and output contract terms (This includes cases where an intermediary adds knowledge unavailable to the participants, such as a lawyer giving advice on how to draft a contract). In practice, many problems which can be solved in principle with multiparty computation will re-arise when we implement protocols in an efficient, practical manner. The God Protocols give us a target to shoot for.Applying this kind of analysis to the performance phase of contracts is less straightforward. For starters, economic theories of the performance phase are not as well developed or simple as the mechanism theory of negotiations. Indeed, most economic theory simply assumes that all contraccts can be perfectly and costlessly enforced. Some of the \"transaction cost\" literature has started to move beyond this assumption, but there are few compelling results or consensus theories in the area of techniques and costs of contract enforcement.Performance phase analysis with multiparty secure computer theory would seem to apply only to those contracts which can be performed inside the virtual computer. But the use of post-unforgeable auditing logs, combined with running auditing protocols inside the shared virtual computer, allows a wide variety of performances outside the virtual computer to at least be observed and verified by selected arbitrators, albeit not proactively self-enforced.The participants in this mutually confidential auditing protocol can verify that the books match the details of transactions stored in a previously committed transaction log, and that the numbers add up correctly. The participants can compute summary statistics on their confidentially shared transaction logs, including cross-checking of the logs against counterparties to a transaction, without revealing those logs. They only learn what can be inferred from the statistics, can't see the details of the transactions. Another intriguing possibility is that the virtual computer can keep state over long periods of time, allowing sophisticated forms of privy and self-enforcing secured credit.If mutually confidential auditing ever becomes practical, we will be able to gain high confidence in the factuality of counterparties' claims and reports without revealing identifying and other detailed information from the transactions underlying those reports. These would provide the basis for solid reputation systems, and other trusted third party systems, that maintain integrity across time, communications, summarization, and preserve confidentiality for transaction participants. Knowing that mutually confidential auditing can be accomplished in principle will hopefully lead us to practical solutions to these important problems.D. Chaum, C. Cr\u00e9peau, and I. Damgaard, Multiparty unconditionally secure protocols; In 19th Symp. on Theory of Computing, pages 11-19. ACM, 1988.\"The Spymasters Double Agent Problem: Multiparty Computations Secure Unconditionally from Minorities and Cryptographically from Majorities,\" D. Chaum, Advances in Cryptology CRYPTO'89, G. Brassard (Ed.), Springer-Verlag, pp. 591-601.C. Cr\u00e9peau, J. van de Graaf, and A. Tapp, Committed Oblivious Transfer and Private Multi-Party Computations; Advances in Cryptology: Proceedings of Crypto '95, Springer-Verlag, pages 110-123, 1995. \u21a9Complete Characterization of Adversaries Tolerable in Secure Multi-Party Computation, Martin Hirt and Ueli Maurer. Computer Science Department, ETH Z\u00fcrich. 1997. in Proceedings of PODC '97 \u21a9Matthias Fitzi, Martin Hirt, and Ueli Maurer: Trading correctness for privacy in unconditional multi-party computation. In Advances in Cryptology \u2014 CRYPTO '98, volume 1462 of Lecture Notes in Computer Science, 1998. \u21a9R. Cramer, I. Damgaard, S. Dziembowski, M. Hirt, T. Rabin, Efficient Multi-Party Computations with Dishonest Majority, Proceedings of Eurocrypt '99, Springer Verlag LNCS, to appear (May '99). \u21a9Please send your comments to nszabo (at) law (dot) gwu (dot) eduCopyright \u00a9 1997-1999 by Nick Szabo\nPermission to redistribute without alteration hereby granted"}
{"prompt": "Multinational Small Business", "completion": "Currently the vast majority of businesses on the planet are small, but the vast bulk of multinational business is conducted by large corporations.In the future the size distribution of multinationals will approach that of local business. The phase change between these states may be quite rapid as telecomm and transport costs pass through a \"melting point\", creating a wide variety of new multinational small businesses, and industries to support those businesses.Barriers to multinational small business includeBoth transport and telecomm costs have become unprecedentedly low, and with fiber optics telecomm costs will drop orders of magnitude further.Small business can cut through the Gordian knot of jurisdictions with the technologies of jurisdictional independence, including strong encryption for communications and databases, digital cash, firewalls, foiling of traffic analysis with proxy servers and digital mixes, and other system security measures. For use of these capabilities to become routine they must be made seamlessly available in the telecommunications equipment and software used by small business. In their commercial dealings, businesses will increasingly deal with industry specific dispute arbitrators rather than traditional legal jurisdictions, and auditing information from transactions will be shared only between the parties necessary to resolve the dispute. Businesses will learn to share the information needed to attract investment and sales, only to those investors and customers, without jeopardizing their legal status in any major market in the maze of obscure jurisdictions they operate in. The companies that first bring these capabilities to international small business at affordable prices stand to reap large fortunes. The new paradigm of smart contracts may provide the cornerstone for building these tools.Once jurisdictional indepdence is won, small business has nearly endless opportunities to arbitrage between the relative strengths and weaknesses of various localities in various aspects of their business, much like multinationals currently take advantage of relaxed regulatory burdens and low labor costs in Third World countries now. Government intervention probably costs the global economy over $3 trillion U.S. dollars annually; thus vast markets wait to be cracked open by short-circuiting the intervention of governments in both macro and micro markets.Language and culture may remain the largest barriers. Two methods of attack:The rise of virtual nations. Multinational small businesses might speak entirely English, Japanese, Mandarin, etc. Their employees might live primarily within a single cultural milieu, dispersed thru a large number of small ethnic communities around the world, keeping close culture-specific, multimedia communications links between the communities. The worldwide Anglo, Japanese, and Mandarin business networks will be taken up by other cultures, and physically dispersed in most cases.Language-translation software. Crude, specialized versions might soon be reliable, convenient, and inexpensive enough for many kinds of small business uses, such as translating technical manuals.English is becoming increasingly the de facto language for business and technology.One interesting question is what small changes might bring about the phase change faster. Something as simple as a user-friendly voice teleconferencing system, might be enough to tip the penguins into the water. Or it might be widespread Internet access with encrypted, route-mixed TCP/IP connections and virtual whiteboards.Another interesting question in any major new trend is what will be the bottleneck pieces. With the clonable PC, Intel's CPUs and Microsoft's DOS turned out to be the only proprietary elements, with assembly, disk drives, terminals, and the like highly competitive. Wealth will flow to the businesses that provide the bottleneck tools for the coming explosion in multinational small business.The flip side of multinational small business is setting up market processes internal to the large multinational corporation.Please send your comments to nszabo (at) law (dot) gwu (dot) eduCopyright \u00a9 1997, 1999 by Nick Szabo\nPermission to redistribute without alteration hereby granted"}
{"prompt": "Shelling Out: The Origins of Money", "completion": "The precursors of money, along with language, enabled early modern humans to solve problems of cooperation that other animals cannot \u2013 including problems of reciprocal altruism, kin altruism, and the mitigation of aggression. These precursors shared with non-fiat currencies very specific characteristics \u2013 they were not merely symbolic or decorative objects.From the very start, England's 17th century colonies in America had a problem \u2013 a shortage of coins[D94][T01] The British idea was to grow large amounts of tobacco, cut timber for the ships of their global navy and merchant marine, and so forth, sending in return the supplies they felt were needed to keep the Americans working. In effect, early colonists were supposed to both work for the company and shop at the company store. The investors and the Crown much preferred this to paying in coin what the farmers might ask, letting the farmers themselves buy the supplies \u2013 and, heaven forbid, keep some of the profit as well.The colonists' solution was at hand, but it took a few years for them to recognize it. The natives had money, but it was very different from the money Europeans were used to. American Indians had been using money for millenia, and quite useful money it turned out to be for the newly arrived Europeans \u2013 despite the prejudice among some that only metal with the faces of their political leaders stamped on it constituted real money. Worse, the New England natives used neither silver nor gold. Instead, they used the most appropriate money to be found in their environment \u2013 durable skeleton parts of their prey. Specifically, they used wampum, shells of the clam venus mercenaria and its relatives, strung onto pendants.Necklace of wampum. During trade the beads were counted, removed, and re-assembled on new necklaces. Native American shell beads were also sometimes woven into belts or other mnemonic and ceremonial devices that demonstrated the wealth and commitment of a tribe to a treaty.Clams were found only at the ocean, but wampum traded far inland. Sea-shell money of a variety of types could be found in tribes across the American continent. The Iriquois managed to collect the largest wampum treasure of any tribe, without venturing anywhere near the clam's habitat.[D94] Only a handful of tribes, such as the Narragansetts, specialized in manufacturing wampum, while hundreds of other tribes, many of them hunter-gatherers, used it. Wampum pendants came in a variety of lengths, with the number of beads proportional to the length. Pendants could be cut or joined to form a pendant of length equal to the price paid.Once they got over their hangup about what constitutes real money, the colonists went wild trading for and with wampum. Clams entered the American vernacular as another way to say \"money\". The Dutch governor of New Amsterdam (now New York) took out a large loan from an English-American bank \u2013 in wampum. After a while the British authorities were forced to go along. So between 1637 and 1661, wampum became legal tender in New England. Colonists now had a liquid medium of exchange, and trade in the colonies flourished.[D94]The beginning of the end of wampum came when the British started shipping more coin to the Americas, and Europeans started applying their mass-manufacturing techniques. By 1661, British authorities had thrown in the towel, and decided it would pay in coin of the realm \u2013 which being real gold and silver, and its minting audited and branded by the Crown, had even better monetary qualities than shells. In that year wampum ceased to be legal tender in New England. In 1710 briefly became legal tender in North Carolina. It continued to be used as a medium of exchange, in some cases into the 20th century \u2013 but its value had been inflated one hundred fold by Western harvesting and manufacturing techniques, and it gradually went the route that gold and silver jewelry had gone in the West after the invention of coinage \u2013 from well crafted money to decoration. The American language of shell money became a quaint holdover \u2013 \"a hundred clams\" became \"a hundred dollars\". \"Shelling out\" came to mean paying in coins or bills, and eventually by check or credit card.[D94] Little did we know that we had touched the very origins of our species.Native American money took many forms besides shells. Furs, teeth, and a variety of other objects with properties we will discuss below were also commonly used as media of exchange. 12,000 years ago, in what is now Washington state, the Clovis people developed some marvelously long chert blades. The only problem \u2013 they break far too easily. They were useless for cutting. The flints were being made \"for the sheer enjoyment\" \u2013 or for some other purpose that had nothing to do with cutting.[G01] As we shall see, this seeming frivolity was, quite likely, actually very important to their survival.Native Americans had not, however, been the first to make artful but useless blades, nor had they invented shell money. Nor, for that matter, had Europeans, even though they, too, in ages past had widely used shells and teeth for money \u2013 not to mention cattle, gold, silver, weapons, and much else. Asians had used all that and faux axes issued by governments to boot, but they as well imported this institution. For archaeologists have found pendants of shells dating to the early Paleolithic that could easily have substituted for Native American money.Beads made from shells of the pea-sized snail Nassarius kraussianus, that lived in a nearby estuary. Blombos Cave, South Africa, 75,000 B.P.[B04]In the late 1990s archaeologist Stanley Ambrose discovered, in a rock-shelter in the Rift Valley of Kenya, a cache of beads made of ostrich eggshell, blanks, and shell fragments. They are dated using the argon-argon (40Ar/39Ar) ratio to at least 40,000 years old[A98]. Pierced animal teeth have been found in Spain also dating to this time.[W95] Perforated shells have also been recovered from early Paleolithic sites in Lebanon[G95]. Recently regular shells, prepared as strung beads and dating further back still, to 75,000 BP, have been found in Blombos Cave in South Africa.[B04]Ostrich-eggshell beads, Kenya Rift Valley, 40,000 B.P. (Courtesy Stanley Ambrose)Our modern subspecies had migrated to Europe and necklaces of shell and tooth appear there, from 40,000 B.P. onward. Shell and tooth pendants appear in Australia from 30,000 B.P. onward[M93]. In all cases, the work is highly skilled, indicating a practice that probably dates much further back in time. The origin of collecting and decorating is quite likely Africa, the original homeland of the anatomically modern subspecies. Collecting and making necklaces must have had an important selection benefit, since it was costly \u2013 manufacture of these shells took a great deal of both skill and time during an era when humans lived constantly on the brink of starvation[C94].Practically all human cultures, even those that do not engage in substantial trade or that use more modern forms of money, make and enjoy jewelry, and value certain objects more for their artistic or heirloom qualities than for their utility. We humans collect necklaces of shells and other kinds of jewelry \u2013 for the sheer enjoyment of it. For the evolutionary psychologists an explanation that humans do something for \"the sheer enjoyment of it\" is not an explanation at all \u2013 but the posing of a problem. Why do so many people find the collection and wearing of jewelry enjoyable? For the evolutionary psychologist, this question becomes \u2013 what caused this pleasure to evolve?Detail of necklace from a burial at Sungir, Russia, 28,000 BP. Interlocking and interchangeable beads. Each mammoth ivory bead may have required one to two hours of labor to manufacture.[W97]Evolutionary psychology starts with a key mathematical discovery of John Maynard Smith[D89]. Using models of populations of co-evolving genes, from the well-developed area of population genetics, Smith posited genes that can code for strategies, good or bad, used in simple strategic problems (the \"games\" of game theory). Smith proved that these genes, competing to be propagated into future generations, will evolve strategies that are Nash equilibria to the strategic problems presented by the competition. These games include the prisoner's dilemma, a prototypical problem of cooperation, and hawk/dove, a prototypical problem of aggression and its mitigation.Critical to Smith's theory is that these strategic games, while played out between phenotypes proximately, are in fact games between genes at the ultimate level \u2013 the level of competition to be propagated. The genes \u2013 not necessarily the individuals \u2013 influence behavior as if they were boundedly rational (coding for strategies as optimal as possible, within the limits of what phenotypes can express given the biological raw materials and previous evolutionary history) and \"selfish\" (to use Richard Dawkins' metaphor). Genetic influences on behavior are adaptations to the social problems presented by genes competing through their phenotypes. Smith called these evolved Nash equilibria evolutionary stable strategies.The \"epicycles\" built on top of the earlier individual selection theory, such as sexual selection and kin selection, disappear into this more general model which, in a Copernican manner, puts the genes rather than individuals at the center of the theory. Thus Dawkins' metaphorical and often misunderstood phrase, \"selfish gene\", to describe Smith's theory.Few other species cooperate on the order of even Paleolithic humans. In some cases \u2013 brood care, the colonies of ants, termites, and bees, and so forth, animals cooperate because they are kin \u2013 because they can help copies of their \"selfish genes\" found in their kin. In some highly constrained cases, there is also ongoing cooperation between non-kin, which evolutionary psychologists call reciprocal altruism. As Dawkins describes it[D89], unless an exchange of favors is simultaneous (and sometimes even then), one party or the other can cheat. And they usually do. This is the typical result of a game theorists call the Prisoner's Dilemma \u2013 if both parties cooperated, both would be better off, but if one cheats, he gains at the expense of the sucker. In a population of cheaters and suckers, the cheaters always win. However, sometimes animals come to cooperate through repeated interactions and a strategy called Tit-for-Tat: start cooperating and keep cooperating until the other party cheats \u2013 then defect yourself. This threat of retaliation motivates continued cooperation.The situations where such cooperation in fact occurs in the animal world are highly constrained. The main constraint is that such cooperation is restricted to relationships where at least one of the participants is more or less forced to be in the proximity of the other. The most common case is when parasites, and hosts whose bodies they share, evolve into symbiotes. If the interests of the parasite and the host coincide, so that both working together would be more fit than either on their own, (i.e. the parasite is also providing some benefit to the host), then, if they can play a successful game of Tit-for-Tat, they will evolve into symbiosis \u2013 a state where their interests, and especially the exit mechanism of genes from one generation to the next, coincides. They become as a single organism. However, there is much more than cooperation going on here \u2013 there is also exploitation. They occur simultaneously. The situation is analogous to an institution humans would develop \u2013 tribute \u2013 which we will analyze below.Some very special instances occur that do not involve parasite and host sharing the same body and evolving into symbiotes. Rather, they involve non-kin animals and highly constrained territory. A prominent example Dawkins describes are cleaner fish. These fish swim in and out of the mouths of their hosts, eating the bacteria there, benefiting the host fish. The host fish could cheat \u2013 it could wait for the cleaner to finish its job, then eat it. But they don't. Since they are both mobile, they are both potentially free to leave the relationship. However, the cleaner fish have evolved a very strong sense of individual territoriality, and have stripes and dances that are difficult to spoof \u2013 much like a difficult to forge brand logo. So the host fish know where to go to get cleaned \u2013 and they know that if they cheat, they will have to start over again with a new distrustful cleaner fish. The entrance costs, and thus the exit costs, of the relationship are high, so that it works out without cheating. Besides, the cleaner fish are tiny, so the benefit of eating them is not large compared to the benefit of a small number of, or even one, cleaning.One of the most pertinent examples.is the vampire bat. As their name suggests, they suck the blood of prey mammals. The interesting thing is that, on a good night, they bring back a surplus; on a bad night, nothing. Their dark business is highly unpredictable. As a result, the lucky (or skilled) bats often share blood with the less lucky (or skilled) bats in their cave. They vomit up the blood and the grateful recipient eats it.The vast majority of these recipients are kin. Out of 110 such regurgitations witnessed by the strong-stomached biologist G.S. Wilkinson, 77 were cases of mothers feeding their children, and most of the other cases also involved genetic kin. There were, however, a small number that could not be explained by kin altruism. To demonstrate these were cases of reciprocal altruism, Wilkinson combined the populations of bats from two different groups. Bats, with very rare exception, only fed old friends from their original group.[D89] Such cooperation requires building a long-term relationship, where partners interact often, recognize each other, and keep track of each other's behavior. The bat cave helps constrain the bats into long-term relationships where such bonds can form.We will see that some humans, too, chose highly risky and discontinuous prey items, and shared the resulting surpluses with non-kin. Indeed, they accomplished this to a far greater extent than the vampire bat. How they did so is the main subject of our essay. Dawkins suggests, \"money is a formal token of delayed reciprocal altruism\", but then pursues this fascinating idea no further. We will.Among small human groups, public reputation can supercede retaliation by a single individual to motivate cooperation in delayed reciprocation. However, reputational beliefs can suffer from two major kinds of errors \u2013 errors of about which person did what, and errors in appraising the value or damages caused by that act.The need to remember faces and favors is a major cognitive hurdle, but one that most humans find relatively easy to overcome. Recognizing faces is easy, but remembering that a favor took place when such memory needs to be recalled can be harder. Remembering the specifics about a favor that gave it a certain value to the favored is harder still. Avoiding disputes and misunderstandings can be improbable or prohibitively difficult.The appraisal or value measurement problem is very broad. For humans it comes into play in any system of exchange \u2013 reciprocation of favors, barter, money, credit, employment, or purchase in a market. It is important in extortion, taxation, tribute, and the setting of judicial penalties. It is even important in reciprocal altruism in animals. Consider monkeys exchanging favors \u2013 say pieces of fruit for back scratches. Mutual grooming can remove ticks and fleas that an individual can't see or reach. But just how much grooming versus how many pieces of fruit constitutes a reciprocation that both sides will consider to be \"fair\", or in other words not a defection? Is twenty minutes of backscratching worth one piece of fruit or two? And how big a piece?Even the simple case of trading blood for blood is more complicated than it seems. Just how do the bats estimate the value of blood they have received? Do they estimate the value of a favor by weight, by bulk, by taste, by its ability to satiate hunger, or other variables? Just the same, measurement complications arise even in the simple monkey exchange of \"you scratch my back and I'll scratch yours\".For the vast majority of potential exchanges, the measurement problem is intractable for animals. Even more than the easier problem of remembering faces and matching them to favors, the ability of both parties to agree with sufficient accuracy on an estimate of the value of a favor in the first place is probably the main barrier to reciprocal altruism among animals.Just the stone tool-kit of even early Paleolithic man that has survived for us to find was in some ways too complicated for brains of our size. Keeping track of favors involving them \u2013 who manufactured what quality of tool for whom, and therefore who owed whom what, and so on \u2013 would have been too difficult outside the boundaries of the clan. Add onto that, quite likely, a large variety of organic objects, ephemeral services (such as grooming), and so on that have not survived. After even a small fraction of these goods had been transferred and services performed our brains, as inflated as they are, could not possibly keep track of who owed what to whom. Today we often write these things down \u2013 but Paleolithic man had no writing. If cooperation occurred between clans and even tribes, as the archaeological record indicates in fact occured, the problem gets far worse still, since hunter-gatherer tribes were usually highly antagonistic and mutually distrustful.If clams can be money, furs can be money, gold can be money, and so on \u2013 if money is not just coins or notes issued by a government under legal tender laws, but rather can be a wide variety of objects \u2013 then just what is money anyway? And why did humans, often living on the brink of starvation, spend so much time making and enjoying those necklaces when they could have been doing more hunting and gathering? Nineteenth century economist Carl Menger[M1892] first described how money evolves naturally and inevitably from a sufficient volume of commodity barter. In modern economic terms the story is similar to Menger's.Barter requires a coincidence of interests. Alice grows some pecans and wants some apples; Bob grows apples and want some pecans. They just happen to have their orchards near each other, and Alice just happens to trust Bob enough to wait between pecan harvest time and apple harvest time. Assuming all these conditions are met, barter works pretty well. But if Alice was growing oranges, even if Bob wanted oranges as well as pecans, they'd be out of luck \u2013 oranges and apples don 't both grow well in the same climate. If Alice and Bob didn't trust each other, and couldn't find a third party to be a middleman[L94] or enforce a contract, they'd also be out of luck.Further complications could arise. Alice and Bob can't fully articulate a promise to sell pecans or apples in the future, because, among other possibilities, Alice could keep the best pecans to herself (and Bob the best apples), giving the other the dregs. Comparing the qualities as well as the quantities of two different kinds of goods is all the more difficult when the state of one of the goods is only a memory. Furthermore, neither can anticipate events such as a bad harvest. These complications greatly add to the problem of Alice and Bob deciding whether separated reciprocal altruism has truly been reciprocal. These kinds of complications increase the greater the time interval and uncertainty between the original transaction and the reciprocation.A related problem is that, as engineers would say, barter \"doesn't scale\". Barter works well at small volumes but becomes increasingly costly at large volumes, until it becomes too costly to be worth the effort. If there are n goods and services to be traded, a barter market requires n^2 prices. Five products would require twenty-five prices, which is not too bad, but 500 products would require 250,000 prices, which is far beyond what is practical for one person to keep track of. With money, there are only n prices \u2013 500 products, 500 prices. Money for this purpose can work either as a medium of exchange or simply as a standard of value \u2013 as long as the number of money prices themselves do not grow too large to memorize or change too often. (The latter problem, along with an implicit insurance \"contract\", along with the lack of a competitive market may explain why prices were often set by long-evolved custom rather than proximate negotiation).Barter requires, in other words, coincidences of supply or skills, preferences, time, and low transaction costs. Its cost increases far faster than the growth in the number of goods traded. Barter certainly works much better than no trade at all, and has been widely practiced. But it is quite limited compared to trade with money.Primitive money existed long before large scale trade networks. Money had an even earlier and more important use. Money greatly improved the workings of even small barter networks by greatly reducing the need for credit. Simultaneous coincidence of preference was far rarer than coincidences across long spans of time. With money Alice could gather for Bob during the ripening of the blueberries this month, and Bob hunt for Alice during the migration of the mammoth herds six months later, without either having to keep track of who owed who, or trust the other's memory or honesty. A mother's much greater investment in child rearing could be secured by gifts of unforgeable valuables. Money converts the division of labor problem from a prisoner's dilemma into a simple swap.The proto-money used by many hunter-gatherer tribes looks very different from modern money, now serves a different role in our modern culture, and had a function probably limited to small trade networks and other local institutions discussed below. I will thus call such money collectibles instead of money proper. The terms used in the anthropological literature for such objects are usually either \"money\", defined more broadly than just government printed notes and coins but more narrowly than we will use \"collectible\" in this essay, or the vague \"valuable\", which sometimes refers to items that are not collectibles in the sense of this essay. Reasons for choosing the term collectible over other possible names for proto-money will become apparent. Collectibles had very specific attributes. They were not merely symbolic. While the concrete objects and attributes valued as collectible could vary between cultures, they were far from arbitrary. The primary and ultimate evolutionary function of collectibles was as a medium for storing and transferring wealth. Some kinds of collectibles, such as wampum, could be quite functional as money as we moderns know it, where the economic and social conditions encouraged trade. I will occasionally use the terms \"proto-money\" and \"primitive money\" interchangeably with \"collectible\" when discussing pre-coinage media of wealth transfer.People, clans or tribes trade voluntarily because both sides believe they gain something. Their beliefs about the value may change after the trade, for example as they gain experience with the good or service. Their beliefs at the time of the trade, although to some degree inaccurate as to the value, are still usually correct as to the existence of gain. Especially in early intertribal trade, restricted to high value items, there was strong incentive for each party to get their beliefs right. Thus trade almost always did benefit both parties. Trade created value as much as the physical act of making something.Because individuals, clans, and tribes all vary in their preferences, vary in their ability to satisfy these preferences, and vary in the beliefs they have about these skills and preferences and the objects that are consequent of them, there are always gains to be made from trade. Whether the costs of making these trades \u2013 transaction costs \u2013 are low enough to make the trades worthwhile is another matter. In our civilization, far more trades are possible than were through most of human history. Nevertheless, as we shall see some kinds of trades were worth more than the transaction costs, for some cultures, probably back to the beginning of homo sapiens sapiens.Voluntary spot trades are not the only kinds of transactions that benefit from lower transaction costs. This is the key to understanding the origin and evolution of money. Family heirlooms could be used as collateral to remove the credit risk from delayed exchanges. The ability of a victorious tribe to extract tribute from the vanquished was of great benefit to the victor . The victor's ability to collect tribute benefited from some of the same kinds of transaction cost techniques as did trade. So did the plaintiff in assessment of damages for offenses against custom or law, and kin groups arranging a marriage. Kin also benefited from timely and peaceful gifts of wealth by inheritance. The major human life events that modern cultures segregate from the world of trade benefited no less than trade, and sometimes more so, from techniques that lowered transaction costs. None of these techniques was more effective, important, or early than primitive money \u2013 collectibles.When H. sapiens sapiens displaced H. sapiens neanderthalensis, population explosions followed. Evidence from the takeover in Europe, c. 40,000 to 35,000 B.P, indicates that H. sapiens sapiens increased the carrying capacity of its environment by a factor of ten over H. sapiens neanderthalensis \u2013 i.e., the population density increased tenfold[C94]. Not only that, the newcomers had spare time to create the world's first art \u2013 such as the wonderful cave paintings, a wide variety of well crafted figurines \u2013 and of course the wonderful pendants and necklaces of seashells, teeth, and eggshell.These objects were not useless decorations. Newly effective wealth transfers, made possible by collectibles as well as other probable advance of the era, language, created new cultural institutions that quite likely played the leading role in the increase of carrying capacity.The newcomers, H. sapiens sapiens, had the same size brain, weaker bones, and smaller muscles than the Neanderthals. Their hunting tools were more sophisticated, but in 35,000 B.P. they were basically the same tools \u2013 they were probably not even twice as effective, much less ten times more effective. The biggest difference may have been wealth transfers made more effective or even possible by collectibles. H. sapiens sapiens took pleasure from collecting shells, making jewelry out of them, showing them off, and trading them. H. sapiens neanderthalensis did not. The same dynamic would have been at work, tens of thousands of years earlier, on the Serengeti, when H. sapiens sapiens first appeared in that dynamic maelstrom of human evolution, Africa.We shall describe how collectibles lowered transaction costs in each kind of wealth transfer \u2013 in the voluntary free gift of inheritance, in voluntary mutual trade or marriage, and in the involuntary transfers of legal judgments and tribute.All these kinds of value transfer occurred in many cultures of human prehistory, probably from the beginning of Homo sapiens sapiens. The gains to be made, by one or both parties, from these major life event transfers of wealth, were so great that they occurred despite high transaction costs. Compared to modern money, primitive money had a very low velocity \u2013 it might be transferred only a handful of times in an average individual's lifetime. Nevertheless, a durable collectible, what today we would call an heirloom, could persist for many generations and added substantial value at each transfer \u2013 often making the transfer even possible at all. Tribes therefore often spent large amounts of time on the seemingly frivolous tasks of manufacturing and exploring for the raw materials of jewelry and other collectibles.The Kula trading network of pre-colonial Melanesia. The kula valuables doubled as \"high power\" money and mnemonic for stories and gossip. Many of the goods traded, mostly agricultural products, were available in different seasons, and so could not be traded in kind. Kula collectibles solved this double-coincidence problem as an unforgeabaly costly, wearable (for security), and circulated (literally!) money. Necklaces circulated clockwise, and armshells counter-clockwise, in a very regular pattern. By solving the double-coincidence problem an armshell or necklace would prove more valuable than its cost after only a few trades, but could circulate for decades. Gossip and stories that about prior owners of the collectibles further provided information about upstream credit and liquidity. In other Neolithic cultures collectibles, usually shells, circulated in a less regular pattern but had similar purposes and attributes.[L94]Kula armshell (mwali).Kula necklaces (bagi).For any institution in which wealth transfer is an important component, we will ask the following questions:What coincidence in time between the event, the supply for the transferred good, and demand for the transferred good was necessary? How unlikely or how high a barrier to the wealth transfer did the improbability of coincidence represent?Would the wealth transfers formed a closed loop of collectibles just based on that institution, or were other wealth transfer institutions necessary to complete circulation cycles? Taking the actual flow graph of monetary circulation seriously is critical to understanding the emergence of money. General circulation among a wide variety of trades did not and would not exist for most of human prehistory. Without completed and repeated loops collectibles would not circulate and would become worthless. A collectible, to be worth making, had to add value in enough transactions to amortize its cost.We shall first examine the kind of transfer most familiar and economically important to us today \u2013 trade.Bruce Winterhalder[W98] surveys models of how and why food is sometimes transferred between animals: tolerated theft, producing/scrounging/opportunism, risk-sensitive subsistence, by-product mutualism, delayed reciprocity, trade/exchange not in kind, and other selection models (including kin altruism). Here we focus on risk-sensitive subsistence, delayed reciprocity, and trade (exchange not in kind). We argue that substituting trade of food for collectibles for delayed reciprocity can increase food sharing. It does so by mitigating the risks of a variable food supply while avoiding the largely insurmountable problems of delayed reciprocity between bands. We will deal with kin altruism and theft (tolerated or not) in broader contexts below.Food is worth far more to starving people than to well fed ones. If the starving man can save his life by trading his most precious valuables, it may be worth to him months or even years of the labor it might take to replace that value. He will usually consider his life worth more than the sentimental value of the family heirlooms. Like fat itself, collectibles can provide insurance against food shortages. Starvation from local shortages could be staved off with at least two different kinds of trades \u2013 for the food itself, or for foraging or hunting rights.Nevertheless, the transaction costs were usually too high \u2013 bands were far more likely to fight than ever trust each other. The hungry band that couldn't find its own food usually starved. However, if the transaction costs could be lowered, by lowering the need for trust between bands, food that was worth a day's labor to one band might be worth several months' labor to the starving band.Local but extremely valuable trade was, this essay argues, made possible among many cultures by the advent of collectibles, by the time of the Upper Paleolithic. Collectibles substituted for otherwise necessary but non-existent trusting long term relationships. If there had existed a high degree of sustained interaction and trust between tribes, or individuals of different tribes, so that they gave each other unsecured credit, this would have stimulated time-lagged barter trade. However, such a high degree of trust then is highly implausible \u2013 for the reasons stated above regarding reciprocal altruism, confirmed by the empirical evidence that most hunter-gatherer tribal relations have been observed to be quite antagonistic. Hunter-gatherer bands usually broke up into small bands for most of the year and gathered into \"aggregates\", something like medieval European fairs, for a few weeks out of the year. Despite the lack of trust between bands, an important trade in staples, of the kind illustrated in the accompanying figure, almost surely occurred in European and probably elsewhere, such as with the big game hunters of America and Africa.The scenario illustrated by the accompanying figure is hypothetical, but it would be very surprising if it did not occur. While many Europeans even in the Paleolithic enjoyed wearing shell necklaces, many lived farther inland and made necklaces instead out of the teeth of their prey. Flints, axes, furs, and other collectibles were also quite likely used as media of exchange.Reindeer, bison, and other human prey migrated at different times of the year. Different tribes specialized in different prey, to the point where over 90%, and sometimes as much as 99%, of the remains from many sites during the Paleolithic in Europe come from a single species[C94]. This indicates at least seasonal specialization and perhaps full-time specialization by a tribe in a single species. To the extent they specialized, the members of a single tribe would have become experts at the behavior, migration habits, and other patterns surrounding their specific prey species, as well as the specialized tools and techniques for hunting them. Some tribes observed in recent times are known to have specialized. Some North American Indian tribes specialized respectively in hunting bison, antelope, and fishing for salmon. In northern Russia and parts of Finland, many tribes, including the Lapp even today, specialized in herding a single species of reindeer.Such specialization was probably far higher when more large prey (horse, auroch, giant elk, bison, giant sloth, mastodon, mammoth, zebra, elephant, hippopotamus, giraffe, musk oxen, etc.) roamed North America, Europe, and Africa in large herds during the Paleolithic. Large wild animals unafraid of humans no longer exist. During the Paleolithic they were either driven extinct or adapted to be afraid of humans and our projectiles. However, for most of the time span of H. sapiens sapiens these herds were abundant and easy pickings to specialist hunters. According to our theory of trade-based predation, specialization was quite likely far higher when large prey roamed North America, Europe, and Africa in large herds during the Paleolithic. Trade-based division of labor in hunting between tribes is consistent with (although not securely confirmed by) the archaeological evidence from the Paleolithic in Europe.These migrating bands, following their herds, frequently interacted, creating many opportunities for trade. American Indians preserved food by drying, making pemmican, and so on in ways that lasted for a few months but typically not a full year. Such food was commonly traded, along with skins, weapons, and collectibles. Often these trades occurred during annual trading expeditions[T01].Large herd animals migrated through a territory only two times a year, with a window most often of one or two months. Without any other source of protein besides their own prey species, these specialist tribes would have starved. The very high degree of specialization demonstrated in the archaeological record could only have occurred if there was trade.Thus, even if the time-offset barter of meat were the only kind of trade, this is quite sufficient to make the use of collectibles quite worthwhile. The necklaces, flints, and any other objects used as money circulate in a closed loop, back and forth, in roughly equal amounts so long as the value of meat traded remains roughly equal. Note that it is not enough, for the theory of collectibles put forth in this paper to be correct, that single beneficial trades were possible. We must identify closed loops of mutually beneficial trades. With closed loops the collectibles continue to circulate, amortizing their costs.As mentioned, we know from archaeological remains that many tribes specialized in a single large prey species. This specialization was at least seasonal; if there was extensive trade it could have been full-time. Becoming experts in the habits and migration patterns, and best methods of taking down, a tribe reaped enormous productive benefits. These benefits, however, would normally be unattainable, for specializing in a single species meant going without food most of the year. Division of labor between tribes paid off \u2013 and trade made it possible. The supply of food would nearly double from trade just between two complementary tribes. There were, however, rather than two prey species, often up to a dozen that migrated through most hunting territories in areas like the Serengeti and the European steppe. The amount of meat available to a species-specializing tribe would thus likely more than double with such trade among a handful of neighboring tribes. On top of this, the extra meat would be there when needed most \u2013 when the meat from a tribe's own species prey would already have been eaten, and without food the hunters would starve.Thus there were at least four gains, or sources of surplus, from a trade cycle as simple as two prey species and two non-simultaneous but offsetting trades. These gains are distinct but not necessarily independent:Making or saving collectibles to trade for food itself was not the only way to insure against bad times. Perhaps even more common, especially where large prey items were not available, was territoriality combined with trade in foraging rights. This can be observed even in some of the remnants of hunter-gatherer culture that exist today.The !Kung San of southern Africa, like all other modern remnants of hunter-gatherer cultures, live on marginal lands. They have no opportunity to be specialists but must take the meager remnants available. They may thus be rather uncharacteristic of many ancient hunter-gatherer cultures, and uncharacteristic of the original Homo sapien sapiens, which first seized the lushest lands and best game routes from Homo sapiens neanderthalensis and only much later drove the Neanderthals from marginal lands. Yet despite their severe ecological handicap, the !Kung use collectibles as items of trade.Like most hunter-gatherers, the !Kung spend most of the year in small, dispersed bands and a few weeks of the year in an aggregate with several other bands. Aggregation is like a fair with added features \u2013 trade is accomplished, alliances are cemented, partnerships strengthened, and marriages transacted. Preparation for aggregation is filled with the manufacture of tradeable items, partly utilitarian but mostly of a collectible nature. The exchange system, called by the !Kung hxaro, involves a substantial trade in beaded jewelry, including ostrich-shell pendants quite similar to those found in Africa 40,000 years ago.Pattern of hxaro exchanges and kinship relations among neighboring tribes of !Khung San hunter-gatherers.Necklaces used in the hxaro exchange.One of the main things the !Kung buy and sell with their collectibles are abstract rights to enter another band's territory and hunt or gather food there. Trade in these rights is especially brisk during local shortages which can be alleviated by foraging in a neighbor's territory[W77][W82] !Kung bands mark their territories with arrows; trespassing without having purchased the right to enter and forage is tantamount to a declaration of war. Like the inter-band food trade discussed above, the use of collectibles to purchase foraging rights constitutes an \"insurance policy against starvation\", to use the phrase of Stanley Ambrose[A98].Although anatomically modern humans surely had conscious thought, language, and some ability to plan, it would have required little conscious thought or language, and very little planning, to generate trades. It was not necessary that tribe members reasoned out the benefits of anything but a single trade. To create this institution it would have sufficed that people follow their instincts to make obtain collectibles with the characteristics outlined below. (as indicated by proxy observations that make approximate estimations for these characteristics). This is to various extents true of the other institutions we will study \u2013 they evolved, rather than being consciously designed. No one participating in the institution's rituals would have explained their function in terms of ultimate evolutionary function; rather they explained in terms of a wide variety of mythologies that served more as proximate motivators of behavior than as theories of ultimate purpose or origin.Direct evidence for trade in food has long since decayed. We may, in the future, find more direct evidence than is now available for this article, via comparison of hunting remains in one tribe with the consumption patterns in another tribe \u2013 the hardest part of this task likely being to identify the boundaries of different tribes or kin groups. According to our theory, such transfer of meat from one tribe to another was common in many parts of the world during the Paleolithic where large-scale and specialized big game hunting occurred.For now, we do have extensive indirect evidence of trade, via the movement of the collectibles themselves. Fortunately there is a good correlation between the durability desired for collectibles and the conditions under which an artifact has survived to be found by today's archaeologists. In the early Paleolithic, when all human movement was on foot, we have instances of perforated sea shells found up to 500 kilometers away from the nearest source[C94]. There was a similar long-distance movement of flint.Unfortunately, trade was severely restricted by high transaction costs in most times and places. The primary barrier was the antagonism between tribes. The predominant relationship between tribes was one of distrust on good days and outright violence on bad days. Only ties of marriage or kinship could bring tribes into a relationship with trust, albeit only occasionally and of limited scope. The poor ability to protect property, even collectibles worn on the person or buried in well-hidden caches, meant that collectibles had to amortize their costs in a few transactions.Trade was thus not the only kind of wealth transfer, and probably not the most important kind during the long human prehistory where high transaction costs prevented the development of the kinds of markets, firms, and other economic institutions we now take for granted[L94]. Underneath our great economic institutions are far more ancient institutions that also involved wealth transfer \u2013 in prehistoric times, the main kinds of wealth transfer. All of these institutions distinguished Homo sapiens sapiens from previous animals. We now turn to one of the most basic kinds of wealth transfer that we humans take for granted but other animals do not have \u2013 passing wealth onto the next generation.Coincidence in time and locale of supply and demand for trade was rare \u2013 so much so, that most kinds of trades and trade-based economic institutions we now take for granted could not exist. Even more unlikely was the triple coincidence of supply with demand with a major event for a kin group \u2013 the formation of a new family, death, crime, or victory or defeat in war. As we shall see, clans, and individuals greatly benefited from a timely transfer of wealth during these events. Such wealth transfer in turn was much less wasteful when it was the transfer of a store of wealth more durable and general than consumables or tools designed for other purposes. The demand for a durable and general store of wealth for use in these institutions was thus even more urgent than for trade itself. Furthermore, the institutions of marriage, inheritance, dispute resolution, and tribute may predate intertribal trade, and involved for most tribes a greater transfer of wealth than trade. These institutions thus more than trade served as the motivator and incubator of the earliest primitive money.In most hunter-gatherer tribes this wealth came in a form that strikes us preposterously wealthy moderns as trivial \u2013 a collection of wooden utensils, flint and bone tools and weapons, shells on strings, perhaps a hut and in colder climates some mangy furs. Sometimes it could all be carried on the person. Nevertheless, these motley assortments were wealth for a hunter-gatherer no less than real estate, stocks, and bonds are wealth for us. To the hunter-gatherer tools and sometimes warm clothes were necessary for survival. Many of the items were highly valued collectibles that insured against starvation, purchased mates, and could substitute for massacre or starvation in event of war and defeat. The ability to transfer the capital of survival to one's descendants was another advantage Homo sapiens sapiens had over previous animals. Furthermore, the skilled tribesman or clan could accumulate a surplus of wealth from the occasional, but cumulative over a lifetime, trade of surplus consumables for durable wealth, especially collectibles. A temporary fitness advantage could be translated into a more durable fitness advantage for one's descendants.Another form of wealth, hidden from the archaeologist, were titles to offices. Such social positions were more valuable than the tangible forms of wealth in many hunter-gatherer cultures. Examples of such positions included clan leaders, war party leaders, hunting party leaders, membership in a particular long-term trading partnership (with a particular person in a neighboring clan or tribe), midwives, and religious healers. Often collectibles not only embodied wealth, but also served as a mnemonic, representing the title to a clan position of responsibility and privilege. Upon death, to maintain order, the heirs to such positions had to be quickly and clearly determined. Delays could spawn vicious conflicts. Thus, a common event was the mortuary feast, in which the deceased was feted while both his tangible and intangible forms of wealth were distributed to descendants, as determined by custom, clan decision-makers, or the will of the deceased.Other kinds of free gifts were quite rare in pre-modern cultures, as Marcel Mauss[M50] and other anthropologists have pointed out. Seemingly free gifts in fact implicitly invoked an obligation in the recipient. Before contract law, this implicit obligation of the \"gift\", along with community dishonor and punishments ensuing if the implicit obligation was not met, was perhaps the most common motivator of reciprocation in delayed exchange, and is still common in the variety of informal favors we do for each other. Inheritance and other forms of kin altruism were the only widely practiced forms of what we moderns would call gift proper, namely a gift that imposed no obligation on the recipient.Early Western traders and missionaries, who often saw natives as childish primitives, sometimes called their tribute payments \"gifts\" and trades \"gift exchanges\", as if they bore more resemblance to the Christmas and birthday present exchanges of Western children than to the contractual and tax obligations of adults. Partly this may have reflected prejudice, and partly the fact that in the West by that time obligations were usually formalized in writing which the natives lacked. Westerners thus usually translated the rich variety of words natives had for their exchange institutions, rights, and obligations as \"gift\". Seventeenth century French settlers in America were thinly scattered among much larger populations of Indian tribes, and often found themselves paying tribute to these tribes. Calling these payments \"gifts\" was a way for them to save face with other Europeans who faced no such necessity and found it cowardly.Mauss and modern anthropologists have unfortunately kept this terminology. The uncivilized human is still like a child, but now innocent like a child, a creature of moral superiority who would not stoop to our kind of base, cold-blooded economic transactions. However in the West, especially in the official terminology used for our laws covering transactions, a \"gift\" refers to a transfer that imposes no obligation. When coming across anthropological discussions of \"gift exchange\" these caveats should be kept in mind \u2013 modern anthropologists are not at all referring to the free or informal gifts we commonly refer to in our modern use on the term \"gift\". They are rather referring to any of a wide variety of often quite sophisticated systems of rights and obligations involved in wealth transfers. The only major transactions in prehistoric cultures similar to our modern gift, in that it was neither itself a widely recognized obligation nor imposed any obligation on the recipient, were parents or maternal kin caring for their children and inheritance. (An exception was that inheriting title to a position imposed the responsibilities of the position on the heir as well as its privileges).Inheritance of some heirlooms might proceed for several generations uninterrupted, but it did not by itself form a closed loop of collectibles transfers. Heirlooms were only valuable if they eventually got used for something else. They often were used in marriage transactions between clans that could form closed loop cycles of collectibles.An early and important example of a small closed loop trade network made possible by collectibles involves the much higher investment humans make in raising offspring than our primate relatives, and the related human institution of marriage. Combining arrangements of long-term matches for mating and child-raising, negotiated between clans, with wealth transfer, marriage is a human universal and probably dates back to the first Homo sapiens sapiens.Parental investment is a long-term and almost one-shot affair \u2013 there is no time for repeated interactions. Divorce from a negligent father or unfaithful wife usually represented several years of time wasted, in genetic fitness terms, by the jilted party. Fidelity and commitment to the children were primarily enforced by in-laws \u2013 the clan. The marriage was the contract between clans that usually included such promises of fidelity and commitment as well as wealth transfer.The contributions a man and a woman will bring to a marriage are seldom equal. This was even more true in an era when mate choice was largely determined by clans and the population from which clan leaders could choose was quite small. Most commonly, the woman was considered more valuable and the groom's clan paid a bride price to the brides clan. Quite rare in comparison was dowry, a payment by the bride's clan to the new couple. Mostly this was practiced by upper classes of monogamous but highly unequal societies in medieval Europe and India, and was ultimately motivated by the far greater reproductive potential of upper class sons than upper class daughters in those societies. Since literature was mostly written about upper classes, dowry often plays a role in European traditional stories. This does not reflect its actual frequency across human cultures \u2013 it was quite rare.Marriages between clans could form a closed cycle of collectibles. Indeed, two clans exchanging partners would be sufficient to maintain a closed loop, as long as brides tended to alternate. If one clan was wealthier in collectibles from some other kind of transfer, it could marry more of its sons to better brides (in monogamous societies) or a greater number of brides (in polygamous societies). In a loop involving only marriages, primitive money would simply serve to replace the need for memory and trust between clans over a long period of delay between unbalanced transfers of reproductive resources.Like inheritance, lawsuit, and tribute, marriage requires a triple coincidence of the event, in this case the marriage, with supply and demand. Without a transferable and durable store of value, the current ability of a groom's clan to supply the current desires of the bride's clan, to a large enough degree to make up the value mismatch between bride and groom, while also satisfying the political and romantic constraints of the match, were quite unlikely to be well satisfied. One solution is imposing an ongoing service obligation from the groom or his clan to the bride's clan. This occurs in about 15% of known cultures[DW88]. In a much larger number, 67%, the groom or groom's clan pays the brides clan a substantial amount of wealth. Some of this bride price is paid in immediate consumables, in plants to be gathered harvested and animals slaughtered for the marriage feast. In herding or agricultural societies much of the bride price is paid in livestock, a long lasting form of wealth. The balance, and usually the most valuable portion of the bride-price in cultures without livestock, is paid with what are usually the most valuable family heirlooms \u2013 the rarest, costliest, and most durable pendants, rings, and so on. The Western practice of the groom giving the bride a ring \u2013 and a suitor giving a maiden other kinds of jewelry \u2013 was once a substantial transfer of wealth and was common in many other cultures. In about 23% of cultures, mostly modern ones, there is no substantial wealth exchange. In about 6% of cultures there is mutual exchange of substantial wealth between bride and groom clans. In only about 2% of cultures does the bride's clan pay the new couple a dowry.[DW88]Unfortunately, some wealth transfers were a far cry from the altruism of the inheritance gift or the joy of marriage. Quite the opposite, in the case of tribute.Death rates from violence in chimp troops and hunter-gatherer human cultures alike are far higher than in modern civilizations. This probably dates at least as far back as our common ancestor with the chimpanzees \u2013 chimp troops, as well, are constantly fighting.Warfare involved, among other things, killing, maiming, torture, kidnapping, rape, and the extortion of tribute in exchange for avoiding such fates. When two neighboring tribes were not at war, one was usually paying tribute to the other. Tribute could also serve to bind alliances, achieving economies of scale in warfare. Mostly, it was a form of exploitation more lucrative to the victor than further violence against the defeated.Victory in war was sometimes followed by an immediate payment from the losers to the winners. Often this just took the form of looting by the enthusiastic victors, while the losers desperately hid their collectibles. More often, tribute was demanded on a regular basis. In this case, the triple coincidence could and sometimes was avoided by a sophisticated schedule of payments in kind that matched the losing tribe's ability to supply a good or service with the victor's demand for it. However, even with this solution primitive money could provide a better way \u2013 a common medium of value that greatly simplified the terms of payment \u2013 very important in an era when terms of the treaty could not be recorded but had to be memorized. In some cases, as with the wampum as used in the Iriquois Confederacy, the collectibles doubled as a primitive mnemonic device that, while not verbatim, could be used as an aid to recall the terms of the treaty. For the winners, collectibles provided a way to collect tribute at closer to the Laffer optimum. For the losers, collectibles buried in caches provided a way to \"under-report\", leading the victors to believe the losers were less wealthy and thus demand less than they might. Caches of collectibles also provided insurance against overzealous tribute collectors. Much of the wealth in primitive societies escaped the notice of the missionaries and anthropologists due to its highly secretive nature. Only archeology can reveal the existence of this hidden wealth.Hiding and other strategies presented a problem that tribute collectors share with modern tax collectors \u2013 how to estimate the amount of wealth they can extract. Value measurement is a thorny problem in many kinds of transactions, but never more so than in the antagonistic collection of tax or tribute. In making these very difficult and nonintuitive trade-offs, and then executing them in a series of queries, audits, and collection actions, tribute collectors efficiently optimized their revenue, even if the results seemed quite wasteful to the tribute payer.Imagine a tribe collecting tribute from several neighbor tribes it previously defeated in war. It must estimate how much it can extract from each tribe. Bad estimates leave the wealth of some tribes understated, while forcing others to pay tribute based on estimates of wealth they don't actually have. The result: the tribes that are hurt tend to shrink. The tribes that benefit pay less tribute than could be extracted. In both cases, less revenue is generated for the victors than they might be able to get with better rules. This is an application of the Laffer curve to the fortunes of specific tribes. On this curve, applied to income taxes by the brilliant economist Arthur Laffer, as the tax rate increases, the amount of revenue increases, but at an increasingly slower rate than the tax rate, due to increased avoidance, evasion, and most of all disincentive to engage in the taxed activity. At a certain rate due to these reasons tax revenues are optimized. Hiking the tax rate beyond the Laffer optimum results in lower rather than higher revenues for the government. Ironically, the Laffer curve was used by advocates for lower taxes, even though it is a theory of tax collection optimum to government revenue, not a theory of tax collection optimal to social welfare or individual preference satisfaction.On a larger scale, the Laffer curve may be the most important economic law of political history. Charles Adams[A90] uses it to explain the rise and fall of empires. The most successful governments have been implicitly guided by their own incentives \u2013 both their short-term desire for revenue and their long-term success against other governments \u2013 to optimize their revenues according to the Laffer Curve. Governments that overburdened their taxpayers, such as the Soviet Union and later Roman Empire, ended up on the dust-heap of history, while governments that collected below the optimum were often conquered by their better-funded neighbors. Democratic governments may maintain high tax revenues over historical time by more peaceful means than conquering underfunded states. They are the first states in history with tax revenues so high relative to external threats that they have the luxury of spending most of the money in non-military areas. Their tax regimes have operated closer to the Laffer optimum than those of most previous kinds of governments. (Alternatively, this luxury may be made possible by the efficiency of nuclear weapons in deterring attack rather than the increased incentives of democracies to optimize to tax collection). When we apply the Laffer curve to examining the relative impact of treaty tributterms on various tribes, we conclude that the desire to optimize revenues causes victors to want to accurately measure the income and wealth of the vanquished. Measuring value is crucial to determining the tributaries' incentives to avoid or evade the tribute by hiding wealth, fight, or flight. For their part, tributaries can and do spoof these measurements in various ways, for example by burying collectibles in caches. Tribute collection involves a measurement game with unaligned incentives.With collectibles, one can demand tribute at strategically optimal times instead of when items can be supplied by the tributary or is in demand by the victor. The victors can then choose when they will in the future consume the wealth, rather than having to consume it at the time the tribute is extracted. Much later, well into the dawn of history, in 700 BC, though trade was widespread, money still took the form of collectibles \u2013 made out of more precious metals, but in their basic characteristics, such as lack of uniform value, similar to most of the proto-money used since the dawn of Homo sapiens sapiens. This was changed by a Greek-speaking culture in Anatolia (modern Turkey), the Lydians. Specifically, the kings of Lydia were the first major issuers of coins in the archaeological and historical record.From that day to this, government mints with self-granted monopolies, rather than private mints, have been the main issuers of coin. Why wasn't minting dominated by private interests, such as private bankers, which did exist at the time in these semi-market economies? The main explanation for government dominance of coin minting has been that only governments could enforce anti-counterfeiting measures. However, they could have enforced such measures in protection of competing private mints, just as they enforce trademarks today and at that time as well.It was far easier to estimate the value of a coin than that of a collectible \u2013 especially at low transaction values. Far more trades could be made with money instead of barter; indeed many kinds of low-value trades became possible for the first time as the small gains from trade for the first time exceeded transaction costs. Collectibles were low velocity money, involved in a small number of high value transactions. Coins were high velocity money, facilitating a large number of low value trades.Given what we have seen about the benefits of proto-money to tribute and tax collectors, as well as the critical nature of the value measurement problem in optimally coercing such payments, it is not surprising that tax collectors, specifically the kings of Lydia, were the first major issuers of coinage. The king, deriving his revenue from tax collection, had a strong incentive to measure to value of wealth held and exchanged by his subjects more accurately. That the exchange also benefited from cheaper measurement by traders of the medium of exchange, creating something closer to efficient markets, and allowing individuals to enter into the marketplace on a larger scale for the first time, was for the king a fortuitous side effect. The greater wealth flowing through markets, now available to be taxed, boosted the king's revenues even beyond the normal Laffer curve effect of reducing mis-measurement between given tax sources.This combination of more efficient tax collection with more efficient markets meant a vast increase in overall tax revenues. These tax collectors almost literally hit a gold mine, and the wealth of Lydian kings Midas, Croesus, and Giges is famous to this day.A few centuries later, the Greek king Alexander the Great conquered Egypt, Persia and much of India, funding his spectacular conquest by plundering Egyptian and Persian temples, filled with assemblages of low-velocity collectibles, and melting them down into high-velocity coins. More efficient and encompassing market economies as well as more efficient tax collection sprung up in his wake.Tribute payments did not form by themselves a closed loop of collectibles. These were only valuable if they ultimately could be used by the victors for something else, such as marriage, trade, or collateral. However, victors could coerce the vanquished into manufacturing for obtaining collectibles, even if it did not serve the vanquished's voluntary interests.Ancient hunter-gatherers did not have our modern tort or criminal law, but they did have an analogous means of settling disputes, often judged by clan or tribal leaders or vote, that covered what modern law calls crimes and torts. Settling disputes through punishments or payments sanction by the clans of the disputing parties substituted for cycles of revenge or vendetta wars. Most pre-modern cultures, ranging from the Iriquois in America to the pre-Christian Germanic peoples, decided that payment was better than punishment. Prices (e.g. the Germanic \"weregeld\" and Iriquois blood money) were assigned to all actionable offenses, ranging from petty theft to rape to murder. Where money was available, the payment took the form of money. Livestock was used in herding cultures. Otherwise, payment of collectibles were the most commonly used remedy.The payment of remedies for damages in a lawsuit or similar complaint led to the same kind of problem of triple coincidence of event, supply, and demand as occurred in inheritance, marriage, and tribute. The judgment of the case had to coincide with the ability of the plaintiff to pay the damages as well as the opportunity and desire of the defendant to benefit from them. If the remedy was a consumable the plaintiff already had plenty of, the remedy still served as a punishment but would not likely satisfy the defendant \u2013 and thus would not curb the cycle of violence. Thus, we here again the value added by collectibles \u2013 in this case, in making possible the remedy to resolve a dispute or terminate a cycle of revenge.Dispute remedies would not form a closed loop if the payments served to entirely eliminate vendettas. However, if the payments did not completely dampen the vendetta, the payments could form a cycle following the cycle of revenge. For this reason, it is possible that the institution reached an equilibrium when it had reduced but not eliminated cycles of revenge until the advent of more densely connected trading networks.Since humans evolved in small, largely self-sufficient, and mutually antagonistic tribes, the use of collectibles to reduce the need for favor-tracking, and to make possible the other human institutions of wealth transfer we have explored, was far more important than the scale problems of barter for most of the timespan of our species. Indeed, collectibles provided a fundamental improvement to the workings of reciprocal altruism, allowing humans to cooperate in ways unavailable to other species. For them, reciprocal altruism is severely limited by unreliable memory. Some other species have large brains, build their own homes, or make and use tools. No other species has produced such an improvement to the workings of reciprocal altruism. The evidence indicates this new development had matured by 40,000 B.P.Menger called this first money an \"intermediate commodity\" \u2013 what this paper calls collectibles. An artifact useful for other things, such as cutting, could also be used as a collectible. However, once institutions involving wealth transfer became valuable, collectibles would be manufactured just for their collectible properties. What are these properties? For a particular commodity to be chosen as a valuable collectible, it would have had, relative to products less valuable as collectibles, at least the following desirable qualities:Humans the world over are strongly motivated to collect items that better satisfy these properties. Some of this motivation probably includes genetically evolved instincts. Such objects are collected for the sheer pleasure of collecting them (not for any particularly good explicit and proximate reasons), and such pleasure is nearly universal across human cultures. One of the immediate proximate motivations is decoration. According to Dr. Mary C. Stiner, an archaeologist at the University of Arizona, \"Ornamentation is universal among all modern human foragers.\"[W02] For an evolutionary psychologist, such a behavior that has a good ultimate explanation, in terms of natural selection, but has no proximate rationale other than pleasure, is a prime candidate to be a genetically evolved pleasure that motivates the behavior. Such is, if the reasoning in this essay is correct, the human instinct to collect rare items, art, and especially jewelry.Point (2) requires some further explanation. At first, the production of a commodity simply because it is costly seems quite wasteful. However, the unforgeably costly commodity repeatedly adds value by enabling beneficial wealth transfers. More of the cost is recouped every time a transaction is made possible or made less expensive. The cost, initially a complete waste, is amortized over many transactions. The monetary value of precious metals is based on this principle. It also applies to collectibles, which are more prized the rarer they are and the less forgeable this rarity is. It also applies where provably skilled or unique human labor is added to the product, as with art.We have never discovered or made a product that does really well on all three scores. Art and collectibles (in the sense that word is used in modern culture, rather in the technical sense it is used in this paper) optimize (2), but not (1) or (3). Common beads satisfy (1) but not (2) or (3). Jewelry, made at first out of the most beautiful and less common shells but eventually in many cultures out of precious metals, comes closer to satisfying all three properties. It is no coincidence that precious metal jewelry usually came in thin forms such as chains and rings, allowing for inexpensive assaying at randomly chosen locations. Coins were a further improvement \u2013 substituting small standard weights and trademarks for assays greatly reduced the costs of small transactions using precious metals. Money proper was just a further step in the evolution of collectibles.The kind of mobile art also made by Paleolithic man, (small figurines and the like) also matches these characteristics well. Indeed, Paleolithic man made very few objects that were not either utilitarian, or shared characteristics (1)-(3).There are many puzzling instances of useless or at least unused flints with homo sapiens. We have mentioned the unusable flints of the Clovis people. Culiffe[C94] discusses a European Mesolithic era find of hundreds of flints, carefully crafted, but which micrograph analysis reveals were never used for cutting.Flints were quite likely the first collectibles, preceding special-purpose collectibles like jewelry. Indeed, the first flint collectibles would have been made for their cutting utility. Their added value as a medium of wealth transfer was a fortuitous side effect that enabled the institutions described in this article to blossom. These institutions, in turn, would have motivated the manufacture of special-purpose collectibles, at first flints that need have no actual use as cutting tools, then the wide variety of other kinds of collectibles that were developed by Homo sapiens sapiens.Shell money from Sumer, c. 3,000 B.C.During the Neolithic era, in many parts of the Middle East and Europe, some kinds of jewelry became more standardized \u2013 to the point where standard sizes and assayability were often valued over beauty. In commercial areas the quantity of this jewelry sometimes greatly exceeded that of traditional jewelry in hoards. This is an intermediate step between jewelry and coins, when some collectibles increasingly took a fungible form. Around 700 B.C., the Lydian kings started issuing coins, as described above. The unforgeable costliness of standard weights of precious metals could now be \"assayed\" in a marketplace, by wage earners, or by tax collectors via trademark, i.e. trust in the mint's brand, instead of chopping coiled wire at a randomly selected spot.It is no coincidence that the attributes of collectibles are shared with precious metals, coins, and the reserve commodities that have backed most non-fiat currencies. Money proper implemented these properties a purer form than the collectibles used during almost all of human prehistory.Silver ring and coil money from Sumer, c. 2,500 B.C. Note the standard size of cross-sections. Many of the pieces had a standard weight, ranging from one-twelfth of a shekel to sixty shekels. To assay a ring or coil, it could be weighed and cut at random locations. (Courtesy Oriental Institute, University of Chicago)A novelty of the 20th century was the issue of fiat currencies by governments. (\"Fiat\" means not backed by any reserve commodity, as the gold- and silver-based currencies of previous centuries were). While generally excellent as a media of exchange, fiat currencies have proven to be very poor stores of value. Inflation has destroyed many a \"nest egg\". It is no coincidence that markets in rare objects and unique artwork \u2013 usually sharing the attributes of collectibles described above \u2013 have enjoyed a renaissance during the last century. One of our most advanced high-tech marketplaces, EBay, is centered around these objects of primordial economic qualities. The collectibles market is larger than ever, even if the fraction of our wealth invested in them is smaller than when they were crucial to evolutionary success. Collectibles both satisfy our instinctive urges and remain useful in their ancient role as a secure store of value.Many kinds of wealth transfers \u2013 one-way and mutual, voluntary and coerced \u2013 face transaction costs. In voluntary trades both parties gain; a truly free gift is usually an act of kin altruism. These transactions create value for one or both parties as much as the physical act of making something. Tribute benefits the victor and a judgment of damages can prevent further violence as well as benefiting the victim. Inheritance made humans the first animals to pass wealth to their next generation kin. These heirlooms could in turn be used as collateral or payment in trade for goods, for food to stave off starvation, or to pay a marriage bride price. Whether the costs of making these transfers \u2013 transaction costs \u2013 are low enough to make the transfers worthwhile is another matter. Collectibles were crucial in making these kinds of transactions possible for the first time.Collectibles augmented our large brains and language as solutions to the Prisoner's Dilemma that keeps almost all animals from cooperating via delayed reciprocation with nonkin. Reputational beliefs can suffer from two major kinds of errors \u2013 errors of about which person did what, and errors in appraising the value or damages caused by that act. Within clans (the small and immediately local kin group, or extended family, which formed a subset of a tribe), our large brains could minimize these errors, so that public reputation and coercive sanctions superseded the limited motivation provided by the counterparty's ability to cooperate or defect in the future as the main enforcer of delayed reciprocation. In both Homo sapiens neanderthalensis and Homo sapiens sapiens, with the same large brain size, it is quite likely that every local clan member kept track of everybody other local clan member's favors. The use of collectibles for trade within the small local kin group may have been minimal. Between clans within a tribe both favor tracking and collectibles were used. Between tribes, collectibles entirely replaced reputation as the enforcer of reciprocation, although violence still played a major role in enforcing rights as well as being a high transaction cost that prevented most kinds of trade.When costliness becomes forgeable \u2013 Glass trade beads, manufactured in Venice in the 16th or 17th century, excavated from Mali, Africa. Such beads were very popular wherever European colonialists encountered Neolithic or hunter-gatherer cultures.To be useful as a general-purpose store of wealth and means of wealth transfer, a collectible had to be embedded in at least one institution with a closed-loop cycle, so that the cost of discovering and/or manufacturing the object was amortized over multiple transactions. Furthermore, a collectible was not just any kind of beautiful decorative object. It had to have certain functional properties, such as the security of being wearable on the person, compactness for hiding or burial, and unforgeable costliness. That costliness must have been verifiable by the recipient of the transfer \u2013 using many of the same skills that collectors use to appraise collectibles today.The theories presented in this paper can be tested by looking for these characteristics (or the lack of them) in the \"valuables\" often exchanged in these cultures, by examining the economic gains from the cycles through which these valuables move, and by observing preferences for objects with these characteristics in a wide variety of cultures (including modern ones).With its unprecedented technology of cooperation, humans had become the most fearsome predator ever seen on the planet. They adapted to a shifting climate, while dozens of their large herd prey were driven, by hunting and climate change in America, Europe, and Asia, to extinction. Today, most large animals on the planet are afraid of projectiles \u2013 an adaption to only one species of predator [R97]. Cultures based more on gathering than hunting also greatly benefitted. A population explosion followed \u2013 Homo sapiens sapiens was able to populate more parts of the planet and at a density over ten times that of Homo sapiens neanderthalensis [C94], despite weaker bones and no increase in brain size. Much of this increase may be attributed to the social institutions made possible by effective wealth transfer and language \u2013 trade, marriage, inheritance, tribute, collateral, and the ability to assess damages to dampen cycles of vengeance.Primitive money was not modern money as we know it. It took on some of the function modern money now performs, but its form was that of heirlooms, jewelry, and other collectibles. The use of these is so ancient that the desires to explore, collect, make, display, appraise, carefully store, and trade collectibles are human universals \u2013 to some extent instincts. This constellation of human desires might be called the collecting instinct. Searching for the raw materials, such as shells and teeth, and manufacturing of collectibles took up a considerable portion of many ancient humans' time, just as many modern humans expend substantial resources on these activities as hobbies. The results for our ancient forebears were the first secure forms of embodied value very different from concrete utility \u2013 and the forerunner of today's money.[A90] Adams, Charles, For Good and Evil: The Impact of Taxes on Civilization \u21a9[A98] Tim Appenzeller, \"Art: Evolution or Revolution?\", Science 282(Nov 20, 1998), p. 1452. See also the home page of Stanley Ambrose \u21a9 \u21a9[B04] The Blombos Cave Project \u21a9 \u21a9[C94] Culiffe, Barry, ed., The Oxford Illustrated History of Prehistoric Europe, Oxford University Press 1994. \u21a9 \u21a9 \u21a9 \u21a9 \u21a9[D89] Dawkins, Richard, The Selfish Gene, Oxford University Press 1989. \u21a9 \u21a9 \u21a9[D94] Davies, Glyn, A History of Money, From Ancient Times to the Present Day, University of Wales Press 1994. \u21a9 \u21a9 \u21a9 \u21a9[DW88] Daly, Martin and Wilson, Margo, Homicide, New York: Aldine (1998). \u21a9 \u21a9[G95] Gilead, I. 1995. \"The Foragers of the Upper Paleolithic Period,\" in Archaeology and Society in the Holy Land. Ed. by T. E. Levy. New York, Facts on File. \u21a9[G01] [ref: http://www-geology.ucdavis.edu/~GEL115/115CH1.html] \u21a9[Gr01] Graeber, David, Towards an Anthropological Theory of Value, Palgrave 2001.[I98] Ifrah, Georges, The Universal History of Numbers, John Wiley & Sons 1998, pg. 73.[K99] Kohn, M. and Mithen, S. \"Handaxes: Products of sexual selection?\", Antiquity, 73, 518-526.[K99] Kohn, M. and Mithen, S. \"Handaxes: Products of sexual selection?\", Antiquity, 73, 518-526.[L94] Landa, Janet, Trust, Ethnicity, and Identity: Beyond the New Institutional Economics of Ethnic Trading Networks, Contract Law, and Gift-Exchange, The University of Michigan Press, second edition, 1998. \u21a9 \u21a9 \u21a9[M1892] Menger, Carl, \"On the Origins of Money\" Economic Journal, volume 2,(1892) p. 239-55. translated by C.A. Foley, at http://www.socsci.mcmaster.ca/~econ/ugcm/3ll3/menger/money.txt \u21a9[M50] Mauss, Marcel, The Gift, 1950, English translation by W.D. Halls, W.W. Norton 1990. \u21a9[M93] (Morse 1993) via http://www.wac.uct.ac.za/wac4/symposia/papers/s095wht1.pdf \u21a9[R96] Riddley, Matt, The Origins of Virtue, Viking 1996.[T01] Taylor, Alan, American Colonies \u2013 The Settling of North America, Penguin 2001. \u21a9 \u21a9[P89] Plattner, Stuart, Economic Anthropology, Stanford University Press 1989.[W77] Wiessner, P. 1977. Hxaro: a regional system at reciprocity for reducing risk among the !Kung San. Unpublished PhD thesis: University of Michigan. \u21a9[W82] Wiessner, P. 1982. Risk, reciprocity and social influences on !Kung San economies. In: Leacock, H. R. & Lee, R.B. (eds) Politics and history in band societies: 61-84. London: Cambridge University Press.[W95] White, Randall, \"Ivory Personal Ornaments of Aurignacian Age: Technological, Social and Symbolic Perspectives\", Institute For Ice Age Studies, http://www.insticeagestudies.com/library/Ivory/Ivorypersonal.html \u21a9[W97] White, Randall, \"From Materials To Meaning\", Institute For Ice Age Studies, http://www.insticeagestudies.com/library/materialstomeaning/index.html \u21a9[W98] Winterhalder, Bruce, \"Intra-Group Resource Transfers: Comparative Evidence, Models, and Implications for Human Evolution\", http://www.unc.edu/depts/ecology/winterweb/intra_group.html \u21a9[W02] Wilford, John, \"Debate is Fueled on When Humans Became Human\", New York Times, February 26th, 2002  \u21a9My thanks to Jerome Barkow, Andrew Odlyzko, Bruce Smith, K. Eric Drexler, Markus Krummenacker, Mark Wiley, Norm Hardy, and others for their insightful comments.Please send your comments to nszabo (at) law (dot) gwu (dot) eduCopyright \u00a9 2002, 2005 by Nick Szabo\nPermission to redistribute without alteration hereby grantedEditor's note: Some links may be broken."}
{"prompt": "The Ricardian Contract", "completion": "Describing digital value for payment systems is not a trivial task. Simplistic methods of using numbers or country codes to describe currencies, and ticker tape symbols to issue bonds, shares, and other financial instruments soon run into shortcomings in their ability to handle dynamic and divergent demands. The seemingly arbitrary variations in the meanings of different instruments are best captured as contracts between issuers and holders. Thus, the digital issuance of instruments can be viewed as the issuance of contracts.This paper proposes that the contract is the issue. A document form is described that encompasses the inherent contractual nature of the financial instrument yet copes with the requirements of being an integral part of a payment system.Little work has been done on classification and description of value in the field of financial cryptography. This paper presents the Ricardian Contract, a method to identify and describe issues of financial instruments as contracts[1]. It was originally developed by Ian Grigg and Gary Howland as part of the Ricardo payment system.The original application was a bond trading system[2]. For trading, a basic component is a transfer or payment system which receives and acts on transfer instructions to move instruments (cash, bonds) from one account to another. Each instruction therefore must identify the instrument.A means was required to capture, identify, and describe the traded instruments. There are thousands of bonds, and potentially millions of other instruments that could be issued and traded, and each has unique characteristics that are not amenable to compression into databases. To such a system, cash is no different to bonds, and requires the same description.When someone issues a currency (or bond or share) over the Internet, what is it? What does the recipient have?Few systems for issuance of value (payment systems) treat these questions adequately. They generally refer to existing external units of currency and tidy up loose edges in a user agreement. For example, Paypal, an issuer of dollars, relies on the familiarity of the US dollar to define much of its service offering. Gold issuers lean more heavily on their user agreements as the metal unit is not so familiar.For trading, it is not sufficient to refer to well-known familiar references, as each instrument is different in finicky ways and these differences matter to traders. Even with currencies, however, the user has difficulty in determining the security and safety of one dollar with respect to another.Classification by numbers or symbols is a starting point. Almost all systems of digital issuance identify their basic issue by allocating numbers or letters as currencies (for example, 840, \"USD\", \"AUG\" [3]). These systems runs into trouble quickly.An issuer with many currencies or many issuers with the same nominal currency raises difficult questions. Can an issuer have two or more dollar units? For example, within ISO3166-1, there are three different US dollars: 840/USD (cash), 998/USS (same day), and 997/USN (next day). Similarly, how does one Digital Gold Currency (\"DGC\") differentiate his gold over that of another issuer, when all are known as \"AUG\"?As bonds are, at their essence, contracts between issuers and users, our problem reduces to one of issuing contracts. Whereas other issues have contracts, our issues are contracts.Our innovation is to express an issued instrument as a contract, and to link that contract into every aspect of the payment system. By this process, a document of some broad utility (readable by user and program) is drafted and digitally signed by the issuer of the instrument. This document, the Ricardian Contract, forms the basis for understanding an issue and every transaction within that issue.By extension, all issues of value, such as currencies, shares, derivatives, loyalty systems and vouchers, can benefit from this approach.This paper is structured as follows. In Section 2, we discuss conventional approaches to identifying and describing issuance, and explore questions and doubts surrounding these approaches. Then, in Section 3, a design to express issuance as a contract is presented. Finally, in Section 4, concluding remarks are added.Consider the case of the pioneering digital cash scheme, eCash, as originally fielded by DigiCash BV. The first valuable currency, issued by Mark Twain Bank of the USA, was identified with the number 4. Lore has it that the early system allocated a small sequential number to each currency. Test systems had already acquired 0,1,2,3 and thus 4 was the next. DigiCash's marketing assumptions then changed to assume one issue per country. In time, this scheme was adjusted to issue currencies numbered after international dialling codes (e.g., 49 for Germany, 61 for Australia). The shortfalls of this scheme became apparent, so a new design was created [4]. One 32 bit number to describe the issue was used, on the pragmatic assumption that this would be large enough to cover foreseeable eventualities.Yet the strains of one issuer, one currency were obvious almost immediately. A more advanced scheme could use a tuple of (issuer, currency) to describe a system whereby each issuer is empowered in some sense to issue multiple competing currencies[5]. It is easy to generalise this system by adding additional elements to the tuple: (issuer, type, identifier) tuple[6]. For example, a zero coupon bond issued by the Joint Universal and Nationwide Keiretsu that pays out in January of 2100 might have a tuple of (JUNK, zero, Jan_2100).Numbers as a space for identifying digital instruments are limiting, and having tuples as an extension is not really an answer.Firstly, what do they describe? In the case of electronic cash systems, they can describe currencies and issuers. Is it one or both, and how do we generalise to other aspects? Secondly, what surety do we have that what is described is accurate? Whilst a lot can be achieved by simply relying on the reputation of the issuer, financial insiders know that the real value is expressed in the detail and the reliability of the claim. Thirdly, how are the numbers derived? Is a central registry required, or can any issuer of digital value acquire a number as per local requirements? Finally, is there a limit to the space? Integer numbers as expressed in packets are generally limited to some quantity of bits, such as 32. For practical software engineering, there need to be limits, but do these limits need to limit the business possibilities?Any successful system will be used in ways that make it appear to be broken. As software engineers, we need to present our inventions with the humility of toolmakers for future generations of builders, not as bureaucrats planning the zoning of the digital commerce space.What happens when we have gone through the early adopters, dominated the moms and pops, and competition is fiercely turning onto our elderly retired set? Imagine mints in the pockets of billions of idle game-playing senior citizens. Or, imagine a world with an issuer of digital loyalty points on every parking meter, or where students must pay for tuition with shares of future earnings. Already we have seen popular musicians selling bonds backed by their music[7], and proposals for software bug fixes financed by securitized issues to anonymous users[8].Consider the zero coupon bond, an instrument that pays a face value of a currency on a given date. The zero is perhaps the simplest general financial instrument in common use, and it formed the benchmark for our design.To describe the face value, the currency of the face value, and the expiry date of this bond, we would add additional elements to the above tuple. But this is only a beginning. In his description of Eurobonds, Noel Clarke expects dozens or hundreds of fields[9]. If we examine just one of these characteristics, for example Event-Related Put Options, we find that a bond needs to describe what happens in the event of:These items bind tightly to the instrument in question, but they represent difficulties to the software architect. We can make a number of observations.Firstly, each event is not simple. Today, one may be able to shoehorn the notion of \"a hostile or friendly takeover\" into a single name-value pair, but this would not survive the evolving scene of regulation and litigation that applies to such events.Secondly, there is no reason to believe that the above list is complete.Thirdly, not only is it going to be hard to design a single field of any sort to cope with these, they are mostly going to be full of legal text.Consider a data layout point of view. To describe the document that forms the basis of a bond we will need a tree-structured database of tuples, as a minimum. More, that layout is only going to work for one instrument, or one extremely tight, nearly fungible set of instruments.Currencies, or cash, might be that tight set. After all, a dollar is a dollar is a dollar. Can we describe money with some simple set of tuples? Even for cash, we argue that a layout of tuples is not sufficient.Take the case of a digital dollar issued by a bank. The digital dollars would be derivatives, often backed by deposits in the same amount. This may be sufficient for marketing purposes but it would not survive a serious financial analysis.Compare such derivative dollars to those issued by the US Federal Reserve Board. The Fed has yet to deny acceptance of its notes if presented with same, if only as a claim on another bunch of the same instrument, or for taxation liabilities. Radical interpretations aside, the Fed has never filed for bankruptcy and remains a pretty solid bet.The same cannot be said of just any bank issuer of derivative dollars. Its digital dollars would be backed by deposits with ... the very same institution. Such a bank can close its doors at any time, and, given the history of the banking sector in the 20th Century, an analyst should take this risk seriously. Further, in the USA at least, the FDIC has already ruled that funds so held on a user's PC are considered to be uninsured deposits[10].This is not to suggest that any given bank is about to close doors, but to ask what happens when an issuer does indeed default on its promise?Any holder of any asset will carry a risk. A holder of electronic dollars will carry the risk that the issuer fails, and the holder of another issuer's dollars carries a similar, comparable, but distinct risk. Each of those risks result in a cost, which should be subtracted from the face value of the dollar to calculate a comparative value. In this risk distinction lies the inescapable fact that any given dollar is not of constant value, even when measured against some well-known dollar such as that issued by the Federal Reserve.If there is no such thing as a single dollar, what is left? Clearly, we must describe each and every dollar for what it is. This would seem to be a task of fine print and detail, and, indeed, every distinct issued currency is a distinct contract between the issuer and the holder.A contract can encapsulate the detail. Consider the original sovereign currency contracts, in which the issuer promised to pay the bearer in ounces of precious metal. That is four datum in the contract already: which sovereign, \"pay to bearer,\" what to pay, and how much of it.So it is with every bond, every currency, and any financial instrument of any complexity. In fact, within the digital domain, the question of how to treat a financial instrument reduces in great part to how to treat a contract.Or, an issue is a contract. Issues within other payment systems have contracts but only as adjunct documents such as user agreements. Often, their role and importance is subject to battles; marketing wants them hidden, while Legal asks for them to be thrust in the user's face at all times.Once we accept that the issue is a contract, the task becomes simple: create a contract that can be linked into the payment system as the centerpiece. That is the subject of the next section.Almost all aspects of Ricardian Contracts are best seen by examining examples, and this section only briefly covers the salient details, before discussing the ramifications. Examples can be found at webfunds.org/ricardo/contracts/ .A Ricardian Contract can be defined as a single document that is a) a contract offered by an issuer to holders, b) for a valuable right held by holders, and managed by the issuer, c) easily readable by people (like a contract on paper), d) readable by programs (parsable like a database), e) digitally signed, f) carries the keys and server information, and g) allied with a unique and secure identifier.In the simplest possible terms, a Ricardian Contract is a document defining a type of value for issuance over the Internet[11]. It identifies the Issuer, being the signatory, and any terms and clauses the Issuer sees fit to add in to make the document stand as a contract.The same document has to be both readable by people and parsable by programs. The Ricardian Contract is formatted as a text file that can be easily read (displayed or printed), and programs can convert it into internal forms for searching for name-value pairs. It includes a special section for each type of contract, such as bond, share, currency, etc. Further sections within describe, in program-parsable terms, usage of decimal points, titles, and symbols.As legal signatory, the Issuer signs the document in the OpenPGP cleartext form with his contract signing key[12]. He includes the full chain of OpenPGP keys within the document to permit programs to directly verify and authenticate.To uniquely identify the contract, any user can calculate a canonical message digest over the clearsigned document. This message digest is included in all records of transactions, and provides a secure (unforgeable) link from the document to the accounting of the issue.E.g., e3b445c2a6d82df81ef46b54d386da23ce8f3775 is the full message digest for Systemics Inc's issue of prepaid services dollars. Commonly called a hash, the message digest is a cryptographic technique to create a relatively small number that is one to one with the document. That is, for each document, there is only one hash, and the hash refers uniquely to that document. The algorithm is the well-known standard, SHA1.The following observations highlight how strong the result is.Hash Limits Frog-Boiling. A gradual change in contract by the stronger party over time is known as frog-boiling. The stronger party is generally the issuer, and can be expected to change the contract if there is a benefit. This is a frequent attack. One result of the use of the hash identifier is that neither party can change the contract arbitrarily or surreptitiously.To see this is true, we need to examine the records that refer to the hash. An application can sign all important records (e.g., payments, tokens, receipts, balances), and these signed records include the hash of a Ricardian Contract. The hash within the record cannot be changed without losing its ability to pass a test of signature validity. Likewise, the contract cannot be changed without losing its relationship to records already signed and delivered. In other words, every record, held by every user, incorporates an unalterable copy of that hash. Any change to the contract creates a new hash, and that new hash is not the one which the users have or value.This crystallises the contract for both parties, stopping the stronger party from modifying the contract subtly at some later stage. To some extent, this redresses the imbalance of power between provider and customer in the offering of a form contract. The lesser party has no option to negotiate, but neither has the greater party the option to claim a distinct contract at a later time. The limitation comes at some cost as it can be a nuisance for the support team of that financial instrument.The Ricardian PKI Delivers Clarity. Ricardian Contracts carry their own Public Key Infrastructure (\"PKI\") with them. The Issuer's top level public key is included in the contract, and it signs his contract-signing key, also included. The contract-signing key signs the contract itself.This achieves several things. Firstly, client software can check the entire digital signature chain in one automated sequence.Secondly, there is no need for a complex multi-party PKI. All the keys are present, and there is no need to go looking for them on the net. This eliminates substitution attacks, whereby a key that might pass some checks could be inserted in some key lookup phase. It also reduces costs dramatically.Thirdly, the canonical hash of the contract also represents a signature on the contract. It is recorded in all relevant records, and thus entangles the contract with those activities[13]. Once the contract has been in play for a while, it establishes its provenance through presence and reliance by the user public. This provides far more persuasive evidence than the issuer's signature itself; once the issuer and the public have spent time and money relying on the contract, via the hash, it is hard for the issuer to renege on the nature of the contract or his signature.The result is a PKI that delivers strong end-to-end reliability, based on a single document. This is simply not present in other designs for PKIs[14]. This reliability pays off in the dispute resolution phase, where, we suggest, the Ricardian Contract can stand alone on its merits and requires no complex descriptions of PKI, digital signatures, or references to uncertain third parties to bolster its provenance. By including the keys, we can draw a couple of simple lines within the contract, asserting \"this key signs that key, and that latter signs the contract. The first key is the top-level key of the individual that signed this contract. That's the whole story, mi'lud.\"Validating the Issuer's Key. All good crypto protocols divide into two parts, the first of which says to the second, \"trust this key completely.\"The top-level key of the Issuer ultimately authenticates the contract. The keys and other information in the contract also permit a protocol such as SOX to bootstrap a strongly secured connection to the server[15].How then to verify that this ultimate key is really the Issuer's? This is not difficult. The business process of digital issuance involves a great deal of relationship-building between Issuers and Users. Many different interactions involve chances to establish trust. For example, from his web site, the Issuer can publish the contract, keys and hashes, and have other sites mirror them. The value so issued will be distributed via payments that include the hash. An already trusted party usually delivers these payments. The payments validly identify the contract, and derive their own validity, via the hash.Contrast this to assumptions in the x.509 PKI behind SSL/HTTPS browsing (the following is highly debatable, but is presented for comparison only). In that PKI, it was originally claimed that a user would present her credit card to sites with which she had no prior relationship and no way for her to establish the provenance of the site's key. Thus, a trusted third party, the Certificate Authority, was put in place to confirm the key.Payments, trading and matters of finance are fundamentally relationship-rich. The nature of money and finance is that participants always conduct their own due diligence, they prefer to listen to peers they already trust, and do not readily accept the word of an independent party. Thus, there is no place for a central third party to stand in and authenticate players. Before the user desires to place any value on a given payment, she has almost certainly been made aware of the contract via other means.Presumption of Possession. The use of the hash as an identifier is a compromise as it is unintelligible to humans[16]. Yet this very compromise delivers an unexpected benefit: Use of the issue leads to a presumption that the user has the contract. To use an issue of value, such as a currency, the user must have the hash in the applicable records. That is, if the user receives a payment, that payment record will include the hash. As the hash is not descriptive, this implies that the user has the contract in order to interpret the issue.To see that this is true, imagine having a record with the hash but without having the contract. The first thing the user will need is a database of parameters telling her what the hash refers to. Unlike a payment in 10 of \"GBP\", a payment of 1000 in \"972097bb...\" is not intelligible.Yet how could software predict what the user needs to know about the hash? Very quickly it becomes apparent that the software is better off storing the source of the information \u2013 the full contract itself \u2013 as it removes an unlimited degree of complexity in storing intermediate or secondary information.Software can still function with only the hash. However, it would be entirely blind to the semantics of the instrument. Such a cavalier approach might be acceptable for communications and storage, but for user software, it is equivalent to a traumatic failure. To cope with this, the client-side software takes especial care to acquire and keep contracts. Hence, we can state the presumption with some degree of confidence: in a functioning system, the user has available the full Ricardian Contract (albeit under software control).This is only a small step for the client software, but is a giant leap forward for the relationship between the issuer and the holder. Specifically, having a strong presumption that the user has the full contract available will simplify many legal aspects about the issuer's responsibilities. (We suggest and thus acknowledge the legal ramifications of the term presumption, but neither space nor expertise permits more in this paper.)The Ricardian Contract delivers a rich source of primary, complete information. The full story is right there in textual form, in parsable parameters, and in the signature chain. Thus, within a dispute, a hostile legal attack has less room to manoeuvre, and can only confirm the facts as laid out in the contract.Our intent is that the contract is the beginning and the end of the discussion; we call this principle the rule of one contract. The legal fraternity refers to \"the contract being bounded by the four corners of the page.\" By showing how we have carefully laid out a readable document, with a verifiable digital signature, and an unforgeable identifier linking to every record, we can more readily ask the judiciary to accept that the single document which is being presented is indeed the valid contract agreed to by the parties.The contract is the keystone of issuance[17]. Our innovation is to express all the salient details of an issuance as an unforgeable contract, unforgeably linked into every action within a payment system. In this way, financial innovation can develop along the lines it always has done \u2013 by means of innovation within contracts. By translating the institution of the contract into the digital domain, we build upon centuries' and even millenia' worth of experience in documenting, sharing and disputing the meaning of agreements between parties.To capture complexity, we can put documents such as contracts into electronic form and sign them using digital signature technologies such as OpenPGP. The result is a reasonable analogue of the paper and ink contracts that most people and businesses are familiar with, bolstered with cryptographic integrity.With the hash as the identifier, software can now uniquely identify a given financial arrangement and can confirm a strong chain of signatures. The hash strongly implies the user has the contract available at all times, and it cannot be changed without being noticed.The Ricardian Contract delivers one huge benefit to the issuer \u2013 clarity in many legal and customer support questions. The user benefits from lower overall costs, and better presentation of information, within a more consistent framework.The form has been in successful use since 1996. Since that time, it has delivered about 20 financial instruments without failure.Disputes. The Ricardian Contract has appeared in two distinct forums of dispute resolution to resolve claims[18]. Anecdotally, each claim was resolved directly and efficiently, and without undue fuss, simply by referring to the applicable Ricardian Contract.Automation. Relatively little has needed to be automated. In practice, fields have been inserted and standardised so that programs can extract decimalisation (dollars versus cents), labels for units (USD versus $), and titles for the issuer and the issue. In contrast to expectations, there has been no demand to parse every field.Cost. The cost of the concept has compared favourably with that incurred with other payment systems. The preparation of the contract text carries some costs, but no more so than a user agreement. OpenPGP infrastructure requirements (keys and signing) add some minor costs to issuers but they are easily offset by the benefits of risk reduction from contract distribution. Custom signing editors have helped to reduce those costs[19].Layering. Layering of contracts is an impending need. Many businesses can take a standard and defined set of terms and draw on them directly. Other contracts result from earlier contracts and need to reference them.XML. Initial efforts suggested that XML would break the rule of one contract, but it seems that we will need something better than the archaic INI format[20]. One recent proposal, the XML Voucher, stops short of presenting itself as a contract[21].Law of Contract. The treatment of the Ricardian Contract as a contract may raise more legal questions than it answers. For example, is this form indeed a contract? How do distinct jurisidictions view the concept (common law, civil law, UCC, Koranic code)? Is this a negotiated or a form contract? When did the user accept the contract? How strong, or rebuttable, is the presumption that the user has the contract?Smart Contracts. By unifying all information in a program-readable file, there is the enhanced potential of smart contracts[22]. We have not gone further in this direction than methods to handle decimals. This is partly for lack of demand, and partly because it is not clear how a court would treat a computer program presented as a contract.Originally introduced in Ian Grigg, \"Financial Cryptography in 7 Layers,\" 4th Conference on Financial Cryptography, Anguilla, 2000, Springer-Verlag LNCS 1962. All papers are at http://iang.org/papers/ \u21a9Ian Grigg, \"Digital Trading,\" Virtual Finance Report, November 1997. \u21a9Country and Currency Codes, ISO3166-1. \u21a9Bryce Wilcox, open design review, DigiCash's developer list, <ecash-dev@digicash.com>, August 1997. \u21a9Ibid, Rachel Willmer, 14 August 1997. \u21a9Robert Hettinga, \"What's a Digital Bearer Bond?\" e$ rants, 19th November, 1995 \u21a9Alex Tajirian, \"David Bowie Bonds,\" \u21a9Ian Grigg and C. Petro, \"Using Electronic Markets Achieve Efficient Task Distribution,\" 1st Conference on Financial Cryptography, Anguilla, 1997, Springer-Verlag LNCS 1318. \u21a9Noel Clarke, Guide to Eurobonds, The Economist Intelligence Unit, 1993. \u21a9FDIC General Counsel's Opinion No. 8; Stored Value Cards, Federal Register, August 2, 1996. Also see the (readable) Press Release entitled FDIC will Continue to rely on General Counsel Opinion rather than issue rules on Stored-Value Cards, 24 June 97. \u21a9Ian Grigg, Guide to Ricardian Contracts, WebFunds project. \u21a9Jon Callas, et al, \"OpenPGP Message Format,\" Internet Draft, RFC2440bis (-10 draft). \u21a9Petros Maniatis, Mary Baker \"Secure History Preservation through Timeline Entanglement\", 11th USENIX Security Symposium, San Francisco, USA. August 2002. \u21a9Jane K. Winn, \"Couriers without Luggage\" 49 South Carolina Law Review 739 (1998) \u21a9Gary Howland, \"Development of an Open and Flexible Payment System\" 1996. \u21a9Bryce Wilcox, \"Names: Decentralized, Secure, Human-Meaningful: Choose Two\", 2003 \u21a9Metaphor by Martin (Hasan) Bramwell. See \"The Contract is the Keystone of Issuance,\" Financial Cryptography blog, 19th September 2003. \u21a9DigiGold v. Systemics, before the Supreme Court of Anguilla (2001), and thereafter referred to the American Arbitration Association (2002). \u21a9Edwin Woudt, ContractSignWizard, WebFunds project. \u21a9Erwin van der Koogh, \"Ricardian Contracts in XML,\" (presented at) Edinburgh Financial Cryptography Engineering (EFCE-2), 2001. \u21a9Ko Fujimura and Masayuki Terada, XML Voucher: Generic Voucher Language, Internet Draft. \u21a9Nick Szabo, \"The Idea of Smart Contracts,\" 1997. \u21a9Ian Grigg\nSystemics, Inc.\niang@iang.org"}
{"prompt": "Triple Entry Accounting", "completion": "The digitally signed receipt, an innovation from financial cryptography, presents a challenge to classical double entry bookkeeping. Rather than compete, the two melded together form a stronger system. Expanding the usage of accounting into the wider domain of digital cash gives 3 local entries for each of 3 roles, the result of which I call triple entry accounting.This system creates bullet proof accounting systems for aggressive uses and users. It not only lowers costs by delivering reliable and supported accounting, it makes much stronger governance possible in a way that positively impacts on the future needs of corporate and public accounting.This paper brings together financial cryptography innovations such as the Signed Receipt with the standard accountancy techniques of double entry bookkeeping.The first section presents a brief backgrounder to explain the importance of double entry bookkeeping. It is aimed at the technologist, and accountancy professionals may skip this. The second section presents how the Signed Receipt arises and why it challenges double entry bookkeeping.The third section integrates the two together and the Conclusion attempts to predict wider ramifications into Governance issues.This paper benefitted from comments by Graeme Burnett and Todd Boyle[1].Accounting or accountancy is these days thought to go back to the genesis of writing; the earliest discovered texts have been deciphered as simple lists of the counts of animal and food stock. The Sumerians of Mesopotamia, around 5000 years ago, used Cuneiform or wedge shaped markings as a base-60 number form, which we still remember as seconds and minutes, and squared, as the degrees in a circle. Mathematics and writing themselves may well have been derived from the need to add, subtract and indeed account for the basic assets and stocks of early society.Single entry bookkeeping is how 'everyone' would do accounting: start a list, and add in entries that describe each asset. A more advanced arrangement would be to create many lists. Each list or 'book' would represent a category, and each entry would record a date, an amount, and perhaps a comment. To move an asset around, one would cross it off from one list and enter it onto another list.Very simple, but it was a method that was fraught with the potential for errors. Worse, the errors could be either accidental, and difficult to track down and repair, or they could be fraudulent. As each entry or each list stood alone, there was nothing to stop a bad employee from simply adding more to the list; even when discovered there was nothing to say whether it was an honest mistake, or a fraud.Accounting based on single entry bookkeeping places an important limitation on the trust of the books. Likely, only the owner's family or in times long past, his slaves could be trusted with the enterprise's books, leading to a supportive influence on extended families or slavery as economic enterprises.Double Entry bookkeeping adds an additional important property to the accounting system; that of a clear strategy to identify errors and to remove them. Even better, it has a side effect of clearly firewalling errors as either accident or fraud.This property is enabled by means of three features, being the separation of all books into two groups or sides, called assets and liabilities, the redundancy of the duplicative double entries with each entry having a match on the other side, and the balance sheet equation, which says that the sum of all entries on the asset side must equal the sum of all entries on the liabilities side.A correct entry must refer to its counterparty, and its counterpart entry must exist on the other side. An entry in error might have been created for perhaps fraudulent reasons, but to be correct at the local level, it must refer to its counterparty book. If not, it can simply be eliminated as an incomplete entry. If it does refer, the existence of the other entry can be easily confirmed, or indeed recreated depending on the sense of it, and the loop is thus closed.Previously, in single entry books, the fraudster simply added his amount to a column of choice. In double entry books, that amount has to come from somewhere. If it comes from nowhere, it is eliminated above as an accidental error, and if it comes from somewhere in particular, that place is identified. In this way, fraud leaves a trail; and its purpose is revealed in the other book because the value taken from that book must also have come from somewhere.This then leads to an audit strategy. First, ensure that all entries are complete, in that they refer to their counterpart. Second, ensure that all movements of value make sense. This simple strategy created a record of transactions that permitted an accountancy of a business, without easily hiding frauds in the books themselves.Double Entry bookkeeping is one of the greatest discoveries of commerce, and its significance is difficult to overstate. Historians think it to have been invented around the 1300s AD, although there are suggestions that it existed in some form or other as far back as the Greek empire. The earliest strong evidence is a 1494 treatise on mathematics by the Venetian Friar Luca Pacioli[2]. In his treatise, Pacioli documented many standard techniques, including a chapter on accounting. It was to become the basic text in double entry bookkeeping for many a year.Double Entry bookkeeping arose in concert with the arisal of modern forms of enterprise as pioneered by the Venetian merchants. Historians have debated whether Double Entry was invented to support the dramatically expanded demands of the newer ventures then taking place surrounding the expansion of city states such as Venice or whether Double Entry was an enabler of this expansion.Our experiences weigh in on the side of enablement. I refer to the experiences of digital money issuers. Our own first deployment of a system was with a single entry bookkeeping system. Its failure rate even though coding was tight was such that it could not sustain more than 20 accounts before errors in accounting crept in and the system lost cohesion. This occurred within weeks of initial testing and was never capable of being fielded. The replacement double entry system was fielded in early 1996 and has never lost a transaction (although there have been some close shaves[3]).Likewise, the company DigiCash BV of the Netherlands fielded an early digital cash system into a bank in the USA. During its testing period, the original single entry accounting system had to be field replaced with a double entry system for the same reason \u2013 errors crept in and rendered the accounting underneath the digital cash system unreliable.Another major digital money system lasted for many years on a single entry accounting system. Yet, the company knew it was running on luck. When a cracker managed to find a flaw in the system, an overnight attack allowed the creation of many millions of dollars worth of value. As this was more than the contractual issue of value to date, it caused dramatic contortions to the balance sheet, including putting it in breach of its user contract and at dire risk of a 'bank run'. Luckily, the cracker deposited the created value into the account of an online game that failed shortly afterwards, so the value was able to be neutralised and monetarily cleansed, without disclosure, and without scandal.In the opinion of this author at least, single entry bookkeeping is incapable of supporting any enterprise more sophisticated than a household. Given this, I suggest that evolution of complex enterprises required double entry as an enabler.Double Entry has always been the foundation of accounting systems for computers. The capability to detect, classify and correct errors is even more important to computers than it is to humans, as there is no luxury of human intervention; the distance between the user and the bits and bytes is far greater than the distance between the bookkeeper and the ink marks on his ledgers.How Double Entry is implemented is a subject in and of itself. Computer science introduces concepts such as transactions, which are defined as units of work that are atomic, consistent, isolated, and durable (or ACID for short). The core question for computer scientists is how to add an entry to the assets side, then add an entry to the liabilities side, and not crash half way through this sequence. Or even worse, have another transaction start half way through. This makes more sense when considered in the context of the millions of entries that a computer might manage, and a very small chance that something goes wrong; eventually something does, and computers cannot handle errors of that nature very well.For the most part, these concepts simply reduce to \"how do we implement double entry bookkeeping?\" As this question is well answered in the literature, we do no more than mention it here.Recent advances in financial cryptography have provided a challenge to the concept of double entry bookkeeping. The digital signature is capable of creating a record with some strong degree of reliabilty, at least in the senses expressed by ACID, above. A digital signature can be relied upon to keep a record safe, as it will fail to verify if any details in the record are changed.If we can assume that the the record was originally created correctly, then later errors are revealed, both of an accidental nature and of fraudulent intent. (Computers very rarely make accidental errors, and when they do, they are most normally done in a clumsy fashion more akin to the inkpot being spilt than a few numbers.) In this way, any change to a record that makes some sort of accounting or semantic sense is almost certainly an attempt at fraud, and a digital signature makes this obvious.A digital signature gives us a particular property, to whit:There are several variants, with softer and harder claims to that property. For example, message digests with entanglement form one simple and effective form of signature, and public key cryptosystems provide another form where signers hold a private key and verifiers hold a public key[4]. There are also many ways to attack the basic property. In this essay I avoid comparisons, and assume the basic property as a reliable mark of having been seen by a computer at some point in time.Digital signatures then represent a new way to create reliable and trustworthy entries, which can be constructed into accounting systems. At first it was suggested that a variant known as the blinded signature would enable digital cash[5]. Then, certificates would circulate as rights or contracts, in much the same way as the share certificates of old and thus replace centralised accounting systems[6]. These ideas took financial cryptography part of the way there. Although they showed how to strongly verify each transaction, they stopped short of placing the the digital signature in an overall framework of accountancy and governance. A needed step was to add in the redundancy implied in double entry bookkeeping in order to protect both the transacting agents and the system operators from fraud.Designs that derived from the characteristics of the Internet, the capabilities of cryptography and the needs of governance led to the development of the signed receipt[7]. In order to develop this concept, let us assume a simple three party payment system, wherein each party holds an authorising key which can be used to sign their instructions. We call these players Alice, Bob (two users) and Ivan (the Issuer) for convenience.When Alice wishes to transfer value to Bob in some unit or contract managed by Ivan, she writes out the payment instruction and signs it digitally, much like a cheque is dealt with in the physical world. She sends this to the server, Ivan, and he presumably agrees and does the transfer in his internal set of books. He then issues a receipt and signs it with his signing key. As an important part of the protocol, Ivan then reliably delivers the signed receipt to both Alice and Bob, and they can update their internal books accordingly.Our concept of digital value sought to eliminate as many risks as possible. This was derived simply from one of the high level requirements, that of being extremely efficient at issuance of value. Efficiency in digital issuance is primarily a function of support costs, and a major determinant of support costs is the costs of fraud and theft.One risk that consistently blew away any design for efficient digital value at reasonable cost was the risk of insider fraud. In our model of many users and a single centralised server, the issuers of the unit of digital value (as signatory to the contract) and any governance partners such as the server operators are powerful candidates for insider fraud. Events over the last few years such as the mutual funds and stockgate scandals are canonical cases of risks that we decided to address.In order to address the risk of insider fraud, the written receipt was historically introduced as being a primary source of evidence. Mostly forgotten to the buying public these days, the purpose of a written receipt in normal retail trade is not to permit returns and complaints by the customer, but rather to engage her in a protocol of documentation that binds the shop attendant into safekeeping of the monies. A good customer will notice fraud by the shop attendant and warn the owner to look out for the monies identified by the receipt; the same story applies to the invention of the cash till or register, which was originally just a box separating the owner's takings from the monies in the shop attendant's pockets. We extend this primary motive into the digital world by using a signed receipt to bind the Issuer into a governance protocol with the users.We also go several steps further forward. Firstly, to achieve a complete binding, Alice's original authorisation is also included within the record. The receipt then includes all the evidence of both the user's intention and the server's action in response, and it now becomes a dominating record of the event. This then means that the most efficient record keeping strategy is to drop all prior records and keep safe the signed receipt.This domination affects both the Issuer and the user, and allows us to state the following principle:As the signed receipt is delivered from Issuer to both users, all three parties hold the same dominating record for each event. This reduces support costs by dramatically reducing problems caused by differences in information.Secondly, we bind a signed contract of issuance known as a Ricardian Contract into the receipt[8]. This invention relates a digitally signed document securely to the signed receipt by means of a unique identifier called a message digest, again provided by cryptography. It provides strong binding for the unit of account, the nature of the issue, the terms, conditions and promises being made by the Issuer, and of course the identity of the Issuer.Finally, with these enabling steps in place, we can now introduce the principle:Within the full record of the signed receipt, the user's intention is expressed, and is fully confirmed by the server's response. Both of these are covered by digital signatures, locking these data down. A reviewer such as an auditor can confirm the two sets of data, and can verify the signatures.The principle of the Receipt as the Transaction has become sacrosact over time. In our client software, the principle has been hammered into the design consistently, resulting in a simplified accounting regime, and delivering a high reliability. Issues still remain, such as the loss of receipts and the counting of balances by the client side software, but these become reasonably tractable once the goal of receipts as transactions is placed paramount in the designer's mind.In order to calculate balances on a related set of receipts, or to present a transaction history, a book would be constructed on the fly from the set. This amounts to using the Signed Receipt as a basis for single entry bookkeeping. In effect, the bookkeeping is derived from the raw receipts, and this raises the question as to whether to keep the books in place.The principles of Relational Databases provide guidance here. The fourth normal form directs that we store the primary records, in this case the set of receipts, and we construct derivative records, the accounting books, on the fly[9].Similar issues arise for Ivan the Issuer. The server has to accept each new transaction on the basis of the available balance in the effected books; for this reason Ivan needs those books to be available efficiently. Due to the greater number of receipts and books (one for each user account), both receipts and books will tend to exist, in direct contrast to fourth normal form. A meld between relationally sound sets of receipts and double entry books comes to assist here.Alice and Bob both are granted a book each within the server's architecture. As is customary, we place those books on the liabilities side. Receipts then can be placed in a separate single book and this could be logically placed on the assets side. Each transaction from Alice to Bob now has a logical contra entry, and is then represented in 3 places within the accounts of the server. Yet, the assets side remains in fourth normal form terms as the liabilities entries are derived, each pair from one entry on the assets side.By extension, a more sophisticated client-side software agent, working for Alice or Bob, could employ the same techniques. At this extreme, entries are now in place in three separate locations, and each holding potentially three records.The digitally signed receipt, with the entire authorisation for a transaction, represents a dramatic challenge to double entry bookkeeping at least at the conceptual level. The cryptographic invention of the digital signature gives powerful evidentiary force to the receipt, and in practice reduces the accounting problem to one of the receipt's presence or its absence. This problem is solved by sharing the records \u2013 each of the agents has a good copy.In some strict sense of relational database theory, double entry book keeping is now redundant; it is normalised away by the fourth normal form. Yet this is more a statement of theory than practice, and in the software systems that we have built, the two remain together, working mostly hand in hand.Which leads to the pairs of double entries connected by the central list of receipts; three entries for each transaction. Not only is each accounting agent led to keep three entries, the natural roles of a transaction are of three parties, leading to three by three entries.We term this triple entry bookkeeping. Although the digitally signed receipt dominates in information terms, in processing terms it falls short. Double entry book keeping fills in the processing gap, and thus the two will work better together than apart. In this sense, our term of triple entry bookkeeping recommends an advance in accounting, rather than a revolution.The precise layout of the entries in software and data terms is not settled, and may ultimately become one of those ephemeral implementation issues. The signed receipts may form a natural asset-side contra account, or they may be a separate non-book list underlying the bookkeeping system and its two sides.Auditing issues arise where construction of the books derives from the receipts, and normalisation issues arise when a receipt is lost. These are issues for future research.Likewise, it is worth stating that the technique of signing receipts works both with private key signatures and also with entanglement message digest signatures; whether the security aspects of these techniques is adequate to task is dependent on the business environment.It will be noted that the above design of triple entry bookkeeping assumed that Alice and Bob were agents of some independence. This was made possible, and reflected the usage of the system as a digital cash system, and not as a classical accounting system.Far from reducing the relevance of this work to the accounting profession, it introduces digital cash as an alternate to corporate bookkeeping. If an accounting system for a corporation or other administrative entity is recast as a system of digital cash, or internal money, then experience shows that benefits accrue to the organisation.Although the core of the system looks exactly like an accounting system, each department's books are pushed out as digital cash accounts. Departments no longer work so much with budgets as have control over their own corporate money. Fundamental governance control is still held within the accounting department by dint of their operation of the system, and by the limited scope of the money as only being usable within the organisation; the accounting department might step in as a market maker, exchanging payments in internal money for payments in external money to outside suppliers.We have operated this system on a small scale. Rather than be inefficient on such a small scale, the system has generated dramatic savings in coordination. No longer are bills and salaries paid using conventional monies; many transactions are dealt with by internal money transfers and at the edges of the corporation, formal and informal agents work to exchange between internal money and external money. Paperwork reduces dramatically, as the records of the money system are reliable enough to quickly resolve questions even years after the event.The innovations present in internal money go beyond the present paper, but suffice to say that they answer the obvious question of why this design of triple entry accounting sprung from the world of digital cash, and has relevence back to the corporate world.Todd Boyle looked at a similar problem from the point of view of small business needs in an Internet age, and reached the same conclusion \u2013 triple entry accounting[10]. His starting premises were that:From those foundations, Boyle concluded that therefore what is needed is a shared access repository that provides arms-length access. Fundamentally, this repository is akin to the classic double-entry accounting ledger of transaction rows (\"GLT\" for General Ledger - Transactions), yet its entries are dynamic and shared.Simple examples will help. When Alice forms a transaction, she enters it into her software. Every GLT transaction requires naming her external counterparty, Bob. When she posts the transaction, her software stores it in her local GLT and also submits it to the shared repository service's GLT.The Shared Transaction Repository (\"STR\") then forwards the transaction on to Bob. Both Bob and Alice are now expected to store the handle to the transaction as an index or stub, and the STR then stores the entire transaction.Boyle's ideas are logically comparable to Grigg and Howland's, although they arive from different directions (the STR is Grigg's Ivan, above) and are not totally equivalent. Where the latter limited themselves to payments, the accuracy of amounts, and protection with hard cryptographic shells, Boyle looked at wider patterns of transactions, and showed that the STR could mediate these transactions, if the core shared data could be extracted and made into a single shared record. Boyle's focus was on the economic substance of the transaction.Imagine a simple invoicing procedure. Alice creates an invoice and posts it to her software (GLT). As she has named Bob, the GLT automatically posts it to Ivan, the STR, and he forwards it to Bob. At this point Bob has a decision to make, accept or reject. Assuming acceptance, his software can then respond by sending an acceptance message to Ivan. The STR now assembles an accepted invoice record to replace the earlier speculative invoice record and posts that threeways. At some related time (to do with payment policy) Bob also posts a separate transaction to pay for the invoice. This could operate in much the same way as a separate transaction, linking directly to the original invoice.Now, as the payment links back, and the invoice is a live transaction within the three entries in the three accounting systems, it is possible for a new updated invoice record to refer back to the payment activity. When the payment clears, the new record can again replace the older unpaid copy and promulgate to all three parties.Software could be written to facilitate and monitor this flow and similar flows. If the payments system is sufficiently flexible, and integrated with the needs of the users, if might be possible to merge the above invoice with the payment itself, at the Receipts level. Seen in this light, the Signed receipt of Ricardo is simply the smallest and simplest pattern within the more general set of patterns. We could then suggest that the narrow principle of the Receipt is the Transaction could be extended into The Invoice is the Transaction.A particular transaction in business almost never stands alone. They come in patterns. For example offers and acceptances form a wider transaction but seldom encapsulate the entire fulfillment and payment cycle. Even if there has been a payment accompanying a PO message, the customer then waits for fulfillment.There is a large body of science and literature built around these patterns of transactions. These have been adopted by the Business Process workgroup of ebXML and other standards bodies, where they are called \"Commercial Transactions.\" Where however the present work distinguishes itself is in breaking down these transactions into the atomic elements. It is to that we now turn.The implementation of Triple Entry Accounting will in time evolve to support patterns of transactions. What has become clear is that double entry does not sufficiently support these patterns, as it is a framework that breaks down as soon as the number of parties exceeds one. Yet, even as double entry is \"broken\" on the net and unable to support commercial demands, triple entry is not widely understood, nor are the infrastructure requirements that it imposes well recognised.Below are the list of requirements that we believed to be important[11][12].1. Strong Psuedonymity, At Least. As there are many cycles in the patterns, the system must support a clear relationship of participants. At the minimum this requires a nymous architecture of the nature of Ricardo or AADS. (This requirement is very clear, but space prevents any discussion of it.)2. Entry Signing. In order to neutralise the threats to and by the parties, a mechanism that freezes and confirms the basic data is needed. This is signing, and we require that all entries are capable of carrying digital signatures (see 1, above, which suggests public key signatures).3. Message Passing. The system is fundamentally one of message passing, in contrast to much of the net's connection based architecture. Boyle recognised early on that a critical component was the generic message passing nature, and Systemics proposed and built this into Ricardo over the period 2001-2004[13].4. Entry Enlargement and Migration. Each new version of a message coming in represents an entry that is either to be updated or added. As each message adds to a prior conversation, the stored entry needs to enlarge and absorb the new information, while preserving the other properties.5. Local Entry Storage and Reports. The persistent saving and responsive availability of entries. In practice, this is the classical accounting general ledger, at least in storage terms. It needs to bend somewhat to handle much more flexible entries, and its report capabilities become more key as they conduct instrinsic reconciliation on a demand or live basis.6. Integrated Hard Payments. Trade can only be as efficient as the payment. That means that the payment must be at least as efficient as every other part; which in practice means that a payment system should be built-in at the infrastructure level. C.f., Ricardo.7. Integrated Application-Level Messaging. As distinct to the messaging at the lower protocol levels (1 above), there is a requirement for Alice and Bob to be able to communicate. That is because the vast majority of the patterns turns around the basic communications of the agents. There is no point in establishing a better payment and invoice mechanism than the means of communication and negotiation. This concept is perhaps best seen in the SWIFT system which is a messaging system, first and foremost, to deliver instructions for payments.Double Entry bookkeeping provides evidence of intent and origin, leading to strategies for dealing with errors of accident and fraud. The financial cryptography invention of the signed receipt provides the same benefits, and thus challenges the 800 year reign of double entry. Indeed, in evidentiary terms, the signed receipt is more powerful than double entry records due to the technical qualities of its signature.There remain some weaknesses in strict comparison with double entry bookkeeping. Firstly, in the Ricardo instantiation of triple entry accounting, the receipts themselves may be lost or removed, and for this reason we stress as a principle that the entry is the transaction. This results in three active agents who are charged with securing the signed entry as their most important record of transaction.Secondly, the software ramifications of the triple entry system that are less convenient than that offered by double entry bookkeeping. For this reason, we expand the information held in the receipt into a set of double entry books; in this way we have the best of both worlds on each node: the evidentiary power of the signed entries and the convenience and local crosschecking power of the double entry concept.Both of these imperitives meld signed receipts in with double entry bookkeeping. As we end up with a logical arrangement of three by three entries, we feel the term triple entry bookkeeping is useful to describe the advance on the older form.To fully benefit from triple entry bookkeeping, we have to expand accounting systems out to agents and offer them direct capabilities to do transactions. That is, we make the agents stakeholders by giving them internal money[14]. Use of digital cash to do company accounts empowers the use of this concept as a general replacement for accounting using books and departmental budgets, and is an enabler for verifying and auditing the centralised accounts system by way of signed receipts.Once there, governance receives substantial benefits. Accounts are now much more difficult to change, and much more transparent. It is our opinion that various scandals and failures of governance would have been impossible given these techniques: the mutual funds scandal would have shown a clear audit trail of transactions and thus late timing and otherwise perverted or dropped transactions would have been clearly identified or eliminated completely[15]. The emerging scandal in the USA known as Stockgate would have been impossible as forgery of shares and value for manipulative trading purposes is revealed by signed receipts. Likewise, Barings would still be a force in investment banking if accounts had been organised around easily transparent digital cash with open and irreducible signed receipts that evidence invisible accounts (88888). Enron style scandals would have permitted more direct \"follow the money\" governance lifting the veil on various innovative but economically meaningless swaps.A draft form of this paper credited Todd Boyle as an author, but this was later withdrawn at his request due to wider differences between the views. \u21a9Friar Luca Pacioli, Summa de Arithmetica, Geometria, Proportioni et Proportionalita 1494, Venice. \u21a9Ian Grigg \"The Twilight Zone,\" Financial Cryptography blog 16th April 2005 \u21a9Entanglement is discussed in: Petros Maniatis and Mary Baker, \"Secure History Preservation through Timeline Entanglement,\" Proc. 11th USENIX Security Symposium, August 2002. \u21a9David Chaum, \"Achieving Electronic Privacy,\" Scientific American, v. 267, n. 2 Aug 1992. \u21a9Robert A. Hettinga \"The Book-Entry/Certificate Distinction\" 1995, Cypherpunks \u21a9Gary Howland \"Development of an Open and Flexible Payment System\" 1996, Amsterdam, NL. \u21a9Ian Grigg \"The Ricardian Contract,\" First IEEE International Workshop on Electronic Contracting (WEC) 6th July 2004 \u21a9E.F. Codd, \"A Relational Model of Data for Large Shared Data Banks,\" Comm. ACM 13 (6), June 1970, pp. 377-387. \u21a9Todd Boyle, \"GLT and GLR: conceptual architecture for general ledgers,\" Ledgerism.net, 1997-2005. \u21a9Todd Boyle, \"STR software specification,\" Goals, 1-5. This section adopts that numbering convention. \u21a9Ian Grigg, various design and requirements documents, Systemics, unpublished. \u21a9A substantial part of the programming and design was conducted by Edwin Woudt (first demo, SOX layers, UI) and Jeroen van Gelderen (message passing client architecture). \u21a9Using internal money instead of an accounting system is not a new idea but has only been recently experienced: Ian Grigg, How we raised capital at 0%, saved our creditors from an accounting nightmare, gave our suppliers a discount and got to bed before midnight. Informal essay (rant), 7 Jul 2003. \u21a9James Nesfield and Ian Grigg \"Mutual Funds and Financial Flaws,\" U.S. Senate Finance Subcommittee 27th January, 2004 \u21a9"}
{"prompt": "Truledger in Plain English", "completion": "Truledger is an anonymous, digitally-signed vault and trading system. Like Loom, it allows anyone to issue assets (digital currencies). Unlike Loom, which relies entirely on (very good) obscurity for security, Truledger's digital signatures allow the server and the customer to prove to each other that they agreed at a particular time on their balances. It does this while allowing destruction of transaction history for closed trades. Truledger will initially provide server-based trading. Eventually, it will provide digital checks and bearer certificates. These, however, WILL require permanent storage of transaction history (unless they expire).doc/db.txt gives a terse description of the Truledger server database and protocol. This page attempts to render the protocol in plain English.Truledger uses public key cryptography to sign all messages passed back and forth between its web interface and the Truledger server. Digital signatures are a virtually unforgeable way to ensure that a message was written by its purported author. Truledger uses OpenSSL for its public key cryptography. You probably use OpenSSL every time you visit a secure web site, https://somewhere.com/, as does the web server. I didn't roll my own. Just used the same tried and true technology that secures the web. You can read more about public key cryptography, digital signatures, and hashing here and here.I'm going to use four actors in the scenarios that follow. \"Server\" is the name of the Truledger server. \"Bob\" and \"Sue\" are two customers, who will trade with each other. \"Spammer\" is a third customer, unknown to Bob or Sue.Sue (via email or IM): Hey, Bob. Check out Truledger. Go to Truledger.com, download the client, and install it on your computer. Then create a private key, and send me your ID, and I'll give you some usage tokens so that you can create an account.Bob (via email or IM): Thanks, Sue! I installed the Truledger client and created a private key. Here's my ID.Sue (via her Truledger client): Hey server, Here's a new request number. Give me a transaction number please.\nSigned: SueServer: Here's a new transaction number.\nSigned: ServerSue: Hey server, here's that transaction number you gave me. Please spend 50 usage tokens to Bob's ID, with a message of \"Hey Bob. Welcome to Truledger!\" I'm paying 2 usage tokens as a transaction fee, which I'll get back when Bob accepts the spend. My balance after this transaction will be 1025 usage tokens. My outbox hash after this transaction will be X.\nSigned: SueServer: I processed your spend of 50 usage tokens to Bob's ID. I agree that the transaction fee at the time of this transaction is 2 usage tokens, and that your balance after this transaction is 1025 usage tokens. I agree with you on your outbox hash.\nSigned: ServerSue (via email or IM): OK, Bob. I've given you 50 usage tokens. You should now be able to create an account at Truledger.com. Send me a message via Truledger when you've registered.Bob (via his Truledger client): Hello server. Here's my ID and my public key. What's your ID and public key?\nSigned: BobServer: Here's my ID and public key.\nSigned: ServerBob: Here's my ID and my public key, please create an account for me.\nSigned: BobServer: I've registered your ID and public key. Somebody gave you enough tokens to register. Welcome to Truledger.\nSigned: ServerIn order to sign a message, you need to have a private key. In order to verify the signature on a message, you need to have the corresponding public key. Truledger identifies customers by the hash of their public key, their ID. The ID is a 40-character string of numbers and the letters A to F, the hexadecimal representation of a 160-bit number. You identify your account to the Truledger client with a passphrase, which is used to encrypt your private key on your disk. You'll only need to copy and paste your ID when you want to tell a trading partner how to send you money for the first time, or to seed your account with usage tokens, as Sue did for Bob.Usage tokens are an idea from Patrick Chkoreff's Loom system. They are a way to charge for the server's resources. You have to buy storage for your account balances, and lease temporary storage for transactions. Usage tokens are the \"currency\" used to do this. Truledger also supports fees in other asset types, for server management that wants to make more than the sale of usage tokens. Truledger uses the file system as a database. One file in the Truledger database costs one usage token. Files vary in size, but are usually about 8K, mostly signatures.Note that Bob had to send his public key to the server twice, once when he requested the server's public key, and again when he registered. Every message going to and from Truledger is digitally signed. It's only possible to verify a digital signature if you know the public key of the signer. A new customer's public key isn't in the database until after he's registered, so the first two messages, in which the new customer gets the server's public key, so that he can verify the server's signatures, and the registration request, both need to include the customers's public key, so that the signatures on those two messages can themselves be verified. After registration is complete, subsequent messages need to carry only the ID; the public key can then be looked up in the database.Actual messages sent (with the signature that goes with each parenthesized item omitted):Bob: Hello server. Here's my ID and a new request number. What's in my inbox?\nSigned: BobServer: Your inbox contains a 50 usage token spend from Sue with a message of \"Hey Bob. Welcome to Truledger!\" It also contains a 10 usage token charge from the server with a message of \"Registration Fee\". Here are two transaction numbers you can use to accept these spends and do a spend yourself.\nSigned: ServerBob: Here's my ID and the first of the transaction numbers you gave me. Accept the spend from Sue with a message of, \"Thanks, Sue. I'm excited about Truledger!\" Accept the server charge. My balance after this transaction will be 39 usage tokens.\nSigned: BobServer: I've processed the spend from Sue and the server charge. I agree that your balance after this transaction is 39 usage tokens.\nSigned: ServerOne possible attack on an electronic server can be for someone to replay an intercepted message. Unless the protocol protects against that, this can cause problems. Except for the serverid request, the registration request, and a request for a customer's last request number, every information request must be accompanied by a request number that is larger than the customer's last used request number, and every transaction must be accompanied by a transaction number that is given out by the server. The server maintains a counter, which it increments each time someone asks for a transaction number. This makes requests that reveal information or initiate transactions impossible to replay without a customer's passphrase and private key. In the Truledger world, your passphrase and your private key are your identity. Guard them well.Another possible replay attack is to intercept a message for one server and send it to another. Customers could protect against this by having different IDs, hence different public/private key pairs, for different servers. But it will be very convenient to use the same ID. Your friends will recognize you, and you'll have only one passphrase to remember. So the server's ID is included in almost every request. Requests meant for another server will not work.You're probably wondering why Bob's balance after the transaction is 39, instead of 40, usage tokens. He got 50 usage tokens from Sue, and paid the server 10 usage tokens for his registration fee. The additional usage token is the price of the new file used to store the usage token balance. Storage costs usage tokens. Loom charges 1 usage token for each 16 bytes of storage. I considered charging per byte, but decided that charging per file was easier to handle, though not quite as fair. It only makes sense if message sizes are limited, of course. If you were allowed megabyte messages, then Truledger would have to charge per byte, or per kilobyte.Actual messages sent:Sue: Hello server. Here's my ID and a new request number. What's in my inbox?\nSigned: SueServer: Your inbox contains an acceptance from Bob of your 50 usage token spend with a message of, \"Thanks Sue. I'm excited about Truledger!\" Here are two transaction numbers you can use to close that transaction and do a new spend.\nSigned: ServerSue: Here's my ID and the first of the transaction numbers you gave me. Clear the spend to Bob. My balance after this transaction will be 1027 usage tokens. My outbox hash after this transaction will be Y.\nSigned: SueServer: I've cleared the spend to Bob (and refunded the usage tokens that were leasing the outbox and inbox locations). I agree that your balance after this transaction is 1027 usage tokens. And I agree that your outbox hash after this transaction is Y.\nSigned: ServerThere are three main parts of a Truledger account: the balances, the outbox, and the inbox. Value is stored in all three places. When you do a spend, your balance for the spent asset is debited, and the spend request is stored in your outbox and in the recipients inbox. You are charged two usage tokens to lease the new outbox and inbox files. When the recipient accepts the spend, his balance for the spent asset is credited, the spend notice is removed from his inbox, and a spend acceptance notice is added to your inbox. When you acknowledge his acceptance of the spend, the spend request is removed from your outbox, the acceptance notice is removed from your inbox, and the two usage tokens you paid to lease those files is credited to your balance. This three step process is necessary, because the server can't modify your balances without your signed permission, and it can't modify the recipient's balances without his signed permission.You may be wondering what an \"outbox hash\" is. Your balances plus your outbox represent the part of your account that you and the server have agreed upon. Your inbox is changed without your knowledge, but the server needs your signed permission to change your outbox (do a spend) or your balances. Since your outbox might get large, instead of sending the entire contents back and forth every time you do a spend, or acknowledge the acceptance (or rejection) of a spend by a recipient, you compute a hash of your outbox, and send that instead, and the server responds with an acknowledgement of that outbox hash (thank you to Patrick Chkoreff for this idea).Actual messages sent:Spammer (likely via an automated client): Hey server. Here's a new request number. Give me a transaction number please.\nSigned: SpammerServer: Here's a new transaction number.\nSigned: ServerSpammer: Hey server. Here's that transaction number you gave me. Please spend 0 usage tokens to Bob's ID, with a message of, \"Go all night. Visit BuyViagra.com.\" I'm paying 2 usage tokens as a transaction fee, which I'll get back when Bob accepts the spend. My balance after this transaction will be 2425 usage tokens. My outbox hash after this transaction will be Z.\nSigned: SpammerServer: I processed your spend of 0 usage tokens to Bob's ID. I agree that the transaction fee at the time of this transaction is 2 usage tokens, and that your balance after this transaction is 2425 usage tokens. I agree with you on your outbox hash.\nSigned: ServerBob: Hello server. Here's my ID and a new request number. What's in my inbox?\nSigned: BobServer: Your inbox contains a 0 usage token spend from Spammer with a message of, \"Go all night. Visit BuyViagra.com.\" Here are two transaction numbers you can use to accept these spends and do a spend yourself.\nSigned: ServerBob: Here's my ID and the first of the transaction numbers you gave me. Reject the spend from Spammer with a message of, \"Thanks for the tokens\", and give me the two usage tokens he paid to send that spam. My balance after this transaction will be 41 usage tokens.\nSigned: BobServer: I've rejected the spend from Spammer. I agree that your balance after this transaction is 41 usage tokens.\nSigned: ServerSpends can be rejected. The amount spent goes back to the spender, but the recipient pockets the transaction fee. Zero spends use Truledger as a simple messaging service. But not a free one, unless the recipient wants the message. IMHO, spam exists largely because it is nearly free to send email. In a system where each spam message costs 2 usage tokens, cheap but not free, I doubt it will be much of a problem. Time will tell.Actual messages sent:Bob: Hey server. Here's a new request number. Give me a transaction number please.\nSigned: BobServer: Here's a new transaction number.\nSigned: ServerBob: Hey server. Here's that transaction number you gave me. Please register a new asset named \"Bob GoldGrams\". It has a scale of 7 and a precision of 3. Its ID is <bobggid>. My balance after this transaction will be 39 usage tokens and -1 <bobggid>.Server: I have registered the new \"Bob GoldGrams\" asset. I agree that your balance after this transaction is 39 usage tokens and -1 <bobggid>.Like Loom, Truledger allows customers to create their own asset types. Then, if they can convince them to do so, other customers can trade in that asset type. The ID of a Truledger asset is the sha1 hash of the creator's ID, its scale, its precision, and its name. But the message the customer signs to create the asset, and that the server signs to acknowledge creation, also contains the serverid. This allows the asset to be registered at multiple servers, with the same ID, but makes each particular registration specific to a specific server. Hence, it makes sense for an asset issuer to provide a service of transferring his holdings of his asset between servers at which he's registered; it's self-evident that Bob GoldGrams at Server A are the same asset as Bob GoldGrams at server B.I plan to support transfer of asset issuance, but I haven't figured out the intricacies yet.Like Loom, all amounts in Truledger are stored as integers. The scale value controls where the decimal point goes in the real-world representation of that value: move it left by scale places. The precision controls the minimum number of decimal places that are printed. So with a scale of 7 and a precision of 3, the value 12000000 will be printed by Truledger clients as 1.200, and the minimum value for Bob's new currency is 0.0000001, one ten-millionth of a gram of gold, or $0.000003 at $30/gram: 3 ten-thousandths of a cent. Hello micropayments.Also like Loom, the sum of all the amounts, in accounts and outboxes, for one asset type is -1. There is one negative balance, owned by the issuer, who can spend as much as he wants, and a bunch of positive balances, and outbox entries. A -1 balance in the issuer's account means there are no outstanding balances or outbox entries in that asset, so that's where Bob's Bob GoldGrams balance begins. Users of an asset have to trust the issuer when he tells them, outside of Truledger, that his asset is backed by something of real value, and that he'll never issue more of the virtual asset than he has in the backing commodity. Well, unless he wants to act like a country, and issue fiat currency that is backed by his Full Faith and Credit and nothing else. Good luck getting people to go for that.Actual messages sent:Bob: Hey server. Here's a new request number. Give me a transaction number please.\nSigned: BobServer: Here's a new transaction number.\nSigned: ServerBob: Hey server. Here's that transaction number you gave me. Make a zero spend to myself. My balance after the transaction will be 38 usage tokens, -311.0347681 Bob GoldGrams in my default sub-account, and 311.034768 Bob GoldGrams in my \"Gun Safe\" sub-account.Server: I did that spend. I agree with you that after the transaction, your balance is 38 usages tokens, -311.0347681 Bob GoldGrams in your default account, and 311.034768 Bob GoldGrams in your \"Gun Safe\" sub-account.Bob: Hey server. Here's a new request number. Give me a transaction number please.\nSigned: BobServer: Here's a new transaction number.\nSigned: ServerBob: Hey server. Here's that transaction number you gave me. Please spend 2.4056304 Bob GoldGrams to Sue, with a message of, \"Well, I finally issued my new currency, backed by Krugerands in my gun safe. I'm giving you a gram in thanks for turning me on to Truledger, and 1.4056304 grams for 36 Capulin Coffee Units, which you said you'd sell me, so I can buy more of Daniel Fourwinds' fine coffee that we relished at your house the other day. I used a gold price of $796.60/ounce, Kitco's bid price this morning.\" My transaction fee will be 2 usage tokens. My balance after this transaction will be 36 usage tokens, and 309.6291376 Bob GoldGrams in my \"Gun Safe\" sub-account. My outbox hash after this transaction will be A.\nSigned: BobServer: I have done your spend of 2.4056304 Bob GoldGrams to Sue, with your message, and a transaction fee of 2 usage tokens. I agree that your balance after this transaction is 36 usage tokens, and 309.6291376 Bob GoldGrams in your \"Gun Safe\" sub-account. I agree on the outbox hash.\nSigned: ServerTruledger supports splitting up your balances into multiple \"sub-accounts\". Much like a conventional server gives you a checking account and a savings account, you can use these sub-accounts to help manage your assets. You can have as many of them as you wish, limited only by having usage tokens to pay for the files.Bob has decided to keep track of his Bob GoldGrams assets with a \"Gun Safe\" sub-account, with a balance recording how many grams of the gold in his safe have not yet been put into circulation. He seeds it with 10 ounces of gold, the part of his holdings that he's willing to sell. Then he spends some of it to Sue, asking for enough Capulin Coffee Units for two pounds of Capulin Coffee ($17.95 per pound, shipped).Note that you don't have to mention all of your balances with every spend. You only mention the balances that change. Also notice that there's no transaction fee for spends to yourself. Moving assets between your sub-accounts costs only tokens for new files. No need for the outbox and inbox stuff.Actual messages sent:To be doneTo be doneCopyright \u00a9 2008 Bill St. Clair, All Rights Reserved."}
{"prompt": "A Cypherpunk's Manifesto", "completion": "Privacy is necessary for an open society in the electronic age. Privacy is not secrecy. A private matter is something one doesn't want the whole world to know, but a secret matter is something one doesn't want anybody to know. Privacy is the power to selectively reveal oneself to the world.If two parties have some sort of dealings, then each has a memory of their interaction. Each party can speak about their own memory of this; how could anyone prevent it? One could pass laws against it, but the freedom of speech, even more than privacy, is fundamental to an open society; we seek not to restrict any speech at all. If many parties speak together in the same forum, each can speak to all the others and aggregate together knowledge about individuals and other parties. The power of electronic communications has enabled such group speech, and it will not go away merely because we might want it to.Since we desire privacy, we must ensure that each party to a transaction have knowledge only of that which is directly necessary for that transaction. Since any information can be spoken of, we must ensure that we reveal as little as possible. In most cases personal identity is not salient. When I purchase a magazine at a store and hand cash to the clerk, there is no need to know who I am. When I ask my electronic mail provider to send and receive messages, my provider need not know to whom I am speaking or what I am saying or what others are saying to me; my provider only need know how to get the message there and how much I owe them in fees. When my identity is revealed by the underlying mechanism of the transaction, I have no privacy. I cannot here selectively reveal myself; I must _always_ reveal myself.Therefore, privacy in an open society requires anonymous transaction systems. Until now, cash has been the primary such system. An anonymous transaction system is not a secret transaction system. An anonymous system empowers individuals to reveal their identity when desired and only when desired; this is the essence of privacy.Privacy in an open society also requires cryptography. If I say something, I want it heard only by those for whom I intend it. If the content of my speech is available to the world, I have no privacy. To encrypt is to indicate the desire for privacy, and to encrypt with weak cryptography is to indicate not too much desire for privacy. Furthermore, to reveal one's identity with assurance when the default is anonymity requires the cryptographic signature.We cannot expect governments, corporations, or other large, faceless organizations to grant us privacy out of their beneficence. It is to their advantage to speak of us, and we should expect that they will speak. To try to prevent their speech is to fight against the realities of information. Information does not just want to be free, it longs to be free. Information expands to fill the available storage space. Information is Rumor's younger, stronger cousin; Information is fleeter of foot, has more eyes, knows more, and understands less than Rumor.We must defend our own privacy if we expect to have any. We must come together and create systems which allow anonymous transactions to take place. People have been defending their own privacy for centuries with whispers, darkness, envelopes, closed doors, secret handshakes, and couriers. The technologies of the past did not allow for strong privacy, but electronic technologies do.We the Cypherpunks are dedicated to building anonymous systems. We are defending our privacy with cryptography, with anonymous mail forwarding systems, with digital signatures, and with electronic money.Cypherpunks write code. We know that someone has to write software to defend privacy, and since we can't get privacy unless we all do, we're going to write it. We publish our code so that our fellow Cypherpunks may practice and play with it. Our code is free for all to use, worldwide. We don't much care if you don't approve of the software we write. We know that software can't be destroyed and that a widely dispersed system can't be shut down.Cypherpunks deplore regulations on cryptography, for encryption is fundamentally a private act. The act of encryption, in fact, removes information from the public realm. Even laws against cryptography reach only so far as a nation's border and the arm of its violence. Cryptography will ineluctably spread over the whole globe, and with it the anonymous transactions systems that it makes possible.For privacy to be widespread it must be part of a social contract. People must come and together deploy these systems for the common good. Privacy only extends so far as the cooperation of one's fellows in society. We the Cypherpunks seek your questions and your concerns and hope we may engage you so that we do not deceive ourselves. We will not, however, be moved out of our course because some may disagree with our goals.The Cypherpunks are actively engaged in making the networks safer for privacy. Let us proceed together apace.Onward.Eric Hughes"}
{"prompt": "The Right to Read: A Dystopian Short Story", "completion": "From The Road to Tycho, a collection of articles about the antecedents of the Lunarian Revolution, published in Luna City in 2096.For Dan Halbert, the road to Tycho began in college\u2014when Lissa Lenz asked to borrow his computer. Hers had broken down, and unless she could borrow another, she would fail her midterm project. There was no one she dared ask, except Dan.This put Dan in a dilemma. He had to help her\u2014but if he lent her his computer, she might read his books. Aside from the fact that you could go to prison for many years for letting someone else read your books, the very idea shocked him at first. Like everyone, he had been taught since elementary school that sharing books was nasty and wrong\u2014something that only pirates would do.And there wasn't much chance that the SPA\u2014the Software Protection Authority\u2014would fail to catch him. In his software class, Dan had learned that each book had a copyright monitor that reported when and where it was read, and by whom, to Central Licensing. (They used this information to catch reading pirates, but also to sell personal interest profiles to retailers.) The next time his computer was networked, Central Licensing would find out. He, as computer owner, would receive the harshest punishment\u2014for not taking pains to prevent the crime.Of course, Lissa did not necessarily intend to read his books. She might want the computer only to write her midterm. But Dan knew she came from a middle-class family and could hardly afford the tuition, let alone her reading fees. Reading his books might be the only way she could graduate. He understood this situation; he himself had had to borrow to pay for all the research papers he read. (Ten percent of those fees went to the researchers who wrote the papers; since Dan aimed for an academic career, he could hope that his own research papers, if frequently referenced, would bring in enough to repay this loan.)Later on, Dan would learn there was a time when anyone could go to the library and read journal articles, and even books, without having to pay. There were independent scholars who read thousands of pages without government library grants. But in the 1990s, both commercial and nonprofit journal publishers had begun charging fees for access. By 2047, libraries offering free public access to scholarly literature were a dim memory.There were ways, of course, to get around the SPA and Central Licensing. They were themselves illegal. Dan had had a classmate in software, Frank Martucci, who had obtained an illicit debugging tool, and used it to skip over the copyright monitor code when reading books. But he had told too many friends about it, and one of them turned him in to the SPA for a reward (students deep in debt were easily tempted into betrayal). In 2047, Frank was in prison, not for pirate reading, but for possessing a debugger.Dan would later learn that there was a time when anyone could have debugging tools. There were even free debugging tools available on CD or downloadable over the net. But ordinary users started using them to bypass copyright monitors, and eventually a judge ruled that this had become their principal use in actual practice. This meant they were illegal; the debuggers' developers were sent to prison.Programmers still needed debugging tools, of course, but debugger vendors in 2047 distributed numbered copies only, and only to officially licensed and bonded programmers. The debugger Dan used in software class was kept behind a special firewall so that it could be used only for class exercises.It was also possible to bypass the copyright monitors by installing a modified system kernel. Dan would eventually find out about the free kernels, even entire free operating systems, that had existed around the turn of the century. But not only were they illegal, like debuggers\u2014you could not install one if you had one, without knowing your computer's root password. And neither the FBI nor Microsoft Support would tell you that.Dan concluded that he couldn't simply lend Lissa his computer. But he couldn't refuse to help her, because he loved her. Every chance to speak with her filled him with delight. And that she chose him to ask for help, that could mean she loved him too.Dan resolved the dilemma by doing something even more unthinkable\u2014he lent her the computer, and told her his password. This way, if Lissa read his books, Central Licensing would think he was reading them. It was still a crime, but the SPA would not automatically find out about it. They would only find out if Lissa reported him.Of course, if the school ever found out that he had given Lissa his own password, it would be curtains for both of them as students, regardless of what she had used it for. School policy was that any interference with their means of monitoring students' computer use was grounds for disciplinary action. It didn't matter whether you did anything harmful\u2014the offense was making it hard for the administrators to check on you. They assumed this meant you were doing something else forbidden, and they did not need to know what it was.Students were not usually expelled for this\u2014not directly. Instead they were banned from the school computer systems, and would inevitably fail all their classes.Later, Dan would learn that this kind of university policy started only in the 1980s, when university students in large numbers began using computers. Previously, universities maintained a different approach to student discipline; they punished activities that were harmful, not those that merely raised suspicion.Lissa did not report Dan to the SPA. His decision to help her led to their marriage, and also led them to question what they had been taught about piracy as children. The couple began reading about the history of copyright, about the Soviet Union and its restrictions on copying, and even the original United States Constitution. They moved to Luna, where they found others who had likewise gravitated away from the long arm of the SPA. When the Tycho Uprising began in 2062, the universal right to read soon became one of its central aims.This note has been updated several times since the first publication of the story.The right to read is a battle being fought today. Although it may take 50 years for our present way of life to fade into obscurity, most of the specific laws and practices described above have already been proposed; many have been enacted into law in the US and elsewhere. In the US, the 1998 Digital Millennium Copyright Act (DMCA) established the legal basis to restrict the reading and lending of computerized books (and other works as well). The European Union imposed similar restrictions in a 2001 copyright directive. In France, under the DADVSI law adopted in 2006, mere possession of a copy of DeCSS, the free program to decrypt video on a DVD, is a crime.In 2001, Disney-funded Senator Hollings proposed a bill called the SSSCA that would require every new computer to have mandatory copy-restriction facilities that the user cannot bypass. Following the Clipper chip and similar US government key-escrow proposals, this shows a long-term trend: computer systems are increasingly set up to give absentees with clout control over the people actually using the computer system. The SSSCA was later renamed to the unpronounceable CBDTPA, which was glossed as the \"Consume But Don't Try Programming Act.\"The Republicans took control of the US senate shortly thereafter. They are less tied to Hollywood than the Democrats, so they did not press these proposals. Now that the Democrats are back in control, the danger is once again higher.In 2001 the US began attempting to use the proposed Free Trade Area of the Americas (FTAA) treaty to impose the same rules on all the countries in the Western Hemisphere. The FTAA is one of the so-called free trade treaties, which are actually designed to give business increased power over democratic governments; imposing laws like the DMCA is typical of this spirit. The FTAA was effectively killed by Lula, President of Brazil, who rejected the DMCA requirement and others.Since then, the US has imposed similar requirements on countries such as Australia and Mexico through bilateral \"free trade\" agreements, and on countries such as Costa Rica through another treaty, CAFTA. Ecuador's President Correa refused to sign a \"free trade\" agreement with the US, but I've heard Ecuador had adopted something like the DMCA in 2003.One of the ideas in the story was not proposed in reality until 2002. This is the idea that the FBI and Microsoft will keep the root passwords for your personal computers, and not let you have them.The proponents of this scheme have given it names such as \"trusted computing\" and \"Palladium.\" We call it treacherous computing\" because the effect is to make your computer obey companies even to the extent of disobeying and defying you. This was implemented in 2007 as part of Windows Vista; we expect Apple to do something similar. In this scheme, it is the manufacturer that keeps the secret code, but the FBI would have little trouble getting it.What Microsoft keeps is not exactly a password in the traditional sense; no person ever types it on a terminal. Rather, it is a signature and encryption key that corresponds to a second key stored in your computer. This enables Microsoft, and potentially any web sites that cooperate with Microsoft, the ultimate control over what the user can do on his own computer.Vista also gives Microsoft additional powers; for instance, Microsoft can forcibly install upgrades, and it can order all machines running Vista to refuse to run a certain device driver. The main purpose of Vista's many restrictions is to impose DRM (Digital Restrictions Management) that users can't overcome. The threat of DRM is why we have established the Defective by Design campaign.When this story was first written, the SPA was threatening small Internet service providers, demanding they permit the SPA to monitor all users. Most ISPs surrendered when threatened, because they cannot afford to fight back in court. One ISP, Community ConneXion in Oakland, California, refused the demand and was actually sued. The SPA later dropped the suit, but obtained the DMCA, which gave them the power they sought.The SPA, which actually stands for Software Publishers Association, has been replaced in its police-like role by the Business Software Alliance. The BSA is not, today, an official police force; unofficially, it acts like one. Using methods reminiscent of the erstwhile Soviet Union, it invites people to inform on their coworkers and friends. A BSA terror campaign in Argentina in 2001 made slightly veiled threats that people sharing software would be raped.The university security policies described above are not imaginary. For example, a computer at one Chicago-area university displayed this message upon login:This is an interesting approach to the Fourth Amendment: pressure most everyone to agree, in advance, to waive their rights under it.The battle for the right to read is already in progress. The enemy is organized, while we are not, so it is going against us. Here are articles about bad things that have happened since the original publication of this article.If we want to stop the bad news and create some good news, we need to organize and fight. The FSF's Defective by Design campaign has made a start \u2014 subscribe to the campaign's mailing list to lend a hand. And join the FSF to help fund our work.The Free Software Foundation is the principal organizational sponsor of the GNU Operating System. Their mission is to preserve, protect and promote the freedom to use, study, copy, modify, and redistribute computer software, and to defend the rights of Free Software users.Copyright \u00a9 1996, 2002, 2007, 2009, 2010 Richard Stallman\nThis essay was written in 1996 and was published in Communications of the ACM, vol. 40, n. 2, February 1997."}
{"prompt": "Areopagitica;\nA Speech of Mr. John Milton\nFor the Liberty of Unlicens'd Printing,\nto the Parliament of England", "completion": "This is true liberty, when free-born men,\nHaving to advise the public, may speak free,\nWhich he who can, and will, deserves high praise;\nWho neither can, nor will, may hold his peace:\nWhat can be juster in a state than this?They, who to states and governors of the Commonwealth direct their speech, High Court of Parliament, or, wanting such accesse in a private condition, write that which they foresee may advance the publick good; I suppose them, as at the beginning of no mean endeavour, not a little alter'd and mov'd inwardly in their mindes: some with doubt of what will be the successe, others with fear of what will be the censure; some with hope, others with confidence of what they have to speake. And me perhaps each of these dispositions, as the subject was whereon I enter'd, may have at other times variously affected; and likely might in these foremost expressions now also disclose which of them sway'd most, but that the very attempt of this address thus made, and the thought of whom it hath recourse to, hath got the power within me to a passion, farre more welcome than incidental to a preface.Which though I stay not to confesse ere any aske, I shall be blamelesse, if it be no other than the joy and gratulation which it brings to all who wish and promote their country's liberty; whereof this whole discourse proposed will be a certain testimony, if not a trophy. For this is not the liberty which we can hope, that no grievance ever should arise in the Commonwealth--that let no man in this world expect; but when complaints are freely heard, deeply considered and speedily reformed, then is the utmost bound of civil liberty attained that wise men look for. To which if I now manifest by the very sound of this which I shall utter, that we are already in good part arrived, and yet from such a steep disadvantage of tyranny and superstition grounded into our principles as was beyond the manhood of a Roman recovery, it will be attributed first, as is most due, to the strong assistance of God our deliverer, next to your faithful guidance and undaunted wisdom, Lords and Commons of England. Neither is it in God's esteem the diminution of his glory, when honourable things are spoken of good men and worthy magistrates; which if I now first should begin to do, after so fair a progress of your laudable deeds, and such a long obligement upon the whole realm to your indefatigable virtues, I might be justly reckoned among the tardiest, and the unwillingest of them that praise ye.Nevertheless there being three principal things, without which all praising is but courtship and flattery: First, when that only is praised which is solidly worth praise: next, when greatest likelihoods are brought that such things are truly and really in those persons to whom they are ascribed: the other, when he who praises, by showing that such his actual persuasion is of whom he writes, can demonstrate that he flatters not; the former two of these I have heretofore endeavour'd, rescuing the employment from him who went about to impair your merits with a trivial and malignant encomium; the latter as belonging chiefly to mine own acquittal, that whom I so extolled I did not flatter, hath been reserved opportunely to this occasion.For he who freely magnifies what hath been nobly done, and fears not to declare as freely what might be done better, gives ye the best covenant of his fidelity; and that his loyalest affection and his hope waits on your proceedings. His highest praising is not flattery, and his plainest advice is a kind of praising. For though I should affirm and hold by argument, that it would fare better with truth, with learning and the Commonwealth, if one of your published Orders, which I should name, were called in; yet at the same time it could not but much redound to the lustre of your mild and equal government, whenas private persons are hereby animated to think ye better pleased with public advice, than other statists have been delighted heretofore with public flattery. And men will then see what difference there is between the magnanimity of a triennial Parliament, and that jealous haughtiness of prelates and cabin counsellors that usurped of late, whenas they shall observe ye in the midst of your victories and successes more gently brooking written exceptions against a voted Order than other courts, which had produced nothing worth memory but the weak ostentation of wealth, would have endured the least signified dislike at any sudden proclamation.If I should thus far presume upon the meek demeanour of your civil and gentle greatness, Lords and Commons, as what your published Order hath directly said, that to gainsay, I might defend myself with ease, if any should accuse me of being new or insolent, did they but know how much better I find ye esteem it to imitate the old and elegant humanity of Greece, than the barbaric pride of a Hunnish and Norwegian stateliness. And out of those ages, to whose polite wisdom and letters we owe that we are not yet Goths and Jutlanders, I could name him who from his private house wrote that discourse to the Parliament of Athens, that persuades them to change the form of democracy which was then established. Such honour was done in those days to men who professed the study of wisdom and eloquence, not only in their own country, but in other lands, that cities and signiories heard them gladly, and with great respect, if they had aught in public to admonish the state. Thus did Dion Prusaeus, a stranger and a private orator, counsel the Rhodians against a former edict; and I abound with other like examples, which to set here would be superfluous.But if from the industry of a life wholly dedicated to studious labours, and those natural endowments haply not the worst for two and fifty degrees of northern latitude, so much must be derogated, as to count me not equal to any of those who had this privilege, I would obtain to be thought not so inferior, as yourselves are superior to the most of them who received their counsel: and how far you excel them, be assured, Lords and Commons, there can no greater testimony appear, than when your prudent spirit acknowledges and obeys the voice of reason from what quarter soever it be heard speaking; and renders ye as willing to repeal any Act of your own setting forth, as any set forth by your predecessors.If ye be thus resolved, as it were injury to think ye were not, I know not what should withhold me from presenting ye with a fit instance wherein to show both that love of truth which ye eminently profess, and that uprightness of your judgment which is not wont to be partial to yourselves; by judging over again that Order which ye have ordained to regulate printing:--that no book, pamphlet, or paper shall be henceforth printed, unless the same be first approved and licensed by such, or at least one of such, as shall be thereto appointed. For that part which preserves justly every man's copy to himself, or provides for the poor, I touch not, only wish they be not made pretences to abuse and persecute honest and painful men, who offend not in either of these particulars. But that other clause of licensing books, which we thought had died with his brother quadragesimal and matrimonial when the prelates expired, I shall now attend with such a homily, as shall lay before ye, first the inventors of it to be those whom ye will be loath to own; next what is to be thought in general of reading, whatever sort the books be; and that this Order avails nothing to the suppressing of scandalous, seditious, and libellous books, which were mainly intended to be suppressed. Last, that it will be primely to the discouragement of all learning, and the stop of truth, not only by disexercising and blunting our abilities in what we know already, but by hindering and cropping the discovery that might be yet further made both in religious and civil wisdom.I deny not, but that it is of greatest concernment in the Church and Commonwealth, to have a vigilant eye how books demean themselves as well as men; and thereafter to confine, imprison, and do sharpest justice on them as malefactors. For books are not absolutely dead things, but do contain a potency of life in them to be as active as that soul was whose progeny they are; nay, they do preserve as in a vial the purest efficacy and extraction of that living intellect that bred them. I know they are as lively, and as vigorously productive, as those fabulous dragon's teeth; and being sown up and down, may chance to spring up armed men. And yet, on the other hand, unless wariness be used, as good almost kill a man as kill a good book. Who kills a man kills a reasonable creature, God's image; but he who destroys a good book, kills reason itself, kills the image of God, as it were in the eye. Many a man lives a burden to the earth; but a good book is the precious life-blood of a master spirit, embalmed and treasured up on purpose to a life beyond life. 'Tis true, no age can restore a life, whereof perhaps there is no great loss; and revolutions of ages do not oft recover the loss of a rejected truth, for the want of which whole nations fare the worse.We should be wary therefore what persecution we raise against the living labours of public men, how we spill that seasoned life of man, preserved and stored up in books; since we see a kind of homicide may be thus committed, sometimes a martyrdom, and if it extend to the whole impression, a kind of massacre; whereof the execution ends not in the slaying of an elemental life, but strikes at that ethereal and fifth essence, the breath of reason itself, slays an immortality rather than a life. But lest I should be condemned of introducing license, while I oppose licensing, I refuse not the pains to be so much historical, as will serve to show what hath been done by ancient and famous commonwealths against this disorder, till the very time that this project of licensing crept out of the Inquisition, was catched up by our prelates, and hath caught some of our presbyters.In Athens, where books and wits were ever busier than in any other part of Greece, I find but only two sorts of writings which the magistrate cared to take notice of; those either blasphemous and atheistical, or libellous. Thus the books of Protagoras were by the judges of Areopagus commanded to be burnt, and himself banished the territory for a discourse begun with his confessing not to know WHETHER THERE WERE GODS, OR WHETHER NOT. And against defaming, it was decreed that none should be traduced by name, as was the manner of Vetus Comoedia, whereby we may guess how they censured libelling. And this course was quick enough, as Cicero writes, to quell both the desperate wits of other atheists, and the open way of defaming, as the event showed. Of other sects and opinions, though tending to voluptuousness, and the denying of divine Providence, they took no heed.Therefore we do not read that either Epicurus, or that libertine school of Cyrene, or what the Cynic impudence uttered, was ever questioned by the laws. Neither is it recorded that the writings of those old comedians were suppressed, though the acting of them were forbid; and that Plato commended the reading of Aristophanes, the loosest of them all, to his royal scholar Dionysius, is commonly known, and may be excused, if holy Chrysostom, as is reported, nightly studied so much the same author and had the art to cleanse a scurrilous vehemence into the style of a rousing sermon.That other leading city of Greece, Lacedaemon, considering that Lycurgus their lawgiver was so addicted to elegant learning, as to have been the first that brought out of Ionia the scattered works of Homer, and sent the poet Thales from Crete to prepare and mollify the Spartan surliness with his smooth songs and odes, the better to plant among them law and civility, it is to be wondered how museless and unbookish they were, minding nought but the feats of war. There needed no licensing of books among them, for they disliked all but their own laconic apophthegms, and took a slight occasion to chase Archilochus out of their city, perhaps for composing in a higher strain than their own soldierly ballads and roundels could reach to. Or if it were for his broad verses, they were not therein so cautious but they were as dissolute in their promiscuous conversing; whence Euripides affirms in Andromache, that their women were all unchaste. Thus much may give us light after what sort of books were prohibited among the Greeks.The Romans also, for many ages trained up only to a military roughness resembling most the Lacedaemonian guise, knew of learning little but what their twelve Tables, and the Pontific College with their augurs and flamens taught them in religion and law; so unacquainted with other learning, that when Carneades and Critolaus, with the Stoic Diogenes, coming ambassadors to Rome, took thereby occasion to give the city a taste of their philosophy, they were suspected for seducers by no less a man than Cato the Censor, who moved it in the Senate to dismiss them speedily, and to banish all such Attic babblers out of Italy. But Scipio and others of the noblest senators withstood him and his old Sabine austerity; honoured and admired the men; and the censor himself at last, in his old age, fell to the study of that whereof before he was so scrupulous. And yet at the same time Naevius and Plautus, the first Latin comedians, had filled the city with all the borrowed scenes of Menander and Philemon. Then began to be considered there also what was to be done to libellous books and authors; for Naevius was quickly cast into prison for his unbridled pen, and released by the tribunes upon his recantation; we read also that libels were burnt, and the makers punished by Augustus. The like severity, no doubt, was used, if aught were impiously written against their esteemed gods. Except in these two points, how the world went in books, the magistrate kept no reckoning.And therefore Lucretius without impeachment versifies his Epicurism to Memmius, and had the honour to be set forth the second time by Cicero, so great a father of the Commonwealth; although himself disputes against that opinion in his own writings. Nor was the satirical sharpness or naked plainness of Lucilius, or Catullus, or Flaccus, by any order prohibited. And for matters of state, the story of Titus Livius, though it extolled that part which Pompey held, was not therefore suppressed by Octavius Caesar of the other faction. But that Naso was by him banished in his old age, for the wanton poems of his youth, was but a mere covert of state over some secret cause: and besides, the books were neither banished nor called in. From hence we shall meet with little else but tyranny in the Roman empire, that we may not marvel, if not so often bad as good books were silenced. I shall therefore deem to have been large enough, in producing what among the ancients was punishable to write; save only which, all other arguments were free to treat on.By this time the emperors were become Christians, whose discipline in this point I do not find to have been more severe than what was formerly in practice. The books of those whom they took to be grand heretics were examined, refuted, and condemned in the general Councils; and not till then were prohibited, or burnt, by authority of the emperor. As for the writings of heathen authors, unless they were plain invectives against Christianity, as those of Porphyrius and Proclus, they met with no interdict that can be cited, till about the year 400, in a Carthaginian Council, wherein bishops themselves were forbid to read the books of Gentiles, but heresies they might read: while others long before them, on the contrary, scrupled more the books of heretics than of Gentiles. And that the primitive Councils and bishops were wont only to declare what books were not commendable, passing no further, but leaving it to each one's conscience to read or to lay by, till after the year 800, is observed already by Padre Paolo, the great unmasker of the Trentine Council.After which time the Popes of Rome, engrossing what they pleased of political rule into their own hands, extended their dominion over men's eyes, as they had before over their judgments, burning and prohibiting to be read what they fancied not; yet sparing in their censures, and the books not many which they so dealt with: till Martin V., by his bull, not only prohibited, but was the first that excommunicated the reading of heretical books; for about that time Wickliffe and Huss, growing terrible, were they who first drove the Papal Court to a stricter policy of prohibiting. Which course Leo X. and his successors followed, until the Council of Trent and the Spanish Inquisition engendering together brought forth, or perfected, those Catalogues and expurging Indexes, that rake through the entrails of many an old good author, with a violation worse than any could be offered to his tomb. Nor did they stay in matters heretical, but any subject that was not to their palate, they either condemned in a Prohibition, or had it straight into the new purgatory of an index.To fill up the measure of encroachment, their last invention was to ordain that no book, pamphlet, or paper should be printed (as if St. Peter had bequeathed them the keys of the press also out of Paradise) unless it were approved and licensed under the hands of two or three glutton friars. For example:Let the Chancellor Cini be pleased to see if in this present work be contained aught that may withstand the printing.I have seen this present work, and find nothing athwart the Catholic faith and good manners: in witness whereof I have given, etc.Attending the precedent relation, it is allowed that this present work of Davanzati may be printed.It may be printed, July 15.Sure they have a conceit, if he of the bottomless pit had not long since broke prison, that this quadruple exorcism would bar him down. I fear their next design will be to get into their custody the licensing of that which they say Claudius intended, but went not through with. Vouchsafe to see another of their forms, the Roman stamp:Imprimatur, If it seem good to the reverend Master of the Holy Palace.ImprimaturasdfasdfSometimes five Imprimaturs are seen together dialogue-wise in the piazza of one title-page, complimenting and ducking each to other with their shaven reverences, whether the author, who stands by in perplexity at the foot of his epistle, shall to the press or to the sponge. These are the pretty responsories, these are the dear antiphonies, that so bewitched of late our prelates and their chaplains with the goodly echo they made; and besotted us to the gay imitation of a lordly Imprimatur, one from Lambeth House, another from the west end of Paul's; so apishly Romanizing, that the word of command still was set down in Latin; as if the learned grammatical pen that wrote it would cast no ink without Latin; or perhaps, as they thought, because no vulgar tongue was worthy to express the pure conceit of an Imprimatur, but rather, as I hope, for that our English, the language of men ever famous and foremost in the achievements of liberty, will not easily find servile letters enow to spell such a dictatory presumption English.And thus ye have the inventors and the original of book-licensing ripped up and drawn as lineally as any pedigree. We have it not, that can be heard of, from any ancient state, or polity or church; nor by any statute left us by our ancestors elder or later; nor from the modern custom of any reformed city or church abroad, but from the most anti-christian council and the most tyrannous inquisition that ever inquired. Till then books were ever as freely admitted into the world as any other birth; the issue of the brain was no more stifled than the issue of the womb: no envious Juno sat cross-legged over the nativity of any man's intellectual offspring; but if it proved a monster, who denies, but that it was justly burnt, or sunk into the sea? But that a book, in worse condition than a peccant soul, should be to stand before a jury ere it be born to the world, and undergo yet in darkness the judgment of Radamanth and his colleagues, ere it can pass the ferry backward into light, was never heard before, till that mysterious iniquity, provoked and troubled at the first entrance of Reformation, sought out new limbos and new hells wherein they might include our books also within the number of their damned. And this was the rare morsel so officiously snatched up, and so ill-favouredly imitated by our inquisiturient bishops, and the attendant minorites their chaplains. That ye like not now these most certain authors of this licensing order, and that all sinister intention was far distant from your thoughts, when ye were importuned the passing it, all men who know the integrity of your actions, and how ye honour truth, will clear ye readily.But some will say, what though the inventors were bad, the thing for all that may be good? It may so; yet if that thing be no such deep invention, but obvious, and easy for any man to light on, and yet best and wisest commonwealths through all ages and occasions have forborne to use it, and falsest seducers and oppressors of men were the first who took it up, and to no other purpose but to obstruct and hinder the first approach of Reformation; I am of those who believe it will be a harder alchemy than Lullius ever knew, to sublimate any good use out of such an invention. Yet this only is what I request to gain from this reason, that it may be held a dangerous and suspicious fruit, as certainly it deserves, for the tree that bore it, until I can dissect one by one the properties it has. But I have first to finish, as was propounded, what is to be thought in general of reading books, whatever sort they be, and whether be more the benefit or the harm that thence proceeds.Not to insist upon the examples of Moses, Daniel, and Paul, who were skilful in all the learning of the Egyptians, Chaldeans, and Greeks, which could not probably be without reading their books of all sorts; in Paul especially, who thought it no defilement to insert into Holy Scripture the sentences of three Greek poets, and one of them a tragedian; the question was notwithstanding sometimes controverted among the primitive doctors, but with great odds on that side which affirmed it both lawful and profitable; as was then evidently perceived, when Julian the Apostate and subtlest enemy to our faith made a decree forbidding Christians the study of heathen learning: for, said he, they wound us with our own weapons, and with our own arts and sciences they overcome us. And indeed the Christians were put so to their shifts by this crafty means, and so much in danger to decline into all ignorance, that the two Apollinarii were fain, as a man may say, to coin all the seven liberal sciences out of the Bible, reducing it into divers forms of orations, poems, dialogues, even to the calculating of a new Christian grammar. But, saith the historian Socrates, the providence of God provided better than the industry of Apollinarius and his son, by taking away that illiterate law with the life of him who devised it. So great an injury they then held it to be deprived of Hellenic learning; and thought it a persecution more undermining, and secretly decaying the Church, than the open cruelty of Decius or Diocletian.And perhaps it was the same politic drift that the devil whipped St. Jerome in a lenten dream, for reading Cicero; or else it was a phantasm bred by the fever which had then seized him. For had an angel been his discipliner, unless it were for dwelling too much upon Ciceronianisms, and had chastised the reading, not the vanity, it had been plainly partial; first to correct him for grave Cicero, and not for scurril Plautus, whom he confesses to have been reading, not long before; next to correct him only, and let so many more ancient fathers wax old in those pleasant and florid studies without the lash of such a tutoring apparition; insomuch that Basil teaches how some good use may be made of Margites, a sportful poem, not now extant, writ by Homer; and why not then of Morgante, an Italian romance much to the same purpose?But if it be agreed we shall be tried by visions, there is a vision recorded by Eusebius, far ancienter than this tale of Jerome, to the nun Eustochium, and, besides, has nothing of a fever in it. Dionysius Alexandrinus was about the year 240 a person of great name in the Church for piety and learning, who had wont to avail himself much against heretics by being conversant in their books; until a certain presbyter laid it scrupulously to his conscience, how he durst venture himself among those defiling volumes. The worthy man, loath to give offence, fell into a new debate with himself what was to be thought; when suddenly a vision sent from God (it is his own epistle that so avers it) confirmed him in these words: READ ANY BOOKS WHATEVER COME TO THY HANDS, FOR THOU ART SUFFICIENT BOTH TO JUDGE ARIGHT AND TO EXAMINE EACH MATTER. To this revelation he assented the sooner, as he confesses, because it was answerable to that of the Apostle to the Thessalonians, PROVE ALL THINGS, HOLD FAST THAT WHICH IS GOOD. And he might have added another remarkable saying of the same author: TO THE PURE, ALL THINGS ARE PURE; not only meats and drinks, but all kind of knowledge whether of good or evil; the knowledge cannot defile, nor consequently the books, if the will and conscience be not defiled.For books are as meats and viands are; some of good, some of evil substance; and yet God, in that unapocryphal vision, said without exception, RISE, PETER, KILL AND EAT, leaving the choice to each man's discretion. Wholesome meats to a vitiated stomach differ little or nothing from unwholesome; and best books to a naughty mind are not unappliable to occasions of evil. Bad meats will scarce breed good nourishment in the healthiest concoction; but herein the difference is of bad books, that they to a discreet and judicious reader serve in many respects to discover, to confute, to forewarn, and to illustrate. Whereof what better witness can ye expect I should produce, than one of your own now sitting in Parliament, the chief of learned men reputed in this land, Mr. Selden; whose volume of natural and national laws proves, not only by great authorities brought together, but by exquisite reasons and theorems almost mathematically demonstrative, that all opinions, yea errors, known, read, and collated, are of main service and assistance toward the speedy attainment of what is truest. I conceive, therefore, that when God did enlarge the universal diet of man's body, saving ever the rules of temperance, he then also, as before, left arbitrary the dieting and repasting of our minds; as wherein every mature man might have to exercise his own leading capacity.How great a virtue is temperance, how much of moment through the whole life of man! Yet God commits the managing so great a trust, without particular law or prescription, wholly to the demeanour of every grown man. And therefore when he himself tabled the Jews from heaven, that omer, which was every man's daily portion of manna, is computed to have been more than might have well sufficed the heartiest feeder thrice as many meals. For those actions which enter into a man, rather than issue out of him, and therefore defile not, God uses not to captivate under a perpetual childhood of prescription, but trusts him with the gift of reason to be his own chooser; there were but little work left for preaching, if law and compulsion should grow so fast upon those things which heretofore were governed only by exhortation. Solomon informs us, that much reading is a weariness to the flesh; but neither he nor other inspired author tells us that such or such reading is unlawful: yet certainly had God thought good to limit us herein, it had been much more expedient to have told us what was unlawful than what was wearisome. As for the burning of those Ephesian books by St. Paul's converts; 'tis replied the books were magic, the Syriac so renders them. It was a private act, a voluntary act, and leaves us to a voluntary imitation: the men in remorse burnt those books which were their own; the magistrate by this example is not appointed; these men practised the books, another might perhaps have read them in some sort usefully.Good and evil we know in the field of this world grow up together almost inseparably; and the knowledge of good is so involved and interwoven with the knowledge of evil, and in so many cunning resemblances hardly to be discerned, that those confused seeds which were imposed upon Psyche as an incessant labour to cull out, and sort asunder, were not more intermixed. It was from out the rind of one apple tasted, that the knowledge of good and evil, as two twins cleaving together, leaped forth into the world. And perhaps this is that doom which Adam fell into of knowing good and evil, that is to say of knowing good by evil. As therefore the state of man now is; what wisdom can there be to choose, what continence to forbear without the knowledge of evil? He that can apprehend and consider vice with all her baits and seeming pleasures, and yet abstain, and yet distinguish, and yet prefer that which is truly better, he is the true warfaring Christian.I cannot praise a fugitive and cloistered virtue, unexercised and unbreathed, that never sallies out and sees her adversary but slinks out of the race, where that immortal garland is to be run for, not without dust and heat. Assuredly we bring not innocence into the world, we bring impurity much rather; that which purifies us is trial, and trial is by what is contrary. That virtue therefore which is but a youngling in the contemplation of evil, and knows not the utmost that vice promises to her followers, and rejects it, is but a blank virtue, not a pure; her whiteness is but an excremental whiteness. Which was the reason why our sage and serious poet Spenser, whom I dare be known to think a better teacher than Scotus or Aquinas, describing true temperance under the person of Guion, brings him in with his palmer through the cave of Mammon, and the bower of earthly bliss, that he might see and know, and yet abstain. Since therefore the knowledge and survey of vice is in this world so necessary to the constituting of human virtue, and the scanning of error to the confirmation of truth, how can we more safely, and with less danger, scout into the regions of sin and falsity than by reading all manner of tractates and hearing all manner of reason? And this is the benefit which may be had of books promiscuously read.But of the harm that may result hence three kinds are usually reckoned. First, is feared the infection that may spread; but then all human learning and controversy in religious points must remove out of the world, yea the Bible itself; for that ofttimes relates blasphemy not nicely, it describes the carnal sense of wicked men not unelegantly, it brings in holiest men passionately murmuring against Providence through all the arguments of Epicurus: in other great disputes it answers dubiously and darkly to the common reader. And ask a Talmudist what ails the modesty of his marginal Keri, that Moses and all the prophets cannot persuade him to pronounce the textual Chetiv. For these causes we all know the Bible itself put by the Papist must be next removed, as Clement of Alexandria, and that Eusebian book of Evangelic preparation, transmitting our ears through a hoard of heathenish obscenities to receive the Gospel. Who finds not that Irenaeus, Epiphanius, Jerome, and others discover more heresies than they well confute, and that oft for heresy which is the truer opinion?Nor boots it to say for these, and all the heathen writers of greatest infection, if it must be thought so, with whom is bound up the life of human learning, that they writ in an unknown tongue, so long as we are sure those languages are known as well to the worst of men, who are both most able and most diligent to instil the poison they suck, first into the courts of princes, acquainting them with the choicest delights and criticisms of sin. As perhaps did that Petronius whom Nero called his Arbiter, the master of his revels; and the notorious ribald of Arezzo, dreaded and yet dear to the Italian courtiers. I name not him for posterity's sake, whom Henry VIII. named in merriment his vicar of hell. By which compendious way all the contagion that foreign books can infuse will find a passage to the people far easier and shorter than an Indian voyage, though it could be sailed either by the north of Cataio eastward, or of Canada westward, while our Spanish licensing gags the English press never so severely.But on the other side that infection which is from books of controversy in religion is more doubtful and dangerous to the learned than to the ignorant; and yet those books must be permitted untouched by the licenser. It will be hard to instance where any ignorant man hath been ever seduced by papistical book in English, unless it were commended and expounded to him by some of that clergy: and indeed all such tractates, whether false or true, are as the prophecy of Isaiah was to the eunuch, not to be UNDERSTOOD WITHOUT A GUIDE. But of our priests and doctors how many have been corrupted by studying the comments of Jesuits and Sorbonists, and how fast they could transfuse that corruption into the people, our experience is both late and sad. It is not forgot, since the acute and distinct Arminius was perverted merely by the perusing of a nameless discourse written at Delft, which at first he took in hand to confute.Seeing, therefore, that those books, and those in great abundance, which are likeliest to taint both life and doctrine, cannot be suppressed without the fall of learning and of all ability in disputation, and that these books of either sort are most and soonest catching to the learned, from whom to the common people whatever is heretical or dissolute may quickly be conveyed, and that evil manners are as perfectly learnt without books a thousand other ways which cannot be stopped, and evil doctrine not with books can propagate, except a teacher guide, which he might also do without writing, and so beyond prohibiting, I am not able to unfold, how this cautelous enterprise of licensing can be exempted from the number of vain and impossible attempts. And he who were pleasantly disposed could not well avoid to liken it to the exploit of that gallant man who thought to pound up the crows by shutting his park gate.Besides another inconvenience, if learned men be the first receivers out of books and dispreaders both of vice and error, how shall the licensers themselves be confided in, unless we can confer upon them, or they assume to themselves above all others in the land, the grace of infallibility and uncorruptedness? And again, if it be true that a wise man, like a good refiner, can gather gold out of the drossiest volume, and that a fool will be a fool with the best book, yea or without book; there is no reason that we should deprive a wise man of any advantage to his wisdom, while we seek to restrain from a fool, that which being restrained will be no hindrance to his folly. For if there should be so much exactness always used to keep that from him which is unfit for his reading, we should in the judgment of Aristotle not only, but of Solomon and of our Saviour, not vouchsafe him good precepts, and by consequence not willingly admit him to good books; as being certain that a wise man will make better use of an idle pamphlet, than a fool will do of sacred Scripture.'Tis next alleged we must not expose ourselves to temptations without necessity, and next to that, not employ our time in vain things. To both these objections one answer will serve, out of the grounds already laid, that to all men such books are not temptations, nor vanities, but useful drugs and materials wherewith to temper and compose effective and strong medicines, which man's life cannot want. The rest, as children and childish men, who have not the art to qualify and prepare these working minerals, well may be exhorted to forbear, but hindered forcibly they cannot be by all the licensing that Sainted Inquisition could ever yet contrive. Which is what I promised to deliver next: that this order of licensing conduces nothing to the end for which it was framed; and hath almost prevented me by being clear already while thus much hath been explaining. See the ingenuity of Truth, who, when she gets a free and willing hand, opens herself faster than the pace of method and discourse can overtake her.It was the task which I began with, to show that no nation, or well-instituted state, if they valued books at all, did ever use this way of licensing; and it might be answered, that this is a piece of prudence lately discovered. To which I return, that as it was a thing slight and obvious to think on, so if it had been difficult to find out, there wanted not among them long since who suggested such a course; which they not following, leave us a pattern of their judgment that it was not the rest knowing, but the not approving, which was the cause of their not using it.Plato, a man of high authority, indeed, but least of all for his Commonwealth, in the book of his Laws, which no city ever yet received, fed his fancy by making many edicts to his airy burgomasters, which they who otherwise admire him wish had been rather buried and excused in the genial cups of an Academic night sitting. By which laws he seems to tolerate no kind of learning but by unalterable decree, consisting most of practical traditions, to the attainment whereof a library of smaller bulk than his own Dialogues would be abundant. And there also enacts, that no poet should so much as read to any private man what he had written, until the judges and law-keepers had seen it, and allowed it. But that Plato meant this law peculiarly to that commonwealth which he had imagined, and to no other, is evident. Why was he not else a lawgiver to himself, but a transgressor, and to be expelled by his own magistrates; both for the wanton epigrams and dialogues which he made, and his perpetual reading of Sophron Mimus and Aristophanes, books of grossest infamy, and also for commending the latter of them, though he were the malicious libeller of his chief friends, to be read by the tyrant Dionysius, who had little need of such trash to spend his time on? But that he knew this licensing of poems had reference and dependence to many other provisos there set down in his fancied republic, which in this world could have no place: and so neither he himself, nor any magistrate or city, ever imitated that course, which, taken apart from those other collateral injunctions, must needs be vain and fruitless. For if they fell upon one kind of strictness, unless their care were equal to regulate all other things of like aptness to corrupt the mind, that single endeavour they knew would be but a fond labour; to shut and fortify one gate against corruption, and be necessitated to leave others round about wide open.If we think to regulate printing, thereby to rectify manners, we must regulate all recreation and pastimes, all that is delightful to man. No music must be heard, no song be set or sung, but what is grave and Doric. There must be licensing dancers, that no gesture, motion, or deportment be taught our youth but what by their allowance shall be thought honest; for such Plato was provided of. It will ask more than the work of twenty licensers to examine all the lutes, the violins, and the guitars in every house; they must not be suffered to prattle as they do, but must be licensed what they may say. And who shall silence all the airs and madrigals that whisper softness in chambers? The windows also, and the balconies must be thought on; there are shrewd books, with dangerous frontispieces, set to sale; who shall prohibit them, shall twenty licensers? The villages also must have their visitors to inquire what lectures the bagpipe and the rebeck reads, even to the ballatry and the gamut of every municipal fiddler, for these are the countryman's Arcadias, and his Monte Mayors.Next, what more national corruption, for which England hears ill abroad, than household gluttony: who shall be the rectors of our daily rioting? And what shall be done to inhibit the multitudes that frequent those houses where drunkenness is sold and harboured? Our garments also should be referred to the licensing of some more sober workmasters to see them cut into a less wanton garb. Who shall regulate all the mixed conversation of our youth, male and female together, as is the fashion of this country? Who shall still appoint what shall be discoursed, what presumed, and no further? Lastly, who shall forbid and separate all idle resort, all evil company? These things will be, and must be; but how they shall be least hurtful, how least enticing, herein consists the grave and governing wisdom of a state.To sequester out of the world into Atlantic and Utopian polities, which never can be drawn into use, will not mend our condition; but to ordain wisely as in this world of evil, in the midst whereof God hath placed us unavoidably. Nor is it Plato's licensing of books will do this, which necessarily pulls along with it so many other kinds of licensing, as will make us all both ridiculous and weary, and yet frustrate; but those unwritten, or at least unconstraining, laws of virtuous education, religious and civil nurture, which Plato there mentions as the bonds and ligaments of the commonwealth, the pillars and the sustainers of every written statute; these they be which will bear chief sway in such matters as these, when all licensing will be easily eluded. Impunity and remissness, for certain, are the bane of a commonwealth; but here the great art lies, to discern in what the law is to bid restraint and punishment, and in what things persuasion only is to work.If every action, which is good or evil in man at ripe years, were to be under pittance and prescription and compulsion, what were virtue but a name, what praise could be then due to well-doing, what gramercy to be sober, just, or continent? Many there be that complain of divine Providence for suffering Adam to transgress; foolish tongues! When God gave him reason, he gave him freedom to choose, for reason is but choosing; he had been else a mere artificial Adam, such an Adam as he is in the motions. We ourselves esteem not of that obedience, or love, or gift, which is of force: God therefore left him free, set before him a provoking object, ever almost in his eyes; herein consisted his merit, herein the right of his reward, the praise of his abstinence. Wherefore did he create passions within us, pleasures round about us, but that these rightly tempered are the very ingredients of virtue?They are not skilful considerers of human things, who imagine to remove sin by removing the matter of sin; for, besides that it is a huge heap increasing under the very act of diminishing, though some part of it may for a time be withdrawn from some persons, it cannot from all, in such a universal thing as books are; and when this is done, yet the sin remains entire. Though ye take from a covetous man all his treasure, he has yet one jewel left, ye cannot bereave him of his covetousness. Banish all objects of lust, shut up all youth into the severest discipline that can be exercised in any hermitage, ye cannot make them chaste, that came not hither so; such great care and wisdom is required to the right managing of this point. Suppose we could expel sin by this means; look how much we thus expel of sin, so much we expel of virtue: for the matter of them both is the same; remove that, and ye remove them both alike.This justifies the high providence of God, who, though he command us temperance, justice, continence, yet pours out before us, even to a profuseness, all desirable things, and gives us minds that can wander beyond all limit and satiety. Why should we then affect a rigour contrary to the manner of God and of nature, by abridging or scanting those means, which books freely permitted are, both to the trial of virtue and the exercise of truth? It would be better done, to learn that the law must needs be frivolous, which goes to restrain things, uncertainly and yet equally working to good and to evil. And were I the chooser, a dream of well-doing should be preferred before many times as much the forcible hindrance of evil-doing. For God sure esteems the growth and completing of one virtuous person more than the restraint of ten vicious.And albeit whatever thing we hear or see, sitting, walking, travelling, or conversing, may be fitly called our book, and is of the same effect that writings are, yet grant the thing to be prohibited were only books, it appears that this Order hitherto is far insufficient to the end which it intends. Do we not see, not once or oftener, but weekly, that continued court-libel against the Parliament and City, printed, as the wet sheets can witness, and dispersed among us, for all that licensing can do? Yet this is the prime service a man would think, wherein this Order should give proof of itself. If it were executed, you'll say. But certain, if execution be remiss or blindfold now, and in this particular, what will it be hereafter and in other books? If then the Order shall not be vain and frustrate, behold a new labour, Lords and Commons, ye must repeal and proscribe all scandalous and unlicensed books already printed and divulged; after ye have drawn them up into a list, that all may know which are condemned, and which not; and ordain that no foreign books be delivered out of custody, till they have been read over. This office will require the whole time of not a few overseers, and those no vulgar men. There be also books which are partly useful and excellent, partly culpable and pernicious; this work will ask as many more officials, to make expurgations and expunctions, that the commonwealth of learning be not damnified. In fine, when the multitude of books increase upon their hands, ye must be fain to catalogue all those printers who are found frequently offending, and forbid the importation of their whole suspected typography. In a word, that this your Order may be exact and not deficient, ye must reform it perfectly according to the model of Trent and Seville, which I know ye abhor to do.Yet though ye should condescend to this, which God forbid, the Order still would be but fruitless and defective to that end whereto ye meant it. If to prevent sects and schisms, who is so unread or so uncatechized in story, that hath not heard of many sects refusing books as a hindrance, and preserving their doctrine unmixed for many ages, only by unwritten traditions? The Christian faith, for that was once a schism, is not unknown to have spread all over Asia, ere any Gospel or Epistle was seen in writing. If the amendment of manners be aimed at, look into Italy and Spain, whether those places be one scruple the better, the honester, the wiser, the chaster, since all the inquisitional rigour that hath been executed upon books.Another reason, whereby to make it plain that this Order will miss the end it seeks, consider by the quality which ought to be in every licenser. It cannot be denied but that he who is made judge to sit upon the birth or death of books, whether they may be wafted into this world or not, had need to be a man above the common measure, both studious, learned, and judicious; there may be else no mean mistakes in the censure of what is passable or not; which is also no mean injury. If he be of such worth as behooves him, there cannot be a more tedious and unpleasing journey-work, a greater loss of time levied upon his head, than to be made the perpetual reader of unchosen books and pamphlets, ofttimes huge volumes. There is no book that is acceptable unless at certain seasons; but to be enjoined the reading of that at all times, and in a hand scarce legible, whereof three pages would not down at any time in the fairest print, is an imposition which I cannot believe how he that values time and his own studies, or is but of a sensible nostril, should be able to endure. In this one thing I crave leave of the present licensers to be pardoned for so thinking; who doubtless took this office up, looking on it through their obedience to the Parliament, whose command perhaps made all things seem easy and unlaborious to them; but that this short trial hath wearied them out already, their own expressions and excuses to them who make so many journeys to solicit their licence are testimony enough. Seeing therefore those who now possess the employment by all evident signs wish themselves well rid of it; and that no man of worth, none that is not a plain unthrift of his own hours, is ever likely to succeed them, except he mean to put himself to the salary of a press corrector; we may easily foresee what kind of licensers we are to expect hereafter, either ignorant, imperious, and remiss, or basely pecuniary. This is what I had to show, wherein this Order cannot conduce to that end whereof it bears the intention.I lastly proceed from the no good it can do, to the manifest hurt it causes, in being first the greatest discouragement and affront that can be offered to learning, and to learned men.It was the complaint and lamentation of prelates, upon every least breath of a motion to remove pluralities, and distribute more equally Church revenues, that then all learning would be for ever dashed and discouraged. But as for that opinion, I never found cause to think that the tenth part of learning stood or fell with the clergy: nor could I ever but hold it for a sordid and unworthy speech of any churchman who had a competency left him. If therefore ye be loath to dishearten utterly and discontent, not the mercenary crew of false pretenders to learning, but the free and ingenuous sort of such as evidently were born to study, and love learning for itself, not for lucre or any other end but the service of God and of truth, and perhaps that lasting fame and perpetuity of praise which God and good men have consented shall be the reward of those whose published labours advance the good of mankind; then know that, so far to distrust the judgment and the honesty of one who hath but a common repute in learning, and never yet offended, as not to count him fit to print his mind without a tutor and examiner, lest he should drop a schism, or something of corruption, is the greatest displeasure and indignity to a free and knowing spirit that can be put upon him.What advantage is it to be a man, over it is to be a boy at school, if we have only escaped the ferula to come under the fescue of an Imprimatur; if serious and elaborate writings, as if they were no more than the theme of a grammar-lad under his pedagogue, must not be uttered without the cursory eyes of a temporizing and extemporizing licenser? He who is not trusted with his own actions, his drift not being known to be evil, and standing to the hazard of law and penalty, has no great argument to think himself reputed in the Commonwealth wherein he was born for other than a fool or a foreigner. When a man writes to the world, he summons up all his reason and deliberation to assist him; he searches, meditates, is industrious, and likely consults and confers with his judicious friends; after all which done he takes himself to be informed in what he writes, as well as any that writ before him. If, in this the most consummate act of his fidelity and ripeness, no years, no industry, no former proof of his abilities can bring him to that state of maturity, as not to be still mistrusted and suspected, unless he carry all his considerate diligence, all his midnight watchings and expense of Palladian oil, to the hasty view of an unleisured licenser, perhaps much his younger, perhaps his inferior in judgment, perhaps one who never knew the labour of bookwriting, and if he be not repulsed or slighted, must appear in print like a puny with his guardian, and his censor's hand on the back of his title to be his bail and surety that he is no idiot or seducer, it cannot be but a dishonour and derogation to the author, to the book, to the privilege and dignity of learning.And what if the author shall be one so copious of fancy, as to have many things well worth the adding come into his mind after licensing, while the book is yet under the press, which not seldom happens to the best and diligentest writers; and that perhaps a dozen times in one book? The printer dares not go beyond his licensed copy; so often then must the author trudge to his leave-giver, that those his new insertions may be viewed; and many a jaunt will be made, ere that licenser, for it must be the same man, can either be found, or found at leisure; meanwhile either the press must stand still, which is no small damage, or the author lose his accuratest thoughts, and send the book forth worse than he had made it, which to a diligent writer is the greatest melancholy and vexation that can befall.And how can a man teach with authority, which is the life of teaching; how can he be a doctor in his book as he ought to be, or else had better be silent, whenas all he teaches, all he delivers, is but under the tuition, under the correction of his patriarchal licenser to blot or alter what precisely accords not with the hidebound humour which he calls his judgment? When every acute reader, upon the first sight of a pedantic licence, will be ready with these like words to ding the book a quoit's distance from him: I hate a pupil teacher, I endure not an instructor that comes to me under the wardship of an overseeing fist. I know nothing of the licenser, but that I have his own hand here for his arrogance; who shall warrant me his judgment? The State, sir, replies the stationer, but has a quick return: The State shall be my governors, but not my critics; they may be mistaken in the choice of a licenser, as easily as this licenser may be mistaken in an author; this is some common stuff; and he might add from Sir Francis Bacon, THAT SUCH AUTHORIZED BOOKS ARE BUT THE LANGUAGE OF THE TIMES. For though a licenser should happen to be judicious more than ordinary, which will be a great jeopardy of the next succession, yet his very office and his commission enjoins him to let pass nothing but what is vulgarly received already.Nay, which is more lamentable, if the work of any deceased author, though never so famous in his lifetime and even to this day, come to their hands for licence to be printed, or reprinted, if there be found in his book one sentence of a venturous edge, uttered in the height of zeal (and who knows whether it might not be the dictate of a divine spirit?) yet not suiting with every low decrepit humour of their own, though it were Knox himself, the reformer of a kingdom, that spake it, they will not pardon him their dash: the sense of that great man shall to all posterity be lost, for the fearfulness or the presumptuous rashness of a perfunctory licenser. And to what an author this violence hath been lately done, and in what book of greatest consequence to be faithfully published, I could now instance, but shall forbear till a more convenient season.Yet if these things be not resented seriously and timely by them who have the remedy in their power, but that such iron-moulds as these shall have authority to gnaw out the choicest periods of exquisitest books, and to commit such a treacherous fraud against the orphan remainders of worthiest men after death, the more sorrow will belong to that hapless race of men, whose misfortune it is to have understanding. Henceforth let no man care to learn, or care to be more than worldly-wise; for certainly in higher matters to be ignorant and slothful, to be a common steadfast dunce, will be the only pleasant life, and only in request.And it is a particular disesteem of every knowing person alive, and most injurious to the written labours and monuments of the dead, so to me it seems an undervaluing and vilifying of the whole nation. I cannot set so light by all the invention, the art, the wit, the grave and solid judgment which is in England, as that it can be comprehended in any twenty capacities how good soever, much less that it should not pass except their superintendence be over it, except it be sifted and strained with their strainers, that it should be uncurrent without their manual stamp. Truth and understanding are not such wares as to be monopolized and traded in by tickets and statutes and standards. We must not think to make a staple commodity of all the knowledge in the land, to mark and licence it like our broadcloth and our woolpacks. What is it but a servitude like that imposed by the Philistines, not to be allowed the sharpening of our own axes and coulters, but we must repair from all quarters to twenty licensing forges? Had anyone written and divulged erroneous things and scandalous to honest life, misusing and forfeiting the esteem had of his reason among men, if after conviction this only censure were adjudged him that he should never henceforth write but what were first examined by an appointed officer, whose hand should be annexed to pass his credit for him that now he might be safely read; it could not be apprehended less than a disgraceful punishment. Whence to include the whole nation, and those that never yet thus offended, under such a diffident and suspectful prohibition, may plainly be understood what a disparagement it is. So much the more, whenas debtors and delinquents may walk abroad without a keeper, but unoffensive books must not stir forth without a visible jailer in their title.Nor is it to the common people less than a reproach; for if we be so jealous over them, as that we dare not trust them with an English pamphlet, what do we but censure them for a giddy, vicious, and ungrounded people; in such a sick and weak state of faith and discretion, as to be able to take nothing down but through the pipe of a licenser? That this is care or love of them, we cannot pretend, whenas, in those popish places where the laity are most hated and despised, the same strictness is used over them. Wisdom we cannot call it, because it stops but one breach of licence, nor that neither: whenas those corruptions, which it seeks to prevent, break in faster at other doors which cannot be shut.And in conclusion it reflects to the disrepute of our ministers also, of whose labours we should hope better, and of the proficiency which their flock reaps by them, than that after all this light of the Gospel which is, and is to be, and all this continual preaching, they should still be frequented with such an unprincipled, unedified and laic rabble, as that the whiff of every new pamphlet should stagger them out of their catechism and Christian walking. This may have much reason to discourage the ministers when such a low conceit is had of all their exhortations, and the benefiting of their hearers, as that they are not thought fit to be turned loose to three sheets of paper without a licenser; that all the sermons, all the lectures preached, printed, vented in such numbers, and such volumes, as have now well nigh made all other books unsaleable, should not be armour enough against one single Enchiridion, without the castle of St. Angelo of an Imprimatur.And lest some should persuade ye, Lords and Commons, that these arguments of learned men's discouragement at this your Order are mere flourishes, and not real, I could recount what I have seen and heard in other countries, where this kind of inquisition tyrannizes; when I have sat among their learned men, for that honour I had, and been counted happy to be born in such a place of philosophic freedom, as they supposed England was, while themselves did nothing but bemoan the servile condition into which learning amongst them was brought; that this was it which had damped the glory of Italian wits; that nothing had been there written now these many years but flattery and fustian. There it was that I found and visited the famous Galileo, grown old, a prisoner to the Inquisition, for thinking in astronomy otherwise than the Franciscan and Dominican licensers thought. And though I knew that England then was groaning loudest under the prelatical yoke, nevertheless I took it as a pledge of future happiness, that other nations were so persuaded of her liberty. Yet was it beyond my hope that those worthies were then breathing in her air, who should be her leaders to such a deliverance, as shall never be forgotten by any revolution of time that this world hath to finish. When that was once begun, it was as little in my fear that what words of complaint I heard among learned men of other parts uttered against the Inquisition, the same I should hear by as learned men at home, uttered in time of Parliament against an order of licensing; and that so generally that, when I had disclosed myself a companion of their discontent, I might say, if without envy, that he whom an honest quaestorship had endeared to the Sicilians was not more by them importuned against Verres, than the favourable opinion which I had among many who honour ye, and are known and respected by ye, loaded me with entreaties and persuasions, that I would not despair to lay together that which just reason should bring into my mind, toward the removal of an undeserved thraldom upon learning. That this is not therefore the disburdening of a particular fancy, but the common grievance of all those who had prepared their minds and studies above the vulgar pitch to advance truth in others, and from others to entertain it, thus much may satisfy.And in their name I shall for neither friend nor foe conceal what the general murmur is; that if it come to inquisitioning again and licensing, and that we are so timorous of ourselves, and so suspicious of all men, as to fear each book and the shaking of every leaf, before we know what the contents are; if some who but of late were little better than silenced from preaching shall come now to silence us from reading, except what they please, it cannot be guessed what is intended by some but a second tyranny over learning: and will soon put it out of controversy, that bishops and presbyters are the same to us, both name and thing. That those evils of prelaty, which before from five or six and twenty sees were distributively charged upon the whole people, will now light wholly upon learning, is not obscure to us: whenas now the pastor of a small unlearned parish on the sudden shall be exalted archbishop over a large diocese of books, and yet not remove, but keep his other cure too, a mystical pluralist. He who but of late cried down the sole ordination of every novice Bachelor of Art, and denied sole jurisdiction over the simplest parishioner, shall now at home in his private chair assume both these over worthiest and excellentest books and ablest authors that write them.This is not, ye Covenants and Protestations that we have made! this is not to put down prelaty; this is but to chop an episcopacy; this is but to translate the Palace Metropolitan from one kind of dominion into another; this is but an old canonical sleight of commuting our penance. To startle thus betimes at a mere unlicensed pamphlet will after a while be afraid of every conventicle, and a while after will make a conventicle of every Christian meeting. But I am certain that a State governed by the rules of justice and fortitude, or a Church built and founded upon the rock of faith and true knowledge, cannot be so pusillanimous. While things are yet not constituted in religion, that freedom of writing should be restrained by a discipline imitated from the prelates and learnt by them from the Inquisition, to shut us up all again into the breast of a licenser, must needs give cause of doubt and discouragement to all learned and religious men.Who cannot but discern the fineness of this politic drift, and who are the contrivers; that while bishops were to be baited down, then all presses might be open; it was the people's birthright and privilege in time of Parliament, it was the breaking forth of light. But now, the bishops abrogated and voided out of the Church, as if our Reformation sought no more but to make room for others into their seats under another name, the episcopal arts begin to bud again, the cruse of truth must run no more oil, liberty of printing must be enthralled again under a prelatical commission of twenty, the privilege of the people nullified, and, which is worse, the freedom of learning must groan again, and to her old fetters: all this the Parliament yet sitting. Although their own late arguments and defences against the prelates might remember them, that this obstructing violence meets for the most part with an event utterly opposite to the end which it drives at: instead of suppressing sects and schisms, it raises them and invests them with a reputation. The punishing of wits enhances their authority, saith the Viscount St. Albans; and a forbidden writing is thought to be a certain spark of truth that flies up in the faces of them who seek to tread it out. This Order, therefore, may prove a nursing-mother to sects, but I shall easily show how it will be a step-dame to Truth: and first by disenabling us to the maintenance of what is known already.Well knows he who uses to consider, that our faith and knowledge thrives by exercise, as well as our limbs and complexion. Truth is compared in Scripture to a streaming fountain; if her waters flow not in a perpetual progression, they sicken into a muddy pool of conformity and tradition. A man may be a heretic in the truth; and if he believe things only because his pastor says so, or the Assembly so determines, without knowing other reason, though his belief be true, yet the very truth he holds becomes his heresy.There is not any burden that some would gladlier post off to another than the charge and care of their religion. There be--who knows not that there be?--of Protestants and professors who live and die in as arrant an implicit faith as any lay Papist of Loretto. A wealthy man, addicted to his pleasure and to his profits, finds religion to be a traffic so entangled, and of so many piddling accounts, that of all mysteries he cannot skill to keep a stock going upon that trade. What should he do? fain he would have the name to be religious, fain he would bear up with his neighbours in that. What does he therefore, but resolves to give over toiling, and to find himself out some factor, to whose care and credit he may commit the whole managing of his religious affairs; some divine of note and estimation that must be. To him he adheres, resigns the whole warehouse of his religion, with all the locks and keys, into his custody; and indeed makes the very person of that man his religion; esteems his associating with him a sufficient evidence and commendatory of his own piety. So that a man may say his religion is now no more within himself, but is become a dividual movable, and goes and comes near him, according as that good man frequents the house. He entertains him, gives him gifts, feasts him, lodges him; his religion comes home at night, prays, is liberally supped, and sumptuously laid to sleep; rises, is saluted, and after the malmsey, or some well-spiced brewage, and better breakfasted than he whose morning appetite would have gladly fed on green figs between Bethany and Jerusalem, his religion walks abroad at eight, and leaves his kind entertainer in the shop trading all day without his religion.Another sort there be who, when they hear that all things shall be ordered, all things regulated and settled, nothing written but what passes through the custom-house of certain publicans that have the tonnaging and poundaging of all free-spoken truth, will straight give themselves up into your hands, make 'em and cut 'em out what religion ye please: there be delights, there be recreations and jolly pastimes that will fetch the day about from sun to sun, and rock the tedious year as in a delightful dream. What need they torture their heads with that which others have taken so strictly and so unalterably into their own purveying? These are the fruits which a dull ease and cessation of our knowledge will bring forth among the people. How goodly and how to be wished were such an obedient unanimity as this, what a fine conformity would it starch us all into! Doubtless a staunch and solid piece of framework, as any January could freeze together.Nor much better will be the consequence even among the clergy themselves. It is no new thing never heard of before, for a parochial minister, who has his reward and is at his Hercules' pillars in a warm benefice, to be easily inclinable, if he have nothing else that may rouse up his studies, to finish his circuit in an English Concordance and a topic folio, the gatherings and savings of a sober graduateship, a Harmony and a Catena; treading the constant round of certain common doctrinal heads, attended with their uses, motives, marks, and means, out of which, as out of an alphabet, or sol-fa, by forming and transforming, joining and disjoining variously, a little bookcraft, and two hours' meditation, might furnish him unspeakably to the performance of more than a weekly charge of sermoning: not to reckon up the infinite helps of interlinearies, breviaries, synopses, and other loitering gear. But as for the multitude of sermons ready printed and piled up, on every text that is not difficult, our London trading St. Thomas in his vestry, and add to boot St. Martin and St. Hugh, have not within their hallowed limits more vendible ware of all sorts ready made: so that penury he never need fear of pulpit provision, having where so plenteously to refresh his magazine. But if his rear and flanks be not impaled, if his back door be not secured by the rigid licenser, but that a bold book may now and then issue forth and give the assault to some of his old collections in their trenches, it will concern him then to keep waking, to stand in watch, to set good guards and sentinels about his received opinions, to walk the round and counter-round with his fellow inspectors, fearing lest any of his flock be seduced, who also then would be better instructed, better exercised and disciplined. And God send that the fear of this diligence, which must then be used, do not make us affect the laziness of a licensing Church.For if we be sure we are in the right, and do not hold the truth guiltily, which becomes not, if we ourselves condemn not our own weak and frivolous teaching, and the people for an untaught and irreligious gadding rout, what can be more fair than when a man judicious, learned, and of a conscience, for aught we know, as good as theirs that taught us what we know, shall not privily from house to house, which is more dangerous, but openly by writing publish to the world what his opinion is, what his reasons, and wherefore that which is now thought cannot be sound? Christ urged it as wherewith to justify himself, that he preached in public; yet writing is more public than preaching; and more easy to refutation, if need be, there being so many whose business and profession merely it is to be the champions of truth; which if they neglect, what can be imputed but their sloth, or unability?Thus much we are hindered and disinured by this course of licensing, toward the true knowledge of what we seem to know. For how much it hurts and hinders the licensers themselves in the calling of their ministry, more than any secular employment, if they will discharge that office as they ought, so that of necessity they must neglect either the one duty or the other, I insist not, because it is a particular, but leave it to their own conscience, how they will decide it there.There is yet behind of what I purposed to lay open, the incredible loss and detriment that this plot of licensing puts us to; more than if some enemy at sea should stop up all our havens and ports and creeks, it hinders and retards the importation of our richest merchandise, truth; nay, it was first established and put in practice by Antichristian malice and mystery on set purpose to extinguish, if it were possible, the light of Reformation, and to settle falsehood; little differing from that policy wherewith the Turk upholds his Alcoran, by the prohibition of printing. 'Tis not denied, but gladly confessed, we are to send our thanks and vows to Heaven louder than most of nations, for that great measure of truth which we enjoy, especially in those main points between us and the Pope, with his appurtenances the prelates: but he who thinks we are to pitch our tent here, and have attained the utmost prospect of reformation that the mortal glass wherein we contemplate can show us, till we come to beatific vision, that man by this very opinion declares that he is yet far short of truth.Truth indeed came once into the world with her divine Master, and was a perfect shape most glorious to look on: but when he ascended, and his Apostles after him were laid asleep, then straight arose a wicked race of deceivers, who, as that story goes of the Egyptian Typhon with his conspirators, how they dealt with the good Osiris, took the virgin Truth, hewed her lovely form into a thousand pieces, and scattered them to the four winds. From that time ever since, the sad friends of Truth, such as durst appear, imitating the careful search that Isis made for the mangled body of Osiris, went up and down gathering up limb by limb, still as they could find them. We have not yet found them all, Lords and Commons, nor ever shall do, till her Master's second coming; he shall bring together every joint and member, and shall mould them into an immortal feature of loveliness and perfection. Suffer not these licensing prohibitions to stand at every place of opportunity, forbidding and disturbing them that continue seeking, that continue to do our obsequies to the torn body of our martyred saint.We boast our light; but if we look not wisely on the sun itself, it smites us into darkness. Who can discern those planets that are oft combust, and those stars of brightest magnitude that rise and set with the sun, until the opposite motion of their orbs bring them to such a place in the firmament, where they may be seen evening or morning? The light which we have gained was given us, not to be ever staring on, but by it to discover onward things more remote from our knowledge. It is not the unfrocking of a priest, the unmitring of a bishop, and the removing him from off the presbyterian shoulders, that will make us a happy nation. No, if other things as great in the Church, and in the rule of life both economical and political, be not looked into and reformed, we have looked so long upon the blaze that Zuinglius and Calvin hath beaconed up to us, that we are stark blind. There be who perpetually complain of schisms and sects, and make it such a calamity that any man dissents from their maxims. 'Tis their own pride and ignorance which causes the disturbing, who neither will hear with meekness, nor can convince; yet all must be suppressed which is not found in their Syntagma. They are the troublers, they are the dividers of unity, who neglect and permit not others to unite those dissevered pieces which are yet wanting to the body of Truth. To be still searching what we know not by what we know, still closing up truth to truth as we find it (for all her body is homogeneal and proportional), this is the golden rule in theology as well as in arithmetic, and makes up the best harmony in a Church; not the forced and outward union of cold, and neutral, and inwardly divided minds.Lords and Commons of England! consider what nation it is whereof ye are, and whereof ye are the governors: a nation not slow and dull, but of a quick, ingenious and piercing spirit, acute to invent, subtle and sinewy to discourse, not beneath the reach of any point the highest that human capacity can soar to. Therefore the studies of learning in her deepest sciences have been so ancient and so eminent among us, that writers of good antiquity and ablest judgment have been persuaded that even the school of Pythagoras and the Persian wisdom took beginning from the old philosophy of this island. And that wise and civil Roman, Julius Agricola, who governed once here for Caesar, preferred the natural wits of Britain before the laboured studies of the French. Nor is it for nothing that the grave and frugal Transylvanian sends out yearly from as far as the mountainous borders of Russia, and beyond the Hercynian wilderness, not their youth, but their staid men, to learn our language and our theologic arts.Yet that which is above all this, the favour and the love of Heaven, we have great argument to think in a peculiar manner propitious and propending towards us. Why else was this nation chosen before any other, that out of her, as out of Sion, should be proclaimed and sounded forth the first tidings and trumpet of Reformation to all Europe? And had it not been the obstinate perverseness of our prelates against the divine and admirable spirit of Wickliff, to suppress him as a schismatic and innovator, perhaps neither the Bohemian Huns and Jerome, no nor the name of Luther or of Calvin, had been ever known: the glory of reforming all our neighbours had been completely ours. But now, as our obdurate clergy have with violence demeaned the matter, we are become hitherto the latest and the backwardest scholars, of whom God offered to have made us the teachers. Now once again by all concurrence of signs, and by the general instinct of holy and devout men, as they daily and solemnly express their thoughts, God is decreeing to begin some new and great period in his Church, even to the reforming of Reformation itself: what does he then but reveal himself to his servants, and as his manner is, first to his Englishmen? I say, as his manner is, first to us, though we mark not the method of his counsels, and are unworthy.Behold now this vast city: a city of refuge, the mansion house of liberty, encompassed and surrounded with his protection; the shop of war hath not there more anvils and hammers waking, to fashion out the plates and instruments of armed justice in defence of beleaguered truth, than there be pens and heads there, sitting by their studious lamps, musing, searching, revolving new notions and ideas wherewith to present, as with their homage and their fealty, the approaching Reformation: others as fast reading, trying all things, assenting to the force of reason and convincement. What could a man require more from a nation so pliant and so prone to seek after knowledge? What wants there to such a towardly and pregnant soil, but wise and faithful labourers, to make a knowing people, a nation of prophets, of sages, and of worthies? We reckon more than five months yet to harvest; there need not be five weeks; had we but eyes to lift up, the fields are white already.Where there is much desire to learn, there of necessity will be much arguing, much writing, many opinions; for opinion in good men is but knowledge in the making. Under these fantastic terrors of sect and schism, we wrong the earnest and zealous thirst after knowledge and understanding which God hath stirred up in this city. What some lament of, we rather should rejoice at, should rather praise this pious forwardness among men, to reassume the ill-deputed care of their religion into their own hands again. A little generous prudence, a little forbearance of one another, and some grain of charity might win all these diligences to join, and unite in one general and brotherly search after truth; could we but forgo this prelatical tradition of crowding free consciences and Christian liberties into canons and precepts of men. I doubt not, if some great and worthy stranger should come among us, wise to discern the mould and temper of a people, and how to govern it, observing the high hopes and aims, the diligent alacrity of our extended thoughts and reasonings in the pursuance of truth and freedom, but that he would cry out as Pyrrhus did, admiring the Roman docility and courage: If such were my Epirots, I would not despair the greatest design that could be attempted, to make a Church or kingdom happy.Yet these are the men cried out against for schismatics and sectaries; as if, while the temple of the Lord was building, some cutting, some squaring the marble, others hewing the cedars, there should be a sort of irrational men who could not consider there must be many schisms and many dissections made in the quarry and in the timber, ere the house of God can be built. And when every stone is laid artfully together, it cannot be united into a continuity, it can but be contiguous in this world; neither can every piece of the building be of one form; nay rather the perfection consists in this, that, out of many moderate varieties and brotherly dissimilitudes that are not vastly disproportional, arises the goodly and the graceful symmetry that commends the whole pile and structure.Let us therefore be more considerate builders, more wise in spiritual architecture, when great reformation is expected. For now the time seems come, wherein Moses the great prophet may sit in heaven rejoicing to see that memorable and glorious wish of his fulfilled, when not only our seventy elders, but all the Lord's people, are become prophets. No marvel then though some men, and some good men too perhaps, but young in goodness, as Joshua then was, envy them. They fret, and out of their own weakness are in agony, lest these divisions and subdivisions will undo us. The adversary again applauds, and waits the hour: when they have branched themselves out, saith he, small enough into parties and partitions, then will be our time. Fool! he sees not the firm root, out of which we all grow, though into branches: nor will beware until he see our small divided maniples cutting through at every angle of his ill-united and unwieldy brigade. And that we are to hope better of all these supposed sects and schisms, and that we shall not need that solicitude, honest perhaps, though over-timorous, of them that vex in this behalf, but shall laugh in the end at those malicious applauders of our differences, I have these reasons to persuade me.First, when a city shall be as it were besieged and blocked about, her navigable river infested, inroads and incursions round, defiance and battle oft rumoured to be marching up even to her walls and suburb trenches, that then the people, or the greater part, more than at other times, wholly taken up with the study of highest and most important matters to be reformed, should be disputing, reasoning, reading, inventing, discoursing, even to a rarity and admiration, things not before discoursed or written of, argues first a singular goodwill, contentedness and confidence in your prudent foresight and safe government, Lords and Commons; and from thence derives itself to a gallant bravery and well-grounded contempt of their enemies, as if there were no small number of as great spirits among us, as his was, who when Rome was nigh besieged by Hannibal, being in the city, bought that piece of ground at no cheap rate, whereon Hannibal himself encamped his own regiment.Next, it is a lively and cheerful presage of our happy success and victory. For as in a body, when the blood is fresh, the spirits pure and vigorous, not only to vital but to rational faculties, and those in the acutest and the pertest operations of wit and subtlety, it argues in what good plight and constitution the body is; so when the cheerfulness of the people is so sprightly up, as that it has not only wherewith to guard well its own freedom and safety, but to spare, and to bestow upon the solidest and sublimest points of controversy and new invention, it betokens us not degenerated, nor drooping to a fatal decay, but casting off the old and wrinkled skin of corruption to outlive these pangs and wax young again, entering the glorious ways of truth and prosperous virtue, destined to become great and honourable in these latter ages. Methinks I see in my mind a noble and puissant nation rousing herself like a strong man after sleep, and shaking her invincible locks: methinks I see her as an eagle mewing her mighty youth, and kindling her undazzled eyes at the full midday beam; purging and unscaling her long-abused sight at the fountain itself of heavenly radiance; while the whole noise of timorous and flocking birds, with those also that love the twilight, flutter about, amazed at what she means, and in their envious gabble would prognosticate a year of sects and schisms.What would ye do then? should ye suppress all this flowery crop of knowledge and new light sprung up and yet springing daily in this city? Should ye set an oligarchy of twenty engrossers over it, to bring a famine upon our minds again, when we shall know nothing but what is measured to us by their bushel? Believe it, Lords and Commons, they who counsel ye to such a suppressing do as good as bid ye suppress yourselves; and I will soon show how. If it be desired to know the immediate cause of all this free writing and free speaking, there cannot be assigned a truer than your own mild and free and humane government. It is the liberty, Lords and Commons, which your own valorous and happy counsels have purchased us, liberty which is the nurse of all great wits; this is that which hath rarefied and enlightened our spirits like the influence of heaven; this is that which hath enfranchised, enlarged and lifted up our apprehensions, degrees above themselves.Ye cannot make us now less capable, less knowing, less eagerly pursuing of the truth, unless ye first make yourselves, that made us so, less the lovers, less the founders of our true liberty. We can grow ignorant again, brutish, formal and slavish, as ye found us; but you then must first become that which ye cannot be, oppressive, arbitrary and tyrannous, as they were from whom ye have freed us. That our hearts are now more capacious, our thoughts more erected to the search and expectation of greatest and exactest things, is the issue of your own virtue propagated in us; ye cannot suppress that, unless ye reinforce an abrogated and merciless law, that fathers may dispatch at will their own children. And who shall then stick closest to ye, and excite others? not he who takes up arms for coat and conduct, and his four nobles of Danegelt. Although I dispraise not the defence of just immunities, yet love my peace better, if that were all. Give me the liberty to know, to utter, and to argue freely according to conscience, above all liberties.What would be best advised, then, if it be found so hurtful and so unequal to suppress opinions for the newness or the unsuitableness to a customary acceptance, will not be my task to say. I only shall repeat what I have learned from one of your own honourable number, a right noble and pious lord, who, had he not sacrificed his life and fortunes to the Church and Commonwealth, we had not now missed and bewailed a worthy and undoubted patron of this argument. Ye know him, I am sure; yet I for honour's sake, and may it be eternal to him, shall name him, the Lord Brook. He writing of episcopacy, and by the way treating of sects and schisms, left ye his vote, or rather now the last words of his dying charge, which I know will ever be of dear and honoured regard with ye, so full of meekness and breathing charity, that next to his last testament, who bequeathed love and peace to his disciples, I cannot call to mind where I have read or heard words more mild and peaceful. He there exhorts us to hear with patience and humility those, however they be miscalled, that desire to live purely, in such a use of God's ordinances, as the best guidance of their conscience gives them, and to tolerate them, though in some disconformity to ourselves. The book itself will tell us more at large, being published to the world, and dedicated to the Parliament by him who, both for his life and for his death, deserves that what advice he left be not laid by without perusal.And now the time in special is, by privilege to write and speak what may help to the further discussing of matters in agitation. The temple of Janus with his two controversial faces might now not unsignificantly be set open. And though all the winds of doctrine were let loose to play upon the earth, so Truth be in the field, we do injuriously, by licensing and prohibiting, to misdoubt her strength. Let her and Falsehood grapple; who ever knew Truth put to the worse, in a free and open encounter? Her confuting is the best and surest suppressing. He who hears what praying there is for light and clearer knowledge to be sent down among us, would think of other matters to be constituted beyond the discipline of Geneva, framed and fabricked already to our hands. Yet when the new light which we beg for shines in upon us, there be who envy and oppose, if it come not first in at their casements. What a collusion is this, whenas we are exhorted by the wise man to use diligence, to seek for wisdom as for hidden treasures early and late, that another order shall enjoin us to know nothing but by statute? When a man hath been labouring the hardest labour in the deep mines of knowledge, hath furnished out his findings in all their equipage: drawn forth his reasons as it were a battle ranged: scattered and defeated all objections in his way; calls out his adversary into the plain, offers him the advantage of wind and sun, if he please, only that he may try the matter by dint of argument: for his opponents then to skulk, to lay ambushments, to keep a narrow bridge of licensing where the challenger should pass, though it be valour enough in soldiership, is but weakness and cowardice in the wars of Truth.For who knows not that Truth is strong, next to the Almighty? She needs no policies, nor stratagems, nor licensings to make her victorious; those are the shifts and the defences that error uses against her power. Give her but room, and do not bind her when she sleeps, for then she speaks not true, as the old Proteus did, who spake oracles only when he was caught and bound, but then rather she turns herself into all shapes, except her own, and perhaps tunes her voice according to the time, as Micaiah did before Ahab, until she be adjured into her own likeness. Yet is it not impossible that she may have more shapes than one. What else is all that rank of things indifferent, wherein Truth may be on this side or on the other, without being unlike herself? What but a vain shadow else is the abolition of those ordinances, that hand-writing nailed to the cross? What great purchase is this Christian liberty which Paul so often boasts of? His doctrine is, that he who eats or eats not, regards a day or regards it not, may do either to the Lord. How many other things might be tolerated in peace, and left to conscience, had we but charity, and were it not the chief stronghold of our hypocrisy to be ever judging one another?I fear yet this iron yoke of outward conformity hath left a slavish print upon our necks; the ghost of a linen decency yet haunts us. We stumble and are impatient at the least dividing of one visible congregation from another, though it be not in fundamentals; and through our forwardness to suppress, and our backwardness to recover any enthralled piece of truth out of the gripe of custom, we care not to keep truth separated from truth, which is the fiercest rent and disunion of all. We do not see that, while we still affect by all means a rigid external formality, we may as soon fall again into a gross conforming stupidity, a stark and dead congealment of wood and hay and stubble, forced and frozen together, which is more to the sudden degenerating of a Church than many subdichotomies of petty schisms.Not that I can think well of every light separation, or that all in a Church is to be expected gold and silver and precious stones: it is not possible for man to sever the wheat from the tares, the good fish from the other fry; that must be the Angels' ministry at the end of mortal things. Yet if all cannot be of one mind--as who looks they should be?--this doubtless is more wholesome, more prudent, and more Christian, that many be tolerated, rather than all compelled. I mean not tolerated popery, and open superstition, which, as it extirpates all religions and civil supremacies, so itself should be extirpate, provided first that all charitable and compassionate means be used to win and regain the weak and the misled: that also which is impious or evil absolutely either against faith or manners no law can possibly permit, that intends not to unlaw itself: but those neighbouring differences, or rather indifferences, are what I speak of, whether in some point of doctrine or of discipline, which, though they may be many, yet need not interrupt THE UNITY OF SPIRIT, if we could but find among us THE BOND OF PEACE.In the meanwhile if any one would write, and bring his helpful hand to the slow-moving Reformation which we labour under, if Truth have spoken to him before others, or but seemed at least to speak, who hath so bejesuited us that we should trouble that man with asking license to do so worthy a deed? and not consider this, that if it come to prohibiting, there is not aught more likely to be prohibited than truth itself; whose first appearance to our eyes, bleared and dimmed with prejudice and custom, is more unsightly and unplausible than many errors, even as the person is of many a great man slight and contemptuous to see to. And what do they tell us vainly of new opinions, when this very opinion of theirs, that none must be heard but whom they like, is the worst and newest opinion of all others; and is the chief cause why sects and schisms do so much abound, and true knowledge is kept at distance from us; besides yet a greater danger which is in it.For when God shakes a kingdom with strong and healthful commotions to a general reforming, 'tis not untrue that many sectaries and false teachers are then busiest in seducing; but yet more true it is, that God then raises to his own work men of rare abilities, and more than common industry, not only to look back and revise what hath been taught heretofore, but to gain further and go on some new enlightened steps in the discovery of truth. For such is the order of God's enlightening his Church, to dispense and deal out by degrees his beam, so as our earthly eyes may best sustain it.Neither is God appointed and confined, where and out of what place these his chosen shall be first heard to speak; for he sees not as man sees, chooses not as man chooses, lest we should devote ourselves again to set places, and assemblies, and outward callings of men; planting our faith one while in the old Convocation house, and another while in the Chapel at Westminster; when all the faith and religion that shall be there canonized is not sufficient without plain convincement, and the charity of patient instruction to supple the least bruise of conscience, to edify the meanest Christian, who desires to walk in the Spirit, and not in the letter of human trust, for all the number of voices that can be there made; no, though Harry VII himself there, with all his liege tombs about him, should lend them voices from the dead, to swell their number.And if the men be erroneous who appear to be the leading schismatics, what withholds us but our sloth, our self-will, and distrust in the right cause, that we do not give them gentle meetings and gentle dismissions, that we debate not and examine the matter thoroughly with liberal and frequent audience; if not for their sakes, yet for our own? seeing no man who hath tasted learning, but will confess the many ways of profiting by those who, not contented with stale receipts, are able to manage and set forth new positions to the world. And were they but as the dust and cinders of our feet, so long as in that notion they may yet serve to polish and brighten the armoury of Truth, even for that respect they were not utterly to be cast away. But if they be of those whom God hath fitted for the special use of these times with eminent and ample gifts, and those perhaps neither among the priests nor among the Pharisees, and we in the haste of a precipitant zeal shall make no distinction, but resolve to stop their mouths, because we fear they come with new and dangerous opinions, as we commonly forejudge them ere we understand them; no less than woe to us, while, thinking thus to defend the Gospel, we are found the persecutors.There have been not a few since the beginning of this Parliament, both of the presbytery and others, who by their unlicensed books, to the contempt of an Imprimatur, first broke that triple ice clung about our hearts, and taught the people to see day: I hope that none of those were the persuaders to renew upon us this bondage which they themselves have wrought so much good by contemning. But if neither the check that Moses gave to young Joshua, nor the countermand which our Saviour gave to young John, who was so ready to prohibit those whom he thought unlicensed, be not enough to admonish our elders how unacceptable to God their testy mood of prohibiting is; if neither their own remembrance what evil hath abounded in the Church by this set of licensing, and what good they themselves have begun by transgressing it, be not enough, but that they will persuade and execute the most Dominican part of the Inquisition over us, and are already with one foot in the stirrup so active at suppressing, it would be no unequal distribution in the first place to suppress the suppressors themselves: whom the change of their condition hath puffed up, more than their late experience of harder times hath made wise.And as for regulating the press, let no man think to have the honour of advising ye better than yourselves have done in that Order published next before this, \"that no book be printed, unless the printer's and the author's name, or at least the printer's, be registered.\" Those which otherwise come forth, if they be found mischievous and libellous, the fire and the executioner will be the timeliest and the most effectual remedy that man's prevention can use. For this authentic Spanish policy of licensing books, if I have said aught, will prove the most unlicensed book itself within a short while; and was the immediate image of a Star Chamber decree to that purpose made in those very times when that Court did the rest of those her pious works, for which she is now fallen from the stars with Lucifer. Whereby ye may guess what kind of state prudence, what love of the people, what care of religion or good manners there was at the contriving, although with singular hypocrisy it pretended to bind books to their good behaviour. And how it got the upper hand of your precedent Order so well constituted before, if we may believe those men whose profession gives them cause to inquire most, it may be doubted there was in it the fraud of some old patentees and monopolizers in the trade of bookselling; who under pretence of the poor in their Company not to be defrauded, and the just retaining of each man his several copy, which God forbid should be gainsaid, brought divers glossing colours to the House, which were indeed but colours, and serving to no end except it be to exercise a superiority over their neighbours; men who do not therefore labour in an honest profession to which learning is indebted, that they should be made other men's vassals. Another end is thought was aimed at by some of them in procuring by petition this Order, that, having power in their hands, malignant books might the easier scape abroad, as the event shows.But of these sophisms and elenchs of merchandise I skill not. This I know, that errors in a good government and in a bad are equally almost incident; for what magistrate may not be misinformed, and much the sooner, if liberty of printing be reduced into the power of a few? But to redress willingly and speedily what hath been erred, and in highest authority to esteem a plain advertisement more than others have done a sumptuous bride, is a virtue (honoured Lords and Commons) answerable to your highest actions, and whereof none can participate but greatest and wisest men.Text is available under the Creative Commons Attribution-ShareAlike License; additional terms may apply. See original source at Wikisource."}
{"prompt": "The libbitcoin Manifesto", "completion": "\u201cTools for The People\u201dAs humans, we share little in common. But that little we do share is the deep core of our being. We search for purpose. We are curious. And we thrive on new information. Our self-awareness, rationality and sapience are the high level features that make up a person. They are our capacity for good or evil.As people, we need to ask ourselves whether we act with purpose, intent and ambition, ask how are we defining ourselves, and what are the values that our lives are promoting.Are you taking concrete steps now to achieve your objective?It's important we ask ourselves these questions, and decide which end of the spectrum between liberty and security we fixate on. A safe life of luxury, and comfort closed in by 4 walls. Or a life of freedom. Freedom to make love, play loud music, create art, wrestle naked, and raise confident kids that think.In criticising the world we're born into, it's easy to point the finger at this or that politician or resign problems to circumstance. And with the perceived lack of power to concede the situation is unfixable and utterly broken. But if we want to know who to blame, we need only to look into a mirror. We support the situation. It is people, not rulers, who create the world of today.Some of us conclude that the situation is just a normal state of affairs, and simply human nature. As if there were one human nature! And disregarding that we all evolve and grow as people in different directions during our lives.Think of the values we are taught as children. How we are taught to behave as civic citizens. The phrases we are told by our parents, teachers and friends. The system is not just the state and corporations, it is a machine encompassing all spheres of life.You might hear for example:I was told all of these sentences in my life. That learning to accept authority is an inevitable part of growing up. That my character is defined by how I look, not how I act. That my single purpose is to be a work-slave. To avoid interaction with random unknowns outside my circle. And that responsibility starts and stops with myself.All of them are bad values.We are not born with these values. They are hard-wired into us from a young age. Luckily knowledge feeds the unlearning process and the internet is an unlearning tool.Have you ever questioned the 15 years of our precious childhood from kindergarten to highschool. We attend a prison with fixed schedules and dinner at an allocated time. We're forced to wear uniforms. If you want to speak, you need to raise your hand. If you need the toilet, you must ask permission. And the lessons amount to little more than drilling information with the given promise of honours and qualifications.The reward for faithfully jumping through all these hoops for 15 years is a worthless piece of paper that isn't even required for a job at McDonalds. And the workers still need training. Our children aren't taught how to cook a healthy meal, grow a garden or even a rudimentary concept of how to organise or lead groups of people without even a glimmer of understanding on how to resolve conflicts without violence. Or the principles of logic, and how to question an ideology. Kids are taught to sit at a desk and listen obediently as the world is packaged into neat boxes.School is little more than a training camp for salaried drones designed to format young minds for a life of subservience, too stupid to question the system itself or the authority of those running it. We are not born with bad values. They are wired into us from a young age.Lets talk about good values.Responsibility is about fulfilling your needs to have a dignified existence, and then expanding that circle to the people around you. To help bring up and out the potential of other free people so that together we thrive. Community and collective action is absolutely essential if we want to rise up. The system thrives by separating people into isolated pockets who get their information from TV and their culture from corporations. United together, we are stronger.\u201cVires in numeris\u201dIndependence and autonomy is the ability to act. If we always need third parties and central organisations to resolve disputes, solve our problems and coordinate us then we are doomed as a species. Central authorities are always a magnet for corruption and that will never change. Learn to be self reliant and make things happen.Understanding is not an easy skill to develop, but it is very powerful. Being able to get into people's minds, to listen and be able to meet their needs is leadership. A leader serves and inspires people into action, whereas a ruler uses coercion. For all their grandeur and force, rulers cannot harness the real potential of people. Nobody thinks under duress.We need assertive individuals who stand unyielding for what they believe in. If you know something is right, then fight for your vision. It will happen. The system feeds off passivity, and giving consent to its exclusive hold of force feeds the machine.Lastly lets approach the world as artists, and bring creativity to our work. The world is diverse, colourful and vibrant. Humans are not meant to live in little boxes and grey concrete jungles. Live art and be creative. Your work is art. Good art makes people think and feel.The role of good people is the vanguard of tomorrow.The penalty good men pay for indifference to public affairs is to be ruled by evil men.It's an old story. David vs Goliath. Starfleet rebels vs galactic deathstar. Anarchist revolutionaries vs the fascist empire. Both sides have existed for centuries and the struggle continues. However in recent decades with the unique political situation, the internet and a dawning awareness among people, the balance of power is shifting in our favour this time around.Humans can look to a future less dominated by the command hierarchies of the past, and more by thriving marketplaces of knowledge and merit.I remember an amateur blue webpage in the summer of 2010 describing a p2p currency that \u201ccannot be controlled by governments or central banks\u201d. Extremely skeptical, I dived into the code and discovered an idea which burnt itself in my memory. My mind latched onto Bitcoin. I realised this unknown project is the future of money.Bitcoin is a tool of resistance gifted to us by Satoshi. The idea has escaped and the idea of cryptocurrency will not be stopped. Bitcoin or some other cryptocurrency will succeed.Bitcoin is about direct trade from peer to peer. The purest value transfer possible between 2 or more people. A direct and personal interaction over digital infrastructure. Welcome to the future of the black market. Real values, real people and uncorrupted markets.The internet is a tool of freedom and self-determination. Meddling in its mechanics is destructive. Whenever a website is blocked, a protocol is corrupted at some low level or undesirable traffic shaping occurs then seismic ripples of censorship and destruction lead to degradation of the network. The internet is fundamental to humanity, and must be protected at all costs.Bitcoin is no different, and must be kept pure. There are real risks to Bitcoin.The protocol is not an axiomatic system fixed by Satoshi. It's been constantly changing, rapidly evolving and the pace is accelerating. The risks are more subtle and probable than a government demanding changes to the fundamentals of Bitcoin's protocol. The chilling effect of self censorship.We don't even need to touch the protocol.As Bitcoin grows, the inevitable specialisation is kicking in. The blockchain is moving towards specialised services, and the future of full Bitcoin nodes is on the server, not personal computers. We have to wake up, adapt and work with the reality rather than persisting in self denial.If development is too centralised, with a small core infrastructure, then businesses will put real pressure to have features that destroy the integrity of the Bitcoin network. The excuse will be to protect themselves from liability. Self-censorship.And what they demand does not have to be protocol changes. They will demand features in the software they use. Software which remains compatible with the network, but works against the interests of individuals, small businesses and the black market.The possible malicious scenarios are endless. Stuff like p2p blacklists to create a 'legitimate' walled garden, or tracking technologies like large databases of IP addresses to triangulate where transactions came from. At the other end of the spectrum, is putting development effort into diversifying the ecosystem to protect against censorship and proxy relay nodes, anonymising mixers, small privacy tweaks and other technologies. That's where developers who believe in Bitcoin should devote time to. Corporations are powerful enough. To developers: serve your community.A diversified Bitcoin of many wallets and implementations is a strong and pure Bitcoin. To protect the integrity of the network, we need to eliminate single points of failure. An inbred Bitcoin with the same software code everywhere shares the same weaknesses, and is susceptible to the same attacks. A single pathogen can wipe out a genetically homogenous population. And centralised software is vulnerable to the dictates of whoever controls development of that software code, and any dictates pressured onto them.The implications of a diversified Bitcoin is a Bitcoin difficult to control. It also sets the protocol in stone, as nobody has sole power over the standard. Consensus from many parties is the way forwards.The proper way to develop a standard is by having many different competing parties that require mutual interest and agreement to pass through changes. History is rife with abuse like when Internet Explorer dominated the browser market, and constantly broke the web standard by introducing proprietary extensions. Their motive was to swallow the market and lock users into Internet Explorer. The result was a broken web. A monopoly likes to dominate the market, shut out competitors and erect high barriers to entry.A diversified ecosystem protects against feature-creep or bloat of the standard. Extra features go beyond the basic function of Bitcoin and so can result in over-complication rather than simple design. Viewed over a longer time period, extra or unnecessary features seem to creep into the system beyond the initial goals and the small code of 15,000 lines set by Satoshi. The result will be a Bitcoin that becomes increasingly difficult to understand or implement without a huge initial investment of resources, time and people. No single person will fully understand Bitcoin anymore, and development monopolies will be further enforced.Linux is the most secure operating system because of its diversity. There is no single exploit that is universal across all versions of Linux. Bitcoin must evolve in the same way to become a resilient and tough system able to serve a global audience.A massive standard is difficult to reimplement. Satoshi Nakamoto gifted us a small, focused and pure Bitcoin.There is no need for compromise. Lets push for our complete vision. Bitcoin is here. We have the initiative and we make our stand now. We have the power and now is the time. Not later. Now.Within a century of the printing press being invented, wars, social strife and revolutions erupted across Europe. Old kings, revered religious leaders and tyrannical rulers were removed from power. People could now read what was being written in their bibles. Mass printing of the bible was subversive. And what was written in their bibles, is not what they were being fed. In the face of hard evidence, people dispelled old notions of what their religion was saying.Our economy will change. Bitcoin will rise as a fundamental technology. Seeking approval from the halls of Washington, and consent from the status quo is mere pandering as lapdogs at the feet of the system. Why would you willingly give your power away? Are you stupid?Some people make the argument that throwing Bitcoin under the bus and corrupting the core of this technology is needed to help businesses which specialise in the exchange of failing government fiat paper-money with Bitcoins. Are we willing to sacrifice the purity of this tool for a few short term gains that primarily benefit US corporations? Do they serve the need of Bitcoin?Others even go further, arguing we need the masses. That being a majority protects people from assaults. Typical herd mentality.And that regulation (and the measures to implement them) are a typical process of acceptance. I have news for you: majorities have been slaughtered like pigs all throughout history. Being \u201cpragmatic\u201d is code speak for obedience and cowardice.Bitcoin is the future. Act like you believe it. Act to prevent corruption of the system. Act to prevent Bitcoin becoming coopted in any way. We must preserve the principles of Satoshi Nakamoto.We have the initiative and the power. You know the truth of the world. Stop supporting your own enemies. We don't need them. They need us. You are the one empowering them. Withdraw your consent. Withdraw your support. Don't accept their terms or try to win a game where they set the rules. Don't try to win your ruler's favour. Don't bother to beg for welfare or good treatment. Worst of all, don't help them hunt down your neighbour.Time we stick our flag in the ground, and make our stand.Our task force will offer balanced, effective solutions for policy makers, law enforcement, regulators and the public.[...]The Task Force, which launched in August, is not solely focussed on child exploitation.[...]The report detailed how criminal and terrorist organisations have turned to digital currency to reap profits from drug trafficking, prostitution and the dissemination of child abuse images.One day master told slave: \u201cDo this small thing and everything is fine. Keep up the good work.\u201d. The slave was happy because not much was asked so he started to create something cool. The master walked in a week later, and said \u201cdo this as well\u201d. The slave was shocked. \u201cBut master, we had an agreement, you said I only needed to do this?\u201d. Master responded \u201cI changed my mind. You need to do this as well.\u201d. The slave reluctantly agreed. At least it wasn't that bad.Over time, the master more and more increased his demands on the slave. By now the slave had created something totally wonderful and was dependant on it, but the master controlled his work and owned him.The task of an activist is not to negotiate systems of power with as much personal integrity as possible- it's to dismantle those systems.The road is long, and real work is needed. Less talk, more action. There are too few people in this world working on worthwhile things for the people. But eventhough the work-load is immense and daunting, there are concrete steps to achieve the global objective.Truth happens. We will succeed. Don't wait around for others to take action. We must dive head first without regard for consequences, and break the inertia of passivity. When enough people do this, the real change will occur.Fight for what you believe in. If you believe, and uphold a truth, then all your energy should be devoted to your objectives. Anytime you are accepting compromise, you are acting against your objective. None of us are pure. We are flawed and imperfect. But as good people we must strive for uncomplicated directness in our actions. Our actions must be transparent in motive and pure in reasoning.The power is within us. It always has been."}
{"prompt": "Bit Gold", "completion": "A long time ago I hit upon the idea of bit gold. The problem, in a nutshell, is that our money currently depends on trust in a third party for its value. As many inflationary and hyperinflationary episodes during the 20th century demonstrated, this is not an ideal state of affairs. Similarly, private bank note issue, while it had various advantages as well as disadvantages, similarly depended on a trusted third party.Precious metals and collectibles have an unforgeable scarcity due to the costliness of their creation. This once provided money the value of which was largely independent of any trusted third party. Precious metals have problems, however. It's too costly to assay metals repeatedly for common transactions. Thus a trusted third party (usually associated with a tax collector who accepted the coins as payment) was invoked to stamp a standard amount of the metal into a coin. Transporting large values of metal can be a rather insecure affair, as the British found when transporting gold across a U-boat infested Atlantic to Canada during World War I to support their gold standard. What's worse, you can't pay online with metal.Thus, it would be very nice if there were a protocol whereby unforgeably costly bits could be created online with minimal dependence on trusted third parties, and then securely stored, transferred, and assayed with similar minimal trust. Bit gold.My proposal for bit gold is based on computing a string of bits from a string of challenge bits, using functions called variously \"client puzzle function,\" \"proof of work function,\" or \"secure benchmark function.\" The resulting string of bits is the proof of work. Where a one-way function is prohibitively difficult to compute backwards, a secure benchmark function ideally comes with a specific cost, measured in compute cycles, to compute backwards.Here are the main steps of the bit gold system that I envision:Note that Alice's control over her bit gold does not depend on her sole possession of the bits, but rather on her lead position in the unforgeable chain of title (chain of digital signatures) in the title registry.All of this can be automated by software. The main limits to the security of the scheme are how well trust can be distributed in steps (3) and (4), and the problem of machine architecture which will be discussed below.Hal Finney has implemented a variant of bit gold called RPOW (Reusable Proofs of Work). This relies on publishing the computer code for the \"mint,\" which runs on a remote tamper-evident computer. The purchaser of of bit gold can then use remote attestation, which Finney calls the transparent server technique, to verify that a particular number of cycles were actually performed.The main problem with all these schemes is that proof of work schemes depend on computer architecture, not just an abstract mathematics based on an abstract \"compute cycle.\" (I wrote about this obscurely several years ago.) Thus, it might be possible to be a very low cost producer (by several orders of magnitude) and swamp the market with bit gold. However, since bit gold is timestamped, the time created as well as the mathematical difficulty of the work can be automatically proven. From this, it can usually be inferred what the cost of producing during that time period was.Unlike fungible atoms of gold, but as with collector's items, a large supply during a given time period will drive down the value of those particular items. In this respect \"bit gold\" acts more like collector's items than like gold. However, the match between this ex post market and the auction determining the initial value might create a very substantial profit for the \"bit gold miner\" who invents and deploys an optimized computer architecture.Thus, bit gold will not be fungible based on a simple function of, for example, the length of the string. Instead, to create fungible units dealers will have to combine different-valued pieces of bit gold into larger units of approximately equal value. This is analogous to what many commodity dealers do today to make commodity markets possible. Trust is still distributed because the estimated values of such bundles can be independently verified by many other parties in a largely or entirely automated fashion.In summary, all money mankind has ever used has been insecure in one way or another. This insecurity has been manifested in a wide variety of ways, from counterfeiting to theft, but the most pernicious of which has probably been inflation. Bit gold may provide us with a money of unprecedented security from these dangers. The potential for initially hidden supply gluts due to hidden innovations in machine architecture is a potential flaw in bit gold, or at least an imperfection which the initial auctions and ex post exchanges of bit gold will have to address."}
{"prompt": "Libertaria in Cyberspace", "completion": "Here are a few points about why \"cyberspace,\" or a computer-mediated network, is more hospitable than physical locations for the kind of \"crypto anarchy\" libertarian system I've been describing.Several folks have commented recently about ocean-going libertarian havens, supertankers used as data havens, and so forth. In the 1970s, especially, there were several unsuccessful attempts to acquire islands in the Pacific for the site of what some called \"Libertaria.\" (Some keywords: Vanuatu, Minerva, Mike Oliver, Tonga)Obtaining an entire island is problematic. Getting the consent of the residents is one issue (familiar to those on the this list who weathered the Hurrican Andrew diversion debate). Being allowed to operate by the leading world powers is another....the U.S. has enforced trade embargoes and blockades against many nations in the past several decades, including Cuba, North Korea, Libya, Iran, Iraq, andothers. Further, the U.S. has invaded some countries---Panama is a good example---whose government it disliked. How long would a supertanker \"data haven\" or libertarian regime last in such an environment? (Stephenson's fascinating Snow Crash didn't address tthe issue of why the \"Raft\" wasn't simply sunk by the remaining military forces.)I should note that the recent splintering of countries may provide opportunities for libertarian (or PPL, if your prefer to think of it in this way) regions. Some have speculated that Russia itself is a candidate, given that it has little vested in the previous system and may be willing to abandon statism. If several dozen new countries are formed, some opportunities exist.The basic problem is that physical space is too small, too exposed to the view of others. \"Libertaria\" in the form of, say, an island, is too exposed to the retaliatation of world powers. (I won't go into the \"private nukes\" strategy, which I need to think about further.)A floating private nation (or whatever it's called) is too vulnerable to a single well-placed torpedo. Even if it serves as a kind of Swiss bank, and thus gets some of the same protection Switzerland got (to wit, many leaders kept their loot there), it is too vulnerable to a single attacker or invader. Piracy will be just one of the problems.Finally, how many of us want to move to a South Pacific island? Or a North Sea oil rig? Or even to Russia?Cyberspace looks more promising. There is more \"space\" in cyberspace, thus allowing more security and more colonizable space. And this space is coterminous with our physical space, accessible with proper terminals from any place in the world (though there may be attempts in physical space to block access, to restrict access to necessay cryptographic methods, etc.).I won't go into the various cryptographic methods here (see my earlier posting on the \"Dining Cryptographers\" protocol and various other postings on public key systems, digital mixes, electronic cash, etc.). Interested readers have many sources. (I have just read a superb survey of these new techniques, the 1992 Ph.D. thesis of Jurgen Bos, \"Practical Privacy,\" which deals with these various protocols in a nice little book.)Alice and Bob, our favorite cryptographic stand-ins, can communicate and transact business without ever meeting or even knowing who the other is. This can be extended to create virtual communities subject only to rules they themselves reach agreement on, much like this very Extropians list. Private law is the only law, as there is no appeal to some higher authority like the Pope or police. (This is why I said in several of my postings on the Hurricane Andrew debate that I am sympathetic to the PPL view.)And this is the most compelling advantage of \"Crypto Libertaria\": an arbitrarily large number of separate \"nations\" can simultaneously exist. This allows for rapid experimentation, self-selection, and evolution. If folks get tired of some virtual community, they can leave. The cryptographic aspects mean their membership in some community is unknown to others (vis-a-vis the physical or outside world, i.e., their \"true names\") and physical coercion is reduced.Communalists are free to create a communal environment, Creative Anachronists are free to create their own idea of a space, and so on. I'm not even getting into the virtual reality-photorealistic images-Jaron Lanier sort of thing, as even current text-based systems are demonstrably enough to allow the kind of virtual communities I'm describing here (and described in Vinge's \"True Names,\" in Gibson's Neuromancer, in Sterling's Islands in the Net, and in Stephenson's Snow Crash...though all of them missed out on some of the most exciting aspects...perhaps my novel will hit the mark?).But will the government allow these sorts of things? Won't they just torpedo it, just as they'd torpedo an offshore ooirig data haven?The key is that distributed systems have no nexus which can be knocked out. Neither Usenet norFidoNet can be disabled by any single government, as they are worldwide. Shutting them down would mean banning computer-to-computer communication. And despite the talk of mandatory \"trap doors\" in encryption systems, encryption is fundamentally easy to do and hard to detect. (For those who doubt this, let me describe a simple system I posted to sci.crypt several years ago. An ordinary digital audio tape (DAT) carries more than a gigabyte of data. This means that thhe least significant bit (LSB) of an audio DAT recordingng carries about 8megabytes of data! So Alice is stopped by the Data Police. They ask if she's carrying illegal data. She smiles inocently and say \"No. I know you'll search me.\" They find her Sony DATman and ask about her collection of tapes and live recordings. Alice is carrying 80 MB of data---about 3 entire days worth of Usenet feeds!---on each and every tape. The data are stored in the LSBs, completely indistinguishable from microphone and quantization noise...unless you know the key. Similar methods allow data to be undetectably packed into LSBs of the PICT and GIF pictures now flooding the Net, into sampled sounds, and even into messages like this...the \"whitespace\" on the right margin of this message carries a hidden message readable only to a few chosen Extropians.)I've already described using religions and role-playing games as a kind of legal cover for the development and deployment of these techniques. If a church decides to offer \"digital confessionals\" for its far-flung members, by what argument will the U.S. government justify insisting that encryption not be used? (I should note that psychiatrists and similar professionals have a responsibility to their clients and to their licensing agencies to ensure the privacy of patient records. Friends of mine are using encryption to protect patient records. This is just one little example of how encryption is getting woven into the fabric of our electronic society. There are many other examples.)In future discussions, I hope we can hit on some of the many approaches to deploying these methods. I've spent several years thinking about this, but I've surely missed some good ideas. The \"crypto anarchy game\" being planned is an attempt to get some of the best hackers in the Bay Area thinking along these lines and thinking of new wrinkles. Several have already offered to help further.Some have commented that this list is not an appropriate place to discuss these ideas. I think it is. We are not discussing anything that is actually illegal, even under the broad powers of RICO (Racketeer-Influenced and Corrupt Organizations Act, used to go after \"conspiracies\" of porn dealers and gun dealers, amongst others). What we are discussing are long-range implications of these ideas.In conclusion, it will be easier to form certain types of libertarian societies in cyberspace than in the real world of nations and physical locations. The electronic world is by no means complete, as we will still live much of our lives in the physical world. But economic activity is sharply increasing in the Net domain and these \"crypto anarchy\" ideas will further erode the power of physical states to tax and coerce residents.-- Tim May"}
{"prompt": "Crypto Glossary", "completion": "From: tcmay@netcom.com (Timothy C. May)\nSubject: Crypto Glossary\nDate: Sun, 22 Nov 92 11:50:55 PSTHere's the glossary of crypto terms we passed out in printed form at the first Cypherpunks meeting in September 1992. Some compromises had to be made in going from the printed form to the ASCII of this transmission, so I hope you'll bear with me.I'm sending it to the entire list because nearly everyone who hears about it says \"Is it online?\" and wants a copy. If you don't want it, discard it.I'm not going to be maintaining the \"Cypherpunks FAQ,\" so don't send me corrections or additions.EnjoyTim May(these sections will introduce the terms in context, though complete definitions will not be given)privacy of messages\nusing ciphers and codes to protect the secrecy of messages\nDES is the most common symmetric cipher (same key for encryption and decryption)\nRSA is the most common asymmetric cipher (different keys for encryption and decryption)proving who you are\nproving you signed a document (and not someone else)untraceable sending and receiving of mail and messages\nfocus: defeating eavesdroppers and traffic analysis\nDC protocol (dining cryptographers)focus: ballot box anonymity\ncredentials for voting\nissues of double voting, security, robustness, efficiencyfocus: privacy in transactions, purchases\nunlinkable credentials\nblinded notes\n\"digital coins\" may not be possibleusing the above to evade government, to bypass tax collection, etc.\na technological solution to the problem of too much governmentopen, free market systems in which voluntary transactions are central.cryptographic protocols are often made clearer by considering parties A and B, or Alice and Bob, performing some protocol. Eve the eavesdropper, Paul the prover, and Vic the verifier are other common stand-in names.all or nothing disclosure of secrets.a credential which asserts some right or privilege or fact without revealing the identity of the holder. This is unlike CA driver's licenses.same as public key cryptosystem.the process of verifying an identity or credential, to ensure you are who you said you were.a type of authentication using fingerprints, retinal scans, palm prints, or other physical/biological signatures of an individual.e.g., tossing a coin and then committing to the value without being able to change the outcome. The blob is a cryptographic primitive for this.A signature that the signer does not remember having made. A blind signature is always a cooperative protocol and the receiver of the signature provides the signer with the blinding information.the crypto equivalent of a locked box. A cryptographic primitive for bit commitment, with the properties that a blobs can represent a 0 or a 1, that others cannot tell be looking whether itUs a 0 or a 1, that the creator of the blob can \"open\" the blob to reveal the contents, and that no blob can be both a 1 and a 0. An example of this is a flipped coin covered by a hand.the path over which messages are transmitted. Channels may be secure or insecure, and may have eavesdroppers (or enemies, or disrupters, etc.) who alter messages, insert and delete messages, etc. Cryptography is the means by which communications over insecure channels are protected.an attack where the cryptanalyst gets to choose the plaintext to be enciphered, e.g., when possession of an enciphering machine or algorithm is in the possession of the cryptanalyst.a secret form of writing, using substitution or transposition of characters or symbols.the plaintext after it has been encrypted.a restricted cryptosystem where words or letters of a message are replaced by other words chosen from a codebook. Not part of modern cryptology, but still useful.an important crypto primitive, or protocol, in which the equivalent of flipping a fair coin is possible. Implemented with blobs.wherein several participants cooperate to deduce the identity of a sender or receiver, or to break a cipher. Most cryptosystems are sensitive to some forms of collusion. Much of the work on implementing DC Nets, for example, involves ensuring that colluders cannot isolate message senders and thereby trace origins and destinations of mail.where a cipher cannot be broken with available computer resources, but in theory can be broken with enough computer resources. Contrast with unconditionally secure.something you do to thwart an attacker.facts or assertions about some entity. For example, credit ratings, passports, reputations, tax status, insurance records, etc. Under the current system, these credentials are increasingly being cross-linked. Blind signatures may be used to create anonymous credentials.banks, credit agencies, insurance companies, police departments, etc., that correlate records and decide the status of records.methods for attacking and breaking ciphers and related cryptographic systems. Ciphers may be broken, traffic may be analyzed, and passwords may be cracked. Computers are of course essential.the economic and political system after the deployment of encryption, untraceable e-mail, digital pseudonyms, cryptographic voting, and digital cash. A pun on \"crypto,\" meaning \"hipen,\" and as when Gore Vidal called William F. Buckley a \"crypto fascist.\"another name for cryptology.the science and study of writing, sending, receiving, and deciphering secret messages. Includes authentication, digital signatures, the hiding of messages (steganography), cryptanalysis, and several other fields.the electronic domain, the Nets, and computer-generated spaces. Some say it is the \"consensual reality\" described in \"Neuromancer.\" Others say it is the phone system. Others have work to do.the dining cryptographers protocol. DC-Nets use multiple participants communicating with the DC protocol.the Data Encryption Standard, proposed in 1977 by the National Bureau of Standards (now NIST), with assistance from the National Security Agency. Based on the \"Lucifer\" cipher developed by Horst Feistel at IBM, DES is a secret key cryptosystem that cycles 64-bit blocks of data through multiple permutations with a 56-bit key controlling the routing. \"Diffusion\" and \"confusion\" are combined to form a cipher that has not yet been cryptanalyzed (see \"DES, Security of\"). DES is in use for interbank transfers, as a cipher inside of several RSA-based systems, and is available for PCs.many have speculated that the NSA placed a trapdoor (or back door) in DES to allow it to read DES-encrypted messages. This has not been proved. It is known that the original Lucifer algorithm used a 128-bit key and that this key length was shortened to 64 bits (56 bits plus 8 parity bits), thus making exhaustive search much easier (so far as is known, brute-force search has not been done, though it should be feasible today). Shamir and Bihan have used a technique called \"differential cryptanalysis\" to reduce the exhaustive search needed for chosen plaintext attacks (but with no import for ordinary DES).technique for cryptanalyzing DES. With a chosen plaintext attack, they've reduced the number of DES keys that must be tried from about 2^56 to about 2^47 or less. Note, however, that rarely can an attacker mount a chosen plaintext attack on DES systems.Protocols for transferring value, monetary or otherwise, electronically. Digital cash usually refers to systems that are anonymous. Digital money systems can be used to implement any quantity that is conserved, such as points, mass, dollars, etc. There are many variations of digital money systems, ranging from VISA numbers to blinded signed digital coins. A topic too large for a single glossary entry.basically, a \"crypto identity.\" A way for individuals to set up accounts with various organizations without revealing more information than they wish. Users may have several digital pseudonyms, some used only once, some used over the course of many years. Ideally, the pseudonyms can be linked only at the will of the holder. In the simplest form, a public key can serve as a digital pseudonym and need not be linked to a physical identity.Analogous to a written signature on a document. A modification to a message that only the signer can make but that everyone can recognize. Can be used legally to contract at a distance.one function of a digital notary public, in which some message (a song, screenplay, lab notebook, contract, etc.) is stamped with a time that cannot (easily) be forged.the untraceable message sending system invented by David Chaum. Named after the \"dining philosophers\" problem in computer science, participants form circuits and pass messages in such a way that the origin cannot be deduced, barring collusion. At the simplest level, two participants share a key between them. One of them sends some actual message by bitwise exclusive-ORing the message with the key, while the other one just sends the key itself. The actual message from this pair of participants is obtained by XORing the two outputs. However, since nobody but the pair knows the original key, the actual message cannot be traced to either one of the participants.given integers a, n, and x, find some integer m such that a^m mod n = x, if m exists. Modular exponentiation, the a^m mod n part, is straightforward (and special purpose chips are available), but the inverse problem is believed to be very hard, in general. Thus it is conjectured that modular exponentiation is a one-way function.the latest NIST (National Institute of Standards and Technology, successor to NBS) standard for digital signatures. Based on the El Gamal cipher, some consider it weak and poor substitute for RSA-based signature schemes.intercepting messages without detection. Radio waves may be intercepted, phone lines may be tapped, and computers may have RF emissions detected. Even fiber optic lines can be tapped.Some large numbers are difficult to factor. It is conjectured that there are no feasible--i.e.\"easy,\" less than exponential in size of number-- factoring methods. It is also an open problem whether RSA may be broken more easily than by factoring the modulus (e.g., the public key might reveal information which simplifies the problem). Interestingly, though factoring is believed to be \"hard\", it is not known to be in the class of NP-hard problems. Professor Janek invented a factoring device, but he is believed to be fictional.security, in which no amount of cryptanalysis can break a cipher or system. One time pads are an example (providing the pads are not lost nor stolen nor used more than once, of course). Same as unconditionally secure.a piece of information needed to encipher or decipher a message. Keys may be stolen, bought, lost, etc., just as with physical keys.the process of sharing a key with some other party, in the case of symmetric ciphers, or of distributing a public key in an asymmetric cipher. A major issue is that the keys be exchanged reliably and without compromise. Diffie and Hellman devised one such scheme, based on the discrete logarithm problem.a cryptanalysis of a cipher where plaintext-ciphertext pairs are known. This attack searches for an unknown key. Contrast with the chosen plaintext attack, where the cryptanalyst can also choose the plaintext to be enciphered.a system for sending and receiving mail without traceability or observability. Receiving mail anonymously can be done with broadcast of the mail in encrypted form. Only the intended recipient (whose identity, or true name, may be unknown to the sender) may able to decipher the message. Sending mail anonymously apparently requires mixes or use of the dining cryptographers (DC) protocol.another name for zero knowledge proofs, favored by Chaum.David Chaum's term for a box which performs the function of mixing, or decorrelating, incoming and outgoing electronic mail messages. The box also strips off the outer envelope (i.e., decrypts with its private key) and remails the message to the apress on the inner envelope. Tamper-resistant modules may be used to prevent cheating and forced disclosure of the mapping between incoming and outgoing mail. A sequence of many remailings effectively makes tracing sending and receiving impossible. Contrast this with the software version, the DC protocol.raising an integer to the power of another integer, modulo some integer. For integers a, n, and m, a^m mod n. For example, 5^3 mod 100 = 25. Modular exponentiation can be done fairly quickly with a sequence of bit shifts and aps, and special purpose chips have been designed. See also discrete logarithm.the largest intelligence agency, responsible for making and breaking ciphers, for intercepting communications, and for ensuring the security of U.S. computers. Headquartered in Fort Meade, Maryland, with many listening posts around the world. The NSA funds cryptographic research and advises other agencies about cryptographic matters. The NSA once obviously had the world's leading cryptologists, but this may no longer be the case.a credential that you possess that you don't want any one else to know, for example, a bankruptcy filing. A formal version of a negative reputation.a large class of difficult problems. \"NP\" stands for nondeterministic polynomial time, a class of problems thought in general not to have feasible algorithms for their solution. A problem is \"complete\" if any other NP problem may be reduced to that problem. Many important combinatorial and algebraic problems are NP-complete: the traveling salesman problem, the Hamiltonian cycle problem, the word problem, and on and on.a cryptographic primitive that involves the probabilistic transmission of bits. The sender does not know if the bits were received.a string of randomly-selected bits or symbols which is combined with a plaintext message to produce the ciphertext. This combination may be shifting letters some amount, bitwise exclusive-ORed, etc.). The recipient, who also has a copy of the one time pad, can easily recover the plaintext. Provided the pad is only used once and then destroyed, and is not available to an eavesdropper, the system is perfectly secure, i.e., it is information-theoretically secure. Key distribution (the pad) is obviously a practical concern, but consider CD-ROM's.a function which is easy to compute in one direction but hard to find any inverse for, e.g. modular exponentiation, where the inverse problem is known as the discrete logarithm problem. Compare the special case of trap door one-way functions. An example of a one-way operation is multiplication: it is easy to multiply two prime numbers of 100 digits to produce a 200-digit number, but hard to factor that 200-digit number.Certainly the most important unsolved problem in complexity theory. If P = NP, then cryptography as we know it today does not exist. If P = NP, all NP problems are \"easy.\"sending extra messages to confuse eavesdroppers and to defeat traffic analysis. Also aping random bits to a message to be enciphered.also called cleartext, the text that is to be enciphered.Phillip Zimmerman's implementation of RSA, recently upgraded to version 2.0, with more robust components and several new features. RSA Data Security has threatened PZ so he no longer works on it. Version 2.0 was written by a consortium of non-U.S. hackers.integers with no factors other than themselves and 1. The number of primes is unbounded. About 1% of the 100 decimal digit numbers are prime. Since there are about 10^70 particles in the universe, there are about 10^23 100 digit primes for each and every particle in the universe!a scheme by Goldwasser, Micali, and Blum that allows multiple ciphertexts for the same plaintext, i.e., any given plaintext may have many ciphertexts if the ciphering is repeated. This protects against certain types of known ciphertext attacks on RSA.proving who you are, either your true name, or your digital identity. Generally, possession of the right key is sufficient proof (guard your key!). Some work has been done on \"is-a-person\" credentialling agencies, using the so-called Fiat-Shamir protocol...think of this as a way to issue unforgeable digital passports. Physical proof of identity may be done with biometric security methods. Zero knowledge proofs of identity reveal nothing beyond the fact that the identity is as claimed. This has obvious uses for computer access, passwords, etc.a formal procedure for solving some problem. Modern cryptology is mostly about the study of protocols for many problems, such as coin-flipping, bit commitment (blobs), zero knowledge proofs, dining cryptographers, and so on.the key distributed publicly to potential message-senders. It may be published in a phonebook-like directory or otherwise sent. A major concern is the validity of this public key to guard against spoofing or impersonation.the modern breakthrough in cryptology, designed by Diffie and Hellman, with contributions from several others. Uses trap door one-way functions so that encryption may be done by anyone with access to the \"public key\" but decryption may be done only by the holder of the \"private key.\" Encompasses public key encryption, digital signatures, digital cash, and many other protocols and applications.the use of modern cryptologic methods to provided message security and authentication. The RSA algorithm is the most widely used form of public key encryption, although other systems exist. A public key may be freely published, e.g., in phonebook-like directories, while the corresponding private key is closely guarded.M.I.T. and Stanford, due to the work of Rivest, Shamir, Adleman, Diffie, Hellman, and Merkle, formed Public Key Partners to license the various public key, digital signature, and RSA patents. These patents, granted in the early 1980s, expire in the between 1998 and 2002. PKP has licensed RSA Data Security Inc., of Redwood City, CA, which handles the sales, etc.a system based on quantum-mechanical principles. Eavesdroppers alter the quantum state of the system and so are detected. Developed by Brassard and Bennett, only small laboratory demonstrations have been made.the trail of positive and negative associations and judgments that some entity accrues. Credit ratings, academic credentials, and trustworthiness are all examples. A digital pseudonym will accrue these reputation credentials based on actions, opinions of others, etc. In crypto anarchy, reputations and agoric systems will be of paramount importance. There are many fascinating issues of how reputation-based systems work, how credentials can be bought and sold, and so forth.the main public key encryption algorithm, developed by Ron Rivest, Adi Shamir, and Kenneth Adleman. It exploits the difficulty of factoring large numbers to create a private key and public key. First invented in 1978, it remains the core of modern public key systems. It is usually much slower than DES, but special-purpose modular exponentiation chips will likely speed it up. A popular scheme for speed is to use RSA to transmit session keys and then a high-speed cipher like DES for the actual message text.Let p and q be large primes, typically with more than 100 digits. Let n = pq and find some e such that e is relatively prime to (p - 1)(q - 1). The set of numbers p, q, and e is the private key for RSA. The set of numbers n and e forms the public key (recall that knowing n is not sufficient to easily find p and q...the factoring problem). A message M is encrypted by computing M^e mod n. The owner of the private key can decrypt the encrypted message by exploiting number theory results, as follows. An integer d is computed such that ed =1 (mod (p - 1)(q - 1)). Euler proved a theorem that M^(ed) = M mod n and so M^(ed) mod n = M. This means that in some sense the integers e and d are \"inverses\" of each other. [If this is unclear, please see one of the many texts and articles on public key encryption.]A system which uses the same key to encrypt and decrypt traffic at each end of a communication link. Also called a symmetric or one-key system. Contrast with public key cryptosystem.a computer chip embeped in credit card. They can hold cash, credentials, cryptographic keys, etc. Usually these are built with some degree of tamper-resistance. Smart cards may perform part of a crypto transaction, or all of it. Performing part of it may mean checking the computations of a more powerful computer, e.g., one in an ATM.posing as another user. Used for stealing passwords, modifying files, and stealing cash. Digital signatures and other authentication methods are useful to prevent this. Public keys must be validated and protected to ensure that others don't substitute their own public keys which users may then unwittingly use.a part of cryptology dealing with hiding messages and obscuring who is sending and receiving messages. Message traffic is often paped to reduce the signals that would otherwise come from a supen beginning of messages.same as private key cryptosystem.sealed boxes or modules which are hard to open, requiring extensive probing and usually leaving ample evidence that the tampering has occurred. Various protective techniques are used, such as special metal or oxide layers on chips, armored coatings, embeped optical fibers, and other measures to thwart analysis. Popularly called \"tamper-proof boxes.\" Uses include: smart cards, nuclear weapon initiators, cryptographic key holders, ATMs, etc.interfering with messages and possibly modifying them. This may compromise data security, help to break ciphers, etc. See also spoofing.some representation, such as ID cards, subway tokens, money, etc., that indicates possession of some property or value.determining who is sending or receiving messages by analyzing packets, frequency of packets, etc. A part of steganography. Usually handled with traffic paping.the protocols for determining who can send messages in a DC protocol, and when. These rules are needed to prevent collision and deliberate jamming of the channels.dummy messages in DC Nets which are used to catch jammers and disrupters. The messages contain no private information and are published in a blob beforehand so that the trap message can later be opened to reveal the disrupter. (There are many strategies to explore here.)In cryptography, a piece of secret information that allows the holder of a private key to invert a normally hard to invert function.functions which are easy to compute in both the forward and reverse direction but for which the disclosure of an algorithm to compute the function in the forward direction does not provide information on how to compute the function in the reverse direction. More simply put, trap-door one way functions are one way for all but the holder of the secret information. The RSA algorithm is the best-known example of such a function.same as information-theoretic security, that is, unbreakable except by loss or theft of the key.where no amount of intercepted ciphertext is enough to allow the cipher to be broken, as with the use of a one-time pad cipher. Contrast with computationally secure.Various schemes have been devised for anonymous, untraceable voting. Voting schemes should have several properties: privacy of the vote, security of the vote (no multiple votes), robustness against disruption by jammers or disrupters, verifiability (voter has confidence in the results), and efficiency.proofs in which no knowledge of the actual proof is conveyed. Peggy the Prover demonstrates to Sid the Skeptic that she is indeed in possession of some piece of knowledge without actually revealing any of that knowledge. This is useful for access to computers, because eavesdroppers or dishonest sysops cannot steal the knowledge given. Also called minimum disclosure proofs. Useful for proving possession of some property, or credential, such as age or voting status, without revealing personal information."}
{"prompt": "Detecting Double Spending", "completion": "Here is an attempt to describe Chaum's digital cash from his paper, Untraceable Electronic Cash, by Chaum, Fiat, and Naor, from the Crypto 88 proceedings. This cash has the property that the user of the cash can remain anonymous so long as she does not spend it more than once, but if she does double-spend then her identity is revealed.This is how it works in general terms: Alice opens an account with a bank non-anonymously. She shows ID so that the bank knows who she is; both she and the bank know her account number. When she withdraws cash, she goes to the bank or contacts them electronically and presents some proof of who she is and what her account number is, and the bank gives her some digital cash. The digital cash is an information pattern, perhaps stored in a computer file on a smart card or magnetic disk. Later, she spends the digital cash by sending or giving it to Bob, a merchant. Bob can check and verify that the cash must have come from the bank. He accepts the cash if it is valid, giving Alice the merchandise. Later, he sends the cash to the bank to be added to his own account.Note that this much could basically be done with a simple RSA signature. The bank could give Alice a statement saying, \"this is worth $1\", signed by the bank's secret key. Bob could verify that the statement was in fact signed by the bank, and know therefore that no one else than the bank could have created that statement. He accepts it and sends it to the bank, which honors it since it recognizes its own signature.One problem with this trivial money is that double-spending can not be detected or prevented since all the cash looks alike. This can be remedied by having the cash include a unique serial number. Now when Bob goes to accept the cash from Alice, he can call the bank and say, has anyone else deposited serial number 123456? If not, he accepts the cash and deposits it. This is called on-line electronic money; the merchant must check with the bank for each transaction.This improved simple system does not deserve to be called cash, though, because it lacks the distinguishing characteristic of digital cash: it is not anonymous. When the bank sees money with serial number 123456 being deposited, the bank recognizes that this was the same bill that Alice withdrew. The bank can therefore deduce that Alice spent the money at Bob's, and from this kind of information a dossier could be built up with all kinds of privacy-destroying information about her.To allow anonymity, we have to get into the mathematics. What we want is for Alice and the bank collectively to create an RSA signature from the bank that could not be forged, but one which the bank will not recognize as coming from Alice. This is the first thing Chaum's paper discusses.The money in this system is of the form (x, f(x)^(1/3)) mod n, where n is the bank's public modulus. f() (and, below, g()) is a one-way function, one which can be calculated easily but for which it is infeasible to calculate the inverse. It should also be infeasible to come up with two different y,z such that f(y) = f(z). Today there are several suitable choices for one-way functions, the most common being the MD5 algorithm from RSA, and the US government's Secure Hash Algorithm (SHA).The reason the expression above would be accepted as cash is two-fold. First, only the bank can calculate anything ^ (1/3) mod n. This is basically the RSA signing operation for the exponent of 3. Nobody else can find cube roots. The reason f(x) is used is this. Suppose we proposed that (x, x^(1/3)) should be the cash, for some random x, reasoning that only the bank could find the cube root of x. Can you see how to forge cash like this? (Take a few moments and try to see how you could construct a pair like this even if you can't take cube roots.)The answer is that it is easy to forge this by first choosing a random y, and exhibiting the pair (y^3, y). Now we have a number and then its cube root. Yet we didn't have to take any cube roots to find it. That's why this kind of money would be no good.Chaum's system avoids this by taking the cube root of a one-way function of x. To forge it without taking a cube root you'd have to produce (finv(y^3), y), which would match the above pattern, but you can't invert the one-way function like that. So only the bank can create money of the proper form. This can be thought of as the formal, mathematical form of my informal \"money\" above which was a digitally signed note with a serial number. Here, x is the serial number, and it's digitally signed in this special way. Nothing more is needed.The nice thing about this money is that it allows for blinding, a method of having the bank sign the value without knowing what value it is signing. It works like this. Alice chooses x, which will be the x in the cash. She calculates f(x), but instead of sending it to the bank to be signed (raised to the 1/3 power) she first chooses a random number r, and sends f(x)*r^3 to the bank. The bank takes this number to the 1/3 power, getting r * f(x)^(1/3). Remember, though, that the bank doesn't see r or f(x) separately, but just their product. It doesn't know what r or f(x) is. They could each be anything, actually.The bank sends this r * f(x)^(1/3) back to Alice, and she divides it by r, which she knows. This gives her f(x)^(1/3), and she puts that together with x to get her digital cash: (x, f(x)^(1/3)). She has a piece of money which could only have been signed by the bank, yet the bank won't recognize it when it is deposited.Other, non-mathematical, things take place as this withdrawal goes on. Alice must prove her identity to the bank, as mentioned above. And the bank will debit her account by the value of the cash. In this system, we are assuming for simplicity that all cash has the same value. In a real system, different values might be encoded by different exponents than 3.When Alice deposits the money, Bob must call the bank to make sure that it hasn't been deposited before, this being an \"on-line\" system. Although the bank won't recognize x (it's never heard of it) it will remember all the x's which have been deposited and so can alert Bob if the money has been spent before. Both Bob and the bank can verify the digital signature on the money and so will honor it.All the material above takes up less than one page of Chaum's nine-page paper. For Chaum, this much is trivial. Now we get to the interesting part. Now we will see the scheme that allows double-spenders to lose their anonymity. This will allow for \"off-line\" electronic cash; Bob will no longer have to check with the bank to see if the money has already been spent. He accepts it from Alice knowing that if she does cheat, the bank will honor the cash and sue Alice to make up the loss.(To make this explanation easier to follow, I will describe a slightly simplified version of Chaum's off-line cash. The version I describe requires the use of a non-invertable one-way function as in the f() used above. Chaum's version does not require as strong an assumption and provides \"unconditional\" untraceability even if the one-way function is broken.)Let's start with the form of the cash itself. It is the product of k/2 numbers, where k is a \"security parameter\" that affects the chance of a cheater succeeding. Each number is of the form g(xi,yi)^(1/3), where g is a two-argument one-way function similar to the f above. (The \"xi\", \"yi\", \"ai\", etc. here are separate values for each i from 0 to k/2.)xi and yi are like this: xi = f(ai), where ai is a random number, and f is another one-way function. yi is kind of complicated. It is f(ai xor <info>), where <info>, the key to this whole operation, is identifying information about Alice's account! It is her account number concatenated with a serial number for the cash.Now, why go through all this? Here's why. If you could find out both ai and (ai xor <info>), for some i, you would know Alice's identity. (Xor'ing them would produce <info>.) When Alice double-spends, both ai and ai xor <info>will be revealed.What happens when Alice spends the coin is this. For each i from 0 to k/2 Bob chooses 0 or 1 at random. If he chooses 1 he gets told ai and yi. If he chooses 0 he gets told (ai xor <info>) and xi. This will let him check the signature on the money, as described in more detail below.Notice that when Bob gets this information, he'll know a bunch of ai's, and he'll know a bunch of (ai xor <info>)'s, but they are for different i's. He doesn't know both ai and (ai xor <info>) for any one i. So he can't break Alice's anonymity.When Bob deposits the money at the bank, he passes along the information he got from Alice regarding the ai's and such.Now, suppose Alice cheats. She spends the money again somewhere else, at Charlie's. Charlie goes through the same procedure as Bob, choosing 0 or 1 at random for each value of i. Here is the catch. Since he is choosing at random, it would be very unlikely that he will choose exactly the same 0's and 1's that Bob chose. (Here is where the size of k matters \u2013 making it bigger makes it less likely that Charlie and Bob will choose the same pattern of 0's and 1's. But it makes the calculations take longer.) That means for one or more values of i, Charlie will probably choose a 0 where Bob chose a 1, or vice versa.Because of this, if Bob got ai for that i, Charlie will get ai xor <info>. Or if Bob got ai xor <info>, Charlie will get ai. Either way, when Charlie sends his record of this information to the bank, the bank will put Bob's and Charlie's information together and get both ai and ai xor <info>. Xor'ing these together reveals <info>, and Alice is caught! This is the main idea.(Chaum suggests not just relying on random chance to make sure Bob and Charlie use different sets of 1's and 0's. At least some of the bits might be assigned to Bob and Charlie by the bank in such a way that everybody gets a different number. This way it would be guaranteed that Bob and Charlie would choose opposite values for some i.)The reason for the money to have the form it does is so that Bob can check that it is signed by the bank. For each value of i Alice has to give him enough information to calculate xi and yi. If Bob choses a 1, she gives him ai and yi. Given ai Bob can calculate xi (=f(ai)), and with this and yi he can calculate g(xi,yi). If Bob chooses a 0, she gives him (ai xor <info>), as described before, and also xi. Given (ai xor <info>), Bob calculates yi (=f(ai xor <info>)), and with this and xi he can calculate g(xi,yi).So for each i, whether Bob gives a 0 or a 1 he gets enough information to calculate g(xi,yi). He multiplies these all together and confirms that they are equal to Alice's original \"money\" value when it is taken to the 3rd power (recall the money was product of g(xi,yi)^(1/3) for all i). Only the bank could have produced a signature on this one-way function f whose arguments take this special form.One more complication exists. (Well, actually, an almost infinite number of complications exist if you look hard enough. But we'll just focus on one more.) Alice needs to get this special form of money from the bank in such a way that the bank won't recognize it. That means she has to blind it. But in this case the bank wants to be sure that the money is of the proper form when it signs it; in particular, it wants to make darned sure that Alice's <info> which is buried deep in all of those f's of g's is actually the right one for her. But since the bank can't see what it is signing, this is hard to do.Chaum uses cut-and-choose for this. He has Alice prepare all these f's and g's according to the form above, carefully embedding her own incriminating <info> in each one. Then she multiplies each g(xi,yi) by a blinding factor ri^3 just like in the first cash. These are what she sends to the bank to be signed.The trick, though, is that she sends twice as many as will be used. She sends k of them, but only k/2 will be used. (That's why the loop above used k/2 as the limit.) The bank chooses k/2 at random out of the k she sent as the ones which will actually be used. Alice then has to send the blinding ri values for the ones which the bank didn't pick.The idea is that if Alice tries to cheat, embedding \"Bozo\" instead of \"Alice\" in that <info> field, she's taking a chance. First, to be useful, she's going to have to embed it in a lot of <info> fields for different values of i. When Bob and Charlie compare notes after she double-spends, every value of i for which they chose different 0's and 1's, which will be on the average half of them, will reveal an <info> field. If she only fakes a few, chances are her real identity will still be revealed.But if she falsifies a great many of them, then when the bank chooses half, chances are at least some of the fake ones will be in the set the bank didn't choose. Then when Alice has to reveal her blinding r's, the jig will be up. The bank will un-blind all those g(xi,yi)'s which aren't being used, and see the fake <info> fields.This cut-and-choose methodology has the disadvantage that Alice has to do twice as much work in preparing the money, half of which will just be thrown away. But it is a simple, \"brute force\" way to make sure that blinding signatures are actually being done on properly-formed data.So, there you have it. Anonymity as long as you don't cheat, and double-spenders get caught. It's a little complicated but that's what computers are for; Bob and Alice wouldn't do all this stuff by hand. Alice would push the \"generate a money candidate\" button and get something to be sent to the bank (lots of the new PDA's have infrared wireless communications that would be perfect for face-to-face transactions). Bob would push the \"check money\" button when Alice spent it and it would flash red or green. As long as the calculations don't actually take too much time, which they really wouldn't in this case despite this long-winded explanation, the people involved can ignore the details.Hal Finney\nhal@rain.orgHal Finney Home Page"}
{"prompt": "The Cathedral and the Bazaar", "completion": "I anatomize a successful open-source project, fetchmail, that was run as a deliberate test of the surprising theories about software engineering suggested by the history of Linux. I discuss these theories in terms of two fundamentally different development styles, the \"cathedral\" model of most of the commercial world versus the \"bazaar\" model of the Linux world. I show that these models derive from opposing assumptions about the nature of the software-debugging task. I then make a sustained argument from the Linux experience for the proposition that \"Given enough eyeballs, all bugs are shallow\", suggest productive analogies with other self-correcting systems of selfish agents, and conclude with some exploration of the implications of this insight for the future of software.Linux is subversive. Who would have thought even five years ago (1991) that a world-class operating system could coalesce as if by magic out of part-time hacking by several thousand developers scattered all over the planet, connected only by the tenuous strands of the Internet?Certainly not I. By the time Linux swam onto my radar screen in early 1993, I had already been involved in Unix and open-source development for ten years. I was one of the first GNU contributors in the mid-1980s. I had released a good deal of open-source software onto the net, developing or co-developing several programs (nethack, Emacs's VC and GUD modes, xlife, and others) that are still in wide use today. I thought I knew how it was done.Linux overturned much of what I thought I knew. I had been preaching the Unix gospel of small tools, rapid prototyping and evolutionary programming for years. But I also believed there was a certain critical complexity above which a more centralized, a priori approach was required. I believed that the most important software (operating systems and really large tools like the Emacs programming editor) needed to be built like cathedrals, carefully crafted by individual wizards or small bands of mages working in splendid isolation, with no beta to be released before its time.Linus Torvalds's style of development\u2014release early and often, delegate everything you can, be open to the point of promiscuity\u2014came as a surprise. No quiet, reverent cathedral-building here\u2014rather, the Linux community seemed to resemble a great babbling bazaar of differing agendas and approaches (aptly symbolized by the Linux archive sites, who'd take submissions from anyone) out of which a coherent and stable system could seemingly emerge only by a succession of miracles.The fact that this bazaar style seemed to work, and work well, came as a distinct shock. As I learned my way around, I worked hard not just at individual projects, but also at trying to understand why the Linux world not only didn't fly apart in confusion but seemed to go from strength to strength at a speed barely imaginable to cathedral-builders.By mid-1996 I thought I was beginning to understand. Chance handed me a perfect way to test my theory, in the form of an open-source project that I could consciously try to run in the bazaar style. So I did\u2014and it was a significant success.This is the story of that project. I'll use it to propose some aphorisms about effective open-source development. Not all of these are things I first learned in the Linux world, but we'll see how the Linux world gives them particular point. If I'm correct, they'll help you understand exactly what it is that makes the Linux community such a fountain of good software\u2014and, perhaps, they will help you become more productive yourself.Since 1993 I'd been running the technical side of a small free-access Internet service provider called Chester County InterLink (CCIL) in West Chester, Pennsylvania. I co-founded CCIL and wrote our unique multiuser bulletin-board software\u2014you can check it out by telnetting to locke.ccil.org. Today it supports almost three thousand users on thirty lines. The job allowed me 24-hour-a-day access to the net through CCIL's 56K line\u2014in fact, the job practically demanded it!I had gotten quite used to instant Internet email. I found having to periodically telnet over to locke to check my mail annoying. What I wanted was for my mail to be delivered on snark (my home system) so that I would be notified when it arrived and could handle it using all my local tools.The Internet's native mail forwarding protocol, SMTP (Simple Mail Transfer Protocol), wouldn't suit, because it works best when machines are connected full-time, while my personal machine isn't always on the Internet, and doesn't have a static IP address. What I needed was a program that would reach out over my intermittent dialup connection and pull across my mail to be delivered locally. I knew such things existed, and that most of them used a simple application protocol called POP (Post Office Protocol). POP is now widely supported by most common mail clients, but at the time, it wasn't built in to the mail reader I was using.I needed a POP3 client. So I went out on the Internet and found one. Actually, I found three or four. I used one of them for a while, but it was missing what seemed an obvious feature, the ability to hack the addresses on fetched mail so replies would work properly.The problem was this: suppose someone named 'joe' on locke sent me mail. If I fetched the mail to snark and then tried to reply to it, my mailer would cheerfully try to ship it to a nonexistent 'joe' on snark. Hand-editing reply addresses to tack on <@ccil.org> quickly got to be a serious pain.This was clearly something the computer ought to be doing for me. But none of the existing POP clients knew how! And this brings us to the first lesson:Perhaps this should have been obvious (it's long been proverbial that \"Necessity is the mother of invention\") but too often software developers spend their days grinding away for pay at programs they neither need nor love. But not in the Linux world\u2014which may explain why the average quality of software originated in the Linux community is so high.So, did I immediately launch into a furious whirl of coding up a brand-new POP3 client to compete with the existing ones? Not on your life! I looked carefully at the POP utilities I had in hand, asking myself \"Which one is closest to what I want?\" Because:While I don't claim to be a great programmer, I try to imitate one. An important trait of the great ones is constructive laziness. They know that you get an A not for effort but for results, and that it's almost always easier to start from a good partial solution than from nothing at all.Linus Torvalds, for example, didn't actually try to write Linux from scratch. Instead, he started by reusing code and ideas from Minix, a tiny Unix-like operating system for PC clones. Eventually all the Minix code went away or was completely rewritten\u2014but while it was there, it provided scaffolding for the infant that would eventually become Linux.In the same spirit, I went looking for an existing POP utility that was reasonably well coded, to use as a development base.The source-sharing tradition of the Unix world has always been friendly to code reuse (this is why the GNU project chose Unix as a base OS, in spite of serious reservations about the OS itself). The Linux world has taken this tradition nearly to its technological limit; it has terabytes of open sources generally available. So spending time looking for some else's almost-good-enough is more likely to give you good results in the Linux world than anywhere else.And it did for me. With those I'd found earlier, my second search made up a total of nine candidates\u2014fetchpop, PopTart, get-mail, gwpop, pimp, pop-perl, popc, popmail and upop. The one I first settled on was 'fetchpop' by Seung-Hong Oh. I put my header-rewrite feature in it, and made various other improvements which the author accepted into his 1.9 release.A few weeks later, though, I stumbled across the code for popclient by Carl Harris, and found I had a problem. Though fetchpop had some good original ideas in it (such as its background-daemon mode), it could only handle POP3 and was rather amateurishly coded (Seung-Hong was at that time a bright but inexperienced programmer, and both traits showed). Carl's code was better, quite professional and solid, but his program lacked several important and rather tricky-to-implement fetchpop features (including those I'd coded myself).Stay or switch? If I switched, I'd be throwing away the coding I'd already done in exchange for a better development base.A practical motive to switch was the presence of multiple-protocol support. POP3 is the most commonly used of the post-office server protocols, but not the only one. Fetchpop and the other competition didn't do POP2, RPOP, or APOP, and I was already having vague thoughts of perhaps adding IMAP (Internet Message Access Protocol, the most recently designed and most powerful post-office protocol) just for fun.But I had a more theoretical reason to think switching might be as good an idea as well, something I learned long before Linux.Or, to put it another way, you often don't really understand the problem until after the first time you implement a solution. The second time, maybe you know enough to do it right. So if you want to get it right, be ready to start over at least once[JB].Well (I told myself) the changes to fetchpop had been my first try. So I switched.After I sent my first set of popclient patches to Carl Harris on 25 June 1996, I found out that he had basically lost interest in popclient some time before. The code was a bit dusty, with minor bugs hanging out. I had many changes to make, and we quickly agreed that the logical thing for me to do was take over the program.Without my actually noticing, the project had escalated. No longer was I just contemplating minor patches to an existing POP client. I took on maintaining an entire one, and there were ideas bubbling in my head that I knew would probably lead to major changes.In a software culture that encourages code-sharing, this is a natural way for a project to evolve. I was acting out this principle:But Carl Harris's attitude was even more important. He understood thatWithout ever having to discuss it, Carl and I knew we had a common goal of having the best solution out there. The only question for either of us was whether I could establish that I was a safe pair of hands. Once I did that, he acted with grace and dispatch. I hope I will do as well when it comes my turn.And so I inherited popclient. Just as importantly, I inherited popclient's user base. Users are wonderful things to have, and not just because they demonstrate that you're serving a need, that you've done something right. Properly cultivated, they can become co-developers.Another strength of the Unix tradition, one that Linux pushes to a happy extreme, is that a lot of users are hackers too. Because source code is available, they can be effective hackers. This can be tremendously useful for shortening debugging time. Given a bit of encouragement, your users will diagnose problems, suggest fixes, and help improve the code far more quickly than you could unaided.The power of this effect is easy to underestimate. In fact, pretty well all of us in the open-source world drastically underestimated how well it would scale up with number of users and against system complexity, until Linus Torvalds showed us differently.In fact, I think Linus's cleverest and most consequential hack was not the construction of the Linux kernel itself, but rather his invention of the Linux development model. When I expressed this opinion in his presence once, he smiled and quietly repeated something he has often said: \"I'm basically a very lazy person who likes to get credit for things other people actually do.\" Lazy like a fox. Or, as Robert Heinlein famously wrote of one of his characters, too lazy to fail.In retrospect, one precedent for the methods and success of Linux can be seen in the development of the GNU Emacs Lisp library and Lisp code archives. In contrast to the cathedral-building style of the Emacs C core and most other GNU tools, the evolution of the Lisp code pool was fluid and very user-driven. Ideas and prototype modes were often rewritten three or four times before reaching a stable final form. And loosely-coupled collaborations enabled by the Internet, a la Linux, were frequent.Indeed, my own most successful single hack previous to fetchmail was probably Emacs VC (version control) mode, a Linux-like collaboration by email with three other people, only one of whom (Richard Stallman, the author of Emacs and founder of the Free Software Foundation) I have met to this day. It was a front-end for SCCS, RCS and later CVS from within Emacs that offered \"one-touch\" version control operations. It evolved from a tiny, crude sccs.el mode somebody else had written. And the development of VC succeeded because, unlike Emacs itself, Emacs Lisp code could go through release/test/improve generations very quickly.The Emacs story is not unique. There have been other software products with a two-level architecture and a two-tier user community that combined a cathedral-mode core and a bazaar-mode toolbox. One such is MATLAB, a commercial data-analysis and visualization tool. Users of MATLAB and other products with a similar structure invariably report that the action, the ferment, the innovation mostly takes place in the open part of the tool where a large and varied community can tinker with it.Early and frequent releases are a critical part of the Linux development model. Most developers (including me) used to believe this was bad policy for larger than trivial projects, because early versions are almost by definition buggy versions and you don't want to wear out the patience of your users.This belief reinforced the general commitment to a cathedral-building style of development. If the overriding objective was for users to see as few bugs as possible, why then you'd only release a version every six months (or less often), and work like a dog on debugging between releases. The Emacs C core was developed this way. The Lisp library, in effect, was not\u2014because there were active Lisp archives outside the FSF's control, where you could go to find new and development code versions independently of Emacs's release cycle[QR].The most important of these, the Ohio State Emacs Lisp archive, anticipated the spirit and many of the features of today's big Linux archives. But few of us really thought very hard about what we were doing, or about what the very existence of that archive suggested about problems in the FSF's cathedral-building development model. I made one serious attempt around 1992 to get a lot of the Ohio code formally merged into the official Emacs Lisp library. I ran into political trouble and was largely unsuccessful.But by a year later, as Linux became widely visible, it was clear that something different and much healthier was going on there. Linus's open development policy was the very opposite of cathedral-building. Linux's Internet archives were burgeoning, multiple distributions were being floated. And all of this was driven by an unheard-of frequency of core system releases.Linus was treating his users as co-developers in the most effective possible way:Linus's innovation wasn't so much in doing quick-turnaround releases incorporating lots of user feedback (something like this had been Unix-world tradition for a long time), but in scaling it up to a level of intensity that matched the complexity of what he was developing. In those early times (around 1991) it wasn't unknown for him to release a new kernel more than once a day! Because he cultivated his base of co-developers and leveraged the Internet for collaboration harder than anyone else, this worked.But how did it work? And was it something I could duplicate, or did it rely on some unique genius of Linus Torvalds?I didn't think so. Granted, Linus is a damn fine hacker. How many of us could engineer an entire production-quality operating system kernel from scratch? But Linux didn't represent any awesome conceptual leap forward. Linus is not (or at least, not yet) an innovative genius of design in the way that, say, Richard Stallman or James Gosling (of NeWS and Java) are. Rather, Linus seems to me to be a genius of engineering and implementation, with a sixth sense for avoiding bugs and development dead-ends and a true knack for finding the minimum-effort path from point A to point B. Indeed, the whole design of Linux breathes this quality and mirrors Linus's essentially conservative and simplifying design approach.So, if rapid releases and leveraging the Internet medium to the hilt were not accidents but integral parts of Linus's engineering-genius insight into the minimum-effort path, what was he maximizing? What was he cranking out of the machinery?Put that way, the question answers itself. Linus was keeping his hacker/users constantly stimulated and rewarded\u2014stimulated by the prospect of having an ego-satisfying piece of the action, rewarded by the sight of constant (even daily) improvement in their work.Linus was directly aiming to maximize the number of person-hours thrown at debugging and development, even at the possible cost of instability in the code and user-base burnout if any serious bug proved intractable. Linus was behaving as though he believed something like this:Or, less formally, \"Given enough eyeballs, all bugs are shallow.\" I dub this: \"Linus's Law\".My original formulation was that every problem \"will be transparent to somebody\". Linus demurred that the person who understands and fixes the problem is not necessarily or even usually the person who first characterizes it. \"Somebody finds the problem,\" he says, \"and somebody else understands it. And I'll go on record as saying that finding it is the bigger challenge.\" That correction is important; we'll see how in the next section, when we examine the practice of debugging in more detail. But the key point is that both parts of the process (finding and fixing) tend to happen rapidly.In Linus's Law, I think, lies the core difference underlying the cathedral-builder and bazaar styles. In the cathedral-builder view of programming, bugs and development problems are tricky, insidious, deep phenomena. It takes months of scrutiny by a dedicated few to develop confidence that you've winkled them all out. Thus the long release intervals, and the inevitable disappointment when long-awaited releases are not perfect.In the bazaar view, on the other hand, you assume that bugs are generally shallow phenomena\u2014or, at least, that they turn shallow pretty quickly when exposed to a thousand eager co-developers pounding on every single new release. Accordingly you release often in order to get more corrections, and as a beneficial side effect you have less to lose if an occasional botch gets out the door.And that's it. That's enough. If \"Linus's Law\" is false, then any system as complex as the Linux kernel, being hacked over by as many hands as the that kernel was, should at some point have collapsed under the weight of unforseen bad interactions and undiscovered \"deep\" bugs. If it's true, on the other hand, it is sufficient to explain Linux's relative lack of bugginess and its continuous uptimes spanning months or even years.Maybe it shouldn't have been such a surprise, at that. Sociologists years ago discovered that the averaged opinion of a mass of equally expert (or equally ignorant) observers is quite a bit more reliable a predictor than the opinion of a single randomly-chosen one of the observers. They called this the Delphi effect. It appears that what Linus has shown is that this applies even to debugging an operating system\u2014that the Delphi effect can tame development complexity even at the complexity level of an OS kernel.[CV]One special feature of the Linux situation that clearly helps along the Delphi effect is the fact that the contributors for any given project are self-selected. An early respondent pointed out that contributions are received not from a random sample, but from people who are interested enough to use the software, learn about how it works, attempt to find solutions to problems they encounter, and actually produce an apparently reasonable fix. Anyone who passes all these filters is highly likely to have something useful to contribute.Linus's Law can be rephrased as \"Debugging is parallelizable\". Although debugging requires debuggers to communicate with some coordinating developer, it doesn't require significant coordination between debuggers. Thus it doesn't fall prey to the same quadratic complexity and management costs that make adding developers problematic.In practice, the theoretical loss of efficiency due to duplication of work by debuggers almost never seems to be an issue in the Linux world. One effect of a \"release early and often\" policy is to minimize such duplication by propagating fed-back fixes quickly[JH].Brooks (the author of The Mythical Man-Month) even made an off-hand observation related to this: \"The total cost of maintaining a widely used program is typically 40 percent or more of the cost of developing it. Surprisingly this cost is strongly affected by the number of users. More users find more bugs.\" [emphasis added].More users find more bugs because adding more users adds more different ways of stressing the program. This effect is amplified when the users are co-developers. Each one approaches the task of bug characterization with a slightly different perceptual set and analytical toolkit, a different angle on the problem. The \"Delphi effect\" seems to work precisely because of this variation. In the specific context of debugging, the variation also tends to reduce duplication of effort.So adding more beta-testers may not reduce the complexity of the current \"deepest\" bug from the developer's point of view, but it increases the probability that someone's toolkit will be matched to the problem in such a way that the bug is shallow to that person.Linus coppers his bets, too. In case there are serious bugs, Linux kernel version are numbered in such a way that potential users can make a choice either to run the last version designated \"stable\" or to ride the cutting edge and risk bugs in order to get new features. This tactic is not yet systematically imitated by most Linux hackers, but perhaps it should be; the fact that either choice is available makes both more attractive.[HBS]It's one thing to observe in the large that the bazaar style greatly accelerates debugging and code evolution. It's another to understand exactly how and why it does so at the micro-level of day-to-day developer and tester behavior. In this section (written three years after the original paper, using insights by developers who read it and re-examined their own behavior) we'll take a hard look at the actual mechanisms. Non-technically inclined readers can safely skip to the next section.One key to understanding is to realize exactly why it is that the kind of bug report non\u2013source-aware users normally turn in tends not to be very useful. Non\u2013source-aware users tend to report only surface symptoms; they take their environment for granted, so they (a) omit critical background data, and (b) seldom include a reliable recipe for reproducing the bug.The underlying problem here is a mismatch between the tester's and the developer's mental models of the program; the tester, on the outside looking in, and the developer on the inside looking out. In closed-source development they're both stuck in these roles, and tend to talk past each other and find each other deeply frustrating.Open-source development breaks this bind, making it far easier for tester and developer to develop a shared representation grounded in the actual source code and to communicate effectively about it. Practically, there is a huge difference in leverage for the developer between the kind of bug report that just reports externally-visible symptoms and the kind that hooks directly to the developer's source-code\u2013based mental representation of the program.Most bugs, most of the time, are easily nailed given even an incomplete but suggestive characterization of their error conditions at source-code level. When someone among your beta-testers can point out, \"there's a boundary problem in line nnn\", or even just \"under conditions X, Y, and Z, this variable rolls over\", a quick look at the offending code often suffices to pin down the exact mode of failure and generate a fix.Thus, source-code awareness by both parties greatly enhances both good communication and the synergy between what a beta-tester reports and what the core developer(s) know. In turn, this means that the core developers' time tends to be well conserved, even with many collaborators.Another characteristic of the open-source method that conserves developer time is the communication structure of typical open-source projects. Above I used the term \"core developer\"; this reflects a distinction between the project core (typically quite small; a single core developer is common, and one to three is typical) and the project halo of beta-testers and available contributors (which often numbers in the hundreds).The fundamental problem that traditional software-development organization addresses is Brook's Law: \"Adding more programmers to a late project makes it later.\" More generally, Brooks's Law predicts that the complexity and communication costs of a project rise with the square of the number of developers, while work done only rises linearly.Brooks's Law is founded on experience that bugs tend strongly to cluster at the interfaces between code written by different people, and that communications/coordination overhead on a project tends to rise with the number of interfaces between human beings. Thus, problems scale with the number of communications paths between developers, which scales as the square of the humber of developers (more precisely, according to the formula N*(N - 1)/2 where N is the number of developers).The Brooks's Law analysis (and the resulting fear of large numbers in development groups) rests on a hidden assummption: that the communications structure of the project is necessarily a complete graph, that everybody talks to everybody else. But on open-source projects, the halo developers work on what are in effect separable parallel subtasks and interact with each other very little; code changes and bug reports stream through the core group, and only within that small core group do we pay the full Brooksian overhead.[SU]There are are still more reasons that source-code\u2013level bug reporting tends to be very efficient. They center around the fact that a single error can often have multiple possible symptoms, manifesting differently depending on details of the user's usage pattern and environment. Such errors tend to be exactly the sort of complex and subtle bugs (such as dynamic-memory-management errors or nondeterministic interrupt-window artifacts) that are hardest to reproduce at will or to pin down by static analysis, and which do the most to create long-term problems in software.A tester who sends in a tentative source-code\u2013level characterization of such a multi-symptom bug (e.g. \"It looks to me like there's a window in the signal handling near line 1250\" or \"Where are you zeroing that buffer?\") may give a developer, otherwise too close to the code to see it, the critical clue to a half-dozen disparate symptoms. In cases like this, it may be hard or even impossible to know which externally-visible misbehaviour was caused by precisely which bug\u2014but with frequent releases, it's unnecessary to know. Other collaborators will be likely to find out quickly whether their bug has been fixed or not. In many cases, source-level bug reports will cause misbehaviours to drop out without ever having been attributed to any specific fix.Complex multi-symptom errors also tend to have multiple trace paths from surface symptoms back to the actual bug. Which of the trace paths a given developer or tester can chase may depend on subtleties of that person's environment, and may well change in a not obviously deterministic way over time. In effect, each developer and tester samples a semi-random set of the program's state space when looking for the etiology of a symptom. The more subtle and complex the bug, the less likely that skill will be able to guarantee the relevance of that sample.For simple and easily reproducible bugs, then, the accent will be on the \"semi\" rather than the \"random\"; debugging skill and intimacy with the code and its architecture will matter a lot. But for complex bugs, the accent will be on the \"random\". Under these circumstances many people running traces will be much more effective than a few people running traces sequentially\u2014even if the few have a much higher average skill level.This effect will be greatly amplified if the difficulty of following trace paths from different surface symptoms back to a bug varies significantly in a way that can't be predicted by looking at the symptoms. A single developer sampling those paths sequentially will be as likely to pick a difficult trace path on the first try as an easy one. On the other hand, suppose many people are trying trace paths in parallel while doing rapid releases. Then it is likely one of them will find the easiest path immediately, and nail the bug in a much shorter time. The project maintainer will see that, ship a new release, and the other people running traces on the same bug will be able to stop before having spent too much time on their more difficult traces[RJ].Having studied Linus's behavior and formed a theory about why it was successful, I made a conscious decision to test this theory on my new (admittedly much less complex and ambitious) project.But the first thing I did was reorganize and simplify popclient a lot. Carl Harris's implementation was very sound, but exhibited a kind of unnecessary complexity common to many C programmers. He treated the code as central and the data structures as support for the code. As a result, the code was beautiful but the data structure design ad-hoc and rather ugly (at least by the high standards of this veteran LISP hacker).I had another purpose for rewriting besides improving the code and the data structure design, however. That was to evolve it into something I understood completely. It's no fun to be responsible for fixing bugs in a program you don't understand.For the first month or so, then, I was simply following out the implications of Carl's basic design. The first serious change I made was to add IMAP support. I did this by reorganizing the protocol machines into a generic driver and three method tables (for POP2, POP3, and IMAP). This and the previous changes illustrate a general principle that's good for programmers to keep in mind, especially in languages like C that don't naturally do dynamic typing:Brooks, Chapter 9: \"Show me your flowchart and conceal your tables, and I shall continue to be mystified. Show me your tables, and I won't usually need your flowchart; it'll be obvious.\"\" Allowing for thirty years of terminological/cultural shift, it's the same point.At this point (early September 1996, about six weeks from zero) I started thinking that a name change might be in order\u2014after all, it wasn't just a POP client any more. But I hesitated, because there was as yet nothing genuinely new in the design. My version of popclient had yet to develop an identity of its own.That changed, radically, when popclient learned how to forward fetched mail to the SMTP port. I'll get to that in a moment. But first: I said earlier that I'd decided to use this project to test my theory about what Linus Torvalds had done right. How (you may well ask) did I do that? In these ways:The payoff from these simple measures was immediate. From the beginning of the project, I got bug reports of a quality most developers would kill for, often with good fixes attached. I got thoughtful criticism, I got fan mail, I got intelligent feature suggestions. Which leads to:One interesting measure of fetchmail's success is the sheer size of the project beta list, fetchmail-friends. At the time of latest revision of this paper (November 2000) it has 287 members and is adding two or three a week.Actually, when I revised in late May 1997 I found the list was beginning to lose members from its high of close to 300 for an interesting reason. Several people have asked me to unsubscribe them because fetchmail is working so well for them that they no longer need to see the list traffic! Perhaps this is part of the normal life-cycle of a mature bazaar-style project.The real turning point in the project was when Harry Hochheiser sent me his scratch code for forwarding mail to the client machine's SMTP port. I realized almost immediately that a reliable implementation of this feature would make all the other mail delivery modes next to obsolete.For many weeks I had been tweaking fetchmail rather incrementally while feeling like the interface design was serviceable but grubby\u2014inelegant and with too many exiguous options hanging out all over. The options to dump fetched mail to a mailbox file or standard output particularly bothered me, but I couldn't figure out why.(If you don't care about the technicalia of Internet mail, the next two paragraphs can be safely skipped.)What I saw when I thought about SMTP forwarding was that popclient had been trying to do too many things. It had been designed to be both a mail transport agent (MTA) and a local delivery agent (MDA). With SMTP forwarding, it could get out of the MDA business and be a pure MTA, handing off mail to other programs for local delivery just as sendmail does.Why mess with all the complexity of configuring a mail delivery agent or setting up lock-and-append on a mailbox when port 25 is almost guaranteed to be there on any platform with TCP/IP support in the first place? Especially when this means retrieved mail is guaranteed to look like normal sender-initiated SMTP mail, which is really what we want anyway.(Back to a higher level....)Even if you didn't follow the preceding technical jargon, there are several important lessons here. First, this SMTP-forwarding concept was the biggest single payoff I got from consciously trying to emulate Linus's methods. A user gave me this terrific idea\u2014all I had to do was understand the implications.Interestingly enough, you will quickly find that if you are completely and self-deprecatingly truthful about how much you owe other people, the world at large will treat you as though you did every bit of the invention yourself and are just being becomingly modest about your innate genius. We can all see how well this worked for Linus!(When I gave my talk at the first Perl Conference in August 1997, hacker extraordinaire Larry Wall was in the front row. As I got to the last line above he called out, religious-revival style, \"Tell it, tell it, brother!\". The whole audience laughed, because they knew this had worked for the inventor of Perl, too.)After a very few weeks of running the project in the same spirit, I began to get similar praise not just from my users but from other people to whom the word leaked out. I stashed away some of that email; I'll look at it again sometime if I ever start wondering whether my life has been worthwhile :-).But there are two more fundamental, non-political lessons here that are general to all kinds of design.I had been trying to solve the wrong problem by continuing to develop popclient as a combined MTA/MDA with all kinds of funky local delivery modes. Fetchmail's design needed to be rethought from the ground up as a pure MTA, a part of the normal SMTP-speaking Internet mail path.When you hit a wall in development\u2014when you find yourself hard put to think past the next patch\u2014it's often time to ask not whether you've got the right answer, but whether you're asking the right question. Perhaps the problem needs to be reframed.Well, I had reframed my problem. Clearly, the right thing to do was (1) hack SMTP forwarding support into the generic driver, (2) make it the default mode, and (3) eventually throw out all the other delivery modes, especially the deliver-to-file and deliver-to-standard-output options.I hesitated over step 3 for some time, fearing to upset long-time popclient users dependent on the alternate delivery mechanisms. In theory, they could immediately switch to .forward files or their non-sendmail equivalents to get the same effects. In practice the transition might have been messy.But when I did it, the benefits proved huge. The cruftiest parts of the driver code vanished. Configuration got radically simpler\u2014no more grovelling around for the system MDA and user's mailbox, no more worries about whether the underlying OS supports file locking.Also, the only way to lose mail vanished. If you specified delivery to a file and the disk got full, your mail got lost. This can't happen with SMTP forwarding because your SMTP listener won't return OK unless the message can be delivered or at least spooled for later delivery.Also, performance improved (though not so you'd notice it in a single run). Another not insignificant benefit of this change was that the manual page got a lot simpler.Later, I had to bring delivery via a user-specified local MDA back in order to allow handling of some obscure situations involving dynamic SLIP. But I found a much simpler way to do it.The moral? Don't hesitate to throw away superannuated features when you can do it without loss of effectiveness. Antoine de Saint-Exup\u00e9ry (who was an aviator and aircraft designer when he wasn't authoring classic children's books) said:When your code is getting both better and simpler, that is when you know it's right. And in the process, the fetchmail design acquired an identity of its own, different from the ancestral popclient.It was time for the name change. The new design looked much more like a dual of sendmail than the old popclient had; both are MTAs, but where sendmail pushes then delivers, the new popclient pulls then delivers. So, two months off the blocks, I renamed it fetchmail.There is a more general lesson in this story about how SMTP delivery came to fetchmail. It is not only debugging that is parallelizable; development and (to a perhaps surprising extent) exploration of design space is, too. When your development mode is rapidly iterative, development and enhancement may become special cases of debugging\u2014fixing 'bugs of omission' in the original capabilities or concept of the software.Even at a higher level of design, it can be very valuable to have lots of co-developers random-walking through the design space near your product. Consider the way a puddle of water finds a drain, or better yet how ants find food: exploration essentially by diffusion, followed by exploitation mediated by a scalable communication mechanism. This works very well; as with Harry Hochheiser and me, one of your outriders may well find a huge win nearby that you were just a little too close-focused to see.There I was with a neat and innovative design, code that I knew worked well because I used it every day, and a burgeoning beta list. It gradually dawned on me that I was no longer engaged in a trivial personal hack that might happen to be useful to few other people. I had my hands on a program that every hacker with a Unix box and a SLIP/PPP mail connection really needs.With the SMTP forwarding feature, it pulled far enough in front of the competition to potentially become a \"category killer\", one of those classic programs that fills its niche so competently that the alternatives are not just discarded but almost forgotten.I think you can't really aim or plan for a result like this. You have to get pulled into it by design ideas so powerful that afterward the results just seem inevitable, natural, even foreordained. The only way to try for ideas like that is by having lots of ideas\u2014or by having the engineering judgment to take other peoples' good ideas beyond where the originators thought they could go.Andy Tanenbaum had the original idea to build a simple native Unix for IBM PCs, for use as a teaching tool (he called it Minix). Linus Torvalds pushed the Minix concept further than Andrew probably thought it could go\u2014and it grew into something wonderful. In the same way (though on a smaller scale), I took some ideas by Carl Harris and Harry Hochheiser and pushed them hard. Neither of us was 'original' in the romantic way people think is genius. But then, most science and engineering and software development isn't done by original genius, hacker mythology to the contrary.The results were pretty heady stuff all the same\u2014in fact, just the kind of success every hacker lives for! And they meant I would have to set my standards even higher. To make fetchmail as good as I now saw it could be, I'd have to write not just for my own needs, but also include and support features necessary to others but outside my orbit. And do that while keeping the program simple and robust.The first and overwhelmingly most important feature I wrote after realizing this was multidrop support\u2014the ability to fetch mail from mailboxes that had accumulated all mail for a group of users, and then route each piece of mail to its individual recipients.I decided to add the multidrop support partly because some users were clamoring for it, but mostly because I thought it would shake bugs out of the single-drop code by forcing me to deal with addressing in full generality. And so it proved. Getting RFC 822 address parsing right took me a remarkably long time, not because any individual piece of it is hard but because it involved a pile of interdependent and fussy details.But multidrop addressing turned out to be an excellent design decision as well. Here's how I knew:The unexpected use for multidrop fetchmail is to run mailing lists with the list kept, and alias expansion done, on the client side of the Internet connection. This means someone running a personal machine through an ISP account can manage a mailing list without continuing access to the ISP's alias files.Another important change demanded by my beta-testers was support for 8-bit MIME (Multipurpose Internet Mail Extensions) operation. This was pretty easy to do, because I had been careful to keep the code 8-bit clean (that is, to not press the 8th bit, unused in the ASCII character set, into service to carry information within the program). Not because I anticipated the demand for this feature, but rather in obedience to another rule:Had I not obeyed this rule, 8-bit MIME support would have been difficult and buggy. As it was, all I had to do is read the MIME standard (RFC 1652) and add a trivial bit of header-generation logic.Some European users bugged me into adding an option to limit the number of messages retrieved per session (so they can control costs from their expensive phone networks). I resisted this for a long time, and I'm still not entirely happy about it. But if you're writing for the world, you have to listen to your customers\u2014this doesn't change just because they're not paying you in money.Before we go back to general software-engineering issues, there are a couple more specific lessons from the fetchmail experience to ponder. Nontechnical readers can safely skip this section.The rc (control) file syntax includes optional 'noise' keywords that are entirely ignored by the parser. The English-like syntax they allow is considerably more readable than the traditional terse keyword-value pairs you get when you strip them all out.These started out as a late-night experiment when I noticed how much the rc file declarations were beginning to resemble an imperative minilanguage. (This is also why I changed the original popclient \"server\" keyword to \"poll\").It seemed to me that trying to make that imperative minilanguage more like English might make it easier to use. Now, although I'm a convinced partisan of the \"make it a language\" school of design as exemplified by Emacs and HTML and many database engines, I am not normally a big fan of \"English-like\" syntaxes.Traditionally programmers have tended to favor control syntaxes that are very precise and compact and have no redundancy at all. This is a cultural legacy from when computing resources were expensive, so parsing stages had to be as cheap and simple as possible. English, with about 50% redundancy, looked like a very inappropriate model then.This is not my reason for normally avoiding English-like syntaxes; I mention it here only to demolish it. With cheap cycles and core, terseness should not be an end in itself. Nowadays it's more important for a language to be convenient for humans than to be cheap for the computer.There remain, however, good reasons to be wary. One is the complexity cost of the parsing stage\u2014you don't want to raise that to the point where it's a significant source of bugs and user confusion in itself. Another is that trying to make a language syntax English-like often demands that the \"English\" it speaks be bent seriously out of shape, so much so that the superficial resemblance to natural language is as confusing as a traditional syntax would have been. (You see this bad effect in a lot of so-called \"fourth generation\" and commercial database-query languages.)The fetchmail control syntax seems to avoid these problems because the language domain is extremely restricted. It's nowhere near a general-purpose language; the things it says simply are not very complicated, so there's little potential for confusion in moving mentally between a tiny subset of English and the actual control language. I think there may be a broader lesson here:Another lesson is about security by obscurity. Some fetchmail users asked me to change the software to store passwords encrypted in the rc file, so snoopers wouldn't be able to casually see them.I didn't do it, because this doesn't actually add protection. Anyone who's acquired permissions to read your rc file will be able to run fetchmail as you anyway\u2014and if it's your password they're after, they'd be able to rip the necessary decoder out of the fetchmail code itself to get it.All .fetchmailrc password encryption would have done is give a false sense of security to people who don't think very hard. The general rule here is:Early reviewers and test audiences for this essay consistently raised questions about the preconditions for successful bazaar-style development, including both the qualifications of the project leader and the state of code at the time one goes public and starts to try to build a co-developer community.It's fairly clear that one cannot code from the ground up in bazaar style[IN]. One can test, debug and improve in bazaar style, but it would be very hard to originate a project in bazaar mode. Linus didn't try it. I didn't either. Your nascent developer community needs to have something runnable and testable to play with.When you start community-building, what you need to be able to present is a plausible promise. Your program doesn't have to work particularly well. It can be crude, buggy, incomplete, and poorly documented. What it must not fail to do is (a) run, and (b) convince potential co-developers that it can be evolved into something really neat in the foreseeable future.Linux and fetchmail both went public with strong, attractive basic designs. Many people thinking about the bazaar model as I have presented it have correctly considered this critical, then jumped from that to the conclusion that a high degree of design intuition and cleverness in the project leader is indispensable.But Linus got his design from Unix. I got mine initially from the ancestral popclient (though it would later change a great deal, much more proportionately speaking than has Linux). So does the leader/coordinator for a bazaar-style effort really have to have exceptional design talent, or can he get by through leveraging the design talent of others?I think it is not critical that the coordinator be able to originate designs of exceptional brilliance, but it is absolutely critical that the coordinator be able to recognize good design ideas from others.Both the Linux and fetchmail projects show evidence of this. Linus, while not (as previously discussed) a spectacularly original designer, has displayed a powerful knack for recognizing good design and integrating it into the Linux kernel. And I have already described how the single most powerful design idea in fetchmail (SMTP forwarding) came from somebody else.Early audiences of this essay complimented me by suggesting that I am prone to undervalue design originality in bazaar projects because I have a lot of it myself, and therefore take it for granted. There may be some truth to this; design (as opposed to coding or debugging) is certainly my strongest skill.But the problem with being clever and original in software design is that it gets to be a habit\u2014you start reflexively making things cute and complicated when you should be keeping them robust and simple. I have had projects crash on me because I made this mistake, but I managed to avoid this with fetchmail.So I believe the fetchmail project succeeded partly because I restrained my tendency to be clever; this argues (at least) against design originality being essential for successful bazaar projects. And consider Linux. Suppose Linus Torvalds had been trying to pull off fundamental innovations in operating system design during the development; does it seem at all likely that the resulting kernel would be as stable and successful as what we have?A certain base level of design and coding skill is required, of course, but I expect almost anybody seriously thinking of launching a bazaar effort will already be above that minimum. The open-source community's internal market in reputation exerts subtle pressure on people not to launch development efforts they're not competent to follow through on. So far this seems to have worked pretty well.There is another kind of skill not normally associated with software development which I think is as important as design cleverness to bazaar projects\u2014and it may be more important. A bazaar project coordinator or leader must have good people and communications skills.This should be obvious. In order to build a development community, you need to attract people, interest them in what you're doing, and keep them happy about the amount of work they're doing. Technical sizzle will go a long way towards accomplishing this, but it's far from the whole story. The personality you project matters, too.It is not a coincidence that Linus is a nice guy who makes people like him and want to help him. It's not a coincidence that I'm an energetic extrovert who enjoys working a crowd and has some of the delivery and instincts of a stand-up comic. To make the bazaar model work, it helps enormously if you have at least a little skill at charming people.It is truly written: the best hacks start out as personal solutions to the author's everyday problems, and spread because the problem turns out to be typical for a large class of users. This takes us back to the matter of rule 1, restated in a perhaps more useful way:So it was with Carl Harris and the ancestral popclient, and so with me and fetchmail. But this has been understood for a long time. The interesting point, the point that the histories of Linux and fetchmail seem to demand we focus on, is the next stage\u2014the evolution of software in the presence of a large and active community of users and co-developers.In The Mythical Man-Month, Fred Brooks observed that programmer time is not fungible; adding developers to a late software project makes it later. As we've seen previously, he argued that the complexity and communication costs of a project rise with the square of the number of developers, while work done only rises linearly. Brooks's Law has been widely regarded as a truism. But we've examined in this essay an number of ways in which the process of open-source development falsifies the assumptionms behind it\u2014and, empirically, if Brooks's Law were the whole picture Linux would be impossible.Gerald Weinberg's classic The Psychology of Computer Programming supplied what, in hindsight, we can see as a vital correction to Brooks. In his discussion of \"egoless programming\", Weinberg observed that in shops where developers are not territorial about their code, and encourage other people to look for bugs and potential improvements in it, improvement happens dramatically faster than elsewhere. (Recently, Kent Beck's 'extreme programming' technique of deploying coders in pairs looking over one anothers' shoulders might be seen as an attempt to force this effect.)Weinberg's choice of terminology has perhaps prevented his analysis from gaining the acceptance it deserved\u2014one has to smile at the thought of describing Internet hackers as \"egoless\". But I think his argument looks more compelling today than ever.The bazaar method, by harnessing the full power of the \"egoless programming\" effect, strongly mitigates the effect of Brooks's Law. The principle behind Brooks's Law is not repealed, but given a large developer population and cheap communications its effects can be swamped by competing nonlinearities that are not otherwise visible. This resembles the relationship between Newtonian and Einsteinian physics\u2014the older system is still valid at low energies, but if you push mass and velocity high enough you get surprises like nuclear explosions or Linux.The history of Unix should have prepared us for what we're learning from Linux (and what I've verified experimentally on a smaller scale by deliberately copying Linus's methods[EGCS]). That is, while coding remains an essentially solitary activity, the really great hacks come from harnessing the attention and brainpower of entire communities. The developer who uses only his or her own brain in a closed project is going to fall behind the developer who knows how to create an open, evolutionary context in which feedback exploring the design space, code contributions, bug-spotting, and other improvements come from from hundreds (perhaps thousands) of people.But the traditional Unix world was prevented from pushing this approach to the ultimate by several factors. One was the legal contraints of various licenses, trade secrets, and commercial interests. Another (in hindsight) was that the Internet wasn't yet good enough.Before cheap Internet, there were some geographically compact communities where the culture encouraged Weinberg's \"egoless\" programming, and a developer could easily attract a lot of skilled kibitzers and co-developers. Bell Labs, the MIT AI and LCS labs, UC Berkeley\u2014these became the home of innovations that are legendary and still potent.Linux was the first project for which a conscious and successful effort to use the entire world as its talent pool was made. I don't think it's a coincidence that the gestation period of Linux coincided with the birth of the World Wide Web, and that Linux left its infancy during the same period in 1993\u20141994 that saw the takeoff of the ISP industry and the explosion of mainstream interest in the Internet. Linus was the first person who learned how to play by the new rules that pervasive Internet access made possible.While cheap Internet was a necessary condition for the Linux model to evolve, I think it was not by itself a sufficient condition. Another vital factor was the development of a leadership style and set of cooperative customs that could allow developers to attract co-developers and get maximum leverage out of the medium.But what is this leadership style and what are these customs? They cannot be based on power relationships\u2014and even if they could be, leadership by coercion would not produce the results we see. Weinberg quotes the autobiography of the 19th-century Russian anarchist Pyotr Alexeyvich Kropotkin's Memoirs of a Revolutionist to good effect on this subject:Having been brought up in a serf-owner's family, I entered active life, like all young men of my time, with a great deal of confidence in the necessity of commanding, ordering, scolding, punishing and the like. But when, at an early stage, I had to manage serious enterprises and to deal with [free] men, and when each mistake would lead at once to heavy consequences, I began to appreciate the difference between acting on the principle of command and discipline and acting on the principle of common understanding. The former works admirably in a military parade, but it is worth nothing where real life is concerned, and the aim can be achieved only through the severe effort of many converging wills.The \"severe effort of many converging wills\" is precisely what a project like Linux requires\u2014and the \"principle of command\" is effectively impossible to apply among volunteers in the anarchist's paradise we call the Internet. To operate and compete effectively, hackers who want to lead collaborative projects have to learn how to recruit and energize effective communities of interest in the mode vaguely suggested by Kropotkin's \"principle of understanding\". They must learn to use Linus's Law.[SP]Earlier I referred to the \"Delphi effect\" as a possible explanation for Linus's Law. But more powerful analogies to adaptive systems in biology and economics also irresistably suggest themselves. The Linux world behaves in many respects like a free market or an ecology, a collection of selfish agents attempting to maximize utility which in the process produces a self-correcting spontaneous order more elaborate and efficient than any amount of central planning could have achieved. Here, then, is the place to seek the \"principle of understanding\".The \"utility function\" Linux hackers are maximizing is not classically economic, but is the intangible of their own ego satisfaction and reputation among other hackers. (One may call their motivation \"altruistic\", but this ignores the fact that altruism is itself a form of ego satisfaction for the altruist). Voluntary cultures that work this way are not actually uncommon; one other in which I have long participated is science fiction fandom, which unlike hackerdom has long explicitly recognized \"egoboo\" (ego-boosting, or the enhancement of one's reputation among other fans) as the basic drive behind volunteer activity.Linus, by successfully positioning himself as the gatekeeper of a project in which the development is mostly done by others, and nurturing interest in the project until it became self-sustaining, has shown an acute grasp of Kropotkin's \"principle of shared understanding\". This quasi-economic view of the Linux world enables us to see how that understanding is applied.We may view Linus's method as a way to create an efficient market in \"egoboo\"\u2014to connect the selfishness of individual hackers as firmly as possible to difficult ends that can only be achieved by sustained cooperation. With the fetchmail project I have shown (albeit on a smaller scale) that his methods can be duplicated with good results. Perhaps I have even done it a bit more consciously and systematically than he.Many people (especially those who politically distrust free markets) would expect a culture of self-directed egoists to be fragmented, territorial, wasteful, secretive, and hostile. But this expectation is clearly falsified by (to give just one example) the stunning variety, quality, and depth of Linux documentation. It is a hallowed given that programmers hate documenting; how is it, then, that Linux hackers generate so much documentation? Evidently Linux's free market in egoboo works better to produce virtuous, other-directed behavior than the massively-funded documentation shops of commercial software producers.Both the fetchmail and Linux kernel projects show that by properly rewarding the egos of many other hackers, a strong developer/coordinator can use the Internet to capture the benefits of having lots of co-developers without having a project collapse into a chaotic mess. So to Brooks's Law I counter-propose the following:I think the future of open-source software will increasingly belong to people who know how to play Linus's game, people who leave behind the cathedral and embrace the bazaar. This is not to say that individual vision and brilliance will no longer matter; rather, I think that the cutting edge of open-source software will belong to people who start from individual vision and brilliance, then amplify it through the effective construction of voluntary communities of interest.Perhaps this is not only the future of open-source software. No closed-source developer can match the pool of talent the Linux community can bring to bear on a problem. Very few could afford even to hire the more than 200 (1999: 600, 2000: 800) people who have contributed to fetchmail!Perhaps in the end the open-source culture will triumph not because cooperation is morally right or software \"hoarding\" is morally wrong (assuming you believe the latter, which neither Linus nor I do), but simply because the closed-source world cannot win an evolutionary arms race with open-source communities that can put orders of magnitude more skilled time into a problem.The original Cathedral and Bazaar paper of 1997 ended with the vision above\u2014that of happy networked hordes of programmer/anarchists outcompeting and overwhelming the hierarchical world of conventional closed software.A good many skeptics weren't convinced, however; and the questions they raise deserve a fair engagement. Most of the objections to the bazaar argument come down to the claim that its proponents have underestimated the productivity-multiplying effect of conventional management.Traditionally-minded software-development managers often object that the casualness with which project groups form and change and dissolve in the open-source world negates a significant part of the apparent advantage of numbers that the open-source community has over any single closed-source developer. They would observe that in software development it is really sustained effort over time and the degree to which customers can expect continuing investment in the product that matters, not just how many people have thrown a bone in the pot and left it to simmer.There is something to this argument, to be sure; in fact, I have developed the idea that expected future service value is the key to the economics of software production in the essay The Magic Cauldron.But this argument also has a major hidden problem; its implicit assumption that open-source development cannot deliver such sustained effort. In fact, there have been open-source projects that maintained a coherent direction and an effective maintainer community over quite long periods of time without the kinds of incentive structures or institutional controls that conventional management finds essential. The development of the GNU Emacs editor is an extreme and instructive example; it has absorbed the efforts of hundreds of contributors over 15 years into a unified architectural vision, despite high turnover and the fact that only one person (its author) has been continuously active during all that time. No closed-source editor has ever matched this longevity record.This suggests a reason for questioning the advantages of conventionally-managed software development that is independent of the rest of the arguments over cathedral vs. bazaar mode. If it's possible for GNU Emacs to express a consistent architectural vision over 15 years, or for an operating system like Linux to do the same over 8 years of rapidly changing hardware and platform technology; and if (as is indeed the case) there have been many well-architected open-source projects of more than 5 years duration\u2014then we are entitled to wonder what, if anything, the tremendous overhead of conventionally-managed development is actually buying us.Whatever it is certainly doesn't include reliable execution by deadline, or on budget, or to all features of the specification; it's a rare 'managed' project that meets even one of these goals, let alone all three. It also does not appear to be ability to adapt to changes in technology and economic context during the project lifetime, either; the open-source community has proven far more effective on that score (as one can readily verify, for example, by comparing the 30-year history of the Internet with the short half-lives of proprietary networking technologies\u2014or the cost of the 16-bit to 32-bit transition in Microsoft Windows with the nearly effortless upward migration of Linux during the same period, not only along the Intel line of development but to more than a dozen other hardware platforms, including the 64-bit Alpha as well).One thing many people think the traditional mode buys you is somebody to hold legally liable and potentially recover compensation from if the project goes wrong. But this is an illusion; most software licenses are written to disclaim even warranty of merchantability, let alone performance\u2014and cases of successful recovery for software nonperformance are vanishingly rare. Even if they were common, feeling comforted by having somebody to sue would be missing the point. You didn't want to be in a lawsuit; you wanted working software.So what is all that management overhead buying?In order to understand that, we need to understand what software development managers believe they do. A woman I know who seems to be very good at this job says software project management has five functions:Apparently worthy goals, all of these; but under the open-source model, and in its surrounding social context, they can begin to seem strangely irrelevant. We'll take them in reverse order.My friend reports that a lot of resource marshalling is basically defensive; once you have your people and machines and office space, you have to defend them from peer managers competing for the same resources, and from higher-ups trying to allocate the most efficient use of a limited pool.But open-source developers are volunteers, self-selected for both interest and ability to contribute to the projects they work on (and this remains generally true even when they are being paid a salary to hack open source.) The volunteer ethos tends to take care of the 'attack' side of resource-marshalling automatically; people bring their own resources to the table. And there is little or no need for a manager to 'play defense' in the conventional sense.Anyway, in a world of cheap PCs and fast Internet links, we find pretty consistently that the only really limiting resource is skilled attention. Open-source projects, when they founder, essentially never do so for want of machines or links or office space; they die only when the developers themselves lose interest.That being the case, it's doubly important that open-source hackers organize themselves for maximum productivity by self-selection\u2014and the social milieu selects ruthlessly for competence. My friend, familiar with both the open-source world and large closed projects, believes that open source has been successful partly because its culture only accepts the most talented 5% or so of the programming population. She spends most of her time organizing the deployment of the other 95%, and has thus observed first-hand the well-known variance of a factor of one hundred in productivity between the most able programmers and the merely competent.The size of that variance has always raised an awkward question: would individual projects, and the field as a whole, be better off without more than 50% of the least able in it? Thoughtful managers have understood for a long time that if conventional software management's only function were to convert the least able from a net loss to a marginal win, the game might not be worth the candle.The success of the open-source community sharpens this question considerably, by providing hard evidence that it is often cheaper and more effective to recruit self-selected volunteers from the Internet than it is to manage buildings full of people who would rather be doing something else.Which brings us neatly to the question of motivation. An equivalent and often-heard way to state my friend's point is that traditional development management is a necessary compensation for poorly motivated programmers who would not otherwise turn out good work.This answer usually travels with a claim that the open-source community can only be relied on only to do work that is `sexy' or technically sweet; anything else will be left undone (or done only poorly) unless it's churned out by money-motivated cubicle peons with managers cracking whips over them. I address the psychological and social reasons for being skeptical of this claim in Homesteading the Noosphere. For present purposes, however, I think it's more interesting to point out the implications of accepting it as true.If the conventional, closed-source, heavily-managed style of software development is really defended only by a sort of Maginot Line of problems conducive to boredom, then it's going to remain viable in each individual application area for only so long as nobody finds those problems really interesting and nobody else finds any way to route around them. Because the moment there is open-source competition for a 'boring' piece of software, customers are going to know that it was finally tackled by someone who chose that problem to solve because of a fascination with the problem itself\u2014which, in software as in other kinds of creative work, is a far more effective motivator than money alone.Having a conventional management structure solely in order to motivate, then, is probably good tactics but bad strategy; a short-term win, but in the longer term a surer loss.So far, conventional development management looks like a bad bet now against open source on two points (resource marshalling, organization), and like it's living on borrowed time with respect to a third (motivation). And the poor beleaguered conventional manager is not going to get any succour from the monitoring issue; the strongest argument the open-source community has is that decentralized peer review trumps all the conventional methods for trying to ensure that details don't get slipped.Can we save defining goals as a justification for the overhead of conventional software project management? Perhaps; but to do so, we'll need good reason to believe that management committees and corporate roadmaps are more successful at defining worthy and widely shared goals than the project leaders and tribal elders who fill the analogous role in the open-source world.That is on the face of it a pretty hard case to make. And it's not so much the open-source side of the balance (the longevity of Emacs, or Linus Torvalds's ability to mobilize hordes of developers with talk of \"world domination\") that makes it tough. Rather, it's the demonstrated awfulness of conventional mechanisms for defining the goals of software projects.One of the best-known folk theorems of software engineering is that 60% to 75% of conventional software projects either are never completed or are rejected by their intended users. If that range is anywhere near true (and I've never met a manager of any experience who disputes it) then more projects than not are being aimed at goals that are either (a) not realistically attainable, or (b) just plain wrong.This, more than any other problem, is the reason that in today's software engineering world the very phrase \"management committee\" is likely to send chills down the hearer's spine\u2014even (or perhaps especially) if the hearer is a manager. The days when only programmers griped about this pattern are long past; Dilbert cartoons hang over executives' desks now.Our reply, then, to the traditional software development manager, is simple\u2014if the open-source community has really underestimated the value of conventional management, why do so many of you display contempt for your own process?Once again the example of the open-source community sharpens this question considerably\u2014because we have fun doing what we do. Our creative play has been racking up technical, market-share, and mind-share successes at an astounding rate. We're proving not only that we can do better software, but that joy is an asset.Two and a half years after the first version of this essay, the most radical thought I can offer to close with is no longer a vision of an open-source\u2013dominated software world; that, after all, looks plausible to a lot of sober people in suits these days.Rather, I want to suggest what may be a wider lesson about software, (and probably about every kind of creative or professional work). Human beings generally take pleasure in a task when it falls in a sort of optimal-challenge zone; not so easy as to be boring, not too hard to achieve. A happy programmer is one who is neither underutilized nor weighed down with ill-formulated goals and stressful process friction. Enjoyment predicts efficiency.Relating to your own work process with fear and loathing (even in the displaced, ironic way suggested by hanging up Dilbert cartoons) should therefore be regarded in itself as a sign that the process has failed. Joy, humor, and playfulness are indeed assets; it was not mainly for the alliteration that I wrote of \"happy hordes\" above, and it is no mere joke that the Linux mascot is a cuddly, neotenous penguin.It may well turn out that one of the most important effects of open source's success will be to teach us that play is the most economically efficient mode of creative work.It's a strange feeling to realize you're helping make history....On January 22 1998, approximately seven months after I first published The Cathedral and the Bazaar, Netscape Communications, Inc. announced plans to give away the source for Netscape Communicator. I had had no clue this was going to happen before the day of the announcement.Eric Hahn, executive vice president and chief technology officer at Netscape, emailed me shortly afterwards as follows: \"On behalf of everyone at Netscape, I want to thank you for helping us get to this point in the first place. Your thinking and writings were fundamental inspirations to our decision.\"\"The following week I flew out to Silicon Valley at Netscape's invitation for a day-long strategy conference (on 4 Feb 1998) with some of their top executives and technical people. We designed Netscape's source-release strategy and license together.A few days later I wrote the following:Netscape is about to provide us with a large-scale, real-world test of the bazaar model in the commercial world. The open-source culture now faces a danger; if Netscape's execution doesn't work, the open-source concept may be so discredited that the commercial world won't touch it again for another decade.On the other hand, this is also a spectacular opportunity. Initial reaction to the move on Wall Street and elsewhere has been cautiously positive. We're being given a chance to prove ourselves, too. If Netscape regains substantial market share through this move, it just may set off a long-overdue revolution in the software industry.The next year should be a very instructive and interesting time.And indeed it was. As I write in mid-2000, the development of what was later named Mozilla has been only a qualified success. It achieved Netscape's original goal, which was to deny Microsoft a monopoly lock on the browser market. It has also achieved some dramatic successes (notably the release of the next-generation Gecko rendering engine).However, it has not yet garnered the massive development effort from outside Netscape that the Mozilla founders had originally hoped for. The problem here seems to be that for a long time the Mozilla distribution actually broke one of the basic rules of the bazaar model; it didn't ship with something potential contributors could easily run and see working. (Until more than a year after release, building Mozilla from source required a license for the proprietary Motif library.)Most negatively (from the point of view of the outside world) the Mozilla group didn't ship a production-quality browser for two and a half years after the project launch\u2014and in 1999 one of the project's principals caused a bit of a sensation by resigning, complaining of poor management and missed opportunities. \"Open source,\" he correctly observed, \"is not magic pixie dust.\"And indeed it is not. The long-term prognosis for Mozilla looks dramatically better now (in November 2000) than it did at the time of Jamie Zawinski's resignation letter\u2014in the last few weeks the nightly releases have finally passed the critical threshold to production usability. But Jamie was right to point out that going open will not necessarily save an existing project that suffers from ill-defined goals or spaghetti code or any of the software engineering's other chronic ills. Mozilla has managed to provide an example simultaneously of how open source can succeed and how it could fail.In the mean time, however, the open-source idea has scored successes and found backers elsewhere. Since the Netscape release we've seen a tremendous explosion of interest in the open-source development model, a trend both driven by and driving the continuing success of the Linux operating system. The trend Mozilla touched off is continuing at an accelerating rate.[JB] In Programing Pearls, the noted computer-science aphorist Jon Bentley comments on Brooks's observation with \"If you plan to throw one away, you will throw away two.\" He is almost certainly right. The point of Brooks's observation, and Bentley's, isn't merely that you should expect first attempt to be wrong, it's that starting over with the right idea is usually more effective than trying to salvage a mess. \u21a9[QR] Examples of successful open-source, bazaar development predating the Internet explosion and unrelated to the Unix and Internet traditions have existed. The development of the info-Zip compression utility during 1990\u2013x1992, primarily for DOS machines, was one such example. Another was the RBBS bulletin board system (again for DOS), which began in 1983 and developed a sufficiently strong community that there have been fairly regular releases up to the present (mid-1999) despite the huge technical advantages of Internet mail and file-sharing over local BBSs. While the info-Zip community relied to some extent on Internet mail, the RBBS developer culture was actually able to base a substantial on-line community on RBBS that was completely independent of the TCP/IP infrastructure. \u21a9[CV] That transparency and peer review are valuable for taming the complexity of OS development turns out, after all, not to be a new concept. In 1965, very early in the history of time-sharing operating systems, Corbat\u00f3 and Vyssotsky, co-designers of the Multics operating system, wroteIt is expected that the Multics system will be published when it is operating substantially... Such publication is desirable for two reasons: First, the system should withstand public scrutiny and criticism volunteered by interested readers; second, in an age of increasing complexity, it is an obligation to present and future system designers to make the inner operating system as lucid as possible so as to reveal the basic system issues. \u21a9[JH] John Hasler has suggested an interesting explanation for the fact that duplication of effort doesn't seem to be a net drag on open-source development. He proposes what I'll dub \"Hasler's Law\": the costs of duplicated work tend to scale sub-qadratically with team size\u2014that is, more slowly than the planning and management overhead that would be needed to eliminate them.This claim actually does not contradict Brooks's Law. It may be the case that total complexity overhead and vulnerability to bugs scales with the square of team size, but that the costs from duplicated work are nevertheless a special case that scales more slowly. It's not hard to develop plausible reasons for this, starting with the undoubted fact that it is much easier to agree on functional boundaries between different developers' code that will prevent duplication of effort than it is to prevent the kinds of unplanned bad interactions across the whole system that underly most bugs.The combination of Linus's Law and Hasler's Law suggests that there are actually three critical size regimes in software projects. On small projects (I would say one to at most three developers) no management structure more elaborate than picking a lead programmer is needed. And there is some intermediate range above that in which the cost of traditional management is relatively low, so its benefits from avoiding duplication of effort, bug-tracking, and pushing to see that details are not overlooked actually net out positive.Above that, however, the combination of Linus's Law and Hasler's Law suggests there is a large-project range in which the costs and problems of traditional management rise much faster than the expected cost from duplication of effort. Not the least of these costs is a structural inability to harness the many-eyeballs effect, which (as we've seen) seems to do a much better job than traditional management at making sure bugs and details are not overlooked. Thus, in the large-project case, the combination of these laws effectively drives the net payoff of traditional management to zero. \u21a9[HBS] The split between Linux's experimental and stable versions has another function related to, but distinct from, hedging risk. The split attacks another problem: the deadliness of deadlines. When programmers are held both to an immutable feature list and a fixed drop-dead date, quality goes out the window and there is likely a colossal mess in the making. I am indebted to Marco Iansiti and Alan MacCormack of the Harvard Business School for showing me me evidence that relaxing either one of these constraints can make scheduling workable.One way to do this is to fix the deadline but leave the feature list flexible, allowing features to drop off if not completed by deadline. This is essentially the strategy of the \"stable\" kernel branch; Alan Cox (the stable-kernel maintainer) puts out releases at fairly regular intervals, but makes no guarantees about when particular bugs will be fixed or what features will beback-ported from the experimental branch.The other way to do this is to set a desired feature list and deliver only when it is done. This is essentially the strategy of the \"experimental\" kernel branch. De Marco and Lister cited research showing that this scheduling policy (\"wake me up when it's done\") produces not only the highest quality but, on average, shorter delivery times than either \"realistic\" or \"aggressive\" scheduling.I have come to suspect (as of early 2000) that in earlier versions of this essay I severely underestimated the importance of the \"wake me up when it's done\" anti-deadline policy to the open-source community's productivity and quality. General experience with the rushed GNOME 1.0 release in 1999 suggests that pressure for a premature release can neutralize many of the quality benefits open source normally confers.It may well turn out to be that the process transparency of open source is one of three co-equal drivers of its quality, along with \"wake me up when it's done\" scheduling and developer self-selection. \u21a9[SU] It's tempting, and not entirely inaccurate, to see the core-plus-halo organization characteristic of open-source projects as an Internet-enabled spin on Brooks's own recommendation for solving the N-squared complexity problem, the \"surgical-team\" organization\u2014but the differences are significant. The constellation of specialist roles such as \"code librarian\" that Brooks envisioned around the team leader doesn't really exist; those roles are executed instead by generalists aided by toolsets quite a bit more powerful than those of Brooks's day. Also, the open-source culture leans heavily on strong Unix traditions of modularity, APIs, and information hiding\u2014none of which were elements of Brooks's prescription. \u21a9[RJ] The respondent who pointed out to me the effect of widely varying trace path lengths on the difficulty of characterizing a bug speculated that trace-path difficulty for multiple symptoms of the same bug varies \"exponentially\" (which I take to mean on a Gaussian or Poisson distribution, and agree seems very plausible). If it is experimentally possible to get a handle on the shape of this distribution, that would be extremely valuable data. Large departures from a flat equal-probability distribution of trace difficulty would suggest that even solo developers should emulate the bazaar strategy by bounding the time they spend on tracing a given symptom before they switch to another. Persistence may not always be a virtue... \u21a9[IN] An issue related to whether one can start projects from zero in the bazaar style is whether the bazaar style is capable of supporting truly innovative work. Some claim that, lacking strong leadership, the bazaar can only handle the cloning and improvement of ideas already present at the engineering state of the art, but is unable to push the state of the art. This argument was perhaps most infamously made by the Halloween Documents, two embarrassing internal Microsoft memoranda written about the open-source phenomenon. The authors compared Linux's development of a Unix-like operating system to \"chasing taillights\", and opined \"(once a project has achieved \"parity\" with the state-of-the-art), the level of management necessary to push towards new frontiers becomes massive.\"There are serious errors of fact implied in this argument. One is exposed when the Halloween authors themseselves later observe that \"often [...] new research ideas are first implemented and available on Linux before they are available / incorporated into other platforms.\"If we read \"open source\" for \"Linux\", we see that this is far from a new phenomenon. Historically, the open-source community did not invent Emacs or the World Wide Web or the Internet itself by chasing taillights or being massively managed\u2014and in the present, there is so much innovative work going on in open source that one is spoiled for choice. The GNOME project (to pick one of many) is pushing the state of the art in GUIs and object technology hard enough to have attracted considerable notice in the computer trade press well outside the Linux community. Other examples are legion, as a visit to Freshmeat on any given day will quickly prove.But there is a more fundamental error in the implicit assumption that the cathedral model (or the bazaar model, or any other kind of management structure) can somehow make innovation happen reliably. This is nonsense. Gangs don't have breakthrough insights\u2014even volunteer groups of bazaar anarchists are usually incapable of genuine originality, let alone corporate committees of people with a survival stake in some status quo ante. Insight comes from individuals. The most their surrounding social machinery can ever hope to do is to be responsive to breakthrough insights\u2014to nourish and reward and rigorously test them instead of squashing them.Some will characterize this as a romantic view, a reversion to outmoded lone-inventor stereotypes. Not so; I am not asserting that groups are incapable of developing breakthrough insights once they have been hatched; indeed, we learn from the peer-review process that such development groups are essential to producing a high-quality result. Rather I am pointing out that every such group development starts from\u2014is necessarily sparked by\u2014one good idea in one person's head. Cathedrals and bazaars and other social structures can catch that lightning and refine it, but they cannot make it on demand.Therefore the root problem of innovation (in software, or anywhere else) is indeed how not to squash it\u2014but, even more fundamentally, it is how to grow lots of people who can have insights in the first place.To suppose that cathedral-style development could manage this trick but the low entry barriers and process fluidity of the bazaar cannot would be absurd. If what it takes is one person with one good idea, then a social milieu in which one person can rapidly attract the cooperation of hundreds or thousands of others with that good idea is going inevitably to out-innovate any in which the person has to do a political sales job to a hierarchy before he can work on his idea without risk of getting fired.And, indeed, if we look at the history of software innovation by organizations using the cathedral model, we quickly find it is rather rare. Large corporations rely on university research for new ideas (thus the Halloween Documents authors' unease about Linux's facility at coopting that research more rapidly). Or they buy out small companies built around some innovator's brain. In neither case is the innovation native to the cathedral culture; indeed, many innovations so imported end up being quietly suffocated under the \"massive level of management\" the Halloween Documents' authors so extol.That, however, is a negative point. The reader would be better served by a positive one. I suggest, as an experiment, the following:Pick a criterion for originality that you believe you can apply consistently. If your definition is \"I know it when I see it\", that's not a problem for purposes of this test.Pick any closed-source operating system competing with Linux, and a best source for accounts of current development work on it.Watch that source and Freshmeat for one month. Every day, count the number of release announcements on Freshmeat that you consider 'original' work. Apply the same definition of 'original' to announcements for that other OS and count them.Thirty days later, total up both figures.The day I wrote this, Freshmeat carried twenty-two release announcements, of which three appear they might push state of the art in some respect, This was a slow day for Freshmeat, but I will be astonished if any reader reports as many as three likely innovations a month in any closed-source channel. \u21a9[EGCS] We now have history on a project that, in several ways, may provide a more indicative test of the bazaar premise than fetchmail; EGCS, the Experimental GNU Compiler System.This project was announced in mid-August of 1997 as a conscious attempt to apply the ideas in the early public versions of The Cathedral and the Bazaar. The project founders felt that the development of GCC, the Gnu C Compiler, had been stagnating. For about twenty months afterwards, GCC and EGCS continued as parallel products\u2014both drawing from the same Internet developer population, both starting from the same GCC source base, both using pretty much the same Unix toolsets and development environment. The projects differed only in that EGCS consciously tried to apply the bazaar tactics I have previously described, while GCC retained a more cathedral-like organization with a closed developer group and infrequent releases.This was about as close to a controlled experiment as one could ask for, and the results were dramatic. Within months, the EGCS versions had pulled substantially ahead in features; better optimization, better support for FORTRAN and C++. Many people found the EGCS development snapshots to be more reliable than the most recent stable version of GCC, and major Linux distributions began to switch to EGCS.In April of 1999, the Free Software Foundation (the official sponsors of GCC) dissolved the original GCC development group and officially handed control of the project to the the EGCS steering team. \u21a9[SP] Of course, Kropotkin's critique and Linus's Law raise some wider issues about the cybernetics of social organizations. Another folk theorem of software engineering suggests one of them; Conway's Law\u2014commonly stated as \"If you have four groups working on a compiler, you'll get a 4-pass compiler\". The original statement was more general: \"Organizations which design systems are constrained to produce designs which are copies of the communication structures of these organizations.\" We might put it more succinctly as \"The means determine the ends\", or even \"Process becomes product\".It is accordingly worth noting that in the open-source community organizational form and function match on many levels. The network is everything and everywhere: not just the Internet, but the people doing the work form a distributed, loosely coupled, peer-to-peer network that provides multiple redundancy and degrades very gracefully. In both networks, each node is important only to the extent that other nodes want to cooperate with it.The peer-to-peer part is essential to the community's astonishing productivity. The point Kropotkin was trying to make about power relationships is developed further by the 'SNAFU Principle': \"True communication is possible only between equals, because inferiors are more consistently rewarded for telling their superiors pleasant lies than for telling the truth.\" Creative teamwork utterly depends on true communication and is thus very seriously hindered by the presence of power relationships. The open-source community, effectively free of such power relationships, is teaching us by contrast how dreadfully much they cost in bugs, in lowered productivity, and in lost opportunities.Further, the SNAFU principle predicts in authoritarian organizations a progressive disconnect between decision-makers and reality, as more and more of the input to those who decide tends to become pleasant lies. The way this plays out in conventional software development is easy to see; there are strong incentives for the inferiors to hide, ignore, and minimize problems. When this process becomes product, software is a disaster. \u21a9I quoted several bits from Frederick P. Brooks's classic The Mythical Man-Month because, in many respects, his insights have yet to be improved upon. I heartily recommend the 25th Anniversary edition from Addison-Wesley (ISBN 0-201-83595-9), which adds his 1986 \"No Silver Bullet\" paper.The new edition is wrapped up by an invaluable 20-years-later retrospective in which Brooks forthrightly admits to the few judgements in the original text which have not stood the test of time. I first read the retrospective after the first public version of this essay was substantially complete, and was surprised to discover that Brooks attributed bazaar-like practices to Microsoft! (In fact, however, this attribution turned out to be mistaken. In 1998 we learned from the Halloween Documents that Microsoft's internal developer community is heavily balkanized, with the kind of general source access needed to support a bazaar not even truly possible.)Gerald M. Weinberg's The Psychology Of Computer Programming (New York, Van Nostrand Reinhold 1971) introduced the rather unfortunately-labeled concept of \"egoless programming\". While he was nowhere near the first person to realize the futility of the \"principle of command\", he was probably the first to recognize and argue the point in particular connection with software development.Richard P. Gabriel, contemplating the Unix culture of the pre-Linux era, reluctantly argued for the superiority of a primitive bazaar-like model in his 1989 paper \"LISP: Good News, Bad News, and How To Win Big\". Though dated in some respects, this essay is still rightly celebrated among LISP fans (including me). A correspondent reminded me that the section titled \"Worse Is Better\" reads almost as an anticipation of Linux. The paper is accessible on the World Wide Web at http://www.naggum.no/worse-is-better.html.De Marco and Lister's Peopleware: Productive Projects and Teams (New York; Dorset House, 1987; ISBN 0-932633-05-6) is an underappreciated gem which I was delighted to see Fred Brooks cite in his retrospective. While little of what the authors have to say is directly applicable to the Linux or open-source communities, the authors' insight into the conditions necessary for creative work is acute and worthwhile for anyone attempting to import some of the bazaar model's virtues into a commercial context.Finally, I must admit that I very nearly called this essay \"The Cathedral and the Agora\", the latter term being the Greek for an open market or public meeting place. The seminal \"agoric systems\" papers by Mark Miller and Eric Drexler, by describing the emergent properties of market-like computational ecologies, helped prepare me to think clearly about analogous phenomena in the open-source culture when Linux rubbed my nose in them five years later. These papers are available on the Web at http://www.agorics.com/agorpapers.html.This essay was improved by conversations with a large number of people who helped debug it. Particular thanks to Jeff Dutky <dutky@wam.umd.edu>, who suggested the \"debugging is parallelizable\" formulation, and helped develop the analysis that proceeds from it. Also to Nancy Lebovitz <nancyl@universe.digex.net> for her suggestion that I emulate Weinberg by quoting Kropotkin. Perceptive criticisms also came from Joan Eslinger <wombat@kilimanjaro.engr.sgi.com> and Marty Franz <marty@net-link.net> of the General Technics list. Glen Vandenburg <glv@vanderburg.org> pointeed out the importance of self-selection in contributor populations and suggested the fruitful idea that much development rectifies 'bugs of omission'; Daniel Upper <upper@peak.org> suggested the natural analogies for this. I'm grateful to the members of PLUG, the Philadelphia Linux User's group, for providing the first test audience for the first public version of this essay. Paula Matuszek <matusp00@mh.us.sbphrd.com> enlightened me about the practice of software management. Phil Hudson <phil.hudson@iname.com> reminded me that the social organization of the hacker culture mirrors the organization of its software, and vice-versa. John Buck <johnbuck@sea.ece.umassd.edu> pointed out that MATLAB makes an instructive parallel to Emacs. Russell Johnston <russjj@mail.com> brought me to consciousness about some of the mechanisms discussed in \"How Many Eyeballs Tame Complexity.\" Finally, Linus Torvalds's comments were helpful and his early endorsement very encouraging."}
{"prompt": "Advances in Distributed Security", "completion": "The last decade has witnessed a revolution in distributed security. Old, pessimistic proofs that security and fault tolerance were \"impossible\", based on assumptions that protocols had to be deterministic and security and fault tolerance properties had to be absolutely certain, have given way to new proofs and implementations of provable security based on the assumption of cryptography and other randomized protocols that achieving security with very high probability is sufficient. The old view \"proved\" that the integrity properties of a wide variety of services on which civilization depends, whether synchronized clocks, public directories, censorship-proof file sharing and publication, or issuing money or securities were \"impossible\" on asynchronous networks like the Internet unless we put unlimited faith in a third party to enforce many of the rules of the service. We now know how to provide such services with a high degree of integrity and availability, yet far more resilient to the possibility that any party might act in a malicious manner.As a result of these new possibilities, we are witnessing a shift in the way we view trust. The old view in computer and network security was that trust was all-or-nothing \u2013 either we must place an essentially blind faith in a third party (for example a certificate authority or an issuer of digital cash) or we must protect against a particular mode of attack completely (as, for example, encryption protects against wiretappers). The old view could not handle most real-life situations which don't fall into either of these extremes. Among knowledgeable distributed security designers, unconditionally trusted third parties are now viewed as a cheat \u2013 \"here we pray for heavenly benevolence\", analogous to the comic-strip mathematician whose proof contains the crucial step, \"here a miracle occurs\". A third party fully trusted with a security property means that property in fact remains fully insecure \u2013 it means the protocol designer has fobbed off security on somebody else rather than actually solved a security problem.The new view reiterates the desirability of complete protection against attack where it is available, but it adds protection against vast new classes of attacks, and protection of a wide variety of other desirable properties of distributed system, that are impossible to protect without at least some trust assumptions. The new trust assumptions are that participants in a critical public service are partially, usually, or more often than not trustworthy, and often only under certain conditions. The set of parties that make up a critical distributed service is never either completely trustworthy nor all malicious.Modern protocols for critical services such as public directories construct, out of all possible subsets of all participants, attack structures consisting of the worst combination of malicious parties that be tolerated, and their complement, access structures, the minimal set of parties that need to act correctly during this operation to perform the function. (Note that access structures have nothing to do with access control lists, a traditional security method that assumes a fully trusted third party and consists of a static list of persons or classes of persons and the resources or classes of resources they have access to).One particular simple example of such an attack and access structure is a threshold structure where the malicious behavior of up to t out of n participants can be tolerated. Although we will describe the protocols below in terms of threshold structures, it will usually be possible to substitute other partitions of the power set of participants into minimum access and maximum attack structures.A given property of a system has perfect security if its access structure is any participant and its attack structure is the empty set. An example of a property with perfect security is the use of a spinning neutron star called a pulsar as a clock. Its access structure is any party that can receive its natural broadcasts, and its attack structure is the empty set \u2013 given the reasonable presumption that there are no aliens out there who can and want to manipulate the very high energy outputs of pulsars in pursuit of some human ends they have learned about.Another perfect security property is that of encryption against third parties, assuming the encryption is unbreakable. However, if we take into account the receiver of a message as a possible attacker, the broader privacy property is not secure \u2013 the receiver is an attack structure of one who can compromise privacy of the entire message encrypted to him.A security property is almost perfect if its attack structure must contain T-1 out of N participants. For example, in the digital mix of Chaum[C81], for a single message, it would take collusion of N-1 out of N of the mix servers to trace a message. The untraceability property of this system has almost perfect security for a single message. On the other hand, the reliability property of the digital mix is almost perfectly insecure, since any one of the n mix servers can block a message from getting through. Often we must trade off two different properties like this. Since reliability is an error reversible by the end user and a privacy breach is not, the tradeoff made here by Chaum makes sense.Alas, for many desirable properties we cannot achieve either perfect or almost perfect security. For some properties of replicated services \u2013 for some kinds of rules they advertise as following \u2013 we can achieve almost perfect security through, for example, the use of cryptography.For any other properties, the maximum attack structure of malicious and colluding servers that can be tolerated is the set complement of the access structure. For the threshold case, this means that T, the maximum number of malicious and colluding servers that can be tolerated, is a certain fraction of the total number of servers, such as 1/3 or 1/2, of the total number of servers comprising the service, N. That is to say, if T+1 out of N of the servers jointly decide to violate the service's rules and thereby corrupt the system, they can do so. Those who wish to stick to the rules must back out of the corrupted transaction and restart the service out-of-band. For this large class of service properties where the access structure is the set complement of the attack structure, the security of a property is neither perfect or almost perfect at one extreme, nor fully depends on a single trusted party at the other extreme. We say that this class of service properties can be implemented with distributed security.Three of the properties we most often want to protect are privacy, liveness (a.k.a. availability) and integrity. For a replicated service, the main focus of this article, we focus on the security of the integrity and liveness of a single operation of a service. The goal is to create attack structures that are very highly unlikely to fail. If or when such failures of widespread collusion do occur, relying parties, i.e. parties who depend on the properties being secured, must go \"out-of-band\" and use supplementary systems to repair the system. These supplementary systems might include a wide variety of interparty integrity constraints, audits, blacklisting, and other schemes involving auditing, reputation, and/or cryptography by participants, relying parties, or third parties. These can further motivate servers to preserve the integrity and liveness of these services, and help users to recover after a (now much rarer) successful attack.Since a wide variety of trust assumptions can now be made by a security protocol and this variety can for the first time be described mathematically \u2013 as attack and access structures \u2013 these supplementary systems can focus on keeping the actual attack structures smaller than the maximally tolerated attack structure, rather than on vastly more difficult task of plugging wide-open security holes called \"trusted third parties\" with these more loosely defined or traditional supplementary institutions.A basic issue of security and fault tolerance that must be resolved is the secure determination of which order events occured in. If a contract specifies a deadline and it goes down to the wire, how can a relying party or third party adjudicator determine whether the deadline was met? The outcome itself, and its fairness, may rest on fairly deciding who came first. If Alice tries to double-spend a piece of digital cash[C82], only the recipient who checks with the bank first is entitled to its value. But if the bank servers are replicated, which of the two recipients Bob or Charles checked with the bank first? In the case of a replicated property title service[S98] we have a similar problem \u2013 if Alice transfers her title to two other owners, which new owner actually received the deed? If property is homesteaded on a first-come first-serve basis, which of two or more \"land rushers\" competing for a lucrative parcel is entitled to the land?Imagine a network where computers don't know how to keep time very well \u2013 they are always getting out of synchronization. (Alas, all you have to really think of here is the actual Internet with PCs). Such a network, called an asynchronous network, lacks an accurate and secure global clock time by which computers can determine the order in which events, which might be messages sent or instructions executed on a particular local machine, have happened. Lamport[L78] was among the first to tackle the problem of how to determine the order of events in such a network.A partial order means that we know in what order some of the elements are, but we aren't sure about some of the others, or some of the others may be equal. An example is the \"less than or equal to\" relationship among a group of integers, some of which can repeat. Some of the integers we know are less than some others, but an integer paired with itself is equal. A total order, on the other hand, is like the \"less than\" relationship among unique integers \u2013 we can always tell when one integer is less than another \u2013 there is no ambiguity left. In the case of events, a partial order means for some pairs of events we know whether one occured before another, and for some others we don't know. We use the same symbols as we would use for the analogous case of the integers, so that \"x <= y\" means \"x either occured before y or we don't know whether it occured before or after y\". In a total of events, we know for any two events which one happened first. We write \"x < y\" meaning \"x occured before y.\"Lamport's answer to the event ordering problem was to show that parties (or, we use the terms equivalently here, nodes on the network) can agree on a partial order of events based on causal relationships between these events \u2013 or at least the subset of events where we can determine that causation could occur. On a network, parties influence each other by talking to each other \u2013 in other words, by sending each other messages. Lamport used these messages as the basic building block for constructing his partial order, according to the following rules:The partial order leaves us with the need to agree on how to break ties \u2013 how to resolve the ambiguities where we can't agree which event took place first \u2013 and thus create a total order of events. We want to do so in a way that is fair, in other words, in a way that cannot be manipulated to the advantage of any particular party.An unfair way to create a total order would be to impose a certain predictable rule for breaking ties. For example, we could decide on a total order for the processes and break ties in the causal order by referring to this total order.However, such a procedure creates a bias that may, depending on the application, favor certain servers over others, and therefore allow those servers to favor certain clients over others.One way to break ties fairly is have the participants toss fair coins \u2013 in other words, generate random numbers in a way that cannot be manipulated and then assign those random numbers to events. There are several ways to toss fair coins over a network and we describe one such way below.Another way to break ties fairly is to have the participants agree to a global clock time that is more accurate than the message delays faced by those who would manipulate timing in favor of some party. This entails using a network with very predictable message lag for the clock synchronization protocol and a less predictable one for the other services. We will describe how to do this below.Certain cryptographic primitives play a crucial role in the recent breakthroughs in distributed security that we will discuss here.Oblivious transfer is an important building block of multiparty secure computations and related protocols. Rather than describing it here, we recommend this good introduction.Alice wants to prove that she can predict the stock market. But she doesn't want to actually reveal her choice to Bob or anybody else until she's actually had a chance to trade on her prediction. But after the fact, she could just read the closing price and pretend to Bob that she predicted it. How can Alice prove to Bob that she actually predicted the market? Using bit commitments.Bit commitments are ways to commit to a string of numbers or data, in such a way that if or when one later publishes the data, it cannot be forged \u2013 it must be the same as the data you earlier committed to.Alice can commit to her data using one-way functions \u2013 functions that are much harder to compute one way than another. (One-way functions are the most basic building block of cryptography). A common kind of a one-way function is a cryptographic hash function.To create a bit commitment, Alice first generates two random numbers. Then she computes the bit commitment by hashing the two random numbers and the data to be committed to. Append on of the random numbers to the end of the hash and sends it to Bob. The next day when Bob wants to examine the data, and prove that it matches the data Alice originally committed to, Alice provides the data along with the second random number. Bob can verify that it is astronomically unlikely that Alice was able to commit to one predication and then later tell Bob she predicted something else.This protocol is called \"bit commitment\" because one can commit to even an individual bit this way. If the data has enough entropy one can commit to that data simply by using a hash function and dispense with the random numbers. We will see below how with secure timestamping other parties can determine when the data was committed to.The ideal protocol would have most trustworthy third party imaginable \u2013 a diety who is on everybody's side. All the parties would send their inputs to God. God would reliably determine the results and return the outputs. God being the ultimate in confessional discretion, no party would learn anything more about the other parties' inputs than they could learn from their own inputs and the output.Network security theorists have recently solved this problem to an astonishing extent. They have developed protocols which create virtual machines between two or more parties. Multiparty secure computation allows any number of parties to share a computation, each learning only what can be inferred from their own inputs and the output of the computation. These virtual machines have the exciting property that each party's input is strongly confidential from the other parties. The program and the output are shared by the parties.For example, we could run a spreadsheet across the Internet on this virtual computer. We would agree on a set of formulas and set up the virtual computer with these formulas. Each participant would have their own input cells, which remain blank on the other participants' computers. The participants share output cell(s). Each input our own private data into our input cells. Alice could only learn only as much about the other participants' input cells as she could infer from her own inputs and the output cells.More information on this exciting breakthrough can be found in the accompanying article \"The God Protocols\". Often, as in the spreadsheet example above, the resulting protocol would be very slow. We will now discuss a special efficient kind of multiparty secure computation \u2013 threshold cryptography.Threshold cryptography has been used to help achieve Byzantine-resilient replication in Rampart, Fleet, SITRA, and several other distributed service or filesystem architectures. Threshold cryptography is an optimized special case of a more general technique called multiparty secure computationIn a threshold public-key cryptosystem there is a single key for encryption, but each party holds a key share for decryption. A threshold scheme implements the threshold case of distributed security as described above. Any T+1 key share holders are needed to jointly perform a decryption, and any N-T key share holders can collude to prevent a decryption from being performed. The parameter T can be set at any positive integer between 1 and N. Often a more general access structure, under the distributed security constraint that the access structure is the set complement of the attack structure, can be implemented as well.For some algorithms one must assume a trusted dealer to generate a private key and distribute shares; for some other algorithms a mutually confidential generation of key shares is possible. During the decryption protocol, each party processes a decryption request for a particular ciphertext and output a decryption share together with a proof of its validity. When a party obtains the ciphertext and at least T+1 valid encryption shares, it can recover the message. In the case of threshold signatures, when at least T+1 signature shares have been obtained, a valid signature can be constructed. [C01]Joe Killian introduces this problem as follows[K90]:Alice and Bob wanted to flip a fair coin, but had no physical coin to flip. Alice offered a simple way of flipping a fair coin mentally.First, you think up a random bit, then I'll think up a random bit. We'll then exclusive-or the two bits together,\" she suggested.\"But what if one of us doesn't flip a coin at random?\" Bob asked.\"It doesn't matter. As long as one of the bits is truly random, the exclusive-or of the bits should be truly random,\" Alice replied, and after a moment's reflection, Bob agreed.A short while later, Alice and Bob happened upon a book on artificial intelligence, lying abandoned by the roadside. A good citizen, Alice said, \"One of us must pick up this book and find a suitable waste receptacle.\" Bob agreed, and suggested they use their coin-flipping protocol to determine who would have to throw the book away.If the final bit is a 0, then you will pick the book up, and if it is a 1, then I will,\" said Alice. \"What is your bit?\"Bob replied, \"1.\"\"Why, so is mine,\" Alice said slyly. \"I guess this isn't your lucky day.\"Bruce Schneier[Sh96] goes on to describe what is wrong with this protocol:Needless to say, this coin-flipping protocol has a serious bug. While it is true that a truly random bit, x, exclusive-ORed with any independently distributed bit, y, will yield a truly random bit, Alice's protocol did not ensure that the two bits were distributed independently. In fact, it is not hard to verify that no mental protocol can allow can allow two infinitely powerful parties to flip a fair coin. Alice and Bob were in trouble until they received a letter from an obscure graduate student in cryptography. The information in the letter ws too theoretical to be of any earthly use to anyone, but the envelope the letter came in was extremely handy.The next time Alice and Bob wished to flip a coin, they played a modified version of the original protocol. First, Bob decided on a bit, but instead of announcing it immediately, he wrote it down on a piece of paper and placed the paper in the envelope. Next, Alice announced her bit. Finally, Alice and Bob took Bob's bit out of the envelope and computed the random bit. This bit was indeed truly random whenever at least one of them played honestly. Alice and Bob had a working protocol, the cryptographer's dream of social irrelevance was fulfilled, and they all lived happily ever after.On a computer, those \"envelopes\" are committed bits \u2013 see the protocol for bit commitment above. Also see Manuel Blum's landmark paper \"Coin Flipping By Telephone\"[B82] for more details. He subtitled the paper \"A Protocol for Solving Impossible Problems\", which was more prescient than he knew.Fair coin tosses can be used to create a fair total order of events out of a partial order of events, defined by sending and receiving times for messages, in an asynchronous distributed system. They can similarly be used to achieve atomic broadcast, and thus Byzantine agreement and replication[C01][CP02].The threshold coin-tossing system developed by Cachin, Kursawe, and Shoup [C01] solves the fair coin tossing problem by implmenting a cryptographic pseudorandom number generator (PRNG) is a distributed manner using threshold cryptography. They use their protocol to solve the Byzantine generals problem for asynchronous networks. We will describe the Byzantine generals problem and its solution on asynchronous networks further below.There are a wide variety of other cryptographic primitives and protocols, beyond the well-known symmetric and asymmetric cryptosystems, that give us security properties not otherwise in distributed systems, including and mixing and channel padding[C81] and blind signatures[C82] to combat traffice analysis.In our time, the tallest and most expensive buildings belong to some of our most important economic institutions \u2013 multinational corporations. The size and expense of our skyscrapers will provide future archaeologists an important clue that these institutions played a big role in our economy. In the high and late Middle Ages, the tallest structures in Europe were bell towers \u2013 larger and more numerous in that region than on any other continent. Chartres in the year 1169 boasted a 437 foot tower, the world\u2019s tallest. These towers, besides the churches they were built upon, were also the most expensive structures in town.Some historians claim that the size and expense of Europe\u2019s steeples and public clocks, like the size and expense of the churches they were built upon, reflected the predominant role of religion in medieval life, as opposed to business in ours. Given that the churches and cathedrals themselves were expensive, this is a plausible claim. However, the Church also played a leading role in the economy, both by its own economic activities and by its role in commercial law. The church bells and their clocks also played a major economic role.Telling time was not the only, and perhaps not even initially the main, function of church towers and their bells. An important early function of the bell tower was as an alarm, to inform the town of emergencies such as a fire or attacking army. The towers also sometimes made a good vantage point to detect such events. They tolled for events such as baptisms and funerals. Timekeeping became its primary function, first in order to call people to mass, but soon as a general service the Church provided to the surrounding Catholic community that supported it. Long before the mechanical clock, residents within a few miles of a church started working their schedules around the canonical hours \u2013 sundial-based unequal hours \u2013 tolled on its bells. Thus in many European cities, long before the invention of the mechanical clock, the local church was trusted to ring the hours. Churches, funded mainly by the nearby parishioners, but often also by the city or directly by a guild of merchants, lavished enormous resources to build, operate, and maintain the towers as well as the bells, and later for the clocks that were installed in those towers. The productive synchronization of human relationships funded the bell towers; the bell towers would provide a ready market for public clocks. Thus did in Europe emerge a \"virtuous circle\" that would advance both its timekeeping technologies and time-dependent institutions beyond those of the other continents.The time rung on the bells was mainly read from a sundial. By the 11th century these were often supplemented by water clocks. By the end of the 14th century most were using the new mechanical clock, backed up by another new technology of that century, the more reliable and personally secure sandglass.In the larger and more important belfries were present at least two bell-ringers. They lived up there full-time[D96]. This arrangement is an example of the pattern of dual control \u2013 each ringer served as a check for the other; neither could spoof the time or other bell signals without the collusion of both.The heaviest and most expensive elements of the towers were the bells. Bells smiths competed to produce the most distantly hearable ringing. The \"Maria Angola\" bell, cast in 1659 and installed in a cathedral in Cusco, Peru could be heard up to 25 miles away[G95]. In Cordova in the 16th century, a cathedral boasted a one-ton bell that could be heard 8 miles away. At the cathedral at Rouen, in 1321, a carillon was installed that played on an array of bells a hymn audible 5 miles away[D96]. The typical range of a parish church\u2019s bells was 3-5 miles. These bells would primarily be heard and in the surrounding town; larger bells could also be heard by peasants working in the fields miles away.The most valuable property of the bell tower time was not its accuracy, but its fairness. Even if it broadcast the wrong time, it broadcast the same wrong time to everybody. An employer, even if he was colluding with the Church to bias the sometimes subjective ringing of the canonical hours, couldn\u2019t tell his favorite employees that it was time to go home, while making other employees work extra, and pretend that it was the same time. (In contrast, on our computer networks such \"Byzantine\" attacks are possible, without advanced safeguards, when \"broadcasting\" time or other information).While nearby churches or monasteries provided the public, standard time, workers and employers both often employed their own timekeeping devices as a check. Peasants could tell the time by observing their own shadow against some standard sized object. In Germany and Flanders, even the smallest peasant villages had \"quadrants to indicate the hours without the sun\". Miners, working underground, followed work bells, operated by the employers, and passed their signal on through the tunnels by workers banging on tools. As a check, the miners had their own marked tallow candles[D96]. Despite the public broadcast of authoritative time, few dispensed with the option to check their own independent sources.See the accompanying article \"On Time\" for more of the fascinating history of Europe's development of clocks and accompanying economic institutions.Broadcasts using sound or radiation, from sources such as bell towers, radio towers, satellites, and pulsars, must send out the same value to every receiver. A remote beacon such as a pulsar has perfect security: the access structure is any party, and its complement, the attack structure, is the empty set. For human controlled broadcasts, the attack structure consists only of the broadcaster and the access structure is any receiver.Natural broadcasts are thus immune to the problem, described in the discussion of the Byzantine Generals problem below, of a transmitter sending different values to different receivers. Indeed, as we will see below, distributed researchers have gone to great lengths just to recreate this simple property on the Internet with logical broadcast protocols.Nature provides clocks that are oblivious to the malicious intentions of any outside parties. In the case of a remote high-energy system such as a pulsar, this means anybody. and many orders of magnitude more accurate than random delays that face attackers on the Internet. If critical Internet servers were synchronized to natural clocks in a secure and timely fashion, they would be immune to attacks that relied on uncertainties in timing. Here are some comparisons of the stability (error creep) in good natural clocks:Pulsars overtake atomic clocks in accuracy after about 4 months.The Internet with its wide and unpredictable variances in message delays makes for an extremely poor method of distributing time. Some clock synchronization protocols for an asynchronous network are described in [C??][CF94]. Unfortunately, their accuracy is limited to the same order of magnitude of uncertainty as that would face an attacker. So they don't clearly eliminate the possibility that an attacker could take advantage of the different servers hosting a critical service disagreeing on the time.Far more accurate are the distribution methods, especially radio broadcast, described in this excellent survey of timekeeping techniques.This article also contains an excellent discussion of the highly distributed system used for reaching agreement on the global standard UTC time. Over 200 centers use their own atomic clocks to update UTC time. This recalibration uses a sophisticated averaging formula that throws out extreme values. There are also 50 centers in 30 different countries that can be queried at any time during the month for the current recalibration according to their own atomic clocks. In addition, there are a variety of services that broadcast UTC time, with varying levels of delay uncertainty and cost that the article describes in detail. The security and tolerance to extreme faults of the entire system from atomic clock to delivery of time updates to relying parties is not clear but probably high. The jurisdictional diversity of the atomic clock sources is far higher than that of common delivery systems such as GPS, but the results of the latter can after the fact be easily checked against the former, keeping the latter honest, so that the resulting end-to-end system is almost universally trusted (taking into account certain well-known adjustments such as selective availability in GPS).Secure time-stamping is a way for a party with a confidential document, or two or more parties sending private messages, to commit to each other and third parties an unforgeable, non-repudiable time-stamp. This time-stamp consists of a place in a total order consisting of this message, other parties' messages, and clock ticks. This commitment is accomplished without the parties having to reveal the actual contents of those messages, unless or until challenged for proof, to any third parties. (Even then, there exist zero-knowledge proofs that allow the party to prove he has a document corresponding to the time-stamp without revealing the document).These protocols work by users sending a cryptographic hash (a.k.a. message digest) of their document to the time-tstamping servers. The servers chain messages and click ticks together by order of arrival. Replicated servers can break ambiguities in order of arrival with a protocol such as fair coin tossing to achieve a fair total order.Lamport created a theoretical structure for security and fault tolerance in a distributed service with the Byzantine generals problem. These generals might be loyal, following orders and passing them on faithfully, or they may be traitors. The worst-case behavior of traitorous generals is modelled by the nasty trick of sending out contradictory orders \u2013 for example, telling one general that the order is to march and another general that the order is to retreat.(Lamport just meant the Byzantine generals story as an interesting, cartoonish illustration of the theory of fault tolerance against corruption by malicious adverseries, but this kind of problem has actually sometimes occurred among generals. The actual generals of the Byzantine Empire were no more prone to such treachery than any of their enemies, such as the Persians or Turks. If one is partial towards the Byzantines, one can think instead of the Iraqi generals in the current war there \u2013 the Coalition generals hope that some of the Iraqi generals will defect and are trying to insert forged messages into their communications network. They hope some generals will be duped into following these specious orders).There are N generals; one of them is the commanding general or field marshall. They can send and receive messages between each other. The Byzantine generals problem is to develop a protocol for the commanding general to send messages to his N-1 subordinates so thatThe protocol should be able to resist up to T traitorous generals. In the case of a fully deterministic protocol (no random choices or cryptography allowed) the best we can do is tolerate T = floor(N/3) - 1 generals for a synchronous network. For an asynchronous and deterministic network no traitors at all can be tolerated.[FLP85]However, the Byzantine general's problem is easily solved by unjammable physical broadcast. Not coincidentally, solving the logical broadcast problem on network where physical broadcast is absent is very similar to, and as hard as, solving the Byzantine generals problem.The above pessimistic results regarding T on deterministic networks \u2013 and the inefficiency of protocols that could provide these weak solutions to the Byzantine generals problem \u2013 until recently has discouraged researchers and engineers from finding practical solutions to securing distributed services. However, under only slightly weaker assumptions \u2013 those of cryptography, that we need only achieve security with a very high probability \u2013 agreement between the Byzantine generals has not only been achieved [Ben-Or] but achieved efficiently [Cachin]. The basic insight in these solutions is that we can break ties in a Lamport partial order in a an unbiased way with random numbers.Point-to-point communications is sufficient for many applications. For many others, nodes need to send a message to many other nodes, or multicast. We call the simple case where a node sends messages to all other nodes participating in a system broadcast.As we've seen, broadcast can be implemented directly in physical media such as sound and radio. We will discuss the problem of implementing logical broadcast over an asynchronous network that directly supports only point-to-point communications. Such broadcasting protocols are subject to node and communications failures, including malicious attacks.Four important design criteria of such a logical network are reliability, consistent ordering, causality preservation, and fairness. Reliability means that a message once broadcast be received by all the functional nodes. Consistent ordering means that different messages sent by different nodes are delivered to all the nodes in the same order. Causality is preserved if this order is consistent with with the causal order in which messages were sent and received. Fairness means that no node can breach the rules or properties of the system we want to protect, particular to some parties advantage or disadvantage, by manipulating this order.Note that physical broadcasts, if they cannot be jammed, easily have these properties. Since the broadcast medium has a finite velocity, messages might not all be received in the same order as sent. However, the receiving nodes can deduce from the physical properties of the medium the expected time lag at their distance and thereby deduce sending times. We say in this case that messages are received in a certain order, queued, and then delivered in a possibly different order.The basic issue here is message delays \u2013 some servers receive messages in different order from others. Clock synchronization can reduce the scope of this problem \u2013 even eliminate it if done over a network where unpredictability in message lag times are much less than in the network over which we run the other services we wish to secure. In such cases clocks can be synchronized with sufficient accuracy that global clock time cannot be spoofed to reorder messages with significant probability. Where we choose not to implement such a global clock (because, for example, the price of retrofitting services with a radio time synchronization service as described above), we have another option for creating a fair total order \u2013 the fair coin flipping methods described above. The result is a logical broadcast with the same basic security properties as an unjammable physical broadcast.The theory of the Byzantine generals has a practical equivalent \u2013 the problem of replicating a serivce \u2013 or, equivalently, a distributed object \u2013 in such as way as to provide distributed security, or fault tolerance against arbitrary behavior of up to T malicious and colluding servers.These services or distributed objects are sometimes called \"intrusion tolerant\", because the replicated service can resist attack and corruption of up to T servers. However, in the real world more perpetrated by insiders rather than intruders. Byzantine-resilient replication of a service across administrative domains or jurisdictions solves both problems.Several Byzantine-resilient replicated service infrastructures have been implemented . They use techniques such as threshold cryptography and fair coin tossing to achieve logical broadcast on asynchronous networks like the Internet, protected against attack structures of colluding and malicious servers, such that the attack structure is the set complement of the access structure. See Appendix A below for sources of more information. A wide variety of Byzantine-resilient services can be built on top of logical broadcast. A high bandwidth, many-to-many unjammable physical broadcast network might provide similar but more efficient solutions in the future. A Byzantine-resilient replicated object library, for implementing online services with distributed trust in the CORBA distributed object system is described in this presentation and this paper.The basic system has the ability to replicate stateful objects resilient to up to 1/3 Byzantine (arbitrarily malicious) failures.In other words, object replication is used to distribute trust in the integrity of data and computations. Instead of obtaining a critical service from a single trusted server \u2013 which may be innately malicious or may get cracked by an outsider \u2013 one obtains the service from N different servers, and the service maintains its integrity as long as less than N/3 of the Vats are malicious.Note that the \"voting\" implicit in Byzantine resilient protocols like that used here protects the integrity of a particular remote method call. Between such invocations, clients can update their own blacklists of servers they have found to be unreliable. With such a blacklist the attacker must manifest their faulty behavior in over N/3 servers during the same call in order to corrupt the call. Once this is discovered the client can blacklist them, removing them from the list of trusted Vats for subsequent calls.Integrity techniques such as cryptographic hashes, digital signatures, secret sharing, and threshold cryptography can be layered on top of this basic Byzantine-resilient replication system to further increase the integrity of certain properties of the replicated state. Which of these techniques are used, and how, depends on what the critical functionality is that one is protecting.Replication of course does not distribute trust in the privacy of the data \u2013 quite the opposite, it magnifies the exposure. However, where this problem is relevant it can easily be overcome with encryption and/or multiparty secure computation, described above.A necessary part of any good distributed security toolkit is a diverse cryptographic library, implementing not only symmetric and assymetric primitives but also those described or referred to in this article.A wide variety of other applications once thought \"impossible\" to secure can now be implemented securely.On a public network a wide variety of values must be agreed upon across trust boundaries, such as mappings of names or addresses to keys (as in a public key infrastructure) or of names to addresses (as in the Domain Name System). Such agreements across trust boundaries can best be thought of as simple kinds of private property to be controlled by their owner, within constrains enforced by the rules followed by the replicated service, a public property titles system.Whether thought of as property rights or not, a wide variety of such currently centralized services can be re-implemented with much greater ensurable integrity and availability by distributing their trust with techniques such as Byzantine-resilient replication.Another large class of potential services that can be distributed are issuers of digital bearer instruments, such as digital cash.This author's design for a secure property title service uses cryptographic hash functions and digital signatures (without the need for a PKI) on top of a Byzantine-resilient replicated object service to maintain the integrity of chains of property titles. It's also suitable for property-like directories such as the Internet's Domain Name System (DNS).The old pessimism has been overturned. Old proofs of \"impossibility\", based on strict insistence in perfect certainty, have given way to new proofs demonstrating how to do the \"impossible\" by being satisfied with extremely high probability against a sophisticated but computationally bounded opponent \u2013 the assumption of cryptography \u2013 rather than of absolute certainty. This overturning of the old view has led to a raft of new possibilities for securing distributed applications. The simple protocol of the bell tower, which broadcast to every resident of a medieval town the same time, can now be implemented on a network \u2013 either through logical broadcast on the Internet or physical broadcast with radio. For the first time we can implement on the Internet the integrity properties on which civilization depends \u2013 including synchronized clocks, unforgeable transactions, and censorship-proof publishing. Where today's Internet, lacking this technology, fails to provide many of these properties, we now know how to provide them with a greater degree of integrity and availability than either the Internet or any previous media was capable of.[A01] Agilent Application Note AN 1289, \"The Science of Timekeeping\"[AMPR00] L. Alvisi, D. Malkhi, L. Pierce, and M. Reiter, \"Fault detection for Byzantine quorum systems.\"[AMPW00] L. Alvisi, D. Malkhi, L. Pierce, M. Reiter, and R. Wright, \"Dynamic Byzantine Quorum Systems\"[B83] M. Ben-Or, \"Another advantage of free choice: Completely asynchronous agreement protocols\", in Proc. 2nd ACM Symposium on Principles of Distributed Computing (PODC), 1983[B82] M. Blum, \"Coin Flipping by Telephone: A Protocol for Solving Impossible Problems\", Proceedings of the 24th IEEE Computer Conference (CompCon), 1982, pp. 133-137. \u21a9[BT85] G. Bracha and S. Toueg, \"Asynchronous consensus and broadcast protocols\", Journal of the ACM, vol. 32, pp. 824-840, Oct. 1985[CP02] C. Cachin, J. Poritz, \"Secure Intrusion-tolerant Replication on the Internet\" \u21a9[C01] C. Cachin, \"Distributing Trust on the Internet\" Conference on dependable systems and networks (DSN-2001). This is an excellent survey of the state of the art in Byzantine-resililient replication as well as presenting his own Byzantine-resilient replication system that uses fair toin cossing. \u21a9[C98] C. Cachin , \"On the foundations of oblivious transfer\", Advances in Cryptology: EUROCRYPT '98, Lecture Notes in Computer Science v. 1403, Kaisa Nyberg, ed., pp. 361-374. Springer-Verlag, 1998.[CT96] T.D. Chandra and S. Toueg, \"Unreliable failure detectors for reliable distributed systems\", Journal of the ACM, vol. 43, no. 2, pp. 225-267, 1996.[C81] \"Untraceable Electronic Mail, Return Addresses, and Digital Pseudonyms,\" D. Chaum, Communications of the ACM, vol. 24 no. 2, February, 1981. \u21a9 \u21a9[C82] \"Blind Signatures for Untraceable Payments,\" D. Chaum, Advances in Cryptology Proceedings of Crypto 82, D. Chaum, R.L. Rivest, & A.T. Sherman (Eds.), Plenum, pp. 199-203. \u21a9 \u21a9[C85] \"Online Cash Checks\", D. Chaum[CE86] \"A Secure and Privacy-Protecting Protocol for Transmitting Personal Information Between Organizations,\" D. Chaum & J.-H. Evertse, Advances in Cryptology CRYPTO '86, A.M. Odlyzko (Ed.), Springer-Verlag, pp. 118-167.[C89] \"Showing Credentials Without Identification: Signatures Transferred Between Unconditionally Unlinkable Pseudonyms,\" D. Chaum, Accepted but not Presented Auscrypt '89.[C89b] \"Privacy Protected Payments: Unconditional Payer and/or Payee Untraceability,\" D. Chaum, Smart Card 2000, D. Chaum & I. Schaumuller-Bichl (Eds.), North Holland, 1989, pp. 69-93.[CV] \"Group Signatures,\" D. Chaum & E van Heyst, Advances in Cryptology EUROCRYPT '91, D.W. Davies (Ed.), Springer-Verlag, pp. 257-265.[C97] C. Cocks. \"Split knowledge generation of RSA paremeters.\" Presented at the 6th IMA Conference on Coding and Cryptography, Cirencester, England, to appear in the proceedings, December 17\u201319, 1997.[CGT95] C. Cr\u00e9peau , J. van de Graaf , and A. Tapp , \"Committed Oblivious Transfer and Private Multi-Party Computations\"; Advances in Cryptology: Proceedings of Crypto '95, Springer-Verlag, pages 110-123, 1995.[C??] F. Cristian [et. al?] on external clock synchronization \u21a9[CF94] F. Cristian and C. Fetzer, \"Probabilistic Internal Clock Synchronization\", 13th Symposium on Reliable Distributed Systems\", 1994 \u21a9[D96] Dohrn-van Rossum, History of the Hour \u2013 Clocks and Modern Temporal Orders, University of Chicago Press, 1996. \u21a9 \u21a9 \u21a9[DA01] W. Du, M. Atallah, \"Secure Multi-Party Computation Problems and Their Applications: A Review And Open Problems\" (2001), New Security Paradigms Workshop \u21a9[FLP85] M.J. Fischer, N.A. Lynch,, and M.S. Peterson, \"Impossibility of distributed consensus with one faulty process\", Journal of the ACM, vol 32, pp. 374-382, April 1985. \u21a9[G95] Vicente Goyzueta, \"Cathedral of Qosco City\" \u21a9[HM97] M. Hirt and U. Maurer, \"Complete characterization of adversaries tolerable in secure multi-party computation\", 16th ACM PODC J. Kilian, Uses of Randomness in Algorithms and Protocols, MIT Press 1990.[ISN93] M. Ito, A. Saito and T. Nishizeki. Secret Sharing Scheme Realizing General Access Structure. J. Cryptology, 6 (1993) 15--20.[K90] J. Kilian, The Use of Randomness in Algorithms and Protocols, MIT Press 1990 \u21a9[L78] L. Lamport, \"Time, Clocks, and the Ordering of Events in a Distributed System\", Communications of the ACM 21(7):558-565, July 1978 \u21a9[L95] Susan K. Langford. \"Threshold DSS signatures without a trusted party.\" In D. Coppersmith, editor, Advances in Cryptology Crypto '95 proceedings, number 963 in LNCS, pages 397 409. Springer-Verlag, 1995. (some context online at http://citeseer.nj.nec.com/context/478327/0)[MR97] D. Maklhi & M. Reiter, \"Byzantine Quorum Systems\", also in 21st ACM STOC, 1979[MM95] L. E. Moser and P. M. Melliar-Smith, \"Total ordering algorithms for asynchronous Byzantine systems.\" In Proceedings of the 9th International Workshop on Distributed Algorithms, Springer-Verlag, September 1995.[MMA99] L. Moser, P.M. Melliar-Smith, V. Agrawala, \"Total ordering algorithms\", Proceedings of the 19th annual conference on Computer Science 1991 , San Antonio, Texas, United States, Pages: 375 - 380 Series-Proceeding-Article Year of Publication: 1999 ISBN:0-89791-382-5 ACM Press New York, NY, USA[MM99] L.E. Moser and P.M. Mellar-Smith, \"Byzantine-resistant total ordering algorithms\", Information and Computation, vol. 150, pp. 75-111, 1999.[NW96] M. Naor and A. Wool, \"Access control and signatures via quorum secret sharing\", 3rd ACM Conf. on Computer and Communications Security[MB94] M. Reiter and K. P. Birman. \"How to securely replicate services.\"\" ACM Transactions on Programming Languages and Systems, 16(3):986\u20131009, May 1994.[P91] T.P. Pedersen. \"A Threshold Cryptosystem without a Trusted Party.\"\" In Eurocrypt'91, LNCS 547, pages 522--526. Springer-Verlag, 1991.[PSL80] M. Pease, R. Shostak, and L. Lamport, \"Reaching Agreement in the Presence of Faults\", Journal of the ACM 27(2):228-234, April 1980[Rab83] M. Rabin, \"Randomized Byzantine Generals,\" Proceedings of the IEEE Symposium on the Foundations of Computer Science, pp. 403-409, IEEE, 1983[SMNTWB02] David Sames, Brian Matt, Brian Niebuhr, Gregg Tally, Brent Whitmore, and David Bakken, \"Developing a Heterogeneous Intrusion Tolerant CORBA System\", Proceedings of the 2002 International Conference on Dependable Systems & Networks, Washington, D.C., June 23-26, 2002.[Sh79] A. Shamir. \"How to share a secret.\"\" In Com. of the ACM, 22(11):612613, 1979. (online at secret.html)[Sh96] B. Schneier, Applied Cryptography, 2nd edition, John Wiley & Sons 1996 \u21a9[SG98] V. Shoup and R. Gennaro. \"Securing Threshold Cryptosystems against Chosen Ciphertext Attack\", in Eurocrypt '98, LNCS 1403, pages 1\u201316. SpringerVerlag, 1998. cf. the extended version for the Journal of Cryptology, available at http://www.shoup.net/papers/[Sh00] V. Shoup, \"Practical threshold signatures\", in Advances in Cryptology: EUROCRYPT 2000 (B. Preneel, ed.) vol. 1087 of Lecture Notes in Computer Science, pp. 207-220, Springer, 2000[S97] N. Szabo, \"Contracts With Bearer\"[S97b] N. Szabo, \"The God Protocols\"[S98] N. Szabo, \"Secure Property Titles with Owner Authority\" \u21a9[S00] N. Szabo, \"Trusted Third Parties are Security Holes\"Please send your comments to nszabo (at) law (dot) gwu (dot) eduCopyright \u00a9 2003 by Nick Szabo\nrough draft \u2013 quoting or redistribution without permission of the author prohibitedEditor's note: Some links may be broken."}
{"prompt": "Online Cash Checks", "completion": "Savings of roughly an order of magnitude in space, storage, and bandwidth over previously published online electronic cash protocols are achieved by the techniques introduced here. In addition, these techniques can increase convenience, make more efficient use of funds, and improve privacy.\"Offline\" electronic money[CFN88] is suitable for low value transactions where \"accountability after the fact\" is sufficient to deter abuse; online payment[C89], however, remains necessary for transactions that require \"prior restraint\" against persons spending beyond their available funds.Three online schemes are presented here. Each relies on the same techniques for encoding denominations in signatures and for \"devaluing\" signatures to the exact amount chosen at the time of payment. They differ in how the unspent value is returned to the payer. In the first, all change is accumulated by the payer in a single \"cookie jar,\" which might be deposited at the bank during the next withdrawal transaction. The second and third schemes allow change to be distributed among unspent notes, which can themselves later be spent. The second scheme reveals to the shop and bank the maximum amount for which a note can be spent; the third does not disclose this information.For simplicity and concreteness, but without loss of generality, a particular denomination scheme will be used here. It assigns the value of 1 cent to public exponent 3 in an RSA system, the value of 2 cents to exponent 5, 4 cents to exponent 7, and so on; each successive power-of-two value is represented by the corresponding odd prime public exponent, all with the same modulus. Much as in [C89], a third root of an image under the one-way function f (together with the pre-image modulo the bank's RSA composite) is worth 1 cent, a 7th root is worth 4 cents, and a 21st root 5 cents. In other words, a distinct public prime exponent is associated with each digit of the binary integer representation of an amount of payment; for a particular amount of payment, the product of all those prime exponents corresponding to 1 's in the binary representation of the amount is the public exponent of the signature.A signature on an image under f is \"devalued\" by raising it to the public powers corresponding to the coin values that should be removed. For instance, a note having a 21st root could be devalued from its 5 cent value, to 1 cent, simply by raising it to the 7th power.In earlier online payment systems[C89], the number of separate signatures needed for a payment was in general the Hamming weight of the binary representation of the amount. Since online systems would be used for higher-value payments (as mentioned above), and extra resolution may be desired to provide interest for unspent funds[C89], an average of roughly an order of magnitude is saved here.In this first scheme the payer periodically withdraws a supply of notes from the bank, each with the system-wide maximum value. Consider an example, shown in Figure 1.1, in which two notes are withdrawn. The n and ri are random. The ri \"blind\" (from the bank) the images under the public, one-way function f. The bank's signature corresponds to taking the h-th root, where h = 3*5*7*11. As in all the figures, the payer sends messages from the left and the bank sends from the right.In preparing the first payment, the payer divides r1 out. The signature is then raised to the 55th power to devalue it from 15 cents to 5 cents. Figure 1.2 shows this first payment. Of course the shop is an intermediary between the payer (left) and the bank (right) in every online payment, but this is not indicated explicitly. Also not shown in the figures are messages used to agree on the amounts of payment.The first two residues sent in paying, n1 and its signed image under f, are easily verified by the bank to be worth 5 cents. The third residue is a blinded \"cookie jar,\" a blinded image under f of a randomly chosen value j. This cookie jar is modulo a second RSA composite that is only used for cookie jars. Once the bank verifies the funds received, and that n1 has not been spent previously, it signs and returns the blinded cookie jar (under the cookie jar modulus) with public exponents corresponding to the change due.The second payment, shown in figure 1.3, is essentially the same as the first, except that the amount is 3 cents and the cookie jar now has some roots already on it. If more payments were to be made using the same cookie jar, all resulting signatures for change would accumulate.The cookie jar might conveniently be deposited, as shown in figure 1.4, during the withdrawal of the next batch of notes. It is verified by the bank much as a payment note would be: the roots must be present in the claimed multiplicity and the pre-image under f must not have been deposited before.The cookie jar approach gives the effect of an online form of \"offline checks\"[C89], in that notes of a fixed value are withdrawn and the unspent parts later credited to the payer during a refund transaction.Figure 2 depicts a somewhat different scheme, which allows change to be spent without an intervening withdrawal transaction. Withdrawals can be just as in the cookie-jar scheme, but here a single modulus is used for everything in the system. The products of public exponents representing the various amounts are as follows: d is the amount paid, g is the note value, the \"change\" c is g/d, and h is again the maximal amount, where d | g | h. A payment (still to the bank through a shop) includes first and second components that are the same as in the cookie-jar scheme. The third component is the amount of change c the payer claims should be returned. The fourth is a (blinded) number m, which could be an image under f used in a later payment just as n is used in this one.The signature returned contains a \"protection\" factor (shown inside the padlock). This factor ensures that the payer actually has the c-th root of f(n), by requiring that the payer apply f to it before dividing the result out of the signature. Without such protection, a payer could get the systemwide maximum change, regardless of how much change is actually due; with it, the change claimed can only be recovered if the corresponding roots on n are in fact known to the payer.The change returned in a payment can be divided into parts that fill in missing denominations in notes not yet spent. Suppose, for example, that the last payment is spent with d = 5*11, c = 3*7, and that m is formed by the payer as shown in the first line of Figure 3.1. Then unblinding after the payment yields the a shown in the second line.(Use === for \"is equivalent to\")From a, the two roots shown in the last two lines of Figure 3.2 are readily computed. (This technique is easily extended to include any number of separate roots.) Thus the values unused in the last payment fill in roots missing in notes n1 and n2.Because overpayment allows change to be returned in any chosen denominations (not shown), the payer has extra flexibility and is able to use all funds held. This also increases convenience by reducing the need for withdrawals.Although the combination of the previous two subsections is quite workable, it may be desirable for the payer not to have to reveal c to the shop or the bank. Figure 4 shows a system allowing this. The payment message is just as in the declared note value protocol above, except that c is not sent. The protection factor (shown again in a lock) is also placed under the signature, but it is missing the extra f and is raised to a random power z chosen by the bankIf z were known to the payer before payment, then the payer could cheat by including f(n) in the third component; this would yield the payer the system-wide maximum change, even if none were due. Consider a single change exponent q. If z mod q is guessed correctly by a cheating payer, then the payer improperly gets the corresponding coin value. Thus the chance of successful cheating is 1/q. If, however, the divisors of h are chosen sufficiently large, quite practical security can be achieved. When the possibilities of distributing change and refunding are included, this scheme's privacy surpasses that of a coin system.Combining online coins improves efficiency, use of funds, convenience, and privacy.Chaum, D., \"Privacy Protected Payments: Unconditional Payer and/or Payee Anonymity,\" in Smart Card 2000, North-Holland, 1989, pp. 69-92. \u21a9 \u21a9 \u21a9 \u21a9Chaum, D., A. Fiat, & M. Naor, \"Offline Electronic Cash,\" Proceedings of Crypto '88. \u21a9"}
{"prompt": "Why I Wrote PGP", "completion": "Whatever you do will be insignificant, but it is very important that you do it.It's personal. It's private. And it's no one's business but yours. You may be planning a political campaign, discussing your taxes, or having a secret romance. Or you may be communicating with a political dissident in a repressive country. Whatever it is, you don't want your private electronic mail (email) or confidential documents read by anyone else. There's nothing wrong with asserting your privacy. Privacy is as apple-pie as the Constitution.The right to privacy is spread implicitly throughout the Bill of Rights. But when the United States Constitution was framed, the Founding Fathers saw no need to explicitly spell out the right to a private conversation. That would have been silly. Two hundred years ago, all conversations were private. If someone else was within earshot, you could just go out behind the barn and have your conversation there. No one could listen in without your knowledge. The right to a private conversation was a natural right, not just in a philosophical sense, but in a law-of-physics sense, given the technology of the time.But with the coming of the information age, starting with the invention of the telephone, all that has changed. Now most of our conversations are conducted electronically. This allows our most intimate conversations to be exposed without our knowledge. Cellular phone calls may be monitored by anyone with a radio. Electronic mail, sent across the Internet, is no more secure than cellular phone calls. Email is rapidly replacing postal mail, becoming the norm for everyone, not the novelty it was in the past.Until recently, if the government wanted to violate the privacy of ordinary citizens, they had to expend a certain amount of expense and labor to intercept and steam open and read paper mail. Or they had to listen to and possibly transcribe spoken telephone conversation, at least before automatic voice recognition technology became available. This kind of labor-intensive monitoring was not practical on a large scale. It was only done in important cases when it seemed worthwhile. This is like catching one fish at a time, with a hook and line. Today, email can be routinely and automatically scanned for interesting keywords, on a vast scale, without detection. This is like driftnet fishing. And exponential growth in computer power is making the same thing possible with voice traffic.Perhaps you think your email is legitimate enough that encryption is unwarranted. If you really are a law-abiding citizen with nothing to hide, then why don't you always send your paper mail on postcards? Why not submit to drug testing on demand? Why require a warrant for police searches of your house? Are you trying to hide something? If you hide your mail inside envelopes, does that mean you must be a subversive or a drug dealer, or maybe a paranoid nut? Do law-abiding citizens have any need to encrypt their email?What if everyone believed that law-abiding citizens should use postcards for their mail? If a nonconformist tried to assert his privacy by using an envelope for his mail, it would draw suspicion. Perhaps the authorities would open his mail to see what he's hiding. Fortunately, we don't live in that kind of world, because everyone protects most of their mail with envelopes. So no one draws suspicion by asserting their privacy with an envelope. There's safety in numbers. Analogously, it would be nice if everyone routinely used encryption for all their email, innocent or not, so that no one drew suspicion by asserting their email privacy with encryption. Think of it as a form of solidarity.Senate Bill 266, a 1991 omnibus anticrime bill, had an unsettling measure buried in it. If this non-binding resolution had become real law, it would have forced manufacturers of secure communications equipment to insert special \"trap doors\" in their products, so that the government could read anyone's encrypted messages. It reads, \"It is the sense of Congress that providers of electronic communications services and manufacturers of electronic communications service equipment shall ensure that communications systems permit the government to obtain the plain text contents of voice, data, and other communications when appropriately authorized by law.\" It was this bill that led me to publish PGP electronically for free that year, shortly before the measure was defeated after vigorous protest by civil libertarians and industry groups.The 1994 Communications Assistance for Law Enforcement Act (CALEA) mandated that phone companies install remote wiretapping ports into their central office digital switches, creating a new technology infrastructure for \"point-and-click\" wiretapping, so that federal agents no longer have to go out and attach alligator clips to phone lines. Now they will be able to sit in their headquarters in Washington and listen in on your phone calls. Of course, the law still requires a court order for a wiretap. But while technology infrastructures can persist for generations, laws and policies can change overnight. Once a communications infrastructure optimized for surveillance becomes entrenched, a shift in political conditions may lead to abuse of this new-found power. Political conditions may shift with the election of a new government, or perhaps more abruptly from the bombing of a federal building.A year after the CALEA passed, the FBI disclosed plans to require the phone companies to build into their infrastructure the capacity to simultaneously wiretap 1 percent of all phone calls in all major U.S. cities. This would represent more than a thousandfold increase over previous levels in the number of phones that could be wiretapped. In previous years, there were only about a thousand court-ordered wiretaps in the United States per year, at the federal, state, and local levels combined. It's hard to see how the government could even employ enough judges to sign enough wiretap orders to wiretap 1 percent of all our phone calls, much less hire enough federal agents to sit and listen to all that traffic in real time. The only plausible way of processing that amount of traffic is a massive Orwellian application of automated voice recognition technology to sift through it all, searching for interesting keywords or searching for a particular speaker's voice. If the government doesn't find the target in the first 1 percent sample, the wiretaps can be shifted over to a different 1 percent until the target is found, or until everyone's phone line has been checked for subversive traffic. The FBI said they need this capacity to plan for the future. This plan sparked such outrage that it was defeated in Congress. But the mere fact that the FBI even asked for these broad powers is revealing of their agenda.Advances in technology will not permit the maintenance of the status quo, as far as privacy is concerned. The status quo is unstable. If we do nothing, new technologies will give the government new automatic surveillance capabilities that Stalin could never have dreamed of. The only way to hold the line on privacy in the information age is strong cryptography.You don't have to distrust the government to want to use cryptography. Your business can be wiretapped by business rivals, organized crime, or foreign governments. Several foreign governments, for example, admit to using their signals intelligence against companies from other countries to give their own corporations a competitive edge. Ironically, the United States government's restrictions on cryptography in the 1990's have weakened U.S. corporate defenses against foreign intelligence and organized crime.The government knows what a pivotal role cryptography is destined to play in the power relationship with its people. In April 1993, the Clinton administration unveiled a bold new encryption policy initiative, which had been under development at the National Security Agency (NSA) since the start of the Bush administration. The centerpiece of this initiative was a government-built encryption device, called the Clipper chip, containing a new classified NSA encryption algorithm. The government tried to encourage private industry to design it into all their secure communication products, such as secure phones, secure faxes, and so on. AT&T put Clipper into its secure voice products. The catch: At the time of manufacture, each Clipper chip is loaded with its own unique key, and the government gets to keep a copy, placed in escrow. Not to worry, though\u2014the government promises that they will use these keys to read your traffic only \"when duly authorized by law.\" Of course, to make Clipper completely effective, the next logical step would be to outlaw other forms of cryptography.The government initially claimed that using Clipper would be voluntary, that no one would be forced to use it instead of other types of cryptography. But the public reaction against the Clipper chip was strong, stronger than the government anticipated. The computer industry monolithically proclaimed its opposition to using Clipper. FBI director Louis Freeh responded to a question in a press conference in 1994 by saying that if Clipper failed to gain public support, and FBI wiretaps were shut out by non-government-controlled cryptography, his office would have no choice but to seek legislative relief. Later, in the aftermath of the Oklahoma City tragedy, Mr. Freeh testified before the Senate Judiciary Committee that public availability of strong cryptography must be curtailed by the government (although no one had suggested that cryptography was used by the bombers).The government has a track record that does not inspire confidence that they will never abuse our civil liberties. The FBI's COINTELPRO program targeted groups that opposed government policies. They spied on the antiwar movement and the civil rights movement. They wiretapped the phone of Martin Luther King. Nixon had his enemies list. Then there was the Watergate mess. More recently, Congress has either attempted to or succeeded in passing laws curtailing our civil liberties on the Internet. Some elements of the Clinton White House collected confidential FBI files on Republican civil servants, conceivably for political exploitation. And some overzealous prosecutors have shown a willingness to go to the ends of the Earth in pursuit of exposing sexual indiscretions of political enemies. At no time in the past century has public distrust of the government been so broadly distributed across the political spectrum, as it is today.Throughout the 1990s, I figured that if we want to resist this unsettling trend in the government to outlaw cryptography, one measure we can apply is to use cryptography as much as we can now while it's still legal. When use of strong cryptography becomes popular, it's harder for the government to criminalize it. Therefore, using PGP is good for preserving democracy. If privacy is outlawed, only outlaws will have privacy.It appears that the deployment of PGP must have worked, along with years of steady public outcry and industry pressure to relax the export controls. In the closing months of 1999, the Clinton administration announced a radical shift in export policy for crypto technology. They essentially threw out the whole export control regime. Now, we are finally able to export strong cryptography, with no upper limits on strength. It has been a long struggle, but we have finally won, at least on the export control front in the US. Now we must continue our efforts to deploy strong crypto, to blunt the effects increasing surveillance efforts on the Internet by various governments. And we still need to entrench our right to use it domestically over the objections of the FBI.PGP empowers people to take their privacy into their own hands. There has been a growing social need for it. That's why I wrote it.Philip R. Zimmermann\nBoulder, Colorado\nJune 1991 (updated 1999)"}
{"prompt": "Measuring Value", "completion": "A crucial issue in transaction costs economicsAn acquaintance does you a favor. How can you pay her back and deepen the relationship? An investor examines the balance sheet of a company. What do the numbers mean? Are they even trustworthy? A judge must decide on an award for damages done to a plaintiff. What amount of money, if any, fairly compensates for the plaintiff's suffering?A wide variety of human relationships and institutions, from the most friendly to the most antagonistic, must tackle the thorny problem of value: how can we securely distinguish, using the inputs of our fallible senses, that which we value from that which we do not? How can we figure out what another person values? Money, wage labor, markets, and many other economic institutions take the forms they do primarily because they solve problems of measuring value. Such questions also lie at the heart of the current crisis in accounting.Questions of value are inherently subjective and personal. Value is very different from the objective phenomena of physics, chemistry, and the like. Societies have evolved institutions such as firms and competitive markets to set prices, legal precedents and judicial proceedings to make judgments, and so forth. These institutions in turn often rely on answering the second question, the topic of our essay \u2013 how can we securely determine value from what we observe? We will examine tax collection as an antagonistic instance of the measurement problem. The last section of this essay will focus on a particular institution developed to measure value \u2013 accounting \u2013 and suggest how it might rise to challenge the radical changes underway in our services and information economies.In the nineteenth century economists developed a theory of perfectly competitive commodity markets (often now called the \"neoclassical model\"). This is the source of supply and demand curves, for example. In the ideal market, supply balances demand resulting in a price that incorporates all the relevant skills and preferences of the market's participants. In such a market, this balance between skills needed to create a commodity and the preferences for that commodity constitute the value of that commodity \u2013 we can measure value by the equilibrium market price. Some modern markets, especially well known ones such as the commodity futures markets, approach this ideal in practice. However, many other institutions, such as the hierarchical firm, operate in very different ways. And modern markets are mostly quite recent in origin. Even today most human economic relationships, such as those that occur within a firm, are far from this ideal.In the competitive market, one commodity is traded for another. (Money is just a particularly interesting kind of commodity). In order for this market to work \u2013 in order for prices to accurately communicate value \u2013 first the participants must be able to measure the value of the two commodities traded. Indeed, that's the main property that distinguishes a commodity from a less economically tractable good or service \u2013 the ability of parties to measure its value \u2013 the ability of parties to observe properties of a good or service, matching what they observe against their private preferences, and making sure this process isn't spoofed by wily traders.The competitive market model was so successful that modern economists are now approaching other economic institutions that we take for granted \u2013 such as the firm \u2013 and asking why they exist at all! They are working backwards from a very clear theory of competitive markets to explain the wide variety of other kinds of economic relationships, usually formalized by property rights and contracts, that we enter into. This school is most widely known as the \"transaction cost\" school of economics. Often it is referred to as \"new institutional\", or \"property rights school.\" The idea of transaction costs was developed by Nobel prize winning economist Ronald Coase. His brilliant heirs include Oliver Hart and Oliver Williamson, along with Steve Cheung, Yoram Barzel, Armen Alchian, Harold Demsetz, Janet Landa, Robert Ellickson, and many others.By comparing a wide variety of contractual forms to the ideal commodity market, and by re-using many of the same assumptions used by neoclassical economists \u2013 individuals with rational self-interest, unique preferences, and unique skills \u2013 we are better understanding these other economic institutions. Modern economies contain a wide variety of commercial institutions, from hierarchically commanded firms on the one hand to freely competitive commodity markets on the other. In between are a wide variety of institutions and the contracts that formalize them.When somebody starts a new company rather than hiring on as an employee at a current one, we can think of this decision as a \"vote\" that the economy needs more market relationships and less employee-employer relationships. Contrariwise, when one firm buys out another, they are implicitly betting that the economy needs less market and more firm. Socialists, seeing the trends of integration and economies of scale in industrial capitalism, thought the world would end up as one big firm, and decided this firm should be run by the government. That worked out horribly. Others have idealized a world in which there are no firms \u2013 everybody is a private contractor, selling their services to other individuals. In many industries that's a non-starter as well. Oliver Williamson and other economists have studied many of these forms and come up with some criteria that make competitive commodity markets less than perfect, causing other contractual forms to be used. (Here \"contractual form\" is shorthand for a certain kind business relationship \u2013 employment, franchising, commodity exchange, etc. The contract used by the parties is usually the most formal and complete description of their relationship, as well as the \"security protocol\" that defines the basic rules of the relationship).These economists have identified a number of limitations of ideal commodity exchange that often cause other contractual forms to be used instead. These include:Security costs. Other kinds of transaction costs are incurred from parties that are opportunistic \u2013 they are self-interested, but they follow the letter if not necessarily the spirit of the rules of a relationship (whether these rules are legal, contractual, or informal). Security costs are incurred from, or to protect a relationship against, parties that are outright malicious \u2013 they might break any of the rules, use threats of force, or actually carry out acts of trespass, theft, or violence, in order to satisfy their (alas, not so rare) coercive kinds of preferences.Rule incompleteness \u2013 the difficulty for parties to anticipate all contingencies that might occur in a relationship, and thus the inability to plan for them with rules (for example, by terms in a contract). Most disputes that go to court, and most interesting new legal precedents, occur over situations that the parties entering into a relationship didn't foresee well enough to deal with up front.Exit costs and/or investments that are specific to a particular relationship. For example, when you take a class to learn how to use Windows or Word, you are investing in a relationship with Microsoft. Another example is when a railroad is built to a coal mine \u2013 the railroad now depends on the mine for business, and the mine operator depends on the railroad to ship his coal. A third example is the layout on a factory floor, where the results of one machine's operation feed into another specific machine. The most common examples are employees developing relationships and learning skills that are specific to a particular job. In these kinds relationships with high investments or exit costs, without good contractual safeguards you can end up stuck in a bad relationship \u2013 even if it goes sour, the other guy cheats on you, it may be too expensive to exit the relationship, or you may lose your investment.When there is both lack of ability to specify rules and relationship specific investments, the result is often vertical integration into a single firm. The coal mine might buy the railroad, the machine operations occur on a factory floor owned by a single company, and so on. On the other hand, a firm has diseconomies of scale due to the increasing inability to match preferences to skills in larger firms. As Friedrich Hayek pointed out, diseconomies of scale in the distribution of knowledge about skills and preferences are a big reason why socialism works so much more poorly than market economies. More generally, these diseconomies limit firm size. Certain innovations (such as in accounting at the beginning of the industrial revolution, or in supply chain management in the last two decades) have improved the reliable distribution of knowledge within a firm and thereby allowed firms to grow larger.Innovations that better cover contingencies or reduce the need for relationship specific investments and exit costs can disadvantage larger firms and advantage a larger number of smaller firms. Rather than an commodity market often a contractual form intermediate between a market and a firm, such as a franchise, is used. A franchise is a long term contract that, roughly speaking, specifies many basic rules for operating a business but leaves temporary or unique problems to the discretion of the local operator.We will shortly turn to perhaps the most important kind of transaction cost, the measurement of value, the main subject of our essay.Before we do that, however, let us note that these kinds of transaction costs, while first studied in the context of markets, are not confined to markets or even market-embedded institutions. They occur any time a good is transferred or a service rendered according to a set of rules or customs, however simple or complicated. Not only do these transaction costs provide a basis for comparing non-market or extra-market institutions such as the firm to the market; they also apply to a wide variety of other institutions, including many we may not typically think of as economic institutions. So, for example, the ancient institutions of inheritance, marriage, tribute, tax collection, and tort law all involved an important component of wealth transfer. All are subject to the main kinds of transaction costs outlined here \u2013 including that of our main topic.The measurement problem is very broad. It comes into play in any system of exchange \u2013 reciprocation of favors, barter, money, credit, employment, or purchase in a market. It is important in extortion, taxation, tribute, and the setting of judicial penalties. It is even important in reciprocal altruism in animals. Consider monkeys exchanging favors \u2013 say pieces of fruit for back scratches. Mutual grooming can remove ticks and fleas that an individual can't see or reach. But just how much grooming versus how many pieces of fruit constitutes a reciprocation that both sides will consider to be \"fair\", or in other words not a defection? Is twenty minutes of back-scratching worth one piece of fruit or two? And how big a piece? And just how long is twenty minutes anyway? In some cases this is relatively easy to solve, as with the delayed barter of blood for blood in vampire bats. These bats can come home from a hunting mission either overstuffed or starving. Overstuffed bats can regurgitate blood to feed hungry ones. The grateful recipient can remember the favor an return it in a future hunting trip when the tables might be turned. And indeed, some degree of reciprocal trade takes place between vampire bats, even among non-kin.Even this simple case of trading blood for blood, is, however, far more complicated then it seems. Just how do the bats estimate the value of blood they have received? Do they estimate the value of a favor by weight, by bulk, by taste, by its ability to satiate hunger, or other variables? Just the same, measurement complications arise even in the simple monkey exchange of \"you scratch my back and I'll scratch yours\".For the vast majority of potential exchanges, the measurement problem is intractable for animals. Even more than the easier problem of remembering faces and matching them to favors, the ability of both parties to agree with sufficient accuracy on an estimate of the value of a favor in the first place is probably the main barrier to reciprocal altruism among animals.It is also likely the most important barrier to exchange among humans. Many kinds of exchange, probably many more than most economists perceive, are rendered infeasible by the inability of one or both parties to the exchange to estimate its value. For most of human history, most kinds of markets that are possible today were not then feasible, in large part due to the inability of potential market participants to measure value: to estimate the value of the transaction to themselves and then use these estimates to discover and agree on a common objective measurement. Measurement of value was and is also important to the development of many economic institutions related to markets. Accounting, which we will examine below, was crucial to the development of large companies and modern systems of taxation.The process of determining the value of a product from observations is necessarily incomplete and costly. For example, a shopper can see that an apple is shiny red. This has some correlation to its tastiness (the quality a typical shopper actually wants from an apple), but it's hardly perfect. The apple's appearance is not a complete indicator \u2013 an apple sometimes has a rotten spot down inside even if the surface is perfectly shiny and red. We call an indirect measure of value \u2013 for example the shininess, redness, or weight of the apple \u2013 a proxy measure. In fact, all measures of value, besides prices in an ideal market, are proxy measures \u2013 real value is subjective and largely tacit.Such observations also come at a cost. It may take some time to sort through apples to find the shiniest and reddest ones, and meanwhile the shopper bruises the other apples. It costs the vendor to put on a fake shiny gloss of wax, and it costs the shopper because he may be fooled by the wax, and because he has to eat wax with his apple. Sometimes these measurement costs comes about just from the imperfection of honest communication. In other cases, such as waxing the apple, the cost occurs because rationally self-interested parties play games with the observable.Measures are critical components of institutions \u2013 such as auctions, contracts, accounting systems, legal damage rules, tax rules, etc. \u2013 that align incentives between parties who, prior to participating in the institution, have incompatible incentives. We can divide the measurement problem into two components \u2013 the first, choosing the phenomena and units that will be measured, and second, measuring those attributes in a way that minimizes spoofing of the measure between parties whose incentives with respect to the value are misaligned.Cost can usually be measured far more objectively than value. As a result, the most common proxy measures are various kinds of costs. Examples include:We now look at a particularly challenging set of measurement problems \u2013 those faced by a tax collector. Taxation being the least cooperative kind of economic relationship \u2013 the incentives between the parties being the most misaligned \u2013 the measurement game played between the parties takes its most serious form.Tax collection is the most efficient department of government. Its efficiency rivals that of many private sector institutions.From the point of view of many taxpayers this is an incredible claim, given that tax collectors take money we ourselves know how to spend quite well, thank you, and often spend it on amazingly wasteful activities. And the rules by which they take it often seem quite arbitrary. Tax rules are usually complex but nevertheless fail to let us account for many events important to the earning of our incomes that differentiate us from other taxpayers.How the money gets spent is outside the scope of the claim that tax collectors are uncommonly efficient. It is the collection process itself that is the subject of that claim, and the tax collection rules. This essay will demonstrate the efficiency of tax collector's rules by two arguments:The tax collector's incentives are aligned with the other branches of their government in a task that benefits all associated with the government, namely the collection of their revenue. No organization of any type collects more revenue with fewer expenditures than tax collection agencies. Of course, they have the advantage of coercion, but they must overcome measurement problems that are often the same as other users of accounting systems, such as owners of large companies. It is not surprising, then, that tax collectors have sometimes pioneered value measurement techniques, and often have been the first to bring them into large scale use.Like other kinds of auditors, the tax collector's measurement problem is tougher than it looks. Investment manager Terry Coxon has described it well[6]. Bad measures or inaccurate measurements allow some industries to understate their income, while forcing others to pay taxes on income they haven't really earned. Coxon describes the result: the industries that are hurt tend to shrink. The industries that benefit pay fewer taxes than could be extracted. In both cases, less revenue is generated for the tax man than he might be able to get with better rules.This is an application of the Laffer curve to the fortunes of specific industries. On this curve, developed by the brilliant economist Arthur Laffer, as the tax rate increases, the amount of revenue increases, but at an increasingly slower rate than the tax rate, due to increased avoidance, evasion, and most of all disincentive to engage in the taxed activity. At a certain rate due to these reasons tax revenues are optimized. Hiking the tax rate beyond the Laffer optimum results in lower rather than higher revenues for the government. Ironically, the Laffer curve was used by advocates for lower taxes, even though it is a theory of tax collection optimum to government revenue, not a theory of tax collection optimal to social welfare or individual preference satisfaction.On a larger scale, the Laffer curve may be the most important economic law of political history. Adams[1] uses it to explain the rise and fall of empires. The most successful governments have been implicitly guided by their own incentives \u2013 both their short-term desire for revenue and their long-term success against other governments \u2013 to optimize their revenues according to the Laffer Curve. Governments that overburdened their taxpayers, such as the Soviet Union and later Roman Empire, ended up on the dust-heap of history, while governments that collected below the optimum were often conquered by their better-funded neighbors. Democratic governments may maintain high tax revenues over historical time by more peaceful means than conquering underfunded states. They are the first states in history with tax revenues so high relative to external threats that they have the luxury of spending most of the money in non-military areas. Their tax regimes have operated closer to the Laffer optimum than those of most previous kinds of governments. (Alternatively, this luxury may be made possible by the efficiency of nuclear weapons in deterring attack rather than the increased incentives of democracies to optimize to tax collection).When we apply the Laffer curve to examining the relative impact of tax rules on various industries, we conclude that the desire to optimize tax revenues causes tax collectors to want to accurately measure the income or wealth being taxed. Measuring value is crucial to determining the taxpayer's incentives to avoid or evade the tax or opt out of the taxed activity. For their part, taxpayers can and do spoof these measurements in various ways. Most tax shelter schemes, for example, are based on the taxpayer minimizing reported value while optimizing actual, private value. Tax collection involves a measurement game with unaligned incentives, similar to but even more severe than measurement games between owner and employee, investor and management, store and shopper, and plaintiff-defendant (or judge-guilty party).As with accounting rules, legal damage rules, or contractual terms, the choice of tax rules involves trading off complexity (or, more generally, the costs of measurement) for more accurate measures of value. And worst of all, as with the other rule-making problems, rule choices ultimately ground out on subjective measures of value. Thus a vast number of cases are left where the tax code is unfair or can be avoided. Since tax collectors are not mind readers, tax rules and judgments must substitute for actual subjective values its judgments of what the \u201creasonable\u201d or \u201caverage\u201d person's preferences would be in the situation. Coxon provides the following example. Imagine that we wanted to optimize the personal income tax rules to measure income as accurately as possible. We might start reasoning along these lines:... look a little closer and you find that an individual incurs costs and expenses in earning a salary. He has to pay for transportation to and from work. He may spend money on clothes he wouldn't otherwise buy and on lunches that would cost less at home. And he may have spent thousands of dollars acquiring the skills and knowledge he uses in this work.Ideal, precise rules for measuring his income would, somehow, take all these and other costs into account. The rules would deduct the cost of commuting (unless he enjoys traveling about town early in the morning and later in the afternoon). They would deduct the cost of the clothes he wouldn't otherwise pay (to the extent it exceeds the cost of the clothes he would buy anyway). They would deduct the difference between the cost of eating lunch at work and the cost of lunch at home (unless he would eat lunch out anyway). And each year these ideal rules would deduct a portion of the cost of his education (unless he didn't learn anything useful in school or had enough fun to offset the cost).Because there are limits to complexity, andbecause tax agents can't read minds, the government gives them arbitrary rules to follow: no deductions are allowed for commuting expenses, for clothing that is suitable for wearing outside of work, for lunches that aren't part of the \u201cbusiness entertainment\u201d or for the cost of acquiring the skills a job requires (although you can deduct the cost of improving your skills).The resulting rules often seem arbitrary, but they are not. They are trade-offs, often non-obvious but brilliant, between the costs of measuring more value with greater accuracy and extra revenue extracted thereby. However, the value measurement problem is hardly unique to tax collection. It is endemic when assessing damages in contract and tort law, and when devising fines punishments in administrative and criminal law. Many private sector rules found in contracts, accounting, and other institutions also have the quality that they use highly non-obvious measures of value that turn out, upon close examination, to be brilliant solutions to seemingly intractable problems of mind-reading and the unacceptable complexity of covering all cases or contingencies. Such measurement problems occur in every kind of economic system or relationship. The best solutions civilization has developed to solve them are in most institutions brilliant but highly imperfect. There is vast room for improvement, but failed large-scale experiments in attempts to improve these measures can be devastating.The Laffer curve and measurement costs can also be used to analyze the relative benefits of various tax collection schemes to government. Prior to the industrial revolution, for example, the income tax was infeasible. Most taxes were on the prices of commodities sold, or on various ad-hoc measures of wealth such as the frontage of one's house. (This measurement game resulted in the very tall and deep but narrow houses that can still be found in some European cities such as Amsterdam. The stairs are so narrow that even normal furniture has to be hauled up to the upper story and then through a window with a small crane, itself a common feature on these houses).Taxes distorted the economy of the Netherlands \u2013 quite literally. Here are some houses in Amsterdam built in the 17th and 18th centuries, and a typical narrow staircase. Furniture and other large objects must be hauled up by the small cranes seen above the top-story windows.Prior to the industrial revolution, incomes were often a very private matter. However, starting in England in the early nineteenth century, large firms grew to an increasing proportion of the economy. Broadly speaking, large firms and joint-stock companies were made possible by two phases of accounting advances. The first phase, double-entry bookkeeping, was developed for the trading banks and \"super companies\" of early fourteenth century Italy. The second phase were accounting and reporting techniques developed for the larger joint stock companies of the Netherlands and England, starting with the India companies in the seventeenth century. Accounting allowed manager-owners to keep track of employees and (in the second phase) for non-management owners to keep track of managers. These accounting techniques, along with the rise of literacy and numeracy among the workers, provided a new way for tax collectors to measure value. Once these larger companies came to handle a sufficient fraction of an jurisdiction's value of transactions, it was rational for governments to take advantage of their measurement techniques, and they did so \u2013 the result being the most lucrative tax scheme ever, the income tax.While the incentives between investors and managers of public companies are not as badly misaligned as that between tax collector and taxpayer, the incentives to play games with measurements are still quite substantial. Let's now look at the challenges that investors, playing an accounting game with management, face as we move beyond the industrial era.Intangible assets \u2013 in the form of trade secrets, intellectual property, brands, human resources, and so on \u2013 have become more valuable than tangible assets to many of today's businesses. In business in general, and accounting in particular, it is common to use cost as a proxy measure for value. Indeed, while the actual economic value of an asset is the discounted value of expected future cash flows, most assets are assigned a value based on their costs rather than their expected future cash flow stream.This usually works because (a) costs are usually based on verifiable events which can be signed off on and audited, whereas predictions of cash flow are mere speculations about the future, (b) under most conditions we expect that managers have acted rationally, expending money only where they expect, on average, an eventual greater return, and (c) skilled readers of financial statements have learned from experience what games can be played by managers (because their incentives differ from other stakeholders), and to detect signs that managers have acted irrationally (e.g. over or under investment in particular assets).Thus, accounting numbers for tangible assets have never been take too literally or in isolation by skilled readers of financial statements. Indeed, the seeming concreteness of tangibles can be quite misleading. A skilled reader knows that most accounting numbers represent costs not value, and apply their knowledge of the industry to determine for themselves how well value may actually be estimated by these costs. For example, a naive reader will take current assets at face value, whereas a skilled reader will look for conditions such as abnormal growth of inventory or receivables. The actual function of a financial statement is to provide clues for analysts based on well-verified facts, not to provide pat final answers for those seeking to evaluate a company.Some objections to including intangibles on the balance sheet are invalid. For example, it is argued that internally generated intangibles cannot be valued because they have not been purchased on the market. However, this is also often the case for unique industrial investments and inventories. We have developed methods such as specific identification to value internally generated assets, and these could be applied to internally generated intangibles as well. Allocation of costs common to several intangible assets (e.g. a software library used in two different software products) can be based on long experience allocating costs common to multiple tangible assets.Another more valid objection is that the actual value, in expected cash flow, of intangibles is far more uncertain than for most physical assets. Thus, the mapping from cost to value is far more uncertain. This mapping can be done with greater certainty only over an aggregate of diverse investments. However, there are certain kinds of physical assets whose value is also highly uncertain, yet are assigned a value based on costs. Rational managers discounted their original investments to take into account such risks. The same is true for intangible assets. Skilled readers of financial statements know when to expect high uncertainty. Often they will demand further details from management about the specific investments. Providing greater detail where intangibles are involved is highly advisable, a point I return to below.On the other hand, many proposed measures of intangible value are non-starters for the purposes of accounting or financial statements. For example, various measures have been put forth allegedly related to expected cash flows (e.g. measuring web site hits, customer retention rates, etc. to try to estimate the value of a brand). The only time expected value rather than cost is used on a balance sheet for tangibles is when the asset can be currently priced on an efficient, competitive, and public market. (For example, inventories of publically traded commodities can be valued in this manner). Otherwise, it is far better to use cost, the actual event of expenditure, and let the skilled readers of the financial statement interpret these numbers properly.Here are some specific comments and proposals for specific kinds of intangible assets:A company owns these legal rights in all developed and most undeveloped economies. Copyrights are very well defined but in some cases very difficult for the company or the state to actually control. Patents can be very ill defined, so that the occurrence of a loss of rights over the actual technology is unclear. However, presumably managers discount their original investments to take into account such risks. Thus, if costs can be allocated to particular patents and copyrights, they constitute a proxy measure for the value of patented and copyrighted assets. This is quite similar to using the cost of a physical asset, whose eventual cash flow value is highly uncertain, to value that asset, and allowing the skilled reader to interpret the resulting number properly.A company owns legal rights to its trademark in all developed and most undeveloped economies. Companies further have some control over perception in people's minds, insofar as their observable actions influence this perception. Some major brands names have shown a very persistent value, while lesser ones are more likely to be forgotten. One can map current accounting treatments for investment in, maintenance of, and depreciation of physical assets to investment in and maintance of a brand, as well as the tendency of customers to forget over time a brand that is not maintained.Employees are not owned, but the labor market is not perfectly fungible. There is some stickiness to it. Indeed, this stickiness can be measured by the turnover rate for the company. The turnover rate, a quite auditable number, may provide an excellent way to depreciate an asset defined by the costs of hiring and training.Until long experience is gained by stakeholders with particular kinds of intangible investments, the ability to judge whether costs are rational, and satisfy the interests of stakeholders besides management, will be poor. A wide variety of reporting experiments, most of which will fail, are nevertheless essential to achieving more accurate reporting of asset values to stakeholders. Interpretation of intangible-heavy financial statements is a job for skilled analysts, not casual readers. For the expert more information is better \u2013 the detailed records of expenditures and their allocation to intangible assets are more important to the skilled stakeholder than the summary totals. Such detailed records should be released to stakeholders despite objections about confidentiality. Only long experience with these details will teach stakeholders whether and how to judge summary totals involving intangibles.The measurement of value is one of the most intractable problems of civilization. Brilliant and highly non-obvious solutions to this problem \u2013 from markets to money to the time-wage to cost accounting \u2013 have constituted some of the most important steps from animal to civilization. Historically, the solutions to one value measurement problem (e.g., accounting for value in a large firm) made possible other institutions as well (e.g. income tax, which must first solve the same kind of problem in order to be Laffer competitive with other kinds of taxation). Intangible asset accounting may now be the most important value measurement problem we face as we move beyond the era where tangible industrial commodities dominated the economy.(under construction)Adams, Charles, For Good and Evil: The Impact of Taxes on Civilization \u21a9Barzel, Yoram, 1982. \"Measurement Cost and the Organization of Markets\", Journal of Law and Economics 25, no 1:27-48Cheung, Steven N.S., 1969. A Theory of Share Tenancy. University of Chicago Press.Cheung, Steven N.S., 1983. \"The Contractual Nature of the Firm\", Journal of Law and Economics 2, no 1:1-22Coase, R.H., 1937, \"The Nature of the Firm\", Economica 4, no. 3:386-405Coase, R.H., 1988 The Firm, the Market and the Law, University of Chicago Press 1988 \u21a9Coxon, T., 1996 Keep What You Earn, Times Business/Random HouseHayek, F., \"The Use of Knowledge in Society\"Williamson, Oliver, The Economic Institutions of Capitalism, Free Press 1985"}
{"prompt": "Financial Cryptography in 7 Layers", "completion": "Abstract: Financial Cryptography is substantially complex, requiring skills drawn from diverse and incompatible, or at least, unfriendly, disciplines. Caught between Central Banking and Cryptography, or between accountants and programmers, there is a grave danger that efforts to construct Financial Cryptography systems will simplify or omit critical disciplines.This paper presents a model that seeks to encompass the breadth of Financial Cryptography (at the clear expense of the depth of each area). By placing each discipline into a seven layer model of introductory nature, where the relationship between each adjacent layer is clear, this model should assist project, managerial and requirements people.Whilst this model is presented as efficacious, there are limits to any model. This one does not propose a methodology for design, nor a checklist for protocols. Further, given the young heritage of the model, and of the field itself, it should be taken as a hint of complexity rather than a defining guide.Financial Cryptography is substantially complex[3]. For a field that is nominally only half a decade old, by some viewpoints, it is apparent from the implementation work that has been done that many more aspects were involved than envisaged by early pioneers.Financial Cryptography appears to be a science, or perhaps an art, that sits at the intersection of many previously unrelated disciplines:At such a busy juncture of so many distinctive bases of knowledge, problems are bound to arise. Not only the inevitable confusion and wasted resources, but the difficulty in acquiring technical, management and marketing talent that can comfortably work in the field is an issue.As a preliminary step to the better understanding of Financial Cryptography projects, it is often of some interest to structure these disciplines into models that aid dialogue, comparisons and decision making.This paper presents one such model that attempts to describe the field in an introductory manner, as a preamble to greater learning. In this model, the terms Finance and Cryptography are stretched out in order to reveal the disciplines that might have been hidden within the name.Of course, no one model can plausibly cover the depth and breadth of a complex subject. The intent of this present model is to allow the reader to conceptualise the entire field, identifying the relationships of the disciplines, without spending too much time on the detailed nature of each component. Depth is sacrificed for breadth.This paper introduces a 7 layer model, akin to the Open Systems Interconnect Reference Model of networking fame, as shown in Figure 1[5][6]. In this model, Finance and Cryptography are stretched out, revealing five more areas of interest.An advantage of this model is traversal from the technical to the application, giving major stakeholders easy points of entry.We can start at the top, the Finance layer, and work top-down; this is a process of mapping requirements and following them down into lower layers. This might be the place to start if engaged in high-level application discussions.Or, we can start at the bottom, the Cryptography layer, and describe tool kits to offer the higher layers. From ever more sophisticated lower layers, we can build our way up to offering a smorgasboard of options to the all-encompassing financial applications layer.Here, we choose a descriptive presentation that traverses bottom-to-top. Later, an example is presented in the reverse order, top-to-bottom.At the bottom is Cryptography[7]. To some extent, the pure science domain of cryptography solves problems in a mathematical sense only, but it delivers useful properties, including:Cryptography also can solve special problems, when correctly formulated[8]. For example, how can Alice sign a statement of Bob's without being aware of the contents of the statement[9]?It takes Software Engineering, layer 2, to usefully benefit from the properties of cryptography. We draw from database theory (atomicity, transactional integrity and recovery) and networking theory (feedback and idempotency) in order to add such properties as reliability and robustness in the face of network and nodal unreliability, or, designed unavailability such as smart cards and handhelds[10][11].Software engineering provides us with a practical network. We can talk about sending a message across an open network and know that a message will eventually get to the addressee. With the integrity techniques of the previous layer, we can know that the information received by the addressee is as intended by the addressor. By using the specialised sequences of database theory, we can preserve the integrity of the messages over time, in the face of software and hardware failure.With both cryptography and software engineering providing a network upon which we can rely, we can think about distributing messages that are designed to Financial Cryptographic purposes[12]. In the Rights layer, we are looking for a protocol that provides a user with control over assets, in an unequivocable, determinable fashion[13]. Techniques aimed at achieving this include:although this is not an exclusive list[19][20].The previous layers provide methods reliable enough to be used for passing something of value, which we call rights, over an otherwise unsuitable network. Now, we need the techniques of Accounting in order to store and manage rights over time, To financial cryptographers, accounting is a mundane field, and it has perhaps been attractive to ignore it, but experience shows that systems without conventional accounting features tend to lose the value entrusted to them.The techniques of the accounting discipline include double-entry bookkeeping, balance sheets, and the accounting equation[21]. Accounting concepts permit builders of Financial Cryptography systems to build complex systems that guarantee not to lose value as long as everyone follows the rules; and to efficiently identify where the rules are not followed.The above layer, Rights, defines what needs to be accounted for. As an example, the most basic method would be token money. An accounting model based on tokens or coins would need a simple store of coins for the client. The server would be more complex, requiring an account for unissued value, a float account, and a double spend database that matches the float amount[22].Once there is a guarantee that the digital amounts \u2013 the accounting numbers \u2013 under management can be securely passed over the net, and stored on nodes safely, we need to cast our view wider to threats outside the technical domain[23].In any working technology, whether it be trading or cash purchasing, the threat of theft or abuse exists from parties who are trusted to manage the system. This problem, known as the agency problem, can be overcome with a wide variety of techniques that here I will label governance[24].Governance includes these techniques:As technologists, we strive to make the protocols that we build as secure and self-sustaining as possible; our art is expressed in pushing problem resolution into the lower layers. This is an ideal, however, to which we can only aspire; there will always be some value somewhere that must be protected by non-protocol means.Our task is made easier if we recognise the existance of this gap in the technological armoury, and seek to fill it with the tools of Governance. The design of a system is often ultimately expressed in a compromise between Governance and the lower layers: what we can do in the lower layers, we do; and what we cannot is cleaned up in Governance[31].With a system that provides internal and external stability and security, we are now in a position to assign value to the structure. By value, we mean the unit of account, the meaning of that unit, and the range of numbers that are applicable.For example, a Value layer might ascribe any one of the following to the virginal numbers of lower layers:As the software is somewhat unconcerned about this decision, we could just as easily used the software for any other value \u2013 but the business needs to harmonise the security and cost implications.We might also call this the Contract layer, as any value in electronic form is an agreement between the holder and the owner[35]. It is here that we design the contract that formalises the agreement between an Issuer and a user.Finally, on top of the value layer, which provides a structure for financial transactions, we can build our application. As we are concerned with Financial Cryptography, it is convenient to call this last layer the Finance layer. Here, we build an application that adds financial meaning to our designs.In the Finance layer, we construct any and all applications that might readily be useful to users. For example,And many more.In order to see the model in its descriptive role, I present an example, starting from the Finance layer and working down, by following the roadmap of requirements.In practice, the model is not a design methodology for setting and mapping requirements, but can be used to reverse-engineer an existing design, for the purposes of presentation and discussion of the mutually agreed contract between the builders and the stakeholders. The following description reflects such a process.Systemics, a company specialising in Financial Cryptography, built a system to trade financial securities[41]. The Ricardo system, as an application, required clients and servers to maintain securities, and they communicated using a value system suitable to manage securities and cash[42].As trials evolved into experience, and strategic analysis of the securities industry evolved into appreciation, if not wisdom, the following primary requirements were built up.These led to many subsidiary requirements:The following discussion concentrates on the value architecture of the Ricardo system built by Systemics, rather than the trading aspects. However, experience shows that trading becomes a tractable problem if the value architecture is solid.The requirements of the Finance layer result in a derivative requirement for a Value architecture, amongst other things. This Value architecture follows directly after the Finance layer, as the former defines the scope of the security requirements for the remaining layers.We developed a notion of instruments as follows:To meet many of these requirements, the notion of a contract for value was developed[43]. This document, which we call a Ricardian contract, documents an agreement between the holder of a security and the issuer of that security, and provides for the flexibility requirement by allowing many and arbitrary clauses to be included.It is both program- and user- readable, and is signed by the Issuer of the instrument as a binding agreement for any holder of units of that issue. By having a strong basis to determine the nature of the contract, in both human and program terms, we support the auditability requirement, and we can clearly identify the regime for resolution of disputes.Once set in stone with a digital signature, an identifier can be allocated, leading to efficient description in packets. Thus, this invention requires two things of lower layers \u2013 a signature form and a unique document identifier \u2013 which are addressed below.Once the Value context is defined, indicating the size and nature of instruments, we can address the Governance issues of payment systems and trading.These are substantially complex[44]. In order to preserve systems intact in the presence of active fraud in the non-technical domain, many disclosure and informational duties abound. In the Ricardo system, we address the governance layer in three main ways:Each of these is discussed below[45].In static governance, we ensure that the user has the contract, and that all concerned know that the user has the contract[46].In order to ensure that the Ricardian contract is always present and available to the user, and is continuously binding to the Issuer, we take the message digest of the document and use that message digest as the identifier of the instrument[47].Consider a message digest, for example, 9c7c9e7bb564224977aea8674623a37407b8f6ee being a large number of bits encoded in hexadecimal. The user cannot meaningfully interpret this string of apparently random information, so the software (and thus, the software engineer) is more or less forced to maintain a database that describes what the message digest represents. As the contract is readable by software, it makes a superior source of data than any other (such as an intermediate database that holds the contents) and thus we can reasonably assume, to the extent that the software can, that the user has the full contract available[48].The system will thus ensure that, to all practical intent, the user has the contract. This provides two cost savings, limiting both on-going support and the likelihood of litigation[49].Within structural governance, we consider the question of insider fraud, the theft of both digital value within the Financial Cryptography system and of any physical value that underlies the virtual value managed by the system.With any payment system, there is an ability to create new assets, or misdirect existing assets, all with no more work than a few button pushes. To address this, we use the approach of separation of concerns to address the agency problem of holding owners' assets, but protecting them from internal attack. This problem is normally handled by separating out management of day-to-day assets with the creation of assets in the system, and increasing the work required for any fraudulent transactions.The general schema that is advised to Issuers is as follows[50]. In order to limit the creation of value, for each issuance, a special account is designated as the mint, or the creator of value. This account is placed in the hands of a reliable professional source such as an accountant or lawyer, who will hopefully only have an interest in using the account under the probity of the governance regime.Then, a manager account is designated that receives any new float from the mint, and also returns any redemptions.It thus becomes the Issuer's responsibility to ensure that the mint account is rarely used, and then with full authorisation and wide scrutiny. Meanwhile, the manager's account is regularly used, but holds only limited amounts of value for day to day requirements.The above are general techniques that are supported within the Ricardo system, but are as applicable elsewhere. Certain features get specific support, such as value caps on accounts and target account limitatons.Note how these protection techniques that we use are partly outside the domain of the technical system. Rather than being outside scope, their discussion here is simply a reflection of the claims that the total security of the system is a holistic issue, and governance is the layer where we solve the security challenges that remain after we have attempted to solve as many as possible in the lower layers.Finally, in dynamic governance, we provide for monitoring of key values by the user community, and thus share the auditing burden. These values can be audited in an issued currency within the Ricardo system:It is also worth noting that when a currency is reserved by an underlying asset (for example, if a gold-denominated currency had physical metal escrowed to reserve it) then the above governance features should be mirrored for the reserves.That is, to continue the example of gold, there should be separate parties responsible for the ingress and egress of metal into storage, and there should be independent verification of the number of bars currently placed in escrow.In order to meet the conflicting objectives of privacy and flexibility, Ricardo uses a conventional accounting model with some additional features:Because of the top level requirement for cheapness, the accounting model was designed for complete reliability, right up to the support desk level. It does this by employing a group of non-obvious techniques:Using these techniques, the accounting model supports the Finance level requirement of being cheap to operate. If the client software is missing something, then it is a bug, and it properly belongs with the software developer, rather than being covered up as an Issuer help desk problem.In order to ensure that owners maintain rights to assets that are managed on the servers, the SOX protocol provides these three major features[56]:Each user creates key(s) which are registered with the server. These keys are as determined by Cryptography layer, below, and are required to provide a unique identifier.Value transfer is via three components:A key can be used to sign a payment order. This payment order can be directed to a target account, or be open (bearer), and it has a fixed amount of some determined type of value[57].In this sense, the payment is analogous to a cheque. It differs from chequing systems in that the SOX payment has no value until settled, whereas a cheque is expected to have value on signing[58].A payment order can be deposited to a sub-account. Settlement depends on a number of checks, such as funds in the source sub-account, and a valid payment order signature from the source key.The Issuer server returns the receipt, mentioned in the above Accounting layer.Finally, in order to cope with network failure, the SOX protocol includes a mail feature, that allows the server to communicate reliably with the client. Packets that must be delivered to the client are placed in the mailbox, and returned on every mail request. Each piece of mail must be signed for, and if not signed for, is simply returned again.In the context of the value transfer above, there is only one piece of mail, being the receipt.SOX is a flexible protocol. By replacing the deposit request, above, with trading requests, it can be used for market trades as well as settlements[59].In the trading context, requests that are implemented emulate standard market functions such as looking at the order book for an instrument, placing an order (buy or sell), monitoring the progress of an order and cancelling an order. The SOX mailbox is used for the return of orders (assets and results).SOX as a protocol spans both the Rights layer and the Software Engineering layer.In networking, every transmission must be considered as a contender for failure. As a corollary to this, relying on a connection-oriented protocol such as TCP will not guarantee reliability, as its promise is only that that the data that gets there is the correct data as sent[60].To cope with these problems, SOX asumes a datagram network only, and handles reliability itself[61].Secondly, it bases communications on a request model, with each request being independent of the next, and each request only being complete when positive feedback is received.Thirdly, SOX requests are idempotent, so they can simply be repeated until some confirmation comes back that one attempt has succeeded. Unique request identifiers are included and used to filter out retries.Fourthly, in order to implement SOX, a client must treat each request as unreliable. For example, when a payment is written by the current client, that payment is recorded as pending, which is eventually matched up with a receipt arriving from the Issuer.Or, the client gives the user the opportunity to cancel the payment simply by re-using the unique identifer, and thus stopping the lost payment ever settling. In this way, where it is impossible to guarantee a result, Ricardo extends reliability management out to include the user.Finally, SOX includes a comms layer that provides for key exchange for confidentiality and authentication purposes.The cryptography demanded by the upper layers includes:All of these algorithms are implemented as part of Cryptix, an open source project that was spun off by Systemics in 1996. Cryptography and the cryptographic techniques used in Ricardo are well discussed in the literature[62].The model works well in tackling and reducing the inherent complexities of Financial Cryptography. It does this by dividing the field into 7 areas, and providing an interconnection method (layering).Once a project is so layered, professionals within different disciplines can clearly deliniate those areas within their expertise, and those which call for other specialisations. Thus, lawyers can recognise the Governance layer as their bailiwick, and pay due attention to it. Other layers can be treated, more or less, as black boxes, interconnecting with requirements down and features up. Likewise, programmers can concentrate on Software Engineering and Rights, with more interest in Accounting than Governance.A project manager, with responsibility for delivery of a Financial Cryptography system, finds this even more powerful, as the model offers a natural checklist and vocabulary for coordinating the activity.As an analogue of the 7 layer ISO Reference Model, it also wins on easy familiarity with what we are trying to achieve.The designation of 7 layers does not, in and of itself, encourage the design or implementation of system components that fall neatly into one layer or another. The notion of a layer 3 protocol providing services to a layer 4 protocol simply does not work in practice[63].Likewise, this model is not a design methodology. The description of a top-down requirements process is illusory, and in practice, the requirements analysis is more modelled by continuing and volatile negotiations between the layers. Whilst it is descriptive to state that a requirement is bouncing up and down between layers one and five, inclusive, this does not give much assistance to a team leader in assisting a design process.It is easy to criticise any model, as by definition, a model falls short of reality. Here are some points:Does the set of layers describe Financial Cryptography accurately? Hettinga suggests, perhaps only partly in jest, the name cryptographic finance, implying that layers one to three may have greater claim to the original term[64].The 7 layer model is static rather than dynamic. Once described, it works, but how did we manage to construct it in the first place?Are there really 7 layers? Are the layers as described? About each of the different layers we can ask many questions, including some troublesome ones:My answer, today, is 'yes' to each, but only time will provide the real answer.The top-down requirements example of Ricardo seems to indicate a natural design flow or methodology, but in practice the design process does not follow that path.Experience has shown that concentration on Finance, and then Value is worthwhile. Then, the vertical flow breaks down; in particular, a lot of time is spent bouncing around the lower 4 layers in a negotiation for the best compromise, with occasional forays upwards in order to tune the requirements. Governance always seems to come last in the design process, as its contents are an admission of what the rest of the architecture has failed to cover.Layers one to four, up to Accounting, are fairly solid in terms of their disciplines, practices and methodologies. Layers five and up (Governance, Value, and Application) are less well-defined.This might represent a flaw, or it might indicate an intrinsically messy area. Perhaps coincidentally, the ISO Reference Model exhibits the same pattern.I believe that these criticisms are valuable in indicating that the model is promising, as they help to refine ideas, rather than destroy them.Ian Grigg can be reached at iang at systemics dot com. He is a founder of Systemics, Inc, a developer of Internet Financial Systems software. \u21a9This paper was presented at FC00 and is originally published in the Proceedings of Financial Cryptography Fourth International Conference, Anguilla, British West Indies, 21st - 24th February 2000. A web copy is located at http://www.iang.org/papers/.The model was initially inspired by discussions on the DBS mailing list, and was progressively refined in discussions with Twan Van Der Schoot. This paper has also benefitted from review remarks by Ian Brown, Zooko Journeyman and Rachel Willmer. \u21a9The term Financial Cryptography was invented by Robert Hettinga as a name for a conference held annually in Anguilla. \u21a9Ian Grigg, Virtual Finance Report, Digital Trading, November 1997. \u21a9Search on Google for ISO OSI Reference Model Seven Layer \u21a9It is mostly coincidence that there are 7 layers, and it may change if we find compelling reasons to add or subtract layers. \u21a9The Cryptix Resources Page lists popular cryptography books, including links for purchasing. \u21a9A large area of such problems, including the blinding property, is described in Rethinking public key infrastructures and digital certificates --- building in privacy Stefan Brands, ISBN 90-901-3059-4, 1999. \u21a9The blinding concept is most easily accessible in Achieving Electronic Privacy Scientific American David Chaum, August 1992. \u21a9An Introduction to Database Systems, Volume 2, by C.J Date, 6th Edition, Addison Wesley, 1995 \u21a9I studied with this text book nigh on 20 years ago, and it still appears to be the main text in the field of protocols and networking: Computer Networks, by Andrew S. Tannenbaum, 3rd ed., Prentice Hall, 1996 \u21a9A fullsome page of links to electronic purses \u2013 implementations of Rights protocols \u2013 is included in Leo Van Hove's bibliography. \u21a9I am indebted to Mark Miller for providing me with the name of this layer. \u21a9At the time of writing, the canonical example would be www.e-gold.com which provides identity-based access to currencies reserved in precious metals. \u21a9For example, the eCash (tm) tokens as implemented by eCash Technologies, Inc. \u21a9Originally presented in the Gary Howland, Development of an Open and Flexible Payment System. \u21a9Mark S. Miller, Chip Morningstar, Bill Frantz, Capability-based Financial Instruments, accepted by Financial Cryptography 2000, Anguilla, February 2000. \u21a9Systems such as Chipper and Mondex. Note that there is no need for a new hardware layer \u2013 the distinction here is that the hardware is supplied, rather than assumed. \u21a9For many more examples of theoretical approaches, see Financial Cryptography First through Fourth International Conferences, Anguilla, British West Indies, February 1997-2000. \u21a9For examples of approaches that have reached practical implementation stage, if not to market, see Edinburgh Financial Cryptography Engineering a new workshop that includes presentations of running code only. \u21a9Check any basic accounting text book for these terms. Google may provide some assistance on these terms. \u21a9As a wider comment, it is possible to model any electronic value scheme as a method of accounting. See Alan Tyree, The legal nature of electronic money.Whilst a valuable modelling exercise, caution is advised, as most conclusions drawn from such exercises are too broad. Specifically, institutional observers tend towards a line of logic: \"it can be modelled as a series of accounts, therefore it should be regulated like banking;\" such an approach is fraught with difficulties and unlikely to be satisfactory. \u21a9For general articles on the Governance aspects of Financial Cryptography, check John Muller's ABA site Electronic Financial Services Resources. \u21a9The Agency Problem:Also sometimes referred to as the principal-agent problem. The difficult but extremely important and recurrent organizational design problem of how organizations can structure incentives so that people (\"agents\") who are placed in control over resources that are not their own with a contractual obligation to use these resources in the interests of some other person or group of people actually will perform this obligation as promised \u2013 instead of using their delegated authority over other people's resources to feather their own nests at the expense of those whose interests they are supposed to be serving (their \"principals\"). Enforcing such contracts will involve transaction costs (often referred to as agency costs), and these costs may sometimes be very high indeed.A Glossary of Political Economy Terms Paul M. Johnson. See also Google. \u21a9Michael Froomkin's writings on Separation of Powers. \u21a9Robert Hettinga suggests some models in The Players \u21a9In Ricardo documentation, and also further below in the section on Structural Governance I suggest breaking up the system into 5 parties, Owner, Mint, Manager, Users, Operator. \u21a9See Jane Kaufman Winn's writings on the validity of current contracts in governance: Jane Kaufman Winn, Couriers without Luggage: Negotiable Instruments and Digital Signatures, South Carolina Law Review, 1998. \u21a9See the DigiGold Page for an example of a real time report on the currency balance sheet. \u21a9See the e-gold Examiner for an example of a real time report on reserves. \u21a9See Jane Kaufman Winn, op cit, for a classic description of the Certificate Authority industry's attempts to clean up a poor security model with an implausible contract. \u21a925 cents is a fair minimum for credit cards, due to the cost of these transactions. $500 is a popular upper limit imposed on smart cards by the threat model (actually, it is 500 of the local unit, for some obscure reason). \u21a9For a description of Individual Transferable Quotas \u2013 ITQs \u2013 describing instruments for quantities of fish stocks, see Policy, Fencing the Oceans A Rights-based Approach to Privatising Fisheries, Professor Birgir Runolfsson, Autumn 1998. \u21a9Ian Brown (ianb at acm dot com) points out that pollution is in fact a public bad. \u21a9Ian Grigg, Universal Value, work in progress. This is introduced later in the example. \u21a9For example, this was the target application of Cybercash Inc, First Virtual Inc, and DigiCash BV (now eCash Technologies Inc). \u21a9Digital Trading, op cit. \u21a9For example, see the so-called second wavers: Beenz, Flooz, Cybergold. \u21a9See Fencing the Oceans, op cit. Whilst not discussed in the article, there are a small number of marketmakers in Iceland that work the thin market in ITQs. For more background on fishing property rights, see The Ecological Implications of Establishing Property Rights in Atlantic Fisheries, Elizabeth Brubaker, April 1996. \u21a9Ian Grigg and C. Petros, Proceedings of Financial Cryptography, Using Electronic Markets to Achieve Efficient Task Distribution, February 1996. \u21a9Ian Grigg and Gary Howland designed the Ricardo system in 1996-1997. \u21a9The Ricardo system is currently in use for a series of metal based currencies managed by DigiGold. \u21a9Ian Grigg, work in progress, Universal Value. \u21a9Many designs of Financial Cryptography systems have limited Issuers to being banks, which allows the designer to assume away many complications. \u21a9This section is based upon Ian Grigg, Talk on DigiGold Governance, Financial Cryptography 1999, commercial sessions. \u21a9The same logic would also imply that the user must have access to dynamic trading information such as prices, but we pass over that here. \u21a9Having abstracted the contents from the identity of the document by taking a message digest of it, we can discuss value, from payment systems perspective, as being fully and uniquely defined by the message digest. This ensures that the Issuer of the security cannot change the terms of the contract in any way without offering to the user terms for exchange. \u21a9This also has a secondary effect of shortening the distance between the contract and the software that manages it, thus simplifying the design. However, the prime objective was, and remains, a system where we know that the user has strong access to contract information. \u21a9Such a scheme might not prevent the software engineer from providing a client application that misrepresents the contract. However, this would be an issue between the user and the software supplier, rather than the system itself, especially, the operators of the system and issuers of securities would clearly not be at fault. \u21a9This is described more fully in a FAQ question on Structural Governance \u21a9In order to force the client to maintain the data, the SOX mail facility, introduced in layer 3, requires signatures for all important documents such as receipts. \u21a9Or, more correctly, to treat such a support call as a bug, in that the client is not making the information available. \u21a9A signed request from the user has more meaning to the user \u2013 the client software must keep track of these as promises to pay, and in this sense, the system is analogous to a cheque system. \u21a9The receipt includes the authentication request supplied by the client in order to provide the chain of authentication back to the user. \u21a9In programming terms, stored balances are banned. The balances that are displayed by the software client are calculated on the fly, including every time the client redraws. Getting this right has proven to be a sizeable cost in development time, but it is believed that the requirements are valid and the costs are covered in the long run. \u21a9SOX is variously Systemics Open Transactions or Secure Open Transactions. It is discussed by its original author in Development of an Open and Flexible Payment System, Gary Howland, 1996, and also in an Executive Summary. An implementation exists in open form as a part of the WebFunds Project. \u21a9SOX provides a string or byte array that determines the type of value, which is open as an implementation detail. But, practically, this is the unique identifier for the Ricardian Contract as discussed in the Value layer. \u21a9Note the way in which SOX melds with the Internet, as implication of layer 2. When passing a payment to someone on the other side of the planet, that payment only has value if it is settled and cleared by the Issuer. Otherwise, the payment is an uninteresting series of bits, with similar value to any other random nonsense.In contrast, the passing of rubber cheques is illegal in some countries, and traumatic in most others. SOX payments are not cheques in that sense. \u21a9The value Issuers are distinct servers to market servers, it is just the protocol that is common. The protocol can also be used for other purposes, wherever a primary requirement is made for a reliable delivery. \u21a9The specific problem with a connection protocol arises when the connection dies. Did the last few bytes make it to the other end or not? With such protocols, there is generally no way to recover from this uncertainty without building an additional reliable protocol over the top of the first. Which of course raises interesting design questions that may lead to alternate paths such as connectionless protocols. \u21a9SOX packets can, and are, sent over TCP connections, but mostly so that firewalls may be easily navigated. \u21a9The Cryptix Resources Page. \u21a9Indeed, in my opinion, neither is it useful for networking. For critiques of the OSI 7 layer models, see M.A. Padlipsky, Elements of Networking Style, and RFC 874. \u21a9Robert Hettinga, email on dbs at philodox dot com. \u21a9Copyright \u00a9 1998 Systemics Ltd. All rights reservedEditor's note: Some links may be broken."}
{"prompt": "The Playdough Protocols", "completion": "Commercial security at the birth of writing, arithmetic, and religion in ancient Sumer (modern Iraq).It is five thousand years ago, and you pace fretfully in your office. Located in the temple of the great goddess Inanna in ancient Nippur (now in Iraq) you are buried, not in a blizzard of paper, but an avalanche of clay. You fret. You have entrusted a valuable cargo of sheep, barley, and beer to a crusty group of sailors from the Baba Temple in the nearby Lagash[1]. These navy types are far from pious devotees of the goddess Inanna and the great god Enlil with whom you are familiar.The sailors\u2018 job, and your payoff \u2013 take the goods down the Persian Gulf and across the sea to Mohenjo-Daro, in the valley of the Indus River (in modern Pakistan). There they will be delivered to your old friend, a trusted agent of Inanna, and sold to the locals for a very substantial amount of silver.Will the sailors get hungry and eat the sheep and barley? Party and drink the beer? Get nasty and poison the lot, throwing disrepute on the great goddess Inanna? Perhaps they will get clever and water down the beer \u2013 or get still more clever and resell your high-quality goods under the name of their crude god.You needn\u2018t worry so much. Long-distance commerce may be a novelty, but you have the clay.Nor, thanks to five thousand years of experience with the technologies of tamper evidence, need we worry so much in our modern era. The occasional embezzlement and rare but quite nasty poisoning occur far less often due to our technological and institutional descendants of the ancients\u2018 clay. And using the digital equivalent of seals, we can bring data integrity and unforgeable identities to online commerce.Terra cotta sealing (bottom) and rectangular stamp seals, Mohenjo-Daro, Indus Valley, c. 2,000 B.C. The central sign on the top seal may represent a house or temple and is a symbol that is often repeated on Indus seals with horned deities seated in yogic position. Courtesy harappa.com.Let\u2018s follow the professional archaeologists and distinguish between seals, the often cleverly carved cylinders or stamps that make the impressions, and sealings, the resulting impressions rolled or stamped on wet clay, and the clay they were impressed upon. Sealings of clay were wrapped around rope knots to seal bales of goods, and around the rims of wicker baskets and pottery jars to seal in their contents. Since these ancients lacked good locks, clay sealings were wrapped around door latches to seal rooms. The security provided \u2013 evidence of tampering, due to damage of the container itself or the clay that sealed it.Seals were carved from hard materials \u2013 usually stone but sometimes faience, glass, metal, wood, or bone. Sometimes sun-dried or baked clay itself was used. The Greeks and Romans used signet rings, their action ends shaped from metal or carved from gems, to stamp wax.The seal design was usually recessed, resulting in a raised impression; occasionally this was reversed. To creating a sealing, first wet clay was shaped around the plug of a jar, the rim of a basket, the knot of a well wrapped rope on a bale, or the latch of a door. Then the surface of the clay was thoroughly covered by the impressions of the seal. The Sumerians commonly used cylinder seals, repeating the pattern across the entire clay surface. Sometimes stamp seals were used for smaller surfaces. Finally, the clay was left to dry, in the sun if possible.While sun-dried clay could usually be remoistened and rewritten, it would have been very difficult to hide from a trained eye. Rejoining the breached container lid, knot, or latch and replacing the broken seal with a new, identical seal would have been, short of stealing the original unique seal carving, impossible to hide from the inspector. Looking for a particular seal impression and examining the container, the inspector could reliably tell whether the contents had been tampered with. The difference between an accidental crack, from dropping or hitting the object, and a breach that allowed the thief or adulterator access to the goods, would also be apparent. Ancient inspectors undoubtedly became experts at looking for clues to distinguish accident from fraud. In any case, a broken seal then as now indicated suspect goods suitable perhaps for the discount bin, but more normally for the trash. It also indicated error for fraud \u2013 and potential punishment.Cylinder seal (left) and its sealing (right), King Darius the Great, Persia, 586\u2013522 B.C., with weapons of warThe earliest stamp seals found were used in Iran in 5,000 B.C. Later on archaeologists can use both the trade in seals themselves, as well as the distances between seals and the corresponding sealings, to trace long-distance trade networks. One such set of seals were manufactured around 1,900 B.C. on two important island trading cities in the Persian Gulf \u2013 Bahrein and Failaka. These seals were traded all over the Middle East, and have been found at diverse and distant locations such as Susa in Iran , Bactria in Afghanistan, Ur in Iraq, and Lothal on the west coast of India. By 1,750 B.C. Common Style seals are found in locations ranging from Spain, to Mycenaean Greece, to Marlik near the shores of the Caspian Sea. These seals were made from faience, a less expensive material, and used by smaller merchants.[2]The first cylinder seals belonged to the now long dead civilization of the Sumerians, the inhabitants of Nippur, Lagash, and other cities on the Euphrates and Tigris rivers in what is now Iraq. They spoke a strange language \u2013 neither Semitic nor Indo-European, the family of languages spoken by many later civilizations and the most current inhabitants of the Middle East. Sumerian was an agglunative tongue, bearing resemblance to such diverse agglutinative languages as Turkish, Finnish, Japanese, and Dravidian. Indeed, it was probably some version of the latter tongue that was spoken by their neighbors, the early inhabitants of the Indus river valley. These Indus valley people developed, soon after the Sumerians, their own civilization and unique style of seals. Modern speakers of Dravidian languages are scattered all over the Indian subcontinent, including remnants in Afghanistan and a large number of Tamils in southern India. Seal impressions have been found in the ancient city of Harrapan, in the Indus River valley (modern Pakistan), that had been made by seals found in Lagash in Sumeria (modern Iraq). From 3,600 B.C. in Sumer, and a little later in the Indus Valley, we can find seals made out of a rare high-quality stone, lapis lazuli. These stones could only have originated from rather distant and inaccessible mines in Afghanistan.For the Sumerians a business protocol was also a religious ritual, and the reverse was usually true as well. In the Middle East seal breaking became one of the most important of these rituals, with terrifying spiritual consequences if the seal were broken by the wrong person or at the wrong time. Three thousand years later these poetic images had reached apocalyptic proportions in the writings of the early Christian mystic John. The grave religious powers that could be unleashed by breaking a seal are well illustrated by his book of Revelations, in which the breaking of the first four seals of a holy book release the Four Horsemen of the Apocalypse:6:1 And I saw in the right hand of him that sat on the throne a book written within and on the backside, sealed with seven seals.6:2 And I saw a strong angel proclaiming with a loud voice, Who is worthy to open the book, and to loose the seals thereof? \u2026A worthy deity is found, who starts breaking the seals and thereby loosing the Horsemen \u20136:5 When he opened the third seal, I heard the third living creature saying, \u201cCome and see!\u201d And behold, a black horse, and he who sat on it had a balance in his hand.6:6 I heard a voice in the midst of the four living creatures saying, \u201cA choenix of wheat for a denarius, and three choenix of barley for a denarius! Don\u2018t damage the oil and the wine!\u201d[3]The Sumerians used thin wires and flat ingots of gold and silver, carefully weighed in balance scales, rather than coins like the Roman denarius. Except for paying the price in coins rather than coils, the commerce of the Third Horseman would have sounded quite familiar to our Sumerian merchant.Wire ring and coil money, Sumeria, c. 2,500 B.C.The first documents ever written, in the 4th millennium B.C., were also about wheat and barley, and also sealed. Far earlier still, at least as far back as 8,000 B.C., archeologists have found even more alient artifacts \u2013 vast numbers of little clay tokens. In the first half of the 20th century archaeologists, looking for important artifacts of civilization like statues of gods and Moses-style law tablets, dismissed these tokens as some kind of trivia, probably game tokens or cheap unstrung beads. Now we know that these tokens led directly to what are now the very basics of our civilization \u2013 reading, writing, and arithmetic.Recall our merchant, entrusting goods to sailors. Not all goods could be sealed in a jar or small room \u2013 a flock of sheep entrusted to shepherds, for instance. And in some cases it was expected that goods would be have to be opened en route \u2013 for example, to be audited by a customs inspector. For this reason, a separate record of the goods was needed. Without writing, how was such a record created?Pebbles, shells, and other counters have long been used to count things. Without even knowing how to verbally count in order \u2013 some cultures do not have words for numbers above three \u2013 one can \u201ccount\u201d objects by placing a pebble, on a pile or in a bag, one for each object. One nomadic tribe in Africa[4] counts cattle passing through a gate by drilling furrows. As each cattle paces, a pebble is placed in the rightmost furrow. When there are nine pebbles in this furrow, and the tenth cow goes through the gate, the pebbles are removed from the first furrow and a single is placed in the next furrow to the left. This is a \u201ccarry\u201d operation, used in abacuses around the world and even used in modern computers. These nomads have, along with many other cultures, invented a kind of abacus, with a ones place, a tens place. A zero is simply an empty furrow. Many other cultures (though not this one) have taken this to the next step and used this abacus, in the form of pebbles on a board or beads strung on rods, to add, subtract, multiply, and perform other computations. Indeed, until the advent of our modern Arabic numbers, everywhere calculations were done by the abacus or fingers, not on paper.Clay envelope and tokens, Sumer, c. 3,400 B.C.In the ancient Middle East, these pebbles took the form of dried clay tokens. The clay was formed into pebbles of various shapes and sizes. Some represented sheep, some standard sized pots of barley, and so on. The number of kinds grew as commerce grew. Some represented one, five, or a dozen of the kind.Soon after 4,000 B.C., the clay tokens were combined with the idea of sealing to create bills of lading and warehouse receipts. To create a bill of lading for a consignment of sheep, the owner put in a one-sheep token for every sheep. Every time he counted five sheep, a five-sheep token could be substituted for a one-sheep token. Once the owner and the consignee agreed on the count, the tokens were placed in a wet clay envelope. The owner and the consignee rolled their seals over the envelope, then let it dry. The procedure for a warehouse receipt was similar. An owner of wheat or barley could consign his fresh harvest to the protection of a warrior-priest in his walled fortress. The receipt was tokens sealed in an envelope \u2013 when the owner got hungry, or wanted to sell to the hungry, or wanted the seed to plant next spring \u2013 he would take the envelope to the warehouse. The claimant and the warehouse operator would inspect the seal, break it, inspect the tokens, and then deliver the goods.It would be nice if one could learn the contents of the envelope \u2013 the number and kind of tokens \u2013 without having take the ominous and irreversible step of breaking the seal. Around 3,400 B.C. in Sumer, marks started appearing on the outside of these envelopes. These marks were simply made by the tokens themselves. The different shapes and sizes of the tokens created correspondingly unique impressions, and thus the same symbols.[4][5]. Such external marks weren\u2018t as secure \u2013 they could be erased, albeit not without detection by a well trained eye.As warehouse receipts and bills of lading became common, commerce diversified. So many different kinds and numbers of goods were involved that the shapes and sizes of clay tokens were growing out of control. What computer scientists call a \u201clevel of indirection\u201d was needed. With different tokens for one sheep, five sheep, one pot of barley, five pots of barley, and so forth, we get m*n different tokens, where m are the numerical denominations of the tokens and n are the number of different kinds of commodities. By creating separate tokens for the numbers and the goods, the number of different kinds of tokens were reduced to m + n, at the cost of up to twice as many tokens per envelope.This development wasn\u2018t entirely new. Abstract counting tokens, reused for sheep and people and pots of barley, are probably far more ancient. Nor were separate words for \u201csheep\u201d, and \u201cbarley\u201d new. What was new were the separate tokens for \u201csheep\u201d, \u201cbarley\u201d, to be used, like the counting tokens, in the bills of lading and warehouse receipts. The were still thought of as corresponding to the objects they represented, not the words \u201csheep\u201d and \u201cbarley\u201d, but it was a big step towards written language. Naturally these symbols also became external marks[4][5].The first written tablets, dating around 3,300 B.C. and again in Sumer, were simply these external marks, inscribed on clay tablets. To maintain the security properties of tokens in clay envelopes, some the tablets were themselves are sealed in clay envelopes.The evolution of writing proceeded from there. A hundred years later reed styluses were being used to badly mimic the clay token marks. Over succeeding centuries, scribes supplemented or replaced token-derived symbols with pictographs for the objects. The pictographs attempted to bring to mind the object visually. Both kinds of symbols became stylized as wedges, or \u201ccuneiform\u201d, optimized for the reed stylus. Still later, words represented by neither pictographs nor token-derived symbols come to be represented by a rebus. An example of a rebus in English is representing the word \u201cI\u201d with a pictographic symbol for \u201ceye\u201d. This gave rise to a semi-phonetic alphabet. From this evolved the Phoenician or true phonetic alphabet, which was in turned borrowed by the Greeks and Romans. We use the Roman alphabet.Evolving beyond clay tokens, accounting was the first use of the external marks and started to take a familiar form. Along with the tamper evident clay, the Sumerians developed a kind of virtual tamper evidence. It took the form of two sets of numbers. On the front of the tablet, each group of commodities would be recorded separately \u2013 For example on the front woudl be recorded 120 pots of wheat, 90 pots of barley, and 55 goats. On the reverse would simply be recorded \u201c265\u201d \u2013 the same objects counted gain, probably in a different order, and without bothering to categorize them. The scribe, or an auditor, would then verify that the sum was correct. If not, an error or fraud had occured. Note the similarity to tamper evident seals \u2013 if a seal is broken, this meant that error or fraud had occured. The breaker of the seals, or the scribe who recorded the wrong numbers, or the debtor who paid the wrong amounts of commodities would be called on the carpet to answer for his or her discrepancy.Checksums still form the basis of modern accounting. Indeed, the principle of double entry bookeeping is based on two sets of independently derived numbers that must add up to the same number. Below, we will see that modern computers, using cryptographic methods, can now compute unspoofable checksums.Breaking a seal still, but fortunately only quite rarely, can have implications that are apocalyptic \u2013 at least for the individuals involved. Tylenol in 1982 and 1986, Excedrin and Lipton Cup-A-Soup in 1986, Sudafed in 1991, and Goody's Headache Powder in 1992 all were tampered with by sickos who added cyanide to the product and killed people. This spurred a new emphasis on tamper evident plastic packaging which can now be found protecting a wide variety of the products we use.Everybody is familiar with shrink-wrapped plastic, a less secure but commonly used technology \u2013 as common as the ubiquitous price tag. Another favorite tamper-evident device is the seal used to protect pill bottles.Evidence bag. Courtesy Custom Specialties Inc. [no relationship to author].Bank employees, our modern descendants of ancient temple accountant-priests, still sometimes work in edifices designed to look like Roman temples. They carry cash, checks, and other valuables in tamper-evident clear plastic envelopes. Evidence of tampering comes either as a tear in the plastic, or from opening the bag normally. In the latter case, a seal (the same place you'd find the zip seal on a Zip-Loc bag) chemically alters, and words such as \u201cVOID\u201d or \u201cOPENED\u201d appear in large letters. When these bags carry unique serial numbers, inspectors at both ends can record the serial number while examining the bag for tampering. The unique serial number prevents the tamperer from simply transferring the contents from one such bag to another. Modern plastic bags with the altering chemical seal, used in conjunction with the tracking of unique serial numbers, provide a very strong kind of tamper evidence, and are used by high security institutions ranging from banks to the military to cryptographic certificate authorities. The evidence bags used by many police departments work the same way.Tamper evident tape on a cabinet door. Note the sequential number, which when recorded and checked detects the replacement of the original tape with a new one. (The security of the serial number assumes that this label is not easy to duplicate using a laser printer). On the right, the broken seal has left a difficult to remove mark including the word \u201ctamper\u201d. Courtesy tamper.com [no relationship to author].Many other kinds of security, from ancient to modern, can be thought of as providing a kind of tamper evidence. Laser-break and glass-break sensors can make an entire building trespass evident. Similarly, guard dogs bark to protect their territories, alterting their masters to visitors.One of the most high-tech kinds of security, cryptography, is no longer just secret writing, but has spawned a whole new family of mathematical functions to protect the integrity of digital data. These functions are quite analogous to the function of ancient seals.One cryptographic function, the hash function, acts like the Sumerian checksum described above. The difference is that the \u201cnumbers\u201d it adds up are the binary digits that make up text, images, or other data. A second difference is that, by using a one way function and very large numbers, it can make the checksum practically unspoofable. The way accountants normally use checksums, the fraudster can sometimes with some ingenuity guess what the input numbers are. With cryptographic hash functions, this is practically impossible for a human, and for a computer it would almost always take millions of years of brute-force guessing to reverse-engineer the checksum.Another cryptographic protocol, the \u201cdigital signature\u201d, resembles one of these ancient seals much more than it does a modern autograph. The protocol operates in two steps. In the first step, a piece of data is sealed using a hash function as describe above. This is analogous to surrounding a basket lid with clay. Then a reverse public key cryptography operation (mathematically equivalent to decrypting a message) is performed. This second step is analogous to rolling the cylinder on the seal to identify the sealer.The digital signature can be made only by the possessor of a private key just as a seal could be made only by the possessor of the unique seal carving. If the digital signature is bad, this provides evidence that the data was tampered with or the signature forged.Rhee, 1981 \u21a9Colon, Dominique, Near Eeastern Seals \u21a9Book of Revelations, Ch. 6 \u21a9Ifrah, Georges, The Universal History of Numbers, John Wiley & Sons 1998, pg. 73 \u21a9 \u21a9 \u21a9Rhee, 1981 \u21a9 \u21a9Schmandt-Bessarat, Denise, Accounting with Tokens in the Ancient Near EastMy thanks to Andrew Odlyzko and K. Eric Drexler for their insightful comments.Originally published on Nick Szabo\u2019s Papers and Concise Tutorials.Please send your comments to nszabo (at) law (dot) gwu (dot) edu"}
{"prompt": "Digital Cash & Privacy", "completion": "I agree with Anonymous that there are problems with the actual use of digital cash in the near term. But it depends to some extent on what problem you are trying to solve.One concern I have is that the move to electronic payments will decrease personal privacy by making it easier to log and record transactions. Dossiers could be built up which would track the spending patterns of each of us.Already, when I order something over the phone or electronically using my Visa card, a record is kept of exactly how much I spent and where I spent it. As time goes on, more transactions may be done in this way, and the net result could be a great loss of privacy.Paying in cash is still possible through the mail, but it is insecure and inconvenient. I think that the convenience of credit and debit cards will overcome most people\u2019s privacy concerns and that we will find ourselves in a situation where great volumes of information exist about people\u2019s private lives.This is a place that I could see digital cash playing a role. Imagine a Visa-like system in which I am not anonymous to the bank. In this model, imagine that the bank is granting me credit similar to a credit card. But instead of giving me just an account number which I read over the phone or send in an email message, it gives me the right to request digital cash on demand.I keep some digital cash around and spend it for transactions as I described in my previous posts. When I get low I send some email to the bank and get some more dcash. Every month I send a check to the bank to cover my account just as I do with my credit cards. My relations with the bank are very similar to my current relationships with the credit card companies: frequent withdrawals and a single payment each month by check.This has several advantages over the system which we are heading towards. No records are kept of where I spend my money. All the bank knows is how much I have withdrawn each month; I may or may not have spent it at that time. For some transactions (e.g. software) I could be anonymous to the vendor; for others the vendor might know my real address, but still no central location is able to track everything I buy.(There is also a security advantage over the ridiculous current system in which knowing a 16 digit number and an expiration date allows anyone to order anything in my name!)Furthermore, I don\u2019t see why this system could not be as legal as current credit cards. All that really differs in this system is the inability to track where users spend their money, and as far as I know this ability was never an important legal aspect of credit cards. Certainly nobody will admit today that the government has a vested interest in moving towards an environment in which every financial transaction is tracked.Granted, this does not provide full anonymity. It is still possible to see roughly how much each person spends (although nothing stops a person from withdrawing much more cash than he will spend in a given month, except perhaps for interest expenses; but maybe he can lend the extra digicash itself and gain interest on that to compensate). And it is oriented around the same customer/vendor model that Anonymous criticized. But I maintain that this model represents the majority of electronic transactions, today and in the near future.It\u2019s worth noting that it is not trivial to become a merchant who can accept credit cards. I went through this with a business I had a couple of years ago. We were selling software through mail order, and this makes the credit card companies very nervous. There is so much phone fraud in which credit card numbers are accumulated over a few months, then large amounts of charges made against them. By the time the user receives his monthly statement and complains, the vendor has disappeared. In order to get our credit card terminal we went to a company which \u201chelps\u201d startups with this. They seemed like a pretty shady outfit, themselves. We had to fudge our application to say that we\u2019d be selling something like 50% of the units at trade shows, which apparently counted as over-the-counter sales. And we had to pay about $3,000 up front, as a bribe, it seemed. Even then we probably couldn\u2019t have done it if we hadn\u2019t had an office in the business district.Under the digital cash system, this might be less of a problem. The main problem with digital cash is double-spending, and if you are willing to go with online verification (reasonable for any business which is going to take anything over several hours to deliver the merchandise) this can be completely prevented. So there is no longer any possibility of merchants collecting credit card numbers for later fraud. (You still have problems with non-delivery of merchandise, though, so not all risks are eliminated.) This might eventually make the system more widely available than current credit cards.I don\u2019t know whether this system could be used to support illegal actions, tax evasion, gambling, or whatever. That is not the purpose of this proposal. It does offer the prospect of improving personal privacy and security, in a framework that might even be legal, and that\u2019s not bad.Hal Finney\nhal@rain.orgHal Finney Home Page"}
{"prompt": "Bitcoin and Me", "completion": "Originally posted on BitcointalkI thought I'd write about the last four years, an eventful time for Bitcoin and me.For those who don't know me, I'm Hal Finney. I got my start in crypto working on an early version of PGP, working closely with Phil Zimmermann. When Phil decided to start PGP Corporation, I was one of the first hires. I would work on PGP until my retirement. At the same time, I got involved with the Cypherpunks. I ran the first cryptographically based anonymous remailer, among other activities.Fast forward to late 2008 and the announcement of Bitcoin. I've noticed that cryptographic graybeards (I was in my mid 50's) tend to get cynical. I was more idealistic; I have always loved crypto, the mystery and the paradox of it.When Satoshi announced Bitcoin on the cryptography mailing list, he got a skeptical reception at best. Cryptographers have seen too many grand schemes by clueless noobs. They tend to have a knee jerk reaction.I was more positive. I had long been interested in cryptographic payment schemes. Plus I was lucky enough to meet and extensively correspond with both Wei Dai and Nick Szabo, generally acknowledged to have created ideas that would be realized with Bitcoin. I had made an attempt to create my own proof of work based currency, called RPOW. So I found Bitcoin facinating.When Satoshi announced the first release of the software, I grabbed it right away. I think I was the first person besides Satoshi to run bitcoin. I mined block 70-something, and I was the recipient of the first bitcoin transaction, when Satoshi sent ten coins to me as a test. I carried on an email conversation with Satoshi over the next few days, mostly me reporting bugs and him fixing them.Today, Satoshi's true identity has become a mystery. But at the time, I thought I was dealing with a young man of Japanese ancestry who was very smart and sincere. I've had the good fortune to know many brilliant people over the course of my life, so I recognize the signs.After a few days, bitcoin was running pretty stably, so I left it running. Those were the days when difficulty was 1, and you could find blocks with a CPU, not even a GPU. I mined several blocks over the next days. But I turned it off because it made my computer run hot, and the fan noise bothered me. In retrospect, I wish I had kept it up longer, but on the other hand I was extraordinarily lucky to be there at the beginning. It's one of those glass half full half empty things.The next I heard of Bitcoin was late 2010, when I was surprised to find that it was not only still going, bitcoins actually had monetary value. I dusted off my old wallet, and was relieved to discover that my bitcoins were still there. As the price climbed up to real money, I transferred the coins into an offline wallet, where hopefully they'll be worth something to my heirs.Speaking of heirs, I got a surprise in 2009, when I was suddenly diagnosed with a fatal disease. I was in the best shape of my life at the start of that year, I'd lost a lot of weight and taken up distance running. I'd run several half marathons, and I was starting to train for a full marathon. I worked my way up to 20+ mile runs, and I thought I was all set. That's when everything went wrong.My body began to fail. I slurred my speech, lost strength in my hands, and my legs were slow to recover. In August, 2009, I was given the diagnosis of ALS, also called Lou Gehrig's disease, after the famous baseball player who got it.ALS is a disease that kills moter neurons, which carry signals from the brain to the muscles. It causes first weakness, then gradually increasing paralysis. It is usually fatal in 2 to 5 years. My symptoms were mild at first and I continued to work, but fatigue and voice problems forced me to retire in early 2011. Since then the disease has continued its inexorable progression.Today, I am essentially paralyzed. I am fed through a tube, and my breathing is assisted through another tube. I operate the computer using a commercial eyetracker system. It also has a speech synthesizer, so this is my voice now. I spend all day in my power wheelchair. I worked up an interface using an arduino so that I can adjust my wheelchair's position using my eyes.It has been an adjustment, but my life is not too bad. I can still read, listen to music, and watch TV and movies. I recently discovered that I can even write code. It's very slow, probably 50 times slower than I was before. But I still love programming and it gives me goals. Currently I'm working on something Mike Hearn suggested, using the security features of modern processors, designed to support \"Trusted Computing\", to harden Bitcoin wallets. It's almost ready to release. I just have to do the documentation.And of course the price gyrations of bitcoins are entertaining to me. I have skin in the game. But I came by my bitcoins through luck, with little credit to me. I lived through the crash of 2011. So I've seen it before. Easy come, easy go.That's my story. I'm pretty lucky overall. Even with the ALS, my life is very satisfying. But my life expectancy is limited. Those discussions about inheriting your bitcoins are of more than academic interest. My bitcoins are stored in our safe deposit box, and my son and daughter are tech savvy. I think they're safe enough. I'm comfortable with my legacy.\n[edited slightly]"}
{"prompt": "Intrapolynomial Cryptography", "completion": "Researchers have proposed a variety of \u201cclient puzzle\u201d or \u201cbusy-work\u201d proposals like hashcash, MicroMint, bit gold, and compute-cost postage to create independent currencies or make spamming costly. The mathematical implication of these proposals is that there is such a thing as intrapolynomial cryptography. Four motivations for intrapolynomial cryptography theory are (a) novel constructions such the aforementioned applications, (b) more accurate estimation of the computational cost of cracking a cipher, (c) it might be easier to prove lower bounds, rather than just conjecture them as is the case with superpolynomial (standard) cryptography, and (d) if there do not exist one-way functions, standard cryptography is intrapolynomial rather than superpolynomial.I propose the following formalization:In other words, there is no algorithm running faster than q(n,k)p(n) which can invert f for more than a negligibly small number of values.One can similarly define average-case, best-case, and worst-case k-degree benchmark functions, analogously to one-way functions. Open question (analogous to the open question in superpolynomial cryptography of whether one-way functions exist): can one prove (3) as lower and upper bounds for some function and k>=1 on some realizable machine model such as RAM-log?Strong and average case are most apropos to cryptography related applications. Unfortunately for these purposes we'd also need:Since this is at least very tedious, one hopes we can in practice get away with a short list which covers all plausibly implemented machine architectures. This might work where for example the total exposure from cracking a protocol is less than the R&D costs of designing and building a novel machine architecture to defeat it. Cryptanalyis would include discovering the machine architectures optimal for breaking an intrapolynomial cipher.There are at least two practical implications of the above analysis. One is that there is very little room for error in the analysis and implementation of compute-cost postage, hashcash, bit gold, MicroMint, and other such intrapolynomial cryptography schemes. Another is that, unless the opponent has a very low budget and is thus limited to standard personal computers, it does not make sense to analyze the security or cost of these schemes without reference to machine architecture. For example, spammers may be able to defeat compute-cost postage by using custom chips optimized for computing the particular puzzle function."}
{"prompt": "RPOW - Reusable Proofs of Work", "completion": "Archived website\nGitHubI'd like to invite members of this list to try out my new hashcash-based server, rpow.net.This system receives hashcash as a Proof of Work (POW) token, and in exchange creates RSA-signed tokens which I call Reusable Proof of Work (RPOW) tokens. RPOWs can then be transferred from person to person and exchanged for new RPOWs at each step. Each RPOW or POW token can only be used once but since it gives birth to a new one, it is as though the same token can be handed from person to person.Because RPOWs are only created from equal-value POWs or RPOWs, they are as rare and \"valuable\" as the hashcash that was used to create them. But they are reusable, unlike hashcash.The new concept in the server is the security model. The RPOW server is running on a high-security processor card, the IBM 4758 Secure Cryptographic Coprocessor, validated to FIPS-140 level 4. This card has the capability to deliver a signed attestation of the software configuration on the board, which any (sufficiently motivated) user can verify against the published source code of the system. This lets everyone see that the system has no back doors and will only create RPOW tokens when supplied with POW/RPOW tokens of equal value.This is what creates trust in RPOWs as actually embodying their claimed values, the knowledge that they were in fact created based on an equal value POW (hashcash) token.I have a lot more information about the system at rpow.net, along with downloadable source code. There is also a crude web interface which lets you exchange POWs for RPOWs without downloading the client.This system is in early beta right now so I'd appreciate any feedback if anyone has a chance to try it out. Please keep in mind that if there are problems I may need to reload the server code, which will invalidate any RPOW tokens which people have previously created. So don't go too crazy hoarding up RPOWs quite yet.Thanks very much -Hal Finney"}
{"prompt": "Negative Reputation", "completion": "An important and general problem seems to be that of tagging a negative behavior source for future recognition. The tag might be used for negative information shared publically (eg, credit ratings) or kept private (eg, kill files). The behavior source might be non-human (eg, recognizing virus patterns for the purposes of virus scanning). Where the behavior source is adaptable and self-interested, it has an incentive to spoof the tagging: a debtor to change names to avoid paying his debt, a virus to scramble its pattern to avoid scanning, and so on. If the tag carries a greater positive reputation (where zero is the reputation of a newcomer) this incentive is lost and the negative side of the reputation \u2014 the disreputation \u2014 must be borne.Can digital credentialling systems facilitate such negative reputation handling?Service-specific, aka local, nym reputation may not be able to accomplish such tracking of negative reputation. If a local nym accumulates more negative than positive credentials, it can simply be replaced by a newcomer local nym for this service, without harming the positive reputation capital of the other behavior source local nyms. Hostile sources can continuously spoof innocent newcomers. Counterparties lose the ability to determine a history of previous hostile behavhior \u2014 kill files, virus scanning, credit ratings, etc. fail.Chaumian credentials also give the credential holder control over the transfer of credentials between his local nyms, creating an incentive to show positive credentials and hide negative ones. To remedy this, counterparties can demand \"non-negative credentials\" (in a form such as, \"Alice in many transactions recorded by me in area X has never done bad things x,y,z\"), Non-negative credentials are limited to areas that can be well-tracked. One such may be credit ratings, as long as one is doing the bulk of one's credit transactions through is-a-person linked local nyms.Where Chaumian credentials are inapplicable, we might raise the cost of entry to be greater than that of a newcomer. This gives us two clearly defined reputation points to compare on an otherwise rather subjective scale: participation threshold and newcomer reputation. Both are subjective in the eye of the party choosing whether or not to participate in an activity with the nym.A participation threshold greater than newcomer reputation clashes with the desirable goal, that one be able to make a fresh start. For that matter, unless previous nyms and their positive reputations are linked to their new nyms, the pioneers cannot make a start, so that the institution itself cannot be started. Ditto for for institutional growth.Tags that bundle the results of a wide variety of transactions \u2014 global nyms, aka universal IDs, aka \"True Names\" \u2014 seem to provide the most incentive for parties to carry their negative credentials. Most people have accumulated enough positive reputation is some areas that it is well-nigh impossible for them to start over their entire lives as newcomers.A big problem arises with negative credentials when they are used, not merely to avoid engaging in a particular activity with a party, but for retribution against that party. Retribution may take some nonviolent online form, such as slander, denial of service attack, and so on, but the most worrisome form of retribution is a violent physical attack. Could we have digital tags that, while tracking negative behavior sources through the digital world, remain strictly unlinked to any kind of physical location data? Alas, we have several important systems, such as cellular phones, shipping addresses, etc. that provide such linkage.A big problem arises with negative credentials when they are used, not merely to avoid engaging in a particular activity with a party, but for retribution against that party. Retribution may take some nonviolent online form, such as slander, denial of service attack, and so on, but the most worrisome form of retribution is a violent physical attack. Could we have digital tags that, while tracking negative behavior sources through the digital world, remain strictly unlinked to any kind of physical location data? Alas, we have several important systems, such as cellular phones, shipping addresses, etc. that provide such linkage.The question may become one of deciding what of these three dimensions are most important, and how they can be traded off:Keep in mind too, that in practice these are evaluated primarily by a market evolving from its current state, rather than by abstract ethical philosophies.Robin Hanson has noted that in a world of global nyms, the use of a local nym may signal the hiding of negative credentials, so that the use of global nyms is in equilibrium. A further problem with local nyms is that our relationships are often not neatly compartmentalizable into standard service types, and even where they are we might like to expand them into new areas. I suggest that, at minimum, we will want to reveal progressively more local nyms to our counterparties as our relationships with them become closer and more co-exposed.While the global nym equilibrium may hold for many of our relationships, there may be plenty of areas where the privity benefits of localizing nyms outweigh the costs of being less or unable to differentiate newcomers from hostiles. (By \"privity\" I refer the entire general task of protecting relationships from hostile third parties; confidentiality and protection of property from theft are two examples of privity). For example, the preference-tracking service at www.firefly.com increases participation via the use of pseudonyms, and suffers little exposure from hostiles. On the other hand, credit transactions typically demand identifying information, because the contractual exposure typically outweighs benefits of privity.Global nym public keys, which have many drawbacks in terms of privity, may be the best way to track negative reputation, but they are no panacea. There is an important conundrum in an ID-based key system: the conflict between the ability to get a new key when the old one is or could be abused by another (key revocation), and the ability of another to be sure they are dealing with the same person again. This may also provide an opportunity for parties to selectively reveal positive credentials and hide negative ones. For example, a person with a bad credit rating could revoke the key under which that rating is distributed and create a new one, while selectively updating their positive credentials to the new key (eg, have their alma mater create a new diploma). Key revocation authorities might combine forces with credit rating agencies to avoid such erasure of negative history, but this gives them even more centralized control \u2014 not merely over IDs but over important elements of reputation associated with those IDs. This further violates the principles of separation of powers and segregation of duties, providing added opportunity for fraudulent issue or revocation of IDs along with fraudulent communication of reputation information.The current universal (non-cryptographic) key in the U.S., the SSN, is very difficult to revoke. Much easier to change your name. This policy is probably no accident, since the biggest economic win of global nym identification is the tracking of negative reputations, which revocation can defeat. As long as the SSN is a shared database key, not used for the purpose of securely identifying a faceless transaction, there is little need for revocation beyond the undesired erasure of negative history. Combining a secret authentication key, which must be revocable, with a public universal ID is quite problematic.Please send your comments to nszabo (at) law (dot) gwu (dot) eduCopyright \u00a9 1996 by Nick Szabo\nPermission to redistribute without alteration hereby granted"}
{"prompt": "PGP Web of Trust Misconceptions", "completion": "One of the key concepts widely used to describe PGP is the \"web of trust\". This brings to mind a network of connections between people who know and communicate with each other. Two people who want to communicate can do so securely if there is a path of connections in the form of signed keys that joins them.But this is not quite right. The fundamental fact about PGP key signatures, which is often misunderstood, is this:You can only communicate securely with someone whose key is signed by a person you know, either personally or by reputation.In other words, if I want to communicate with joe@abc.com, I can only do so if one of the signators of his key is a person I know. If not, I have no way of judging the validity of his key.This belies simple interpretations of the \"web of trust\". I may have signed A's key, A has signed B's, B has signed C's, C has signed D's, and D has signed Joe's, but this is of no value unless I know D. Only then can I trust Joe's key.This means that, in the \"web\" picture, I can only communicate securely with people who are at most two hops away in the web of connections. I can communicate with the people I know, and I can communicate with the people they know, and that is it.This is unfortunate, because the simple web model ties into some famous research which suggests that any two people chosen at random are only about half a dozen steps apart in the web of who-knows-whom connections. (This result is where the title of the movie \"Six Degrees of Separation\" comes from.) If you had a system which actually supported communications via such a web model, it actually would have hope of letting two people communicate who did not have a very long chain between them. But PGP, with a maximum chain length of two, will not allow this.What would have to be added in order to allow a true web of trust model to be used in a program like PGP? Basically what is needed is some way to judge the trustworthyness of signatures by people you don't know. This would most plausibly be provided by the people who had signed their keys. For example, if there were another type of key signature which did not only vouch for the person's identity, but also for his trustworthyness and care in signing keys, then a chain of such signatures could serve as the basis for a true web of trust. Obviously such signatures could not be given out nearly as easily as the kind we have now, where a glance at some stranger's drivers' licence is often all we get, but they could be given to close friends and those we know and trust.More elaborate systems might include numerical ratings of trustworthiness which would help to estimate the strength of any given path. The main point is that some information of this kind would be needed in order to allow communication with people distant in the web of connections.Without this, I think we will continue to have problems with PGP being unable to validate keys of people we want to communicate with. People will collect huge laundry lists of signatures in the hopes that whoever wants to communicate with them will know one of those people. Centralized key validators will appear (as in the case of the SLED service being started now, which will sign a key based on a signed check with your name on it). The result may be a choice between using an unsigned key or using one signed by some faceless bureaucracy, which is no better than the original PEM conception.(People may be confused by this essay because they thought PGP worked this way already. PGP does have a follow-the-web model, but that is only for following signatures. In the example above, where I wanted to talk to Joe and there was a chain to him through A, B, C, and D, we have to first suppose that I know and trust all of A, B, C, and D. Given that, what PGP can do is to determine whether I have valid keys for all of those people. It will notice that A has signed B's key, so it is valid. I know B and told PGP he was trustworthy, and he signed C's key, so therefore that one is valid. Similarly, I know C and I know D so PGP can follow the chain through them. Finally we come to Joe, whom I don't know, but because I know D and PGP followed the web to determine that D's key is valid, PGP can determine that Joe's key is valid. But again, that was only because I knew D and everyone else in the chain. The bottom line is still that I can only communicate with people who know someone I know.)Hal Finney\nhal@rain.orgHal Finney Home Page"}
{"prompt": "Scarce Objects", "completion": "A more intuitive and secure approach to programming with objects distributed across trust boundaries is presented. The approach involves scarce objects and software to support markets in trading scarce objects \"rights.\"Scarce objects are computational objects that like physical objects are finite and excludable, and force the client to either conserve or consume (use up) their own rights to use the object. References to scarce objects are bearer certificates with two key properties: (1) they are use-once or use-N-times tokens, and (2) like digital cash they are transferred using online clearing using \"spent lists\" to conserve the number of these scarce object references.Scarce objects, a.k.a. conserved objects, provide a user and programmer friendly metaphor for distributed objects interacting across trust boundaries. (To simplify the language, I will use the present tense to describe architectures and hypothetical software). Scarce objects also give us the ability to translate user preferences into sophisticated contracts, via the market translator described below. These innovations will enable us for the first time to break through the mental transaction cost barrier to micropayments and a micromarket economy.A scarce object is a software object (or one of its methods) which uses a finite and excludable resource \u2013 be it disk space, network bandwidth, a costly information source such as a trade secret or a minimally delayed stock quotes, or a wide variety of other scarce resources used by online applications. Scarce objects constrain remote callers to invoke methods in ways that use only certain amounts of the resources and do not divulge the trade secrets. Furthermore, scarce object wrappers form the basis for an online economy of scarce objects that makes efficient use of the underlying scarce resources.Scarce objects are also a new security model. No security model to date has been widely used for distributing objects across trust boundaries. This is due to their obscure consequences, their origins in single-TCB computing, or both. The security of scarce objects is much more readily understood, since it is based on duplicating in computational objects the essential intuitive features of physical possessions. Our brains reason in much more sophisticated ways about physical objects than about computational objects. Scarce objects are thus readily understood by programmers and end users alike. Scarce objects lower mental transaction costs, which are the main barrier to sophisticated small-scale commerce on the Net. Finally, scarce objects will solve for the first time denial of service attacks, at all layers above the primitive scarce object implementation.The intuitive physical metaphor of scarce objects gives scarce objects the following basic properties:Closely related to these is a social property of objects critical to the success of economies:Property rights and contracts are highly evolved methodologies for dealing with economic objects and each other across trust boundaries. Scarce object architecture can reuse this working paradigm, because it reuses the mental model of the physical world in which this security paradigm was invented.With scarce objects, any computation across trust boundaries will have these properties of atomicity, conservation, composition, and the accompanying clear delineation of rights and responsibilities. This model is rather restrictive compared to what we are used to within trust boundaries. However, it will much more readily keep programmers from writing obscurely insecure code, which is easy to do with either ACLs, capabilities, or cryptography. Furthermore, conservation (scarcity) and lack of externalities are the two major assumptions of microeconomics, the study of commercial transactions across trust boundaries. So the scarce objects security model allows us to inherit a rich literature of formal reasoning about such systems.Scarce objects are, in other words, online commodities. These commodities may represent, typically, rights (or expectations) to services \u2013 the right to use an e-mail or news service (or a component of that bundle of rights, e.g. the right to use that service\u2019s e-mail server), the right to upload or cache content, the \"right\" (here more like an expectation) to have e-mail read (digital postage to prevent spam), etc. Such service rights will usually be limited against the client by time or resource usage or number of invocations. When represented properly, by scarce objects, these services are conserved. Such \"rights\" or codified expectations are enforced against the server by reputation, by the \"physics\" of scarce objects, or both, in substitute for or in addition to expensive traditional legal means.Scarce objects may also represent unique or finite relationships between people and bits \u2013 names that correspond to addresses, ownership of trademarks, authorship of content, ownership of certain rights to content (which probably does not, for security reasons, include the right to exclude others from copying the bits), etc.Scarce objects are not a complete model of computation across trust boundaries. Indeed, there are many smart contracts that can be implemented with cryptographic protocols and/or secure hardware but not with scarce objects. What scarce objects provide is a straightforward basis for implementing, in an intuitively secure way, the anonymous commodity exchange economies formalized in microeconomics in a P2P fashion on the Internet.Another area important to scarce objects is in reasoning about supply chains. In distributed objects, the call graph is the supply chain. To stretch call graphs across trust boundaries, we must replace rigid client-server relationships with dynamically adaptable customer-supplier relationships. The ideal here is to create a rich toolset of exception handling across trust boundaries. Note that credit risks are a proper subset of supply chain risks. Ka-Ping Yee recently put the supply chain problem succinctly: \"be wary of return values from objects you don't trust.\"The scarce object architecture suggested here shares some things in common with capabilities, but it secures more kinds of resources and is far more affordable for users and programmers. Capabilities (along with ACLs) are a means of implementing access control. Access control simply deals with the first-level of issue of whether an entity has access or not to a given resource. If an entity has such access, this access is, as modelled or implemented by basic capabilities or ACLs, effectively unlimited in scope. Scarce objects, on the other hand, limit resource usage in three ways \u2013 first, by limiting the amount of resources used per invocation, second, by limiting the number of resources used per right (per ticket), and third, by limiting the number of tickets issued.A raw distributed capability system (i.e. what Mark Miller refers to as \"caps-as-data\", to distinguish from capabilities local to the TCB (\"object caps\") which have strictly stronger security properties) give out capabilities of infinite duration and unlimited invocations, cannot be considered to be a true principle of least authority (POLA) system. For an object reference to implement POLA, it must be finite in every dimension. A true POLA system never gives out more authority than is necessary and proper to compute the needed function. It is never either necessary or proper to allocate infinite resources, and usually it is not necessary to allocate large resources. The scarce object architecture is the first design for object systems to achieve finite authority, and to allow small allocations for objects that need only small amounts of resources. Scarce objects are thus the first architecture to make true POLA possible.Scarce object architecture depends on a distributed object architecture that makes minimal security assumptions. A good implementation strategy may be therefore to implement this model on top of E. No sophisticated use of its distributecd capability architecture need be made to securely distribute scarce objects; rather the resource-conserving features of scarce objects can be relied on for securing resources.A bearer right to invoke a scarce object method takes the form of a bearer certificate, or ticket. It can be generic, meaning a right to an N invocations of one of a set of similar or identical objects, or specific, meaning a right to invoke a particular object method in a unique way. Generic rights are fungible and can be transferred unlinkably, using Chaumian blinding.The general steps to build a scarce object are (1) define a normal object, then (2) wrap it in a layer that protects its public methods using tickets. Our sketch of the architecture here describes how this wrapping layer can work.The wrapping layer involves three different servers: a transfer agent (TA), a Provider, and an Issuer. The Issuer and TA operate like an accountless digital cash mint. The Issuer signs tickets. The TA clears the transfer of tickets for generic rights. Both the Issuer and TA have copies of the private keys (\"plates\") corresponding to each issue of generic right. A particular kind of generic right (e.g., a particular denomination of digital coin) can have multiple issues, usually ordered sequentially. Digital cash is a special case: money is the most generic of rights. Here is another example of a generic right, or class of fungible objects: \"A queriable SQL database with up to 10 MB of storage, and certain standard response time guaruntees\".It is a design option whether to combine the Issuer and TA into a single server (thereby reduce exposure of the private key) or keep them separate (thereby enable certain personell controls based on separation of duties). Distributed servers, described below, are an even better way to increase the trustworthiness of Issuers and TAs.The Provider is responsible for actually holding the object, which can contain unique state. It publishes a signed description of its scarce object method, describing a particular kind of generic right (e.g. in the form of design-by-contract pre- and post-conditions). The issuer and transfer agent then create plate(s) and prepare to issue tickets for the method.Any or all of these component servers can be distributed, using the methods described here and here. A distributed signature is used to issue tickets (M out of N must sign using a distributed private key for a verifiable signature to be produced). Such distribution greatly reduces exposure to breach of trust and thus lowers the mental transaction costs of reputation tracking.To implement exclusive transfers, the TA keeps a list of cancelled ticket numbers. A ticket is cancelled whenever it is transferred or used. The Provider instructs the TA when a ticket has been used, or alternatively they both write to a shared list of cleared tickets.The TA and Issuer see only classes of fungible objects. The Provider and users see particular instances with unique state. In the above example of a database generic right, the Provider sees a database filled with unique information while the TA and Issuer see only the generic description of the database object invocation methods.In contrast to the servers, the remote user of a scarce object wraps his object invocation stub with calls that trade for needed tickets (again using a market translator), send the tickets as needed with method invocations to those methods\u2019 Provider(s). In some (hopefully many) cases sufficiently identical generic services will be provided by competitors. Where this occurs a \"ticket client\" may also \"shop around\" in the sense that if the pre- or post-conditions of the method invocation fail, or if the invocation is otherwise detected as faulty, the ticket client will retry by invoking the competitor's method.The Provider server is almost just another ticket client to the TA, which like other clients can transfer or receive tickets. It special role is in informing the TA when tickets have been used thus should be cancelled (or, altrneatively, writing the cancelled ticket number directly to a list of cancelled ticket numbers that it shares with the TA). Only the Issuer can create tickets, and only the Provider can consume them.At the core of the Provider is the raw object itself, the set of methods that provide the defined services for scarce object clients. The Provider is the wrapper around this object. Besides its gatekeeping, ticket verification, and ticket consumption functions, the Provider can keep track of and inform the Issuer regarding resource usage.The Issuer in turn is the interface to the micromarket functions, especially the market translator described below. The Issuer may, for example, via a market translator, which incorporates the preferences of the person who operates the Provider, negotiate barter deals in which certain tickets are issued and exchanged for certain other tickets giving rights to invoke the counterparty's or a third party's scarce object methods. The negotiations might also be multi-party, i.e. auctions, and secondary exchanges for generic rights may also be developed for scarce object tickets. In turn, the market translator, to enable automated (low mental transaction cost) bartering operations, depends on the existence of reasonably liquid online exchanges of generic scarce object rights.The TA generates ticket supply only at the behest of the Issuer, and destroys it only at the behest of the Provider. All its own transfers conserve the supply of a particular generic right. The Provider is also responsible for the delivery of service to the client that satisfies the service description (contract, e.g. pre and post conditions), at which time the Provider \"deposits\" the generic ticket(s), i.e. adds them to the cancelled list.The Provider issues along with the initial generic rights ticket a signed affadavit, machine or human readable, describing aspects of the object which may be non-exlusive and unique, along with that instance's ticket number and the public key(s) of the generic right(s) for which it is valid. For example, it might say \"a database containing quotes of these two dozen listed stocks as of 12:22 pm Monday\", without actually containing those quotes. Often such description is worth more when bundled with generic exclusive rights, such as the right to a fast response time. The specific rights can elaborate in unique ways upon the generic rights, as long as these elaborations are not taken to define exclusive rights. The generic rights let the TAs garuntee exclusivity to users and conservation of resources to Providers, while the specific rights describe the unique state to any desired degree of elaboration. The Provider must be prepared to service any specific promise it has issued, as long as it is accompanied by the proper conserved generic tickets.This method of composing specific and generic rights, transferred as a bundle but with exlusive generic atoms cleared by different TAs, allows arbitrarily sophisticated rights bundles, referring to objects with arbitrarily unique state, to be transferred unlinkably. A wide variety of derivatives and combinations are possible. The only restriction is that obtaining rights to specific exclusive resources must either be deferred to the consumption phase, or transferred with online clearing via expensive communications mix.If the Provider wished to garuntee exclusivity to a specific right, transfer seems to require an expensive communications mix between Provider and transferee, rather than a cheap blinded ticket. For example, \"Deep Space Station 60 from 0500-0900 Sunday\" or \"a lock on autoexec.bat now\" demands exclusivity to a specific right, and thus seems to require a communications mix to unlinkably transfer. On the other hand, \"A one hour block on DSS-60 in May\" and \"the right to lock autoexec.bat at some point\" are generic and can be transferred privately with the much less expensive blinding, given a sufficient population of other ticket for this class of generic right transfered between the issuance and consumption of a given ticket.Clients can deal with the TA without a communications mix. They deal with the Provider via a communications mix. If both the initial and final holders failed to do this, the Provider could link them. If just the final holder failed to do so, the Provider could identify him as the actual user of the resource. Thus for full privacy generic transfers are cheap, and nonexclusive transfers are cheap, while specific exsclusive transfers and actually using the object seem to require the expensive communications mix.Here's a review of our architecture:Scarce objects, by creating a simpler and far more intuitive model of computation across trust boundaries, can make the distribution of objects on the global Internet a reality, just as the simplification of hypertext into HTML made the Web a reality.Click for larger versionThe mental transaction cost problem is one that underlies all markets \u2013 the mental effort it takes to shop \u2013 to map private preferences to prices to decide whether a bundle of rights is worth the cost. In particular this problem presents a severe barrier to micropayments and market-based resource allocation for networks and computers.The market translator is aimed squarely at solving, for the first time, this problem for Internet commerce. A market translator both enables and depends on online micromarkets to automate resource allocation among scarce objects. It will do so by enabling the following:The problem of \"translating\" between bearer contracts (which represent and secure rights to scarce objects) can be cast as a problem of translating between monetary currencies. For our purposes, a \"currency\" in a scarce object economy is simply any kind of bearer contract used for holding and transferring wealth, rather than for consumption by the holder. It is thus a \"collectible\" (or \"intermediate commodity\", to use Carl Menger\u2019s term). The market translator, incidentally, makes the O(n^2) prices in a barter economy, versus O(n) in a monetary economy, a far less important distinction.So let\u2019s look at currencies. Let's say small businessman Alice is negotiating cyberspace contracts with Bob, Charlie, etc. Typical of international contracts, terms can be denominated in a variety of ways. These are potentially unreliable: Joe-Bob's remailer postage, U.S. Federal Reserve Notes in their 1970s mode (or in 2003), Seychelles gold cache warehouse receipts, \"Asian Tiger\" currencies in 1997, and so on.Unreliable currencies can play havoc with:Each problem interferes with potential solutions to the other. On the one hand, picking one single best currency for all contracts concentrates risk. In some cases there is nothing close to a reliable currency, and in any case diversification is preferable. Without hedging Alice remains exposed to risks that more sophisticated traders can easily hedge.Another way of looking at it: there are no issuers in the world who are 100% trustworthy and 100% reliable. Lacking a security protocol to ensure that a currency retains its value, Alice needs risk management.On the other hand Alice, to plan her (personal and/or small business) budget and properly express her preferences, needs a simple, consistent long-term unit of account. Budgeting with a single fluctuating currency is bad enough, but if Alice denominates different expenditures and revenues in different currencies, her budget becomes an inconsistent mess. It's also unreasonable to ask a non-financial professional to worry about the finer points of exchange rates, hedging, etc.What is Alice to do? Old answer: Alice either hires, at a cost of both money and privacy, an accountant or financial planner, and may gain a few crude improvements. Mostly, she's out of luck: small businessmen have left most international trade to big corporations, whose finance officers partake in sophisticated hedging strategies.Proposed new answer: use a market translator to help Alice draft her contracts. This market translator should be useful for both normal law-enforced contracts and untraceable self-enforcing contracts, where the latter are feasible. In the following post I will sketch how a market translator can work.Automatic currency conversion, as done today by some credit cards and ATM machines, is a useful primitive kind of market translation. The casual reader (and user) can think of the market translator (MT) as a fancy kind of automated currency convertor, and get the basic gist of it. The MT serves to convert, hedge, and in general restructure the payment terms contracts negotiated in any manner.Our main novelty is to account for personal budgets, not in terms of any external standard of value, but rather in terms of personal accounting units (PAUs). PAUs correspond to what Alice can express of her personal utility. The MT determines Alice's static and and temporal preferences from the budget Alice already maintains (for example, her small business budget in Quicken). Additional preference specification forms may be provided beyond those of a normal budgeting program. For example, Alice\u2019s software preference settings, her behavior with keyboard and mouse, and similar clues might be usefully interpreted as economic preferences, for example with regard to where to allocate scarce screen real estate and network bandwidth.For convenience Alice's PAU might correspond to the local currency most commonly used by Alice. If most of Alice's budget items deal with online contracts negotiated via MT, then using the local currency is by no means necessary, and is undesirable if that currency is unstable.Here is a diagram showing Alice and Bob negotiating a contract using their market translators:One mode in which the MT can be used is to have Bob offer a take-it-or-leave-it binary contract, corresponding to the current retail practice of take-it-or-leave-it prices. In the mode pictured above, Alice and Bob negotiate back and forth. The negotation of the source contract terms will usually be manual. The \"source language\" will typically be a human readable GUI, while the \"target\" will be a standard formal contract language. If Alice and Bob can input preferences leading to automated negotiations, then a \"shopping bot\" and \"catalog bot\" respectively may be used. This is a layer above and beyond the scope of the MT. The MT is only a \"shopping bot\" in the restricted but important area of contracts composed of atomic bearer contracts \u2013 rights to scarce objects \u2013 to the extent that the price relationships between these bearer contracts are available from quoted markets.The MT acts like a computer language compiler. But it translates both ways, and in real time as Alice and Bob negotiate payment terms. So, for example, Alice changes a term in her contract, proposing to pay fewer Alice-PAUs for Bob's services. Her MT translates this into a series of payments and hedges: a sophisticated synthetic contract as obscure to Alice and Bob as binary code is to many programmers these days. This synthetic is constructed out of liquid market securities (bearer contracts) and derivatives of low transaction cost. A synthetic contract is naturally represented as a composite object, a part-whole hierarchy composing primitive contractual \"atoms\", such as securities and derivatives.Bob's MT reverse-translates the actual market terms into Bob-PAUs. Although they each agree to different looking amounts of payment, the visible structure besides amounts and the complete underlying contract is the same. They can be confident that when their preferences have been satisfied, their minds have met and they can commit to the contract.As a result, both Alice and Bob see the contract in terms of their own consistent personal utility units. All consideration of exchange rates, inflation risks, and so on is handled by the MT.Alice and Bob's MTs can make side conversions, hedges, and restructurings to balance their portfolios. These side hedges are not revealed to each other. Any binary terms which can be side hedged can be made almost arbitrarily distant from what Alice and Bob prefer financially. Thus Alice and Bob need not reveal their financial preferences to each other.(Note: For contracts with delayed payment terms, Alice and Bob determining the credit risk caused by each others' credit exposures is an important problem, but beyond the scope of the MT as I have described it).The whole set of Alice's contracts with all her counterparties constitutes her complete portfolio \u2013 not merely a segregated investment portfolio, but a complete portfolio encompassing all her finances. This portfolio is is represented as a composite of composite contracts, and forms the basis for all of Alice's financial planning, and for the automated portfolio rebalancing activity of the MT.The main data structure representing the contracts for analytical purposes is the chance/choice decision tree. This tree has two kinds of nodes, \"chance\" nodes which iterate through all material possibilities, and \"choice\" nodes where the optimal choice is made. The result is the expected value of a set of contractual terms. The trees can represent a large number of contracts with low resolution (lots of pruning and heuristics), or a simple contract with high resolution (all possibilities considered). Desktop computers are or will soon be fast enough to search through thousands of contingencies, and synthetic contracts composed of hundreds of atomic contracts, with delays less than Internet latencies. So the binary contract can be a very sophisticated synthetic, as long as its analysis is fully automated, and still conserve mental transaction costs.The MT relies on online, automated exchanges hosting liquid markets for fixed income securities and derivatives. These markets reveal the information the MT needs to properly hedge currencies. Market makers and arbitrageurs maintain these markets, ensuring the most accurate information on risk premiums, yield curves, and so on is available to MTs. Some information not automatically derivable from market prices might be made available online by financial consultants, in a standard format, downloadable by MTs for a fee.The source contract is normally negotiated and closed manually, as per normal shopping. The MT is a a \"shopping bot\", but only in the very restricted but important realm of finance related to payment terms. Sincethere should be no need for manual intervention in the hedging translation process. If such manual intervention is required, the system very quickly loses its appeal for most users.If the preference or market information is not available, or the securities and derivatives exchanges are not available, the market translator can revert back to simple automated currency conversion.The market translator thus solves a vexing problem faced by multinational small business, the hedging of payment terms using potentially unreliable currencies. More generally, the market translator built on a scarce object architecture will lower the mental transaction cost barrier to micropayments and micromarkets. It will translate skills and preferences into microrights and microduties for use in fine-grained allocation of resources and services \u2013 whether online e-mail accounts, online game collectibles, screen real estate, network bandwidth and caching, or a variety of other network objects which, thanks to scarce object architecture, become economic objects."}
{"prompt": "The Geodesic Market", "completion": "\u201cThe path-breaking work of Robert Hettinga was published in a series of newsletters issued by FT Virtual Finance Report during 1998-1999. Bob is well-known for starting the famous e$ and e$pam mailing lists, to which I was an early subscriber, and as the founder of the Internet Bearer Underwriting Corporation (IBUC). Along with fellow privacy stewards, Vince Cate and Ray Hirschfeld, he launched the world's first conference on financial cryptography, FC97, on the island of Anguilla.\u201dSince the invention of the telegraph, financial transaction settlement has had a problem: how do you transact business at a distance when the simplest way to execute, clear and settle a transaction is with an exchange of bearer certificates?Our current system of so-called \u2018book-entry\u2019 transaction settlement was invented in order to handle the problems caused by remote transaction execution and the subsequent need to physically exchange bearer certificates for settlement. We now have the means to return to \u2018digitally encoded\u2019 bearer settlement with a three orders of magnitude cost saving.Soon enough, the era of book-entry settlement, our way of representing money as offsetting debits and credits exchanged between the two parties of a trade through a hierarchy of trusted intermediaries, will be over.I think that the social and economic impact of the new alternative to book-entry settlement, digital bearer settlement, will be quite large, because, at the root of the status quo\u2019s book-entry transaction protocols is the need to involve government and regulation at the most intimate levels. Essentially, \u2018\u2026and then you go to jail\u2019 is the penultimate error-handling step in a book entry transaction.In the old days, before telegraphy, most financial transactions were done by trading bearer certificates, or tokens, of one form or another. Exchanging cash for a bearer bond would be a good 19th century example. Even trading bearer forms of equity was trivial and instantaneous: the offer, the acceptance of the offer, and the settlement of the transaction occurred almost all in one operation.With the advent of telegraphy and eventually telephony, it was possible to make the offer and accept the offer at a distance, but settlement had to wait until bearer certificates were physically relocated, sometimes over long distances and then exchanged. After all, you couldn\u2019t very well send them over a wire.The solution was to move all the certificates to a central trusted location, called a clearinghouse, and for the trading parties to swap debits and credits between themselves and the clearinghouse. It\u2019s pretty apparent that having the certificates physically locked down in the clearinghouse\u2019s vault becomes superfluous in such a scheme, because what really matters is the impartial arbitration of the clearinghouse in the case of a transaction dispute. All except for one thing. If someone lies or reneges on a book entry transaction, there isn\u2019t much that the other two parties can do except bar them from trading, which, of course, works in bearer certificates, but not nearly as well in book-entry settlement.So, we need several things to cope with nonrepudiation in book-entry settlement. First, we need the ability to determine who physically made what book-entry so we can find them and send them to jail for fraud if necessary. That\u2019s because book entries are inherently unstable, insecure, digits sitting in a database somewhere. Many people in Asia are familiar with commodities and derivatives traders who were capable of hiding fraudulent book-entries for long enough periods of time to bring down their respective firms, for instance. In cryptography we call this an authentication problem.So, besides authentication of the book-entries themselves, we need to secure the links between various charts of database accounts, first by authenticating the users of those electronic links, originally with passwords, then with cryptographic keys and signatures, and now with some combination of biometrics (finger or retinal prints, say) and digital signatures. And, second, by actually encrypting the links themselves so that no one can see what they are even if they can\u2019t change the authenticated data without someone noticing.Sorry for the long-winded explanation, but it\u2019s long-winded stuff, as most people who clear trades on the net for a living will tell you. Anyway, for all intents and purposes, you now know everything there is to know about the guts of electronic commerce on the Internet. When you punch your credit card number into a secure web page, pretty much all of the above happens, plus or minus the retinal scan.However, all this stuff about moving book-entries down encrypted pipes on the internet, including the much-heralded SET protocol for credit cards, is so much financial \u2018shovelware\u2019.Fortunately, there is much more that can be done with financial cryptography. There\u2019s a whole string of cryptographic protocols out there, beginning with David Chaum\u2019s blind digital signature patent in the middle 1980\u2019s. You can actually create unique digital objects which can\u2019t be forged if you handle them right (if you only exchange them on-line, for instance). You can attach any arbitrary financial value you want to these cryptographically secure objects as long as everyone else agrees with you, and, most important, you honor your agreements concerning their exchangeability into some other financial instrument. So, I call these objects \u2018digital bearer certificates\u2019, after the paper bearer certificates of yore, which I claim these crypto-blobs behave like, more or less.The fun part comes when you actually start to trade these things. The first thing you notice is that they settle instantly. I give you digital cash certificates, you give me digital bearer bond certificates. Trade over. Elapsed time, thousandths of a second. I can turn right around and take that bearer bond and sell it again, if I want. More to the point, I don\u2019t have to wait for my broker work out how to move my money to your broker through the clearinghouse, for their banks to arrange to pay each other, all of which takes days and costs lots of money. The cost of your on-line Schwab or E-trade transaction could move from being measured in dollars to somewhere in the sub-penny range, and probably less over time.Actually, these aren\u2019t account based protocols at all. So there ain\u2019t no Schwab, or Merrill Lynch, or Morgan Stanley, required. Well, not completely true. You still need financial intermediaries, no matter how small, to \u2018rent\u2019 reputation to a given transaction.As far as non-repudiation goes, I know that what you gave me is real because I can test it with the issuer. You can do the same thing. It\u2019s so trivial that I equate the act with the physical inspection each of us does, unconsciously or not, when we\u2019re handed a piece of cash. If I don\u2019t like what I \u2018see\u2019 (determined by the calculation of the cyptographic protocol, of course), I don\u2019t trade with you. I\u2019d say it\u2019s much better than detecting fraud after the fact, finding who made the offending book-entry, and apprehending, trying, and jailing the miscreant. Frankly, I\u2019d go one further and say book-entry settlement is so complicated and unwieldy that the only reason we have book-entry settlement now is because we couldn\u2019t shove paper down a wire back when telegraphy was invented.Finally, there\u2019s no real recordkeeping of transaction logs with digital bearer settlement. Like a pile of cash, you count it up, and that\u2019s what you have. There is no need for seven years of audit trails at up to six different transacting parties because you don\u2019t have to hunt someone down and send them to jail for reneging on a trade before it settles, and more frequently, to prove you\u2019re innocent should you be suspected of something untoward. You don\u2019t need a lawyer or an accountant to keep you out of jail at tax time for making the wrong book entry somewhere.In fact, you don\u2019t care who gave you what money as long as they\u2019re happy with what you gave them in exchange for it. Reputation becomes the most important thing there is, because damaging someone\u2019s reputation is your only recourse in a world where your digital signature is your only identity. The threat of blackballing is in fact a very effective fraud deterrent, and once a digital reputation is trashed, it takes time and higher transaction risk premia to build a new one. To quote J. Pierpoint Morgan on the subject, \u2018I wouldn\u2019t buy anything from a man with no character if he offered me all the bonds in Christendom.\u2019Once we get to digital bearer bonds, stocks, and derivatives thereof, the world starts to change considerably. However, I still claim that reality is not optional. If you reduce the cost of settling a transaction to effectively zero (okay, past the last basis point but not zero), then the financial markets are going to figure out how to use the technology. Not only is it cheaper, but by being cheaper, it allows for smaller and smaller publically held entities. And automated financial intermediaries. The asset sizes of various trades could get much smaller, but, in addition, I claim, that because trading of financial instruments can happen so quickly, efficiently, and by so many self-interested actors, it\u2019ll probably be the way money is raised for very large security issues and for very large projects. Maybe Intel\u2019s inevitable $10 billion chip fab, for instance, will be floated into a market \u2018swarm\u2019 of financial intermediaries. Microintermediation, instead of disintermediation, in other words\u2026Okay. I\u2019ve now walked you up the edge of the abyss, and pushed you over the cliff, and, you\u2019ll notice, you didn\u2019t get hurt at all. That\u2019s important to think about, because sometimes being quantitatively cheaper has qualitative effects, but, for modern society at least, the future is no different from the past, except that we\u2019ve figured out how to live better. I expect if we can blow the doors of the cost of financial services with digital bearer settlement, the world will be a much better place to live in, indeed.Back to table of contentsWhen I\u2019m working on a problem, I never think about beauty. I think only how to solve the problem. But when I have finished, if the solution is not beautiful, I know it is wrong.This is the first of a series of articles Duncan Goldie-Scot has commissioned me to write on the future of financial technology in an age of ubiquitous internetworks, Moore\u2019s law, and strong financial cryptography.I\u2019m calling this series The Geodesic Market, in the spirit of a \u2018popular\u2019 book I\u2019ve in the works named, oddly enough, Beyond Civilization: Life in a Geodesic Society. Actually, the core technology we\u2019re going to talk about is a group of financial cryptographic protocols I have termed digital bearer transaction settlement, which is the title of another book I\u2019m working on.When I was a teenager in the 70\u2019s, my best friend Jeff Blanton and I zealously devoured all of Stewart Brands\u2019 Whole Earth \u2018Domebooks\u2019. Back in 1974, when capitalism was the farthest thing from our mildly drug-addled minds, who would have thought that \u2018Bucky\u2019, R Buckminster Fuller, the greatest designer since Leonardo, we thought, had discovered not just an easy way for freaks like us to build cheap housing and squat on someone else\u2019s land, but that he had actually discovered the way that society, mapped as always to our communication topologies, would look in the not too distant future.Buckminster Fuller, for all his latter-day attempts to solve global resource allocation by good old fashioned top-down hierarchical industrial centralism, might not have imagined that the economics of semiconductor switching on telephone networks would eventually create giant, decentralized, capital markets. Markets so powerful that they would make the most out-of-control, rapacious 19th century industrial trust look like the most bucolic feudal guild. On a feast day. With their feet up. Capital markets operating on a network topology almost identical to the geodesic structures my friend and I were all so enamored with back in the days of the Allman Brothers, Levi\u2019s Big Bells, and ubiquitous low-yield psychochemicals.Even more ironic, you and I are going to raucously cheer these new geodesic markets on, as they surfact large concentrations of financial information and capital into fractally smaller and smaller bits, microintermediating it all like so much grease in soapy dishwater, in an instantaneous transnational market for capital. We\u2019re going to cheer these new markets on because they\u2019re going to make us so damned much money.These market will operate, finally, under the control of economics, instead of the confiscatory \u2018policies\u2019 of aristocrats or nation-states. Nation-states will eventually be as ceremonial as modern-day constitutional monarchs. Like the way physics and philosophy got out from under theology at the end of the dark ages, economics will no longer be the handmaiden of politics in a geodesic market.The fun part is, it\u2019s inevitable. It will come from the collapse of microprocessor prices, the 50% decline every 18 months that is Moore\u2019s \u2018Law\u2019, more an observation of the human ability to learn than any physical law. The geodesic market will come from the ubiquitous geodesic internet those prices create, and, in a remarkable reversal of history, a reemergence of the kinds of transaction settlement methods thought to be killed by the telegraph, and, ironically, mainframe batch computing.A geodesic market will use digital bearer transaction settlement protocols, perfect pseudonymity, and reputation sanction on ubiquitous public networks, instead of book-entry settlement, audit trails, and la, on the closed, private networks that we now have.Stunning? Outrageous? Preposterous? Before you click away in disgust, remember we only have what we use now because it was cheaper than what we used to use. Hence you and I don\u2019t go down to a bunch of merchants in the City to trade paper cash for paper shares anymore. I am perfectly serious. With financial cryptography and digital bearer transaction settlement, we can do perfectly safe, rational business on the internet without lawyers. Or, for that matter, cops.In addition to transaction costs three orders of magnitude cheaper than book-entry settlement (yes, past the last basis point: it\u2019s time to pick a new measurement unit), you will have perfect financial privacy as a happy accident of the same technology which drastically reduces transaction prices. Just like requiring the privacy-invading physical force of a nation-state in our very transaction clearing processes was an unhappy accident of book-entry settlement.All of this will happen with more non-repudiation and more asset safety features, including seemingly impossible things like limited liability and shareholder voting.The reason we have database marketing, book-entry taxes, (like income, capital gains, value added, and sales taxes), and book-entry regulations, (like, well, practically all regulation, these days), is because the book-entries are there.We need those book-entries in order to prevent repudiation of transactions. And, to enforce rules against a transaction\u2019s proven repudiation, we need the police. So, if you don\u2019t need book-entries, you can\u2019t have that other stuff, including, as Doug Barnes of C2NET likes to say \u2018\u2026and then you go to jail\u2019 as the error handling step in your transactions protocol.Impossible? If we can do digital bearer transactions, safely and anonymously over the internet for, say, 1000 times cheaper than book-entry settlement, what do you think will happen?As a brief preview, let\u2019s take a look at the things you can do with digital bearer settlement. Not surprising, it\u2019s everything you can do with book-entry settlement, and more.Consumer Debt: Instead of using a credit card, imagine issuing personal bearer bonds. Whole bond issues, actually. Microintermediated, by, you guessed it, a syndicate of micro-underwriters, living in the ubiquitous internet, all of whom, like under- writers always do, intermediate the market\u2019s loan of money to you based upon your reputation for repayment.Digital Cash: Since most people pay off their credit card purchases within a month after purchase, you will be relieved to know that instead of having to hassle with a credit card bill just to cover your normal monthly purchases, and the lack of privacy which goes with it, you will be able to use digital bearer cash, which will be as safe to use as checks or a credit cards are now, all without interest, or at least annual fees.The main reason you\u2019ll use digital bearer cash is, however, that eventually there\u2019ll be no float on your checks or even your credit cards. Notice how debit cards are cheaper already to use than credit cards, and that merchants are starting to see the advantages of getting their money without chargebacks hanging over their head.This is so fundamental a process that it should be a law of finance or something: the closer an electronic book-entry transaction system gets to instantaneous, the more digital bearer settlement becomes financially necessary. As a friend at a large IT consultancy in Cambridge (Massachusetts) likes to say, \u2018Real-time gross settlement is digital bearer settlement.\u2019Capital Markets: Instead of purchasing a stock through a broker with limited, hierarchical, almost oligopolistic access to the capital markets, you\u2019ll be able buy your digital bearer bonds or shares in public, or at least privately, using public networks. The internet is the equivalent of the old buttonwood tree on Wall Street, as I once wrote in Wired. I show up on the net with cash, you show up with your bearer shares, we exchange the two, and the trade is over. Execution, clearing and settlement, all in one step. Anonymously, because it\u2019s cheaper. That\u2019s the beauty of digital bearer settlement. You can do this for any financial instrument, debt, equity, or derivative.Internet Resource Allocation: Also, there are the things you can do with digital bearer settlement that you just can\u2019t do any other way. It\u2019s easy to imagine very small packets of digital bearer cash \u2018buying\u2019 a message across the internet, with each router buying packet switching low, and selling it high. Look, Ma, no human hands: No \u2018peering\u2019 arrangements, probably no network \u2018engineering\u2019 either, in the long run, as the internet becomes, like any free market, a complex self-adaptive system. I joke about \u2018picomoney as processor food\u2019. \u2018Micromoney mitochondria\u2019. Auction markets for bandwidth, certainly. Maybe for the guts of the machine itself, memory and processing time. All you need is Moore\u2019s Law, fast enough processors, and, of course, digital bearer financial cryptography protocols.Utilities: But, wait, it gets worse. You can pay for electricity, in cash, as you use it, down, of course, the same wire you got the electricity from. You can pay for roads as you use them, perhaps every few hundred yards or at every intersection. Like you can on the internet, you can pick the cheapest or fastest route to your destination. So much for \u2018public\u2019 roads. Just about everything you think of as a \u2018public service\u2019, or a \u2018natural monopoly\u2019 may be reduced some day to a continuous cash-settled electronic auction between competing parties. Moore\u2019 s law creates diseconomies of scale and geodesy. Hierarchy and economies of scale are a function of expensive (human) information switching.Geodesic Warfare?: Even force can be auctioned off and sold, same as it ever was, only this time to the highest microbidder. Imagine your land covered with semiautonomous landmines, keyed to your digital signature, which only go off when you tell them to. No, don\u2019t imagine them taking bribes to change sides. It\u2019s real. Someone at the US Army War College wrote a paper on just such a scenario four years ago. Of course, whether we\u2019ll need state-funded armies in a world where force has been disintermediated to such an extent or where taxes might be \u2018optional\u2019 is an entertaining proposition.So, who knows what the future\u2019s really going to look like. I may almost have my videophone now, but I have yet to see a (useable!) flying car, for instance. However, there\u2019s one thing we can be certain of. Information and knowledge will be developed and sold in much cheaper and smaller bits than we do it now. The prices for industrial goods will fall in a geodesic economy just like agricultural goods and raw materials did in the industrial economy.Just how far it goes is limited by Moore\u2019s Law. Moore\u2019s Law also enables the ubiquitous use of cryptographic financial protocols, like Chaum\u2019s original blind signature algorithm for digital bearer certificates, or the one for Rivest\u2019s MicroMint micropayment protocol.This series of articles is about how those markets, well capital markets, will come to be, how they will operate, and what actors will probably succeed in those markets.Next month I\u2019ll discuss geodesic networks and why I think they create geodesic social institutions like geodesic markets, how trade and money, how human society itself looks when viewed historically through the lens of their communications architectures. Then, I\u2019m going to talk in laymen\u2019s terms about the financial cryptography underpinning digital bearer transaction settlement, and then survey some of the different kinds of digital bearer settlement protocols on the market and in the labs at the moment.After that, I\u2019m going to apply these different protocols to different pieces of the capital markets we now have, and show you what the world looks like in a geodesic market for capital.Back to table of contentsIn this second instalment of the Geodesic Market, I\u2019m going to show how to underwrite digital bearer securities, using cash as an example.The business model I\u2019m using should be familiar to anyone who\u2019s been in the securities business for more than 20 years, and especially to anyone who\u2019s studied financial history. There\u2019s no surprise in that. We have 5,000 years of experience with bearer transactions. There\u2019s nothing new, except the cryptographic protocol, to worry about, and we\u2019re not going to talk about cryptography here in any detail.Another nice thing about this model as applied to cash is that it will be possible for people to convert their money to digital cash in and out of their own bank accounts, just like they can for paper cash. The underwriter, as I call the issuer of digital cash, becomes the internet equivalent of a third-party ATM machine, something everyone\u2019s familiar with.Because of this modular plug-and-play approach, it\u2019s pretty simple to obey all the rules we currently have about handling cash, while dramatically reducing the cost of cash transactions in the process.So, let\u2019s get started with a look at the players in this market.A consumer is someone who buys a piece of digital cash from a financial intermediary, an underwriter, in exchange for some other kind of money, a change in a bank account balance in this case, in order to effect a transaction on the net.A merchant is someone who accepts a digital bearer certificate in payment for something else.Of course, I hate the use of the words consumer and merchant because they don\u2019t describe geodesic peer-to-peer transactions very well, but the banking world understands them perfectly, like they do underwriter or trustee or custodian, so I use them here.The underwriter issues digital bearer certificates, and is fiduciarily responsible for exchanging them into other forms of money, again a bank account balance change, held by a custodian in a reserve account. Someday, of course, the reserve assets collateralising an issue of digital cash could be some other digital bearer asset.The second most important thing an underwriter does is to verify, at every transaction, that a given digital bearer cash certificate hasn\u2019t been double spent, copied by someone and spent twice. After that, the underwriter issues a brand new signature- blinded certificate to the person accepting the cash in payment. If the exchange fails at any point, so does the transaction, and the person offering the cash is prevented from double spending it, thus preventing repudiation of the transaction at execution time. Cheques, credit cards, or any book-entry transaction can\u2019t offer that security. Even with on-line validation for fraud, the merchant is still at risk of stopped checks or chargebacks.Finally, the most important thing an underwriter does is to market its certificates to the world. Which, if you look at an underwriter in the capital markets, is exactly what they do for both primary and secondary transactions, and that\u2019s why I use the label here.The original DigiCash ecash mint at Mark Twain Bank was a used 486 machine, just to give you an example of the hardware cost of being an under- writer. Eventually underwriting may be automated to the point of processor husbandry in the same way that one tends a web or router farm today, but it should always be done by a separate financial entity other than the trustee.A trustee, or custodian, holds the money reserving an issue of digital cash, on behalf of the cash certificate holders, in a bank account, though someday the reserve assets could be held in bearer form under the trustee\u2019s control. Like bond trustees or mutual fund custodians, the trustee operates according to an agreement, like a bond debenture, between the underwriter and the certificate holders. This agreement could specify fees and, most important in the early adoption process, reserve ratios.So, while the underwriter is the direct financial intermediary, and keeps the interest which accrues on the reserve account, the trustee risks their reputation by holding the reserves, is compensated for it, and controls that risk by making sure that the reserve agreement is adhered to.Put simply, there is no way to to get exchangeability of digital bearer securities into book-entry assets without a genuine, fully regulated trustee/custodial bank, which, in my opinion, is why we don\u2019t have internet digital bearer settlement today.The holders of the blind signature patent, and other protocol inventors, have a hard time understanding this. DigiCash, as the canonical example, will only license their patent to a single bank in a single country, and not to any one else, forcing the trustee and underwriter to be the same entity, creating a very brittle and not very robust network of financial entities. The result has been market failure, for the most part. Having a competitive, many-to-many, underwriter/trustee market system fixes that problem completely, as we\u2019ll see in a bit.For all intents and purposes, the consumer, merchant, underwriter and trustee are really all the financial entities necessary in a market for a digital bearer instrument.There are other entities required to make this work, of course. There are developers of the software for that market and, most important, the inventors of the financial cryptography protocols, like David Chaum, Mark Manasse, Stephan Brands, Ron Rivest or Ian Goldberg.Developers can either sell their software directly to customers or merchants, or they can sell servers to the underwriters and the underwriters can give away clients to their users.Inventors can license their protocol to the market as a whole through the trustee. This way, trustees can take royalties out of a percentage of the underwriters\u2019 interest earnings on the reserve account, or from the fees charged when some other asset is converted into the bearer instrument in question, or some combination of both.With book-entry or bearer-collateralised trustees, this rewards innovation cheaply and easily. You don\u2019t even need patents to do it. Even with bearer-collateralised trustees, the inventor of the protocol still gets paid, no matter who or where he is. This, among other things, is part of the judge role I was talking about above. The trustee, who\u2019s in business to be fair and impartial, loses reputation capital otherwise.The consumer buys, from a software developer, or is given, by an underwriter, a wallet: a client application which allows the storage and disbursement of digital bearer certificates. Wallets will probably be specific to the cash-protocol used, and not to the underwriter using the protocol.With a wallet installed, maybe as a browser plug-in, the consumer goes to the underwriter\u2019s secure web page. The consumer enters, either by swiping a card or emitting stored information on her hard drive, the account and PIN number for her bank account just like she would at an ATM. The consumer\u2019s account information is probably blinded, so that not even the underwriter, or even the trustee, sees it as it goes through the trustee and onto the ATM network for authorisation.The consumer\u2019s bank sends an authorisation message back to the trustee, who notifies the underwriter of the reserve account change, who in turn disburses digital cash certificates to the customer in the amount of her request. With the exception of the issuance of digital bearer cash instead of paper cash, this is roughly what happens with a private ATM machine.This is all done for whatever fee the underwriter charges, in the same way traveller\u2019s checks are sold at a premium at the time of sale, or that a foreign ATM machine charges for non-customer transactions. In fact, redeeming it off the net at par like a traveller\u2019s cheque, and exchanging it free for other digital bearer cash online is probably fundamental for merchant acceptance.The consumer then uses the new cash to buy something from a merchant on the net. In theory, a merchant could do offline transactions, without involving a direct exchange and replacement of certificates from the underwriter, but they\u2019re ridiculously insecure from the standpoint of double spending.This exchange of certificates, this printing of new certificates at the time of each transaction, is still orders of magnitude cheaper than book-entry payment methods, and, since it\u2019s blinded by cryptographic protocol, the transaction retains its bearer quality. That is, the asset changes hands anonymously (on the net at least), it exists in only one place at one time, and the only proof required for non-repudiation is the certificate itself. Just like dollar bills, only three orders of magnitude cheaper than an internet debit or a credit card transaction.With the transaction over, the merchant can instantly spend his newly minted cash certificate somewhere else, this time for free, because the longer it stays on the net, the more interest it earns in the underwriter\u2019s reserve account, all at minimal cost to the underwriter.Or, the merchant can turn around and redeem the certificate at par through the underwriter, who in turn has the trustee clear the money through the ATM system to the merchant\u2019s bank in the exact reverse of the process which got the money onto the net in the first place.Notice, for the first time, it is technically possible to use the ATM system for a cash deposit from a foreign bank, in this case, from the trustee, on behalf of the underwriter, to the merchant\u2019s bank account. Finally, notice that, since the wallets will probably be free, anyone can get paid in cash over the internet. They only need a bank account to put money on the net or take it off, important in the early stages, but not nearly so as time goes on.It should be obvious by now that we\u2019re looking at a classic case of Metcalfe\u2019s Law. The more entities there are in this market\u2019s network the more robust and valuable it is.The model gives us a many-to-many universe of interdependent underwriters, trustees, software developers and protocols, all in competition with their peers to offer the best price, collateral, reputation, quality of execution, and so on. The idea is to create a ubiquitous geodesic capital market composed of efficient, instantaneously cash-settled auctions of fungible, non-branded, risk-graded, digital bearer financial instruments.The other thing the model creates is something I call microintermediation. Because of the information processing diseconomies of scale in Moore\u2019s law, we have lots of small, automated financial intermediaries, each one operating directly between a given buyer and seller. This, I believe, is the logical outcome of financial disintermediation, which, until now, has been about removing multiple intermediaries between a buyer and seller. As we\u2019re starting to see in the internet search engine market, we\u2019ll start to see a speciation of financial intermediaries, by financial instrument, risk, etcetera, all brought about by Moore\u2019s law. After all, no single processor in a geodesic network can handle all the traffic.Note also that everyone who puts money on to the net or takes it off is identified to the complete satisfaction of government regulators everywhere. Digital bearer cash is treated just like physical cash in the eyes of regulators, and is subject to the same regulations. There is no functional difference between a digital cash underwriter and an ATM machine. And, yet, on the net itself, transactions are perfectly anonymous.This is the ultimate paradox of digital bearer settlement. The transaction protocols are so strong cryptographically that you don\u2019t need identity to keep your trades from breaking. More to the point, you don\u2019t even need biometric identity to prevent fraud. A digital signature is persistent enough to actually attach a reputation to.We\u2019ll talk more about this, and about digital bearer bonds, next month.Back to table of contentsIf you read the last instalment of The Geodesic Market, you now know how to put digital bearer cash on to the net. Of course, you can put every type of financial instrument into digital bearer form, and this month we\u2019re going to look at debt, which is the simplest extension of the cash model I showed you last time.Of course, to issue debt, the borrower (or any other market actor, of course, except secondary buyers and sellers) needs a good reputation, and we\u2019re going to talk about that first.With much fanfare, I now trot out my favourite quote from J Pierpoint Morgan, the last major denizen of the bearer-settled financial universe.At the time he uttered this pearl of financial wisdom, Morgan was more or less on his deathbed, and was literally hauled in front of the US Congress to testify before he died.So, imagine yourself there, in a congressional committee-room in 1913, (one year after 1912, the year libertarian columnist Vin Suprynowicz says was the high water mark in American liberty) and there you are, looking at the only man in history to refill Fort Knox with the proceeds of a typically-oversubscribed European bond issue on the strength of his signature alone, after this very same Congress had spent that treasury empty in the first place.A man who single-handedly stopped several bank panics, one of them by while playing solitaire in one room of the Morgan Library, with a roomful of bank presidents arguing in the room across the hall, shuttling occasional proposals to him for his hoped-for approval over the course of a few days, all while Wall Street held its breath.A very old man, now. An old man, being commanded, upon contempt of the best Congress money could ever buy before or since, to tell them the ultimate secret of banking. The most important thing a banker had to have to succeed.Is it the right, um, \u2018family background?\u2019 they seem to ask this paradigm of New England WASPiness. The right school tie? Never mind that Morgan was tutored for the most part. The right secret society membership? Of course, Morgan wasn\u2019t much of a joiner, except that he ran the board of trustees of his church, and that of the Metropolitan Museum of Art, like he did the rest of his enterprises, with an iron fist.Morgan just scowls at them. His answer is very simple:\u2018Character.\u2019Our would-be congressional inquisitor was probably dumbstruck. He was surely some loutish turn-of-the-twentieth-century urban machine politician, or maybe a rural silver-shoes-on-yellow-goldbrick-road bimetal free-silver populist in extreme Dorothy-Gone-to-Oz Mode.Whatever he was, he was almost certainly hoping for a financial conspiracy story of Bilderburg proportions to put into the next day\u2019s muckraking headlines. And, I bet, this modern Torquemada couldn\u2019t believe his ears.\u2018Character?\u2019, he sputters. Like he\u2019d never heard the word before.Morgan puffs himself up to his full 5-foot-rotund-something, gives the man one of those famous withering glares over a rosacea-mangled nose.\u2018Sir, I wouldn\u2019t buy anything from a man with no character if he offered me all the bonds in Christendom.\u2019Parsing that language to account for, um, \u2018late nineteenth-century Episcopalian sexism\u2019, we get as clear a definition of the enforcement power of reputation as has ever been stated this side of \u2018Caveat Emptor\u2019.In other words, if you lie, I don\u2019t do business with you again. Ever.And, in the world Morgan found himself in, that kind of financial shunning was pretty much all anyone really could do.It was really ever thus, throughout the history of money, much less finance. Sure, you could go to your friendly local force monopoly, be they monarchical, tyrannical, empirical (in the manner of Napoleon, not Hume), or oligarchal (or, even, democratic, on extremely rare occasions), and you could try to get them to beat up someone who ripped you off. But, usually, that was way too much work. Said regional force monopoly had to actually find this person, and then apprehend, try and convict him, and, frankly, more likely than not, he\u2019s changed his name and venue and spent the cash you paid him for those bogus bearer bonds you\u2019re now holding, and, well, so sorry, sir, but them\u2019s the breaks.And so, to sanitise and paraphrase the immortal Bluto Blutarski of \u2018Animal House\u2019 fame, it was actually you who screwed up: you trusted this brigand to begin with. You believed he had character, a good reputation, in other words, and it turned out that he didn\u2019t, at all.This was true up to and including J Pierpoint Morgan\u2019s day, where, although you could use a telegraph to execute a trade on the New York Stock Exchange floor, you still had to bring in actual paper and swap it for some other actual paper to clear and settle the trade.Yet, oddly enough, reputation sanction, plain old fashioned shunning, worked just fine for over 5,000 years. Marvellously well, in fact.Though, we now know what happened to J Pierpoint Morgan\u2019s tidy little financial universe of men with good character. Tabulators and comptometers begat computers, and, next thing we know, we\u2019re all using wires and computers to move accounting entries around, my debits for your credits, and bang, financial transactions execute, clear and settle more or less electronically, modulo a tape swap and a batch job or two.And, now, all I need to buy something over the internet is to give you a credit card account to take the money out of, and, maybe, but not necessarily, a cryptographic authentication (obviously, I hate the current misuse of \u2018signature\u2019, much less \u2018certificate\u2019) to prove that it was I who told you where the account with the money in it was.Yet, there\u2019s a little problem with book entry settlement and clearing, and it involves that force monopoly I was talking about.When we have to make copies of our transactions and give them to a \u2018trusted\u2019 third party to keep us from lying to each other, that\u2019s pretty awful, and not only from the standpoint of simple privacy.More important, there\u2019 s something particularly insidious to freedom itself about just shoving around debits and credits, instead of physical objects, or, now, digital objects, when you pay for things or convert one asset into another.With book entry settlement, you have to keep a virtually perpetual audit trail, so that on a \u2018syntactic\u2019 level, you can prove the trade happened some indeterminant date in the future, and so you can prevent the other party from denying (that famous legal double-negative, \u2018non-repudiation\u2019) the trade ever took place. And, once you\u2019ve done that, it\u2019s real easy to use those records to call a cop and send that person to jail. Actually, you\u2019re forced to, for any of a number of reasons, not the least because the clearing/settlement lag is such that someone might have absconded before you knew what happened to your money, and giving the clearing house physical enforcement capabilities in meatspace would make cause undue competitive pressure on the sovereign\u2019s monopoly on force.Now you can see why book-entry transaction settlement requires very strict biometric identification for anyone who changes the book-entries themselves, or even those who order book-entries to be changed. Everyone else (us customers, in other words) must deposit in advance of any significant financial activity, as sort of hostage capital to whatever transactions we execute.Everyone under the jurisdiction of the SEC has their fingerprints on file, for a reason, not to mention their current name and address. Enough information to drive a totalitarian tyranny through, frankly.And, so, the real reason governments have grown to control such an increasingly huge part of our lives, through book-entry taxes (sales, VAT , capital gains, income) and regulation (think of a regulation which doesn\u2019t eventually rely on transaction audit trails), is because, we require government intervention in our economic processes, our very transactions themselves, or those selfsame transactions wouldn\u2019t occur at all. Book-entry settlement and the ad baculum argument at the core of the very idea of the modern industrial nation-state are intimately related. A tax on income is easy to enforce because you need force to make the income transactions execute to begin with. One hand washes the other. Pay packets with paper cash cost too much to handle when you can just issue cheques for people to deposit into mainframe-enabled chequing accounts.Seen from a network perspective, a book-entry transaction is about shoving a very insecure piece of data, a positive or negative integer, a debit or credit, down a very secure pipe. And, to get access to that pipe, you have to be physically, um, obtainable, to law enforcement at any point in time before, during, and after the fact, should you lie about it.With digital bearer settlement, we have turned that last paragraph completely on its head. With a blind signature cryptographic protocol, for instance, we can send a secure transaction, a strongly encrypted and cryptographically authenticated token (a digital bearer certificate, if you will), down an insecure pipe, the internet, in other words, and with the right software, that\u2019s the end of the transaction.We don\u2019t need biometrically authenticated access control to a proprietary secure network in order to shove an inherently insecure book entry back and forth out of someone\u2019s database of transactions and, by extension, their chart of accounts. We actually don\u2019t need to keep audit trails at all anymore, much less for years at at time, and, more dramatically, we don\u2019t even need cops to hunt down miscreants who \u2018break\u2019 our trades, either in execution, settlement, or clearing.Instead, with a simple exchange of digital bearer certificates, we can execute, clear, and settle the transaction all at once, and the cryptographic financial protocol, executed in software, simply won\u2019t operate unless all conditions are met for the transaction to occur.Which, oddly enough, is exactly the way a physical bearer certificate works: I show up with my cash, you show up with your paper bonds, we agree on a price, we inspect and swap our various pieces of paper, and we walk away. I know the bonds are good by inspecting them, you know the cash is good by inspecting that, and, frankly, we don\u2019t care who each other is. Ever.Now, with digital bearer certificates, we can do exactly the same thing on the net. That \u2018inspection\u2019 step now occurs when we test and redeem our cash or bond certificates with their issuers online, and, if the certificates can\u2019t be redeemed, the trade can\u2019t even execute.It stops before it starts. Nobody gets burned, frankly, except the criminals who want to double spend the certificates. The only people who even need a reputation in the transaction itself are the issuers of the respective digital bearer certificates involved, and not the buyers and sellers of those certificates in the secondary markets.And, of course, that \u2018reputation\u2019 we\u2019re talking about here is the past behaviour, on the net, of a public-private keypair used in the authentication and issuance of a given digital bearer certificate. Or in the sale of anything else, for that matter. Just by using the public key and the signature on the certificate, anyone in the market can validate that the certificate was issued by the entity issuing or underwriting it. And, in the course of a transaction, as we said, the issuer itself can validate the \u2018semantic\u2019 part of the transaction, that the certificate is in fact unique and exchangeable at no cost for another unique set of bits representing the same value.So, a digital bearer certificate is authenticated by the issuer of that certificate, in the same way that the intaglio printing, special paper, serial numbers and signatures on a given paper bearer bond make it unique and non-replicable.That makes not only for a more secure, and completely private, transaction, but it also makes for a radically cheaper transaction, which is really the whole point. As we all know by now, the reason we have book-entry settlement to begin with is because it\u2019s radically cheaper than the physical delivery of paper bearer certificates, not so the government, or anyone else, can surveil us in our very grocery purchases.On the net, we talk about accumulating and quantifying reputation in some imaginary future denomination and we call that stuff \u2018reputation capital\u2019. Which immediately leads to the cypherpunk inside-joke about permanent shunning being \u2018reputation capital punishment\u2019. And, actually, that\u2019s pretty understandable. Instead of going off to San Francisco in the 1850\u2019s to change your name and venue after screwing up, you just delete your private/public key pair, and start a new reputation over from scratch. In a bearer settled world, of course, it happened all the time.I expect, like corporations today, reputations will be sold, and the variance between the market value of the assets controlled by that reputation, and the market value of the reputation itself will be our imaginary reputation \u2018capital\u2019, something we call \u2018goodwill\u2019 today.Now, to quote Bill Cosby, \u2018I told you that story to tell you this one.\u2019With digital bearer settlement, and the sanction of reputation against public keys which have bad character, as Morgan called it (reputation, to you and me) it is now possible to create digital bearer bonds.Actually, last time, in my underwriting model for digital cash, I cheated. When you think about it, a bank note, cash in other words, is an instantly callable, perpetually issued bond which pays no interest. It represents a claim, in the old days, at least, on some principal amount of a given debt, and not its interest, redeemable upon demand in the asset the note is reserved against and denominated in.So, to issue a digital bearer bond with a simple coupon, you just issue a digital bearer certificate for the principal amount, redeemable at the end of the life of the bond, and you bundle a bunch of coupons with that certificate for the redemption of principal, one for each interest period, and redeemable at the end of that interest period, and sell them all together as a unit.To do a zero-coupon bond, simply issue a certificate payable at expiration and sell it for the net present value of that amount given some fixed interest rate.Strips are just that. Strip the coupon certificates from the principal one and sell them all as individual certificates with their own prices. Notice that we bump into the old fixed income analysis chestnut about a bond being a series of options on cash flow, which, of course, I\u2019ll muck around with a bit more, when we get to derivatives.Convertible bonds should be redeemable either in cash or stock. Bearer stock, of course, which we\u2019ll talk about next time.Money market instruments, for the most part, are just bonds with extremely short lifespans.It\u2019s even conceivable to have microbonds, issued by individuals. After all, the size of an individual underwriter, and the resulting syndicates of underwriters, to boot, is probably completely driven by Moore\u2019s law. I joked in Wired a few years ago about a syndicate of microbond \u2018bots\u2019 loaning me the money for lunch, payable at the end of the month.If you can have microbonds, macrobonds are also possible. I expect that digital bearer settlement will be a universal phenomenon, just like book-entry settlement is today.Secured bonds, like equipment mortgage bonds, can use various trusted entities to validate the worth of the assets securing the bond, just like a trustee/custodian does for a bond or cash issue.And, of course, you can add all kinds of call provisions, redemption exclusions, and anything else you can think of, to a digital bearer bond, only this time, you\u2019re writing software, and not law, as the old cypherpunk mantra goes.Finally, any of the above bonds will be rated, just like bonds are today, yielding the same market we have now, with fungible graded commodities, in perfect competition, only, now the velocity of those markets can be greatly accelerated. After all, you are executing, settling, and clearing, instantly, and for cash.Notice several things here. First, the language of bearer settlement completely underlays our very discussion of bonds even today. The word \u2018coupon\u2019, for interest, \u2018holding\u2019 a bond, all of that. Digital bearer settlement makes it that more relevant. Back to the future, and all that. It says to me that we\u2019re not going to have too much conceptual trouble thinking about a world of digital bearer settlement, which is one of the principal attractions, besides reducing transaction cost by three orders of magnitude, of course.Second, and probably more important, by creating actual digital financial objects, objects which make electrons behave in certain ways online, just like the mouseprint covering those huge paper bearer bonds of yore caused lawyers and judges to behave in certain ways in meatspace, you have freed finance from a huge chunk of legal cycle-time itself, and you get a genuine financial ecology on the net, on top of that geodesic economy I talk so much about. In fact, most of the time it seems to me that they\u2019re part of the same thing. The geodesic network being the substrate upon which this bestiary of financial entities and objects are born, live, and die. It gets worse when I talk about the idea of \u2018micromoney mitochondria\u2019 at the end of this series, but I\u2019ll soften you up a bit before we get that far out over the edge of the cliff, into cartoon physics, as it were.Anyway, in this new financial ecosystem, financial theory and practice become one and the same thing, the behaviour of financial software and digital bearer objects on a ubiquitous global internetwork. It may be that, after years of using mathematics and physical analogs to describe financial economics, the ultimate anathema to mathematical finance will occur, and finance will become an observational science again.Frankly, I think we\u2019re looking at some combination of the two, where mathematical finance will propose, and the genetic behaviour of the market will dispose. Which, when you think about it, is exactly what happens today.Next month, we\u2019ll talk about digital bearer stock, and, implicit in that, how to achieve limited liability in \u2018cypherspace\u2019.Back to table of contentsSince law attempts to be as logical as possible, and software is nothing but mathematics, I\u2019m about to show you how to turn common law, or some of it, anyway, into software. We\u2019re going to do it all, of course, by talking about digital bearer equity.One of my favourite people in philosophical history is Bertrand Russell. Most people familiar with the history of computational logic know that not only did Russell discover a paradox that eventually undermined the foundations of logic when Goedel solved it a few decades later, that consistent systems could never be complete and complete systems could never be consistent, but also that Russell and his partner Alfred North Whitehead quite literally broke their brains proving, logically, that 1+1 was 2 using symbolic logic alone, unifying maths and logic for the first time.The idea of joint control of an enterprise is as old as western civilisation. Before the time of the Greeks, hierarchy and property rights had gotten so evolved that everyone belonged to someone else. Ministers of the pharaohs used to routinely sign their correspondence to their superiors, \u2018Your Slave\u2019. Hydraulic monopoly has a weird effect on people that way. Certainly the Chinese, Brahmins, and, to a lesser degree, the Mesopotamians, refined hierarchical lifetime control of their subjects to a fine art.It\u2019s questionable whether the Greeks were the sole inventors of democracy, small hunter-gatherer bands like the Australian aborigines had a more egalitarian society than most larger agricultural societies, for instance. Nonetheless, the Greeks are certainly the people we like to remember as the originators of the practice of voting as a \u2018protocol\u2019 for group decision-making. Especially since they actually had agriculture and actually kept written records of the votes they took.The Roman republic, literally, \u2018re publica\u2019, the public thing, abstracted direct voting up one level by electing representatives who in turn did the actual voting, proxies, if you will. This allowed a much greater span of control than a simple city state, Delian League or not. First \u2018pecunia\u2019, then \u2018re publica\u2019. Those Romans got to invent all the fun words, didn\u2019t they?Notice that neither democracies or republics are necessarily stable or even representative. Greece and Rome, or any of their early modern replicas including the one I\u2019m fond of, excluded most of their populations from actual voting control, but, as communication technology and industrial requirements for education increased in prevalence, suffrage tended to become universal, and, ironically, slavery itself has been shown to be a peculiarly agricultural institution, all of Marx\u2019s protestations to the contrary.Another way to think about it comes from an old college logic professor of mine. We all have the same information and intelligence, and the future is uncertain, so we might as well vote about what to do next.Of course, joint ownership is not new either, and neither is proportional voting control of businesses, or anything else. The corporation, peculiar this time to industrialism and the modern nation-state, has direct antecedents in other common-law business forms not requiring the force of that nation-state for their very existence, something important to anyone trying to code up erst-corporate behaviour in software instead of law.You don\u2019t even need the legal sanction of a nation state to have limited liability. Common law created limited partnership long before corporations. Britain had fully functioning non-corporate limited liability entities at least until the end of the nineteenth century. Lloyds not withstanding, of course.So, the point is, can you make all this fun stuff happen in software?Let\u2019s look at the cryptography for a bit. For starters, you can store multiple \u2018hashes\u2019 of the same data in such a fashion that with any m of n pieces, you can reconstruct the whole dataset. That is useful for storing, say, your digital bearer bonds, in various blinded cryptographic storage areas all over the net, for a fee of course, but it also provides a pointer to controlling a business entity as well.Why? Remember that \u2018identity\u2019 directly maps to \u2018key-pair\u2019 in cypherspace. With an m-of-n reconstruction scheme, any m members of a board could vote to control the \u2018root\u2019 key of a virtual corporation, for instance, you could actually control that key. There\u2019s considerable doubt whether hierarchies make sense in this context at all. In fact, most global name-space schemes based on key-management hierarchies bump right into Russell\u2019s Paradox and Goedel\u2019s Result as if their designers never took logic at all.Anyway, this form of m-of-n key-control works best for simple partnerships, but you still have the problem of voting control of larger entities, particularly if you want lots of shareholders. Fortunately, there are cryptographic protocols for anonymous voting, as well. I\u2019ll spare you the gory cryptographic details, but there are ways to elect a board, and for boards to vote control of a key, which can then be used to authenticate the actions of as large a business entity that you want. The creation of voting proxies, in other words.So, we\u2019ve taken care of common stock, and, because we know about digital bearer bonds, we can get a hint about how to do dividends: just present some token at the time of the dividend and collect cash. But, what kind of token do we use when all we have is a stock certificate? Clearly we don\u2019t want to redeem that at dividend time, do we?No, we don\u2019t have to. There is yet another class of cryptographic protocol called, weirdly enough, zero-knowledge proofs of knowledge. Using these methods, it is possible to hash a given bit of information and use that hash to prove to someone that you have that information in its entirety. No, it\u2019s not magic, it\u2019s mathematics. Using zero knowledge proofs on a stock certificate, you can prove not only that you are entitled to vote, but that you are entitled to collect dividends as well. In fact, you can use it to prove that you are a preferred stockholder, or that you are a holder of Class B instead of A, or anything else. Finally, the issuer can use these proofs to show that you have already collected a dividend, voted a stock, whatever.Oh. One other thing. Want to authenticate the books of a corporation for a given price earnings ratio without seeing the entire set? Want to authenticate an actual cashflow or asset holding for a debtor? Use the same zero-knowledge proof cryptography. Eric Hughes even claims to have invented a way to publish completely \u2018open\u2019, publicly available files, cryptographically munged, of course, which, when, a business entity wanted to prove a certain figure or set of line-items was in that otherwise encrypted information, they could use their unique key pair and a zero knowledge proof to show that the expenditure was in fact there. This could even be audited by a trusted third party, whose signature would be on the encrypted data. It just keeps getting weirder.Frankly, the reason we don\u2019t use zero knowledge proofs for bond payments is because bonds have finite duration. They all, with one exception proving the financial rule called a \u2018perpetuity\u2019, expire sooner or later. It\u2019ll probably be cheaper to just issue all the digital bearer certificates, principal and interest, en masse. It\u2019ll certainly be more financially reasonable from the standpoint of calculating the value of those certificates, as any student of fixed income mathematics will tell you. Simply issue all the certificates at once, and let them each be priced, and traded, accordingly.But getting back to equity, what about limited liability? Well, think about this for a minute. If, for instance, you have anonymous control of information, then the only thing you can do to the holder of that information in any meaningful sense is to discount the value of that information in the market. Remember, when we talked about reputation, we talked about reputation \u2018capital punishment\u2019, where a given cryptographic key pair is shunned, its economic value effectively zero.These days we do it with laws which say that a shareholder of a corporation is only liable for whatever money he invested into it, and, when the market says a stock is worthless, there isn\u2019t anything such thing as negative value.But, again, in cypherspace, we try to replace law with strong cryptographic software, and, most of the time, we get the same result. Funny how symbolic logic works that way. Call it Russell\u2019s revenge.In other words, if a shareholder spends money on a digital bearer certificate signifying partial ownership in an enterprise, and that bearer certificate, for whatever reason, is worth nothing, that\u2019s all the shareholder has lost. Since he\u2019s holding a certificate normally, his key is completely blinded, and he is thus anonymous. Only if he double spends the certificate is he unmasked. So, on a \u2018semantic\u2019 level, there\u2019s no other \u2018recourse\u2019 the market has but to the value of the equity certificates he holds. And, as any person who\u2019s holding shares of a fraudulently accounted company can tell you, that penalty is a good enough proxy for limited liability.Issuing digital bearer equity, or debt and cash, of course, is different, in that the key issuing the certificate must be known to have a good reputation, and have proven asset value in the case of collateralised debt. The holders of the certificates, though, don\u2019t need to be known at all for the system to work.Pretty cool, huh? With digital bearer equity, you can have publicly held business entities whose size limits are only driven by transaction cost, just as Coase\u2019s theorem says it should be, and, the shareholders can be completely anonymous.And, of course, as we all know by now, I claim, at least three times before breakfast every day, that digital bearer settlement will drop transaction costs by at least three orders of magnitude, which is why you have anonymous shareholders, and not though any desire for privacy per se. The reason we have registered stock ownership, remember, is because we have book-entry settlement. If we could do digital bearer settled equity, there would be no need to register securities from an economic standpoint, and, as I\u2019m also fond of saying, physics begets economics, which begets common law, which begets legislation and \u2018policy\u2019. You cannot run the causation movie backwards and get any money.So, no, I don\u2019t think that absolute deregulation of equities markets will be the only component of that cost reduction, though it may one of the most interesting effects of that cost reduction, no matter what its magnitude.Next time, we\u2019ll talk about digital bearer derivatives, but, after that, we\u2019ll come back to equity, and Coase\u2019s Theorem, and talk about micromoney, and its impact on the size of the firm. Stay tuned.Back to table of contentsDigital bearer derivatives are possible and, at the margin, digital bearer settlement is probably the technology most suited for the execution, clearing and settlement of derivatives.With the free-falling price of microprocessing, we\u2019re going to get more, and more complicated, derivatives, whether we want them or not, and, with ubiquitous internetworks, they\u2019re going to be digital bearer derivatives, because that\u2019s going to be the cheapest way to do them.So, before we start, let\u2019s review my (and Russell\u2019s) mantra that reality starts with physics and economics and ends with law, \u2018policy\u2019, and philosophy. Trying to legislate economics and finance, for instance, is one of the sillier things any sovereign, much less any religion, can do.I say religion here because, at some point in Christian theology, probably in deference to the Temple money-changing episode, interest was declared immoral, and, from that now-curious beginning, we get modern derivative transactions.Christian monarchs, in trying to outlaw interest, found that, no matter how hard they tried, they just couldn\u2019t, really. Eventually, in the late middle ages, they let religious undesirables, like Jews, be the money lenders and charge interest, but only after a ridiculous amount of creative denial.Muslim countries still outlaw interest today, for instance, and they go through an amazing amount of gyrations to keep their banks in business as a result. But, as Joe McCarthy used to say about communism, no one in, say, Saudi Arabia, dare call it \u2018interest\u2019, even today.Nonetheless, buried, deep in the glosses, palimpsests and marginalia, among all the shucks and jives that mediaeval sovereigns did to avoid the \u2018i\u2019 word, were some very interesting residents of the then-hand-illuminated financial bestiary. These critters really did look an awful lot like bonds, and, even, derivatives. Of course, they couldn\u2019t possibly be those unholy chimera, because they would be, quite literally, an abomination, a sin unto God Himself.Yet, in England, for instance, there was the ever-ubiquitous tally-stick, which started out being a poor man\u2019s depository receipt for taxes, with big notches for big money, and small notches for small, and split between the two counterparties to keep everyone honest. These sticks ended up, in rather short order, representing \u2018fictitious\u2019 transactions, and, more important, contingent claims, on some other asset, usually, bullion. The king would, instead of paying creditors in gold, pay them with tally-sticks, which would then \u2018mature\u2019 sometime later at the time of the bullion\u2019s eventual arrival in the treasury. These discounts were, of course, representing the, um, opportunity cost, of the money involved. Certainly not interest. That would be evil, of course.In fact, the considerable fortunes of the Knights Templar, and Hospitalar, too, were built on bills of exchange, issued to crusading nobility, who could, magically, deposit money in one place in Europe, and take it out of somewhere else upon their arrival in the Holy Land. \u2018Of course, Sire. Interest would be a sin. We can, however, sell you this bill of exchange at a discount, if you would should desire it\u2026\u2019You can account for a multitude of risks, if not sins, in the discounted price of that bill of exchange, including the obvious one of said Sovereign getting lost, bill and all, at sea on occasion.Not to mention creating bills of exchange for assets which never leave a country at all, thus avoiding taxes, even for the sovereign, at least in countries like England where the sovereign was accountable, even marginally, to the law. Bills of exchange were even created representing assets which might never exist, except if some contingency occurred. Guess what those were?Of course, most reasonably clueful bond folks will gladly haul out a trusty Fabozzi book or two and show you that, yes, a bond is, in fact, an option on some future cashflow that the bond promises, or, more precisely, that a bond is a bundle of options (interest coupons, remember?) on that future cash-flow, the granularity of the option\u2019s settlement date being either every quarter, if you feel discrete, or infinite, if you feel continuous and remember that most bonds are quite liquid assets. And this tide of financial calculus floats all boats, even a crusader\u2019s fleet mired in the middle ages, modulo the occasional Mediterranean storm.So, just like quarks, it seems that options and other derivatives are the very conceptual building blocks of the financial universe, and to ignore or restrict them is to do so at one\u2019s own economic peril, if not one\u2019s mortal soul.Thought about in those terms, of course, derivatives become as old as civilisation itself. Thales of Meletes (who was the world\u2019s first philosopher if you\u2019re in a medieval mood, and believe in the infallibility of Aristotle), answered the world\u2019s oldest taunt, \u2018if you\u2019re so smart, how come you aren\u2019t rich\u2019, by cornering the local olive oil-pressing futures market, monopolising those presses at harvest time. It not only made him rich, but famous, too, especially to everyone who\u2019s taken the nickel tour at the Chicago Board of Trade and walked away dreaming of being latter-day Hunt Brothers. Doing that ill-fated silver corner right, of course...Even before Hellenic Asia Minor, the owners of various grain depositories in Egypt, and even Babylon, raked it in one haircut at a time, purchasing grain before it was even planted, and flipping that imaginary grain, over and over again, until the harvest actually came in.This kept people from dumping grain in the streets at harvest time, certainly, because the prices were too low then, which is exactly the apocryphal event precipitating modern futures exchanges in places like Chicago, sans hydraulic monopoly. Those who forget history, and so forth.At the root of every derivative is a polite, and frequently mathematical, fiction. A fiction, which, if it turns to real prophecy, makes money. And, if you\u2019ve ever listened to any entrepreneur in heat spouting his latest funding pitch, you\u2019ll notice that predictions are pretty cheap to make. Moreover, an awful lot of of those predictions exist about any one event at any one point in time. Putting a value on that vast quantity of fiction might have been worth a Nobel Prize to some people who should now know better than to hang out with the likes of Mr Merriwether, but, more important, the process is driven by supply and demand. The initial price of futures, options, and other contingent claims, relative to the assets they make claims on, are, like talk, cheap for the most part.In addition, if the underlying asset of a class of contingent claims is volatile, it\u2019s a very good idea to settle and clear the purchase and sale of those claims as soon as possible, so people won\u2019t forget their sometimes large obligations, or can collect on their occasionally formidable returns. Which, oddly enough, is exactly what happens at options exchanges all over the world. Chicago, for instance, now has next day settlement, if I remember, and the trend has been towards even shorter settlement times, wherever possible.And digital bearer transactions settle fastest and cheapest.We need to look at something else about a derivative. All those conditions under which the contingent claim will be executed make things very complicated. You simply cannot have a modern derivative without computers and online real-time information. You need even more computational horsepower to model the damn things to see if they do what you want them to.This complexity, and the corresponding computational modelling requirements, has always been seen to be a bug. It\u2019s really a feature, though. The more you automate the process the better it works, and now, it can be automated up to and including settlement, scaring the wits out even the hardiest of souls.Already I can hear quite a few disgusted \u2018harumphs\u2019 out there, particularly from those of you who have seen formerly boring equity exchanges go limit-down like some CBOT pork-belly pit. You\u2019ve seen \u2018portfolio insurance\u2019 contracts blow up like so many World War I barrage balloons under the tracer bullets of illiquidity, causing markets to crash around the world.More to the point, we\u2019ve seen countless portfolio managers who claimed to be using derivatives, but who were doing nothing but speculation with large amounts of other people\u2019s money as if it were just another game of liar\u2019s poker.So, what does digital bearer settlement bring to the party? For starters, increased automation, of course. You can build an actual object, which lives out there on the network all by itself, waiting for the proper market conditions to be met before it executes. Furthermore, because of those extremely reduced transaction costs, you can do transactions at extremely small sizes. Well, sizes considerably less than the hundred-million, or even billion, dollar transactions required to make institutional-scale money in derivatives today.Because of this small transaction cost, you could actually create a bunch of micro-derivatives, set them loose, and see if they work. Nothing like small-scale working models to see what really works, certainly. You could even create, abomination of abominations, auto-mutating derivatives, following genetic algorithms, spawning slightly altered copies of themselves at settlement time with some of the proceeds. Fast, cheap, and out of control, indeed. It\u2019s enough to send you scurrying back to the monastery, sandals flying every which way\u2026Dragging us back to the human universe, with this kind of granularity you could also create a whole array of derivatives, representing a whole spectrum of possible positions, in smaller transaction sizes, allowing you much more flexibility in your financial plans. That\u2019s why derivatives exist, after all, to hedge your purchase or sale of something else against the unforeseen. At the expense of Godless speculators, of course.But, the primary problem with modern derivatives is that nobody is there on the other side of a desired trade at crunch time. Nobody there in the specific volume desired, and so, most hedging transactions, like the limit orders they are, go unanswered until the price is much lower, defeating the purpose of the derivative in the first place. Being able to execute a score of smaller transactions, instead of one giant one, at some intermediate prices in an avalanche of continuously falling prices gives a portfolio manager at least some comfort of dollar-cost averaging on the way down. Frankly, I expect that it will tame volatility as a result. It is precisely these precipitous free-falls with no answering bid, which cause the volatility problem in the first place.Oh. Right. Before I forget, the transactions are all anonymous, of course.So, how do you do all this fun stuff? Well, if you couple some bit of autoexecutable code with a digital bearer instrument, or a bundle of digital bearer instruments, you can execute all the pricing, and other financial data, requirements you want. Certainly a bit of XML, or Java, done right and properly authenticated, could do the trick, but, like most problems in financial cryptography, that trick is usually harder than it looks.Fortunately, what looks like an initial solution to the problem was presented at the 1998 International Conference on Financial Cryptography, FC98 to its friends, held this past February in Anguilla.X-Cash, a new transaction protocol by Markus Jakobsson of Bell Labs and Ari Juels of RSA Labs, is a bundle of digital bearer instruments which look for the terms they want, and when those terms meet with an acceptable offer, they execute, clear, and settle the transaction, all at once. If you\u2019re interested in this paper, and a whole bunch of others on the cutting edge of Financial Cryptography, you might want to look at the conference\u2019s proceedings, which are now available from Springer-V erlag. See www.fc98.ai for details.Of course, figuring out how, and doing it, are two entirely different things, and, frankly, X-Cash is only the first of what will necessarily be many attempts at solving the problem of autoexecutable, digitable bearer, derivatives.It\u2019s the same problem financial cryptographers fight every day: the problem of turning law and legal agreement into something much better: running software. Turning law, and apparently, thrill-addiction, into economic, literally physical, objects.Objects beyond the control of gamblers and, apparently, experts at liar\u2019s poker.Back to table of contents\u201cWhen the going gets weird, the weird turn pro\u201d, as Hunter S. Thompson once said, and the going, for this article, is going to get pretty weird, and in hurry.I\u2019ve taken you from digital bearer cash, through bonds and equity, and, last month, we ended up with derivatives, showing you could get as weird as you wanted, financially, and still use digital bearer settlement technology to make transaction settlement cheaper to use than book-entry methods. Probably by several orders of magnitude, or a thousand times, cheaper.Now we\u2019re going back to cash, microcash, to be exact, and, in the weird spirit of Mr. Thompson, we\u2019re going to talk not about Yage, or Ibogaine, or various reptilian pineal extracts, but about different kinds of hash.Well, okay, not hashish, exactly. Hashes, actually. And not anything even vaguely psychochemical, though the consequences of hashes might get pseudobiological sooner than you might imagine, and simply mind-bending to contemplate when we get there.The technology I\u2019m talking about here is that venerated mathematical algorithm and staple of computer science, the hash function.A hash function is something they teach you in your first year of computer science. Properly defined, a hash is a usually smaller, mechanically derived, fixed-length sample, subset, or just plain correlated bunch of bits related to usually a larger, and variable-length, bunch of other bits. A hash is something that allows you to mechanically check the integrity of data without actually examining the data itself. I can send you a hash of some computer program I\u2019ve written, so that you can run a hash of your copy, compare the hash you have to the hash I gave you, and, if they\u2019re identical, it\u2019s highly unlikely that your copy is different than mine.It\u2019s that \u201chighly unlikely\u201d bit that\u2019s important, here. For instance, if I hash a given bit of information and the result is 2128 bits in size, and the hash method is a one-way function which gives me a more or less random output, I have a 1 in 2128 chance of getting the same hash from some other bunch of data. Nice large number, that. Longer than the number of seconds the universe has been alive, even. Longer the total age of the universe if Mr. Hawking, and, more recently, experimental data, were both wrong and the universe is in fact closed.However, like all large numbers, including infinity, you can control those, um, astronomical probabilities if you want, and that control is at the heart of micromoney.If you reduce the output size of a one-way random hash function which uses a key (a \u201ccryptographic\u201d hash, in other words) you can control how much computation (money, in other words) is spent in the generation of a hash \u201ccollision\u201d, which is the name for happens when two entirely different blobs of data generate exactly the same hash value. Finally, if you use the right kind of hash function this way, and you find a hash collision, you can use that information to generate as many collisions like it as you want, with very little extra computation at all. Each one of those hashes are as hard to forge as the first one is.What you get is exactly the economics of minting a penny, only with bits, which are much cheaper to mint with. To mint a penny you have to literally build a factory, because that\u2019s what a modern mint really is. But, the next penny after the first one is barely noticeable in terms of marginal cost, and, so, it behooves you to mint as many pennies as possible to earn back the investment in your mint. That is, if you were selling pennies for a living, which governments claim they really don\u2019t do, though they book it on their balance sheets as seignorage income, nonetheless\u2026 Using hash collisions, as found in various the various micromoney algorithms out there including MicroMint from Ron Rivest and it\u2019s several progeny, and in Millicent by Mark Manasse, and in HashCash, a simple anti-spam protocol by Adam Back, that\u2019s exactly what you can do. You can take in people\u2019s money in one form or another and quite literally print them a positively huge amount of extremely low-value cryptographic hash-collision tokens, all while still turning a tidy profit. Seignorage for the rest of us, to paraphrase Mr. Jobs.The disparity in cost between the cost of \u201cminting\u201d the first token and minting the second is enormous, much greater than that required to mint the second penny in our example above. Remember, again, how long it takes to \u201cbrute-force\u201d a hash-string the size of 16 bytes, the size of this one: \u201c1234567812345678\u201d. That is, 128 bits divided by 8 bits per byte.Those 16 bytes, if handled properly, are certainly small enough to stick onto the most mundane events in cyberspace and pay directly for some service at the time it\u2019s rendered. All without an invoice, or clearing a check, or authenticating a credit card. and, without, of course, the finance and accounting departments backing them up.You can use those 16 bytes to pay for sending a piece of email. Or downloading a web page. Or, even, with enough 18-month turns of Moore\u2019s law and a stiff tailwind, routing a group of packets from here to there across the net.Imagine every router on the net buying bandwidth low and selling it high in a continuous, digital-bearer, microcash-settled, cash-on-the-routerhead auction for internet switching. In such a world, you don\u2019t even need network engineering, at least as we\u2019ve defined it today, because the market, and not some grand top-down design, will determine where the next router will go, without any human intervention in the purchase at all.\u2026Good. I see you\u2019ve drunk the Electric Kool-Aid, and the visuals are just starting to kick in. Great stuff, huh? Remember, I did warn you this was going to get weird in a hurry, and now, I believe, it\u2019s time for the weird to turn pro. Hold on\u2026But, wait, as they say in the more manic infomercials, there\u2019s more. As the internet becomes more and more ubiquitous, and microprocessors become cheaper and cheaper to make, the internet, defined as the TCP/IP protocol (or it\u2019s progeny, whatever that will be), it interlinks the most amazing places into a unified geodesic network, reachable through the air from local antennas, or satellite antennas, or just physically, by connecting you to the network with a wire or fiber optic cable. With an increasingly ubiquitous internetwork, you can sell even more and more mundane things this way. In the ultimate throes of this anarchocapitalist madness, everything can be for sale.Let\u2019s start with the obvious one first. Electricity. Already, they have demonstrated IP over electric lines in Britain. It is mostly trivial to do, especially over higher voltage power lines. Now, if you squint, you can see, with your newly dilated pupils, the very electrical appliances in your house, your microwave oven, your toaster, your teakettle, paying for their very electricity as they use it. With microcash.It\u2019s not that hard to do. I just showed you how, right? All you need is a hash-handling chip in the toaster a little smarter than the chip in that expensive \u201cgourmet\u201d toaster sitting right there, right now, on the shelf in the gourmet kitchen store down the street. I call these imaginary chips micromoney mitochondria, and with them you get the quasibiological effect of picomoney as processor food.If you remember the history of this century, and the first article in this series, it wasn\u2019t until checking accounts and hierarchical industrial networks became prevalent that lots of working folks stopped paying for their flat\u2019s electricity with actual coins in a meter somewhere on the premises. As we\u2019ll find out in the next article, that kind of \u201cunwinding\u201d of history is a very quick and dirty way to figure out how a bearer settled geodesic economy looks, if not how to implement it from scratch.To continue the weirdness, think about a world where an internet router can save enough retained cash out of operations to buy a new line to a less busy router. Or copy of itself. Or to sell itself off into \u201cslavery\u201d(?) to another router (which is buying a copy of itself, remember?) after losing too much money to stay in business anymore. Transported. Mr. Macawber, thy name is \u201ccypherspace\u201d. More time, running backwards, on Moore\u2019s law.Great acid, yes?But wait, there\u2019s more. If you can really do this with roads, paying at every intersection to get through it (money\u2019s cheap and small, remember?), does a, um, hierarchically organized force monopoly, a nation-state or it\u2019s smaller hierarchical subdivisions, need to \u201cown\u201d that road anymore? Shades of a favella in Sao Paulo, where the \u201cproperty\u201d lines extend into the middle of the street. Actually, not so \u201cproperty\u201d anymore, as the favella dwellers, along with their private piece of concrete to the middle of the street, now have secured real property rights to that concrete and the now-legally recognized road under it. So, are they charge you to drive over their little piece of micro-road? Stop this trip. Now. Please, make it go away\u2026 What\u2019s next? Paying microcash for water as it comes out of the tap? No, let\u2019s not think about the inverse of that particular plumbing operation, as it\u2019s fraught with images of misers, Gordon Gekko (as someone likened me to, after I started thinking too hard about this in public on the net), and of course, Scrooge himself, speaking of unwinding the clock to a more Dickensian universe.Paying auction prices for force? Landmines which won\u2019t blow up if you have the right key? And keep paying them? Mama told me not to come\u2026Okay. Let\u2019s abstract our selves back a level or two, and think about actual micro-economics for a while, both to cool off our blazing neurons, and to honor a promise I made last time. Early in this decade, Ronald Coase, formerly of the LSE \u2013 and now, I believe, at the University of Chicago, where all good Nobel laureates go to die \u2013 won, you guessed it, a Nobel prize in economics. Coase won the Nobel by hypothecating (without actual mathematics, a boon and comfort to innumerates like me everywhere), that firm size is directly related to transaction costs.That is, the cheaper the transaction cost, the smaller the firm can be. This has been proven, with actual data, to as much certainty as a fact of physics itself in the decades since the 1920\u2019s when Coase made this prediction.Well? Notice something? Some digital bearer protocols are really cheap to use. Some get us to efficient transaction spreads in milli-to-microcent range. That makes for really small \u201cfirms\u201d. Market actors. Proprietors, in other words.More to the point, if Moore\u2019s law reduces the price of switching enough to bearer-settle even the smallest conceivable purchases, like bandwidth, or road passage, or electricity, you end up a very strange universe, populated with a swarm of extremely competitive, dumb, randomly-behaving business entities motivated only by, as Dickens\u2019 Mr. Macawber said, \u201ckeeping income over expenditures\u201d. Curiouser and curiouser, to mix my Victorian fiction a bit.You don\u2019t just have an invisible hand, anymore.To steal the name of the Cato Institute\u2019s football team, you have an invisible foot. Something which can kick the pants off any large, vertically-integrated, hierarchically-organized industrial-era business now trying to combat its transfer pricing problems in order to compete with a market which, these days, values that business in pieces much more than it does the entire business, because, of course, the transaction costs are now low enough for those pieces of the old firm to sell their services directly to the market instead of doing it behind the \u201cfirewall\u201d of a company\u2019s chart of accounts.Diseconomies of scale, in other words. The world turned upside down. \u201cCats and dogs\u201d, as Bill Murray (who played Mr. Thompson once), \u201cliving together.\u201dThe weird have indeed turned pro.Cheers,\nRobert HettingaBack to table of contentsIn the final part of his series on the use of digital bearer financial instruments, Robert Hettinga moves on from the theory to explain how we can actually deploy these instruments.You couldn\u2019t have gotten through the capital market upheavals of the 1980\u2019s, much less Oliver Stone\u2019s movie Wall Street, without bumping into Sun Tsu, the ancient Chinese military thinker who, for our purposes, is best summed up by the Stonewall Jackson maxim, \u2018Hit \u2018em where they ain\u2019t\u2019.Among other things, Sun said that a small army should look large, a large army small, that one should attack when the enemy retreated, and retreat when the enemy attacked. You can almost hear P.T. Barnum muttering, somewhere, \u2018Never give a sucker an even break.\u2019 Mao, accommodating his intended audience with many simple single-worded exhortations and lots of exclamation points, recapitulated Sun\u2019s logic and won his wars in much the same way.I propose, in less florid terms here, to think about the deployment of digital bearer transactions in that same spirit. That is, start where book-entry settlement ain\u2019t, and move on from there. With that fulcrum, we can lever complexity of digital bearer settlement against itself, and start \u2018surfacting\u2019 the existing glops of book-entry markets into smaller, more geodesic ones.If you think about it, we face almost the same task that Copernicus, Kepler, and Gallileo did when they removed the earth from the centre of the universe. Like Kepler, we\u2019re going to use the simple mathematical ellipses of financial cryptography to replace the financial and legal Ptolomaic epicycles industrial economies had to build on top of their electronic, but still human-switched, information networks. We want to move money across these new geodesic networks we\u2019ve built in cypherspace without the financial shovelware that currently passes for internet transaction settlement. If, of course, that\u2019s what you can call the out of band settlement of internet-executed transactions, which is what internet credit card and even check transactions really are.I\u2019ve already spent the last six months telling you, with a broad brush, how to apply digital bearer transaction technology to every security imaginable. This article is about specific applications of digital bearer transaction technology to problems people have told me about. It\u2019s an effort to jump-start your own thinking about digital bearer settlement in your own business.Last November I went to to London, where, when I wasn\u2019t speaking to the E-Finance Forum, or to someone in the City, and, ultimately, to the Adam Smith Institute\u2019s conference on internet trading, all thanks to Duncan Goldie-Scot, I spent two evenings in a Kensington Australian wine bar, thinking about a couple of capital market bearer-settlement ideas with a few of the conference\u2019s participants.After we\u2019re through with those two, I\u2019d like to talk about micromoney mitochondria some, and an effort underway at DARPA to make the internet \u2018smarter\u2019.The first example, and the easiest to think about, is an already existing bearer-held Swiss hedge fund. Of course, bearer in Switzerland (or the BVI\u2019s, or wherever else) is quite different from the bearer I\u2019ve been talking about the past few months. Bearer shares are typically registered with a trustee of some kind, but that registration is blinded from the portfolio manager. So, imagine, in the spirit of my previous \u2018Bill and Ted\u2019s excellent mutual fund\u2019 scenario, we created Bill and Ted\u2019s excellent bearer hedge fund.That is, this existing hedge fund puts up a blind-signature certificate mint, right in the same room with their existing web server. When people pay the server digital cash, they are issued a digital bearer certificate representing assets in the fund. Right. What\u2019s digital cash? Okay, so we don\u2019t have digital cash. So we use checks, or bank wires. Somebody goes to a web page, is issued a non-transferable provisional certificate right off the bat, and, when the wire or cheque clears, they can come back and get real bearer certificates in exchange for the provisional one.If done right, such an automated customer service scheme will probably be much cheaper the way it\u2019s done now, even with the added complication of transaction latency, which is there right now, anyway. Whenever digital bearer cash is available, handling shareholder exchanges will be even that much cheaper. Again, as a portfolio manager, you don\u2019t ever know who your customers are, anyway. The trustee administers your customer\u2019s money in the logical opposite of an American blind trust. Instead of the customers not knowing what the portfolio\u2019s invested in, though, the portfolio manager doesn\u2019t know, legally, who\u2019s invested in his fund. Which is the rub.Notice my use of the word legally. There\u2019s this whole industry of fund trustees in Switzerland, using lots of lawyers no doubt, all devoted to administering those blinded lists of shareholders in bearer funds. I would even venture to guess that my digital bearer version of Bill and Ted\u2019s excellent Swiss bearer hedge fund is illegal, in order to perpetuate this cottage industry, though it might be fun to push the legal envelope a bit, to see how strong it is. We\u2019re still figuring it out.However, I would bet that if using digital bearer certificate servers lowered the trustee\u2019s customer service by three orders of magnitude, they would have to adopt the technology, and that\u2019s exactly how to sell this idea in Switzerland. Portfolio managers would much rather just run their money, without having to think about such things for the time being. Save that box in Bill and Ted\u2019s machine room for some later regulatory regime and a few more iterations of Moore\u2019s law.Which brings me, again, to the most important point I\u2019ve been making throughout this series of articles. There\u2019s not a cryptoanarchist cypherpunk in the world who wouldn\u2019t jump at doing this particular contract. If the blind signature patent was clear, which we\u2019ll talk about in a bit. But, unfortunately, those people are jumping at this kind of work for entirely the wrong reasons. It\u2019s almost as if they think that just because they can put up a digital bearer-settled fund, that in and of itself will sell the fund to investors.Remember again, slipping the surly bounds of earth is all well and good, but it\u2019s coach fare from Kitty Hawk to Dayton which put people into the air. Nobody\u2019s going to invest in \u2018Bill and Ted\u2019 s\u2019 excellent Swiss bearer hedge fund at all unless they can make more money there than they can at home. Part of that present advantage, is, of course, taxes, and, probably, more than one case of investing ill-gotten gains, defined how you will in the jurisdiction of the money\u2019s origin.However, the market for financial privacy is infinitesimally, ludicrously, small when compared to the market for cheaper transactions in general. And, frankly, the Swiss trustee, much less Bill and Ted themselves, are profitable enough already with the legislated privacy they already have, or they wouldn\u2019t be in business as it were.No, what will sell this contract to some lucky financial cryptography systems integrator is lowered cost of customer service, pure and simple. Again, I claim, issuing bearer certificates to the net is the way to do this, even if those certificates are purchased the old fashioned way, with cheques, bank wires, or, given the location in question, suitcases full of cash. Again, we\u2019re eventually looking at a world where digital cash will be involved, and, when that\u2019s possible, the whole idea of safe jurisdictions like Switzerland may end up an interesting footnote in financial history. If they don\u2019t do it in Switzerland first, of course, and get a technological jump on the rest of the world\u2026Now, lets look at the second deployment idea. This one is one where you\u2019d least expect it, in the heart of the institutional clearing system, literally under EuroClear\u2019s nose. Big institutions in Europe decided they needed a place to function for the myriad European exchanges in the same way that the Depository Trust Company does for the New York Stock Exchange. They hired J.P. Morgan to play that role, and called the system EuroClear. The problem is that the costs of the system are such that smaller institutions can\u2019t really afford to clear their trades there. A bunch of us figured, over some nice Australian Cabernet (and, um, kangaroo), that if you applied the model of digital bearer underwriting we talked about in July, and used Morgan as the institutional custodian for a jointly-held aggregate account, you could underwrite a bunch of closed-system bearer certificates against those shares and money, which a \u2018club\u2019 of smaller institutions could use to instantaneously clear trades against each other. Since this \u2018club\u2019 of smaller institutions would all be known to each other in the aggregate, all of the \u2018know your customer\u2019 rules could be adhered to, and, yet, the system could still, paradoxically, settle trades anonymously between club members.The result would be extremely lowered transaction costs between the club\u2019s members, and, of course, instantaneous clearing and settlement. Something which might even be interesting to the much larger members of EuroClear to use someday, we figured. Maybe, someday, anonymity in settlement could translate to anonymity in execution itself\u2026 This rather insidious application of digital bearer technology, at the very place where one would expect the next generation of book-entry technology to be deployed, is exactly what Sun Tsu, Stonewall Jackson, and I mean by \u2018hit \u2018em where they ain\u2019t\u2019.In other words, deploy digital bearer settlement where book-entry settlement, well, ain\u2019t, yet, and don\u2019t fool around with attacking the Maginot Line of the existing book-entry-settled capital market infrastructure until the battle\u2019s already over. Dropping a few geodesic smart-mines on their escape routes, like we did in the two examples above, would work perfectly.For the final deployment example, I\u2019ve just learned about a project which which leads me to believe that the era of cash-settled switching-level auctions of internet bandwidth is not too far off after all. DARPA, the Defense Research Projects Agency, the very agency which funded the original internet, has hired firewall/security/spook-crypto company Trusted Information Systems (now part of McAffee\u2019s and PGP\u2019s parent, Network Associates, Inc.), to build a so-called Active Network, a technology where internet packets include code which tells the router where they want to go.This is instead of a router needing increasingly larger route-lookup tables, requiring, you guessed it, hierarchical networks with big fast routers at the top-level \u2018backbone\u2019. Moreover, these packets will be cryptographically signed, to prevent their execution instructions from being tampered with.All of this is so the network can be more, you guessed it again, geodesic in structure and thus cheaper to use. Will wonders ever cease? So, avoiding geek-vs-spy conspiracy theories and the odd technological ad hominae against TIS in the expectation that the market requirement for cryptographic open source code solves the cypher-paranoia problem, this executable-as-network-packet idea looks like exactly like a running-code proof of my assertion that attaching micromoney to the information at the packet level is completely within technological reason. Welcome, one final time, to the future.Which brings me to a final hobbyhorse. Most of the problems, I think, with the deployment of digital bearer transactions are legal ones. Oddly enough, it\u2019s not even laws and regulation against bearer transactions themselves, which, on the face of it, are quite considerable. Even these regulations are completely surmountable given enough cost-reductions and increased profit margins. Law follows economics, in other words.The primary problem, as I see it, is the effective control, by the nation-state, of intellectual property. I tend to be extremely Coasian when it comes to my definition of private property. I believe that once information is on my hard drive, decrypted, and in a form useful to me, that\u2019s about as private as property can possibly be. It\u2019s mine. I can do anything I want to with it including sell it. Furthermore, as the internet becomes more and more location independent, you can\u2019t keep me from selling it.I challenge anyone to enforce an intellectual property patent against me in an environment where anything, encrypted or not, watermarked or not, can be auctioned to the highest bidder, in usable digital form, for digital bearer cash. Cryptolopes, or electronic software distribution, or stenographic watermarks, even custom-compiled executable code and escrowed funds, do not add a whit of value in such a world. As an inventor, much less a seller, of digital goods, there is simply no reason to increase your transaction costs, and, correspondingly, reduce your profit, in order to control your digital product once it has been sold to someone. Just auction your product off to the highest bidder and be done with it.The economics of the geodesic auction market says that if you have the first information of a specific type, you will make more money on that information than anyone else. Yet, before we can get there from here, there is a rather juicy irony involved. Because you need to cash digital bearer certificates into book-entry money sooner or later, the patents for digital bearer certificate technology are completely enforceable at the point of conversion, the gateways between the cypherspace and meatspace.As I\u2019m fond of saying, bankers and corporation presidents, as very creatures of the law itself, don\u2019t like to get sued for patent infringement anymore than they like to go to jail for financial crime in general. In fact, I think that patents on digital bearer transaction technology are so enforceable that they are completely obstructing progress in digital bearer settlement right now.I would even go so far as to say that none of the current holders of digital bearer patents, (and, frankly, most of the current crop of people who want to control those patents in the future) know the least thing about financial markets and about how to market digital bearer transaction settlement to the financial community.Well, actually, there is one person who might be the exception to that rule, and that\u2019s Scott Loftesness, the recently appointed President of DigiCash, Inc. DigiCash, you will remember, was founded by David Chaum, the father of modern financial cryptography, and is the company which holds the blind signature patent, the original patent on anonymously-transferable digital bearer certificates.Unfortunately, after finally getting control of his company\u2019 s intellectual property, Mr Loftesness now has to pay down a mountain of debt, mostly in failed bridge loans to venture capitalists, all of which are secured by those patents.In my opinion, this debt may already exceed the estimated experimental licensing revenue remaining in the useful lifetime of the patents involved. And, given DigiCash\u2019s failure to find a market for their digital bearer certificates, licenses for experimental purposes is about the only alternative left.DigiCash is already in Chapter 11, and, unless someone can see a way to market for that technology that others haven\u2019t seen already, the firm may not re-emerge.And so, a group of us are looking at putting together a research-based syndicate to hold the DigiCash patents, or at least the most important internet-only pieces of that portfolio, in order to keep it from being tied up for the rest of its usable lifetime. The idea would be to license it for research purposes to all comers, and only when bearer certificates using the patented technology were exchanged into book-entry assets would a modest royalty accrue to the syndicate membership, payable at the gateway between the internet and the proprietary financial networks.Syndicate members would get unlimited use of the patent, or at least a reduced royalty rate, as further remuneration for their investment. As much as I hate the idea of path dependency, I think that there are only so many neurones which any one company can apply to the problem of digital bearer settlement. If one company controls a critical bit of technology, the chances are too great, in a still incredibly experimental marketplace, of a dog in the manger preventing anyone else from making something happen.Internet years are too short for the rules on patent duration as it is without financial cryptographers trying to be software developers, or banks, or anything else; something I\u2019ve railed about on the net many times in the past few years. Since invalidating the very idea of software patents anytime soon is not reasonable (to the contrary, even business processes seem patentable at the moment, one look at the Walker Digital patent farm tells you that much), it might be worth figuring out a way for cryptographic protocol inventors to get paid for their intellectual property without holding up research in the field for everyone else.While I think forming a syndicate to hold those patents, or a royalty association, something like what ASCAP does for songwriters, is the way to solve the problem, I\u2019m certainly open to other suggestions.So, there, after about six months, you have it. Not only have I discussed the enormous possibilities of the emerging world of digital bearer transaction settlement, but I\u2019ve shown you how to do every financial instrument you can ever imagine in digital bearer form, using ubiquitous geodesic internetworks as your marketplace. All of this, hopefully, for significantly less cost than it would be to drag all those book-entry audit trails behind you all over the internet. I certainly enjoyed this series of articles, and I hope you did, too.Back to table of contentsThe weeks running up to this year\u2019s Financial Cryptography Conference (FC99) were really amazing, especially if you\u2019re a fan of digital bearer transaction settlement.First, there was a lot of excitement about the forthcoming disposal, out of bankruptcy, of the DigiCash patent portfolio. This includes David Chaum\u2019s blind signatures, which are useful, as you remember, for macro-scale cash, bonds, and even equity.Mark Briceno, a former DigiCash employee now turned dealmeister, said at FC99 that he has put together a syndicate which includes all of DigiCash\u2019s former licensees, and that upon acquisition, the patents will be royalty-free for open source and experimental use. Unfortunately, two of his promised closing days since have come and gone, however.Yet, I recently talked to Nicholas Negroponte at the joint MIT Media Lab/USENIX Things that Think / Embedded Systems Workshops. Negroponte, the Media Lab\u2019s founder, is also, hopefully, the final Chairman of DigiCash, and has arrows in his back to prove it. He was talking to me quite nicely about Zero Knowlege Systems, the primary sponsor of Briceno\u2019s syndicate effort, so maybe something is in the offing. Finally.Another wierd thing happened to me the week before the conference, when I got a query from a local investment banker, representing a public corporation with $5 million in cash and $7 million in market value. He proposed creating a company by buying both DigiCash and DEC/Compaq\u2019 s Millicent technology. I went downtown to visit him, and said no, that wasn\u2019t a good idea, but that doing some kind of publicly-held financial cryptography patent royal trust, a cross between an oil-patch deal and Buffet\u2019s Berkshire Hathaway, might be a fun thing to try. His firm didn\u2019t like the idea, but I still think it\u2019s a good one, and, upon leaving, I felt like I was resigned to evangelizing this stuff to deaf ears forever.But, that very night, things changed enormously. I got an email message that night from Ron Rivest, sent to John Gilmore and Paul Kocher and cc\u2019d to me and Adi Shamir. Rare company, indeed.Ron Rivest and Adi Shamir are, of course, the R and S of RSA, the DC3 of the public key cryptography business. Rivest, himself of MIT, is responsible for RC4, the cipher behind the lock that appears on your browser when you encrypt your credit card number to Amazon and purchase a book.In addition to co-inventing RSA with Rivest, Adi Shamir, from the Weisman Institute in Israel, has blown up more ciphers, more smart-card hardware, more supposedly secure commercial cryptosystems than practically any other man alive.John Gilmore is one of the founders of Sun Microsystems, one of the founding board members of the Electronic Frontier Foundation, and a founding cypherpunk. For someone who\u2019s stirred up so much trouble, and with all the right people, he\u2019s one of the kindest folks I\u2019ve ever met.Gilmore\u2019s also the man who funded, for $250,000 of his own money, a special-purpose cryptographic supercomputer humorously called \u2018Deep Crack\u2019, which broke the US Government-mandated 56-bit Data Encryption Standard, or DES. In less than 3 days. At an amortized cost per key of about $360.Paul Kocher, a well-respected cryptographer with several famous cryptosystem attacks of his own to his credit, was the man who designed and built \u2018Deep Crack\u2019 for Gilmore, and who now runs it occasionally, on behalf of the EFF, under whose auspices the DES effort was undertaken to begin with.DES is ubiquitous in finance: $3 trillion a day in currency transactions are encrypted using DES, for instance. Breaking DES, in so short a time, and especially for so little money, was an act which sent shivers up the spine of bank security professionals everywhere.It\u2019s even worse than that. 56 bits, the largest keysize possible with DES, is also the largest key-size allowed for export by the US government. Not a good place for the financial community to be in, technology-delaying \u2018exemptions\u2019 for financial cryptography aside.So, into my email inbox arrives a message by and for the aforementioned cryptographic pantheon. The message says, quite simply, that just by designing and building a special-purpose machine to brute-force-search the DES keyspace, Kocher and Gilmore had inadvertently constructed a prototype MicroMint machine. They had, without knowing it, built a machine which would mint money in very, very, small denominations. A production machine would start at one thousandth of a dollar and go down from there.I just sat there, stunned. I thought it would be years before something like this was going to happen. Digital bearer microcash has always been my \u2018way out there in left field\u2019 scenario, something I used to scare old people, children and politician with. I joked about routers that would use micromoney to buy bandwidth low and sell it high, saving enough out of operations to buy a copy of themselves. Or about toasters which would buy their electricity out of the wall. Or cars which pay tolls to use neighborhood streets and roads. Privately owned streets and roads, much to the joy of libertarians everywhere.Rivest apparently cc\u2019d me on this amazing email message because I had talked to him over lunch, almost two years ago, about commercializing MicroMint someday.So, in my reply to this email message from cryptographic Olympus, I effused, at typical great length, about my underwriting model for digital bearer settlement, and how, since the prototype was already there in the form of \u2018Deep Crack\u2019, it was probably time to talk about building a production version of a MicroMint machine. Somehow. An actual financial cryptography supercomputer, probably costing several million dollars or more. Somehow.Since everyone but Gilmore was going to Anguilla the next week for FC99 anyway, something I\u2019m sure Rivest knew when he\u2019d sent the email, I proposed that all of us talk about it there.Immediately, I started emailing all the other people I thought I needed to make this work. Fortunately, they, too, were almost all going to Anguilla for FC99.The very first person I wanted sitting on my shoulder for a reality check, Jiminy to my Pinnochio, was Paul Guthrie, VP of Advanced Technology at VISA. Paul has been a long-time subscriber to my all digital commerce and financial cryptography lists, and has gone to every one of my Financial Cryptography conferences since the beginning.Paul and I have talked extensively in the past about what it takes to effect a withdrawal of digital bearer cash from the automated teller network on to the internet, instead of a mere purchase of digital bearer cash with a credit card. Even more important was solving the problem of deposits from the net, which, oddly enough, is not intractable at all. Since VISA has it\u2019s hand in practically all funds-transfer and payment-systems networks, especially, for my purposes, the PLUS ATM network (Cirrus is owned by MasterCard), Paul\u2019s a very good person to know, and we have a lot of fun talking about this stuff.It dawned on me, as we approached the conference, that the only two people I really needed to talk to to see if this was technologically possible, better, to have talk to each other, was Paul Kocher, the builder of \u2018Deep Crack\u2019, and Paul Guthrie, who could figure out in detail what integrating a MicroMint machine with the rest of book-entry financial system meant. Everyone else was just window dressing.Did I get some amazing window dressing. I ended up with a dinner, for 17 people, at a nice French resturaunt just down the beach from FC99\u2019s first-night cocktail reception. I just went around the room towards the end of the reception, grabbing everyone I thought I needed and hauling them down the beach to dinner.Besides Duncan Goldie-Scot, of this newsletter, this crypto-herding exercise included people like Nicko van Someren, the founder and CTO of nCipher, a British company which makes cryptographic accellerator hardware for internet commerce; Adam Shostack, cypherpunk turned CTO of Netect, a network security software company; Fearghas McKay, former British Internet Society chairman and now CTO of MIDS, an internet traffic-analysis company; Derek Atkins, of PGP 3.0 fame and now of Lucent; and Jason Cronk, owner of a large Florida web-hosting firm, and a big advocate of cash-settled geodesic recursive markets for intellectual property.I didn\u2019t grab Ron Rivest himself and shove him down the beach towards dinner like I did the rest, because as someone with lots of people wanting his attention I figured he would be busy. But, to my surprise, after we had all sat down to dinner, Rivest and his wife wandered in for dinner on their own, and they came and sat with the rest of us. I was very happy.So, after sitting all the right people together so they could talk to each other afterward, I banged on a glass for attention and got everyone caught up on Rivest\u2019s email message about the possibility of \u2018Deep Crack\u2019 being used to run MicroMint, kicking off an excellent dinner conversation on how to make an internet bearer microcash system happen.It turns out that while it may be a little complicated to make changes to the ATM system to allow deposits from a third-party machine in much the same way that you can make withdrawls now, you can use other systems like ACH to get the same result, and, in fact, most of the problems faced by a nacent MicroMint are regulatory. People like Paul Guthrie kept beating me over the head with Federal Reserve Regulation E, which, as currently written, prevents digital bearer cash from being treated the same way as paper bearer cash is.At this point I said something fateful. I said, \u2018If you guys can design a system which allows me to withdraw money, in microcash, from my bank account over the internet, and to deposit it later the same way, I\u2019ll get you guys, Ron (Rivest), Paul (Kocher), Paul (Guthrie), and Nicko (van Someren) in front of Alan Greenspan himself if I have to, demo it, and get Reg E changed.\u2019 Dead silence. Followed by skeptical laughter all around.Fortunately, I\u2019m still immune to this stuff. I\u2019d been there before, and I consoled myself with my favorite Schopenhauer quote, the one about how new ideas are first ridiculed, then fought violently, and then declared obvious.Yet, Greenspan, a not-so-closet libertarian, if not a closet \u2018Austrian\u2019 economist, loves the idea of private currencies like we would be doing with this MicroMint box, and, if talked to in the right way, he would probably become an advocate for a revision of Reg E to account for digital bearer cash.So, for the next day or so, I couldn\u2019t get this idea out of my mind. It was dawning on me that, because of developments with the DigiCash patents, and especially with this news about MicroMint, that there was simply no scientific or technological obstacle whatsoever to the underwriting of internet-based digital bearer instruments, not just microcash, not just \u2018macro\u2019cash, but, someday soon, debt, equity, and any derivative thereof.It\u2019s time to do some actual finance with all the financial cryptography. Later in the conference II came up with a company name for an internet bearer underwriting corporation. I called it, oddly enough, the Internet Bearer Underwriting Corporation. The fact that the corporation\u2019s initials sound like \u2018I-Buck\u2019 never entered into my mind.Two weeks ago, I went downtown to the lawyers who incorporated my last company and got the ball rolling. We registered the Internet Bearer Underwriting Corporation in Delaware a week later, and I\u2019m actively seeking officers, a board of directors, and, of course, shareholders. I have signed the incorporation papers, so I guess it\u2019s official.I\u2019m hoping to turn the key on all of this, to go live to the net, by the first week of July, 2000. That should allow whatever Y2K hysteria is left to transpire, certainly, but it\u2019s mostly because I don\u2019t think I can raise money and get anything built faster than that, anyway. And, frankly, it will probably be later, \u2018internet years\u2019 or no.I want IBUC to underwrite, after 5 years, $30 billion a year in internet microcash, in bearer form, at an average front-end load of 85 basis points. That\u2019s how the investment hockey-stick looks, anyway. $30 billion is a scary number in the technology business, but it\u2019s not too scary in finance remember that $3 trillion-a-day currency market.So, wish me luck, everyone.Back to table of contentsAt the end of last month I began building the revenue model for IBUC, the Internet Bearer Underwriting Corporation, which I founded here in Boston, and wrote about in the last issue. You can \u2018back\u2019 into some pretty interesting numbers without doing a market test at all, something which is, frankly, impossible anyway, given the mostly unknown, and not insignificant capital cost of building the MicroMint box, for instance. First, you need an adoption curve. Typically, people in marketing use the logistics equation\u2019s curve. In our case, however, we had some real data, the historical and estimated future dollar volume of internet retail transactions, which, of course, are mostly credit card transactions. We got some from a fairly reliable source. These adoption curves start in the small hundreds of millions in 1995 or so, and, from 1996, they grow at a compound annual growth rate of about 100% or so over the last four years, into the tens of billions for this year. Using this time series, we now have as good a guess for an adoption curve as any for a proposed digital bearer payment technology. If something proves useful, it\u2019ll probably be adopted this fast, and if done right, probably won\u2019t be complementary or competitive with existing transaction types, thus increasing the dollar volume of internet transactions over time. So, we can take this normalised curve and tweak it for all transactions executed by mulitiplying the credit card number by some factor, or, we can use it fractionally, like we did, to gin up some numbers for a specific product. Again, you can back into a fairly nice approximation with actual data. Every year, the Bank for International Settlement publishes a report showing the global transaction counts and dollar volumes by each payment method, cash, credit cards, checks, wire, ACH, and so forth. Since virtually all transactions on the internet are executed with credit cards, if an meatspace-equivalent-risk digital form existed in digital bearer form, it\u2019s safe to assume that we might apply the meatspace ratio of that method to credit cards to the cypherspace credit card number. Of course, that doesn\u2019t work so good for MicroMint-based microcash, which doesn\u2019t have a meatspace equivalent, but it\u2019s a good start. So, use that factor times whatever market penetration number you think you can justify, and you have, voila, a revenue curve. So, now, we need an upper bound to all this unbounded enthusiasm. My CFO and I were wondering how we were going to do this, when, we remembered that we were in the underwriting business. After rooting around a bit, it dawned on us that Goldman Sachs had just filed a shelf offering for their IPO, so we went to the Securities and Exchange Commission\u2019s EDGAR website to go look at it. Right up there, on a metaphorical movie screen, was about a megabyte of information on how to be an underwriter, including the size of the global capital markets, Goldman\u2019s underwriting revenue and profits, and a whole host of other goodies. When we got through reading this, we were swinging from the lamp posts.Cheers,\nRobert HettingaBack to table of contentsRegulators have not even started to get to grips with the challenges they will face in the wired world.In the summer of 1996, about a year after a bunch of us started the Digital Commerce Society of Boston, friend and fellow ex-cypherpunk Perry Metzger, formerly of Bellcore and Morgan Stanley and now owner of Piermont Systems (www.piermont.com), a well-regarded financial computer security integrator, came up from New York to talk to us about how financial cryptography would allow the issue, on to the net in digital bearer form, of any financial instrument we could conceive of. Perry discussed some whimsical \u2018gold-denominated Burmese opium futures\u2019, for which he named his talk that day.Implicit in that title, of course, was the point that government financial regulation, and, someday, governments themselves, were somehow \u2018optional\u2019 in a world of totally anonymous, but still non-repudiable transactions.Eric Hughes, one of the co-founders of the cypherpunk cryptography enthusiasts\u2019 list, went even further in his thinking. He liked to say that, in imagining a world with ubiquitous internetworks and strong cryptography, it helped to \u2018think like an illegal actor\u2019. Imagine, in other words, a world of ubiquitous recreational vices, murder-for-hire, and all the other staples of any good mob novel: all of it available, with impunity, everywhere, all the time, on the net, for a price. A frankly romantic vision, now, in hindsight.If anything, recent history seems to show otherwise: all law seems to be enforceable everywhere, all at once.For instance, several years ago a gentleman was extradited to Tennessee and convicted for the pornographic contents of his California computer bulletin board.Within the last few years, two members of the cypherpunks list themselves have been convicted, and sent to jail, for making public threats to specific federal judges and officials, both involving completely hypothetical digital-cash-settled assassination auctions. Hypothetical, of course, because there isn\u2019t a working digital cash system, among other things. One of those convictions seemed, to me at least, more for a form of tacky political performance art than any physical threat to a judge, though the judge apparently thought otherwise.And, of course, we should expect equivalent international incidents of these kinds, sans theatrics, sooner or later. After all, almost all countries have extradition treaties with each other for violent crime, and most at least for fraud, if not necessarily for other financial or tax crimes. If the aforementioned gold-denominated Burmese opium futures were illegal in one place at all, current legal opinion holds, cyberspace makes them extraditable, and thus illegal, everywhere, no matter the server\u2019s physical jurisdiction.Yet, cryptography itself, the thing which could so romantically change this state of affairs, is still being \u2018decriminalized\u2019, and, recently, it has been done so an astonishing rate. Within the last month alone, Canada, Germany, and Britain, even France, who virtually outlawed cryptography of any strength whatsoever, have all seen the writing on the digital commerce wall, and have announced, grudgingly, that they will explicitly \u2018decontrol\u2019 cryptography in some fashion or another.As people on the net have known for years, nation-states can now see that digital commerce means financial cryptography, and that financial cryptography must, of necessity, be the strongest possible cryptography available if it is to be of any use at all.In other words, nation-states understand one of Hettinga\u2019s many \u2018laws\u2019 of digital commerce: Financial cryptography is the only cryptography that matters.Even national security is taking a back seat to commercial \u2018signals intelligence\u2019. Last month, the US Congress found itself the scene of the most amazing spectacle, with the National Security Agency claiming, of all things, attorney-client privilege in order to keep from discussing Echelon, a 40-year-old \u2018I\u2019ll spy on your people if you spy on mine\u2019 co-operative eavesdropping arrangement between the intelligence services of most developed nations.Yet, the primary reason for such sunshine in dark places is not politics at all: it is business.In the ultimate swords-to-ploughshares exercise, Echelon data, obtained at enormous taxpayer cost, is now being used, evidently, to give US companies an economic advantage in their international business negotiations. Why? Because, of course, other countries do it for their citizens. France, with its ironically strict cryptography controls, has been repeatedly caught informing companies like Bull and Airbus about the results of its operations against companies like IBM and Boeing.Access to Echelon data seems to have even been offered by David Aaron, the Clinton administration\u2019s erstwhile roving cryptography ambassador, as an inducement for countries like Australia to sign on to the Wassanar \u2018 arrangement\u2019, an \u2018informal\u2019 agreement among a large number of industrial nations to promote so-called \u2018key-escrow\u2019 encryption, a form of cryptography where the government has a copy of everyone\u2019 s encryption keys. Key-escrow, or Government Access to Keys (GAK) to its foes, is, of course, mutually exclusive from digital commerce, and GAK\u2019s various US legislative incarnations have been steamrollered accordingly.My guess is that the Jospin government finally figured out that \u2018infowar\u2019, when it happens, will occur not between nation-states, but between businesses, and that the best way for France to protect her businesses, and thus her tax base, is to allow their use of the strongest possible financial cryptography available. Which, given the eventual use of financial cryptography on the internet to hide private financial assets from confiscation by nation-states, makes for a marvelous paradox indeed.So, what about that romantic vision of \u2018cryptoanarchy\u2019 , as Tim May, another founding cypherpunk, called it?Remember, most of the acts that we call criminal today, especially those involving violence and property, still happen in \u2018meatspace\u2019, the abode of humans, and not \u2018cypherspace\u2019, the abode of encrypted electrons.Meatspace, as anyone who has seen (or suspected) a surveillance camera knows, is becoming more and more supervised with every iteration of Moore\u2019 s Law. A digital CCD video camera, ready to be plugged into the internet as a web-cam, sells for less than $100 these days. Thus, it\u2019 s no surprise that an overwhelming majority of this surveillance is the completely private supervision of completely private property to prevent that property\u2019s theft or damage. Yet, people don\u2019t complain about this ubiquitous videography nearly as much as they would if a government did it. In fact, except for ostensibly personal spaces like restrooms or employee locker rooms, people don\u2019 t complain at all about private supervision of private property.As we encrypt our digital property to protect it in \u2018cypherspace\u2019, making it more invisible to nation- states, we increasingly supervise our physical property to protect it in meatspace, making it more visible if you will, all without requiring a nation-state to do it for us.More important, we increasingly enforce those property rights with private means: security guards, for example, armed or otherwise. That\u2019s because, like everything else we buy, it is increasingly cheaper to buy private goods and services than \u2018public\u2019 ones, even force.Put another way, direct payments, priced in auction markets, are increasingly cheaper than transfer payments, at a calculated price, between various accounts on a firm\u2019s, or a country\u2019s, books. Professor Von Mises and his calculation argument against socialism strikes one more time.Moore\u2019s law accelerates this by dramatically reducing transaction costs, both in obtaining and processing necessary market information, first with cheap telephony, personal computers and faxes, and now with email and the web, but also in reducing the execution cost of those transactions themselves, with SSL and digital signatures for credit cards and checks, and, eventually, the clearing and settlement cost of those transactions as well, with digital bearer financial cryptography.The result of lower transaction costs, as Coase tells us, is smaller, and more autonomous, \u2018firms\u2019: private, public, or otherwise. The fractal disintegra- tion of large hierarchical empires like the former Soviet Union, or Yugoslavia, is a case in point, but so too is the peaceful \u2018devolution\u2019 of centralized power to smaller governmental units in both the US and Britain. Or, even, when one thinks about it, the apparent commercialisation of the Chinese People\u2019s Liberation Army.Nation-states, like their aristo/theocratic predeces- sors did with industrialism, will have to stand back and let the geodesic train go by. And, like aristo- crats and theologians before them, politicians will increasingly become mere ceremonial appendages to a larger, more geodesic, economy and society. The nation-state as entertainment, if you will.So, we might actually have gold-denominated Burmese opium futures someday. Financial cryp- tography allows anything to be bought and sold, of course, as long as it can be represented on a wire with bits. Getting delivery of physical goods in some eventually private \u2018 jurisdictions\u2019 may be an- other thing altogether.We might even have, heaven forbid, auction mar- kets for private-sponsored assassination itself, just as Hughes and May predicted, so long ago, at least in net-years. Certainly the death penalty is a type of state-sponsored assassination, and lots of countries still have that. Commercial assassination, ala \u2018The Godfather\u2019 is a, um, horse, of a different colour en- tirely, though.War is, of course, murder on a grand scale, and something the more centrally-controlled nation- states have been particularly good at in this century.But, I think, on the whole, with enough private supervision of private property, physical crimes, especially violent ones, will decline over time, and maybe even dramatically.War and murder, are, after all, seriously bad for business \u2013 ask any Serbian shopkeeper these days \u2013 and the best way to prevent vandalism and the destruction of property, even on a large scale, is to identify the people doing it and then physically prevent them from doing so. This process would start from the ground up, it would seem to me, just by securely broadcasting criminal actions to a geodesic network, and warning others nearby to secure their property, and by force, if necessary.So, even if, over time, most financial assets will migrate to the net, and the ability for an individual to act remotely to effect a physical outcome \u2013 even a violent one \u2013 increases, this action-at-a-distance can only occur within the bounds of someone else\u2019s private surveillance and protection scheme.Your freedom to act ends where my nose begins, in other words.That is not an intolerable state of affairs at all.Back to table of contentsBob Hettinga continues his series about his start-up Internet Bearer Underwriting Corporation \u2013 IBUCI started IBUC, my new internet bearer underwriting venture, because bearer micropayments, a technology I had left for the distant future of internet commerce, had come out of nowhere to be the easiest technology to implement first?The same kind of unexpected, amazing thing happened on the demand side of the equation last month, when internet advertising revenue began to decline precipitously.It was only within the past year that advertising revenue was overtaken by commerce revenue as the mainstay of the internet economy. First with brochure sites for companies such as AT&T made by companies with names such as net. genesis and RazorFish, and then with internet gold-rush sites such as Pathfinder, HotWired, Yahoo, Lycos, and Excite, it seemed that the only way to make money on the net was to either construct a brochure site, which itself was nothing but an advertisement, or own a content site, which was itself supported by advertising. Even better, obviously, was selling equipment and services to those who did one or the other of the above. Gold pans and blue jeans to the miners.The realisation that inventory databases could be linked with financial cryptography on a web-server means that commerce for things normally stored in warehouses and sold by salesmen has exploded on the net. Companies such as Dell and Cisco get a majority of their multi-billion-dollar revenues straight from the web, for instance. The total amount of internet commerce is expected by several sources to top a trillion dollars by 2002. With the very sizeable exception of financial assets (a majority of all individual stock trades will soon be originated from the internet, for instance), and travel services, most of that projected internet commerce revenue will still be for items you can physically touch, things which are delivered later, instead of now, things which you\u2019ll keep after you purchase them and not literally throw away after a single use.But it isn\u2019t that commerce for books, computers, and other actual stuff is just getting bigger than that for advertiser-paid content. Not at all. Advertisements on the web have shown themselves to be eminently ignorable by the web-browsing public, and, as a result, advertising revenue has actually fallen, and considerably so. Every large web-content site you have ever heard of has a huge budget for advertising outside the net, print, magazine, television, even radio, because ads on the internet itself just aren\u2019t that effective. And, yet, what these very firms sell, ostensibly, is internet advertising, and not the actual content of their websites. So, while things haven\u2019t reached panic proportions yet in the content business, it will be interesting to see how content providers are going to react to all this.The very definition of industrial-age mass media is that it is produced on something cheap enough that it can thrown away after consumption. Of course, geodesic media has the same or cheaper delivery cost. Furthermore, Moore\u2019s Law on a ubiquitous internetwork allows the size of a \u2018production run\u2019, or \u2018audience size\u2019, to approach one. Or, at least, you could do it that way, if you could lower your transaction costs far enough. In other words, in a geodesic medium such as the net, it will probably turn out cheaper to actually pay the content\u2019s creator directly for custom content with digital bearer microcash than it is to \u2018target\u2019 advertising through one or more industrially-organised \u2018infomediaries\u2019 (or whatever McKinsey\u2019 s buzzword-du-jour is these days).That\u2019ll be true no matter how big, or fast, your customer datamines can be. The market is your database, in other words. Database marketing, just like database transaction settlement, will choke on the sheer volume of \u2018targeted impressions\u2019 it has to monitor, and, more important, transfer prices it has calculate to pay for those impressions. A geodesic market sees such information choke points as damage, and routes around them.Advertising supported mass-media, is, of course, the quintessential transfer-priced command economy. That is, accountants, not markets, attempt to calculate the value of whatever content an advertiser purchases on behalf of that content\u2019s consumers, using not-always-accurate heuristics like cost per thousand impressions, say, or percentage audience share. As most serious students of finance already know, it was the demonstration of the near-impossibility calculating a transfer price which resulted in most of the Nobel prises in economics given out in the last few decades. And so, as I\u2019ve said about financial cryptography and cryptography itself, financial economics is the only economics that matters these days. In fact, the only time transfer pricing is even attempted is when transaction costs outside the firm were too high, for one reason or another, to get a market price. This is, of course, Coase\u2019s theorem, the fundamental theorem of microeconomics, and that theorem, in turn, is the very definition of what is, or isn\u2019t, a firm. More to the point, transaction cost determines exactly how large any firm can be.The very concept of economy of scale comes from this. Since we at IBUC have sworn ourselves the equivalent of a barbarian blood-oath against transfer pricing on the internet, we have always considered web-page advertising as an almost unitary proxy for the potential content segment of digital bearer microcash market, and thus completely fair game when we go \u2018viking\u2019 in that direction. However, it now appears, the market for that unitary proxy has fallen. Does mean that there\u2019ll be no more content on the internet, especially at very low cost? Hardly. It only means that transfer pricing doesn\u2019t work as a way to pay for internet content. It\u2019s only really a problem for industrial-style distribution hierarchies, not the people who actually produce new content. As the technology of internet content delivery keeps exploding, and the price of distribution itself collapses accordingly.MP3 audio files proliferate, much to the consternation of record company executives everywhere. And much to the delight of those artists getting heard by more people just by disintermediating those very same record companies. And, it\u2019s getting cheaper.All this new networked content business needs is a new way to pay for it all at that exponentially falling delivery price. (Shhhh. If you listen very carefully, you can hear a Norse rowing song coming up the river.) So, while most industrial content \u2018infomediaries\u2019 may be hiding behind their castle walls of lawyers, professional managers and strategic consultants, the smarter ones are investing a little danegeld to get involved in these new markets for content and get along with their new barbarian neighbours. After all, artists just want to be seen and heard, not sell to themselves.Intermediation doesn\u2019t go away in this new world: it atomises into smaller and smaller bits with each iteration of Moore\u2019s law. So there is a way to pay for micro-cost content, and that is digital bearer micropayment. It\u2019s simple to imagine a protocol where a content client keeps putting pennies into a server\u2019s coinbox for a certain number of megabytes or seconds of additional streamed content. It\u2019s even easier to see some kind of XML function for doing things with each web page we see. The problem is, most of this potentially valuable content is still, for all practical intents and purposes, buried deep inside the transfer-priced cost of other things, like advertising, and even internet access. Internet access which, itself, is buried in the cost of telephony in certain tariff-mandated transfer-priced markets such as Great Britain. It\u2019s \u2018free\u2019, in other words. That the word \u2018free\u2019 actually means a redirected payment and a transfer price makes no difference to an uninformed, and, frankly, innumerate, public. They are \u2018paying\u2019 all that they want to for using the web, for internet access, and especially for telephony and, they expect the price to fall as time goes on.It\u2019s what Michael Eisner likes to call the financial \u2018box\u2019 we have to operate in. As long as a customer\u2019s cost to use the net falls over time, he\u2019s happy, whether he pays cash to every website he sees, or he pays for it by the month to an ISP, or he pays what amounts to a tax on his phone calls, to get it.How does a content provider bootstrap this? Easy. Damn the torpedoes, sell stuff for cash anyway, and let the market sort it out. Transfer-priced content is going to go away, one way or another, and clinging to the sinking ship of advertiser revenue and other equivalents won\u2019t help matters.What will happen in the content market is what always happens when revenue dries up: a shakeout. If it\u2019s not currently underway, that is. Pathfinder, for instance, is gone, subsumed by a separate site for each Time Warner\u2019s media properties. The people who do things for free will continue to do so until their expenditures, or their opportunity cost, causes them to quit. The people who do really valuable things will continue to do so as well, and get paid for it somehow. For the rest, it\u2019s really a question of either being the lowest cost producer/ distributor, or finding new revenue streams, or some combination of both.My claim is that those in the last group will be people who focus on aggregating and distributing content instead of creating it, that everyone\u2019s going to be the lowest cost producer/distributor, that the transfer-priced revenue they were invented for will dry up. Any good market eats it\u2019s young, and all that.That brings me to something I\u2019ve called a geodesic recursive auction. I\u2019ve actually talked about the idea here in this column before, but this new \u2018emergency\u2019 in internet content revenue dictates a little more detail in the discussion.The idea itself is pretty simple. I create new content. I sell it to you for the most I can get for it, and I keep doing that until nobody else wants to buy it anymore. If people are deluging my server with purchase requests, I raise my prices until the load goes down to something manageable. If I have no traffic, then I\u2019m charging too much. Buy low, sell high; charge all that the market will bear. Darwin rules. By the same token, if I download something from you, I can turn right around and sell it again to anyone who wants to buy it, thus maybe recoup my costs, and even make a profit. The assumption is that on the net, things like copyright and other intellectual \u2018property\u2019 controls simply cost too much to enforce. It\u2019s hard to reach out and arrest somebody over the net, particularly if functionally anonymous bearer transactions are the cheapest possible transactions. Also, the additional cost of copy-control mechanisms such as \u2018watermarks\u2019, \u2018cryptolopes\u2019 and so on is simply too high for whatever extra value they might provide.Before the advent of ubiquitous geodesic internetworks, much less auction-priced digital bearer transactions, huge amounts of profit were eaten up in the inefficient transfer-pricing of production assets, or, more important, the information about that assets, up and down the organisation chart and its corresponding chart of accounts. Industrial-era record companies, publishers, and entertainment networks are all still fairly hierarchical entities today, even though the economics of Moore\u2019s law has changed their business considerably over the last thirty or forty years. It\u2019s not without a reason that the most important person in the movie business these days is the artist\u2019s agent, and not the studio head, for instance. Digital bearer cash, at sufficiently small denominations, probably the $10-3 (a tenth of a penny) range, or maybe lower, enables the direct purchase, and, more important, the immediate disposal of content after its use.In so doing, it solves precisely the problem that advertising does by batching impressions and transfer-pricing the cost of delivering the content responsible for those impressions. More to the point, it uses economics and software to solve the problem of copyright infringement, because storage cost should vastly exceed purchase price. (By the way, we at IBUC call $10^-3 a \u2018minidollar\u2019 because \u2018millidollar\u2019 sounds too close to \u2018Millicent\u2019 a proprietary trade-name belonging to Digital, now Compaq. Another transfer pricing problem, yes?) In other words, digital bearer minidollars give us the exact industrial definition of \u2018mass-media\u2019 \u2013 use it once and throw it away \u2013 but without the transfer-pricing overhead of hierarchically organised markets. Toffler\u2019s \u2018mass-customisation\u2019, indeed. Only there\u2019s no industrial-era \u2018mass\u2019 to any of it. Every single bit is paid for directly by the user of those bits, in a hyper-efficient, auction-priced, cash settled, geodesic, market. The customer, and the producer, get exactly what they want, and more of it, for less money. Sounds like progress, instead of disaster, to me. And, of course, for us at IBUC, it\u2019 s almost divine providence.Back to table of contents\"Who needs money anyway?\": The New Monetary Economics, Monetary Separation, and Digital Bearer SettlementOne of my best friends in the whole world is Mark Tenney of Mathematical Finance in Alexandria, Virginia. The best man at my wedding, I met Mark during my mostly sad attempt to go to the University of Chicago as a \u201cStudent-at-Large\u201d, where I snuck in the back door and hung out for almost a year before they threw me out \u2013 though, to my credit, or lack there of, it was for impecuniosity, more than anything else. \u201cFirst thing you do, you get the money\u201d, and all that.It was fun, though, and I did manage to transfer enough credit from Chicago to finish my undergraduate philosophy degree at Missouri. Up until the last five years or so, when I discovered the \u201cUniversity of the Internet\u201d, I\u2019d always wished I could afford to go back some day and play some more, especially in finance and economics.Anyway, Mark was one of those scary mathematical prodigies who finished both high-school and college in three years apiece, finished all-but-a-doctoral-dissertation in Physics at Brandeis in three years, hedging himself with an Master\u2019s, then turned on a dime and did the same thing in Finance at Chicago, hedging again with an MBA in Finance. All this before wading into the fray of quantitative fixed-income analytics-for-hire, swinging that claymore-sized intellect of his with both hands.Last year, I told Mark that I had decided to concentrate on digital bearer transactions full-time, and he asked a bunch of questions like he always does when I reveal my latest off-the-wall idea. And not saying much in reply, which he also always does, being one of the most laconic people I\u2019ve ever met. That\u2019s okay, I suppose. I talk enough for both of us.Anyway, a few days later, Mark calls me up, all excited. Well, as excited as Mark gets, anyway. \u201cYou could issue digital bearer certificates backed up by an S&P 500 portfolio,\u201d Mark says with not much affect, followed by dead air, which is my cue to talk.\u201cYup,\u201d says I, chattering away, \u201cThat\u2019s easy. Old hat. We talked about stuff like that on cypherpunks years ago. The only problem is, it\u2019s illegal in the US for various reasons, and proving that you\u2019re only issuing to and redeeming from foreign nationals is really too complicated. We don\u2019t call it \u2018digital bearer settlement\u2019 for nothing. Of course, that doesn\u2019t keep several smash-the-state cryptoanarchists out there from daydreaming, in color, about that idea pretty much full time. Expressions like \u2018tax-evasion\u2019 and \u2018money-laundering\u2019 only make them work harder, after all. Me, I\u2019m only in it to reduce transaction costs. Illegal business is chump change compared to putting the entire global economy onto the net in digital bearer form.\u201cSteve Schear and I even figured that you could do it with just about any stock, anywhere, from anywhere, as long as it was legal in the jurisdiction you did it from. Sort of an \u2018Unsponsored Network Depository Receipt\u2019, UNDRs, for short\u2026\u201d and then, I proceeded to go into an entire rant on that. In four-part harmony. Arlo Guthrie would have been proud\u2026Finally, I run out of gas, like I always do, and Mark says, \u201cIf you issue digital bearer certificates collateralized by the S&P 500, you won\u2019t need cash anymore.\u201d More dead air.\u201cWell,\u201d I said, jumping back in, \u201cmaybe, maybe not. I mean, the dollar\u2019s pretty much pecunia franca right now, yes? Anyway, you wanna write something up about it, and we\u2019ll zing it out onto some of my mail lists for comment?\u201dI figure that if Mark was excited enough, he could bash on the mathematical finance of this idea much better than I ever could, being mostly innumerate myself, with my undergraduate philosophy degree from a midwestern state-school, and leftover student-at-large credit from UofC.I mean, the closest thing I ever got to a genuine financial education was sneaking out of the University of Chicago Bookstore Graduate School of Business textbook section with books like Brealy & Meyers\u2019 \u201cCorporate Finance\u201d, and Sharpe\u2019s \u201cInvestments\u201d. Needless to say, reading stuff like that, and hanging around people like Mark at a place like Chicago pretty much set my \u201cif there\u2019s not a market for it, it really doesn\u2019t matter\u201d view of reality into steel-reinforced concrete. It\u2019s kind of the core of my anti-state bias as well, I suppose.Mark is, of course, a pro at this kind of stuff, having figured ways to use Green\u2019s functions to kill off lots of Monte-Carlo modeling, building closed-form solutions for various security prices, and so forth. His asset-liability models sit in the guts of several very large insurance companies, and there are questions about his asset-value calculation methods on the US actuarial exam. One of his latest projects is building the analytical core of start-up e-finance company in an as-yet undisclosed European country, and his client before that was one of the largest financial services firms in the world, owning well-known insurance and mutual fund companies everywhere you would care to name.So, I didn\u2019t hear much from Mark about this idea of his anymore, probably because most of his \u2018wetware\u2019 bandwidth is paid for these days, with real money, and he doesn\u2019t have much time to spare for actual fun \u2013 much less writing a non-reviewed finance paper that I would just pass around the net for free. And so that\u2019s the last I heard of it for a while.Then, a few months ago, after I\u2019d started up my new company, IBUC.COM, to actually issue digital bearer cash and other stuff some day, some newbie on the cypherpunks list talked about trying to do yet another internet currency, a smallish rant with a whole bunch of, well, wrong stuff in it. So wrong, in fact, I can\u2019t even remember most of it. As is unfortunately usual in these circumstances, I ended up writing my own rant in reply. It centered around my own favorite point on the subject, that unless any \u201cinternet currency\u201d was exchangeable into dollars, or some other standard unit of exchange, nobody was going to pay any attention to it.There have been several efforts on cypherpunks and elsewhere to think about synthetic currencies based on attention, or machine cycles, for instance, and, while using machine cycles to prevent forgery is at the core of most decent micromoney protocols like MicroMint, but you have to denominate your digital bearer cash in something financial, or it will be of no real use to normal people. Not that most cypherpunks care about being normal, you understand, but there it is.Nonetheless, I did toss off some nice words in the direction of the e-gold guys, who, at the time, were issuing a kind of gold-backed \u201cinternet currency\u201d, albeit in book-entry form. They had been having some success with it, mostly among the anarcho-survivalist gold-bug crowd. Meaning that a lot of very bright erst- and proto-cypherpunks have been playing with e-gold, for reasons of politics, paranoia, or both. Or at least so I figured at the time, anyway.Dr. Douglas Jackson, the oncologist-turned-founder of e-gold, is quite a bit more phlegmatic about these things himself, though certainly never a fan of fiat currency. He understands, for instance, that storage costs can make gold-backed account balances actually depreciate over time. But, in implementing the e-gold payment system, he and several thousand e-gold users have ended up with quite a bit more experience in non-credit-card internet payments than anyone else has to date, mostly because they didn\u2019t try to do anything too complicated in the early stages.More to the point, all of Doug\u2019s competition (like First Virtual, CyberCash, and DigiCash, to name a few) have killed themselves off going for the main chance. They kept trying to conquer the world, trying to be some kind of sole transactor of business on the web, without understanding that finance is a business of herds and swarms and that nobody trusts anyone who\u2019s the sole anything.Meanwhile, Doug\u2019s still doing a tidy, if not land-office, business, precisely because he\u2019s not trying to take over the world. In fact, I\u2019d say that anyone who\u2019s interested in internet payment should pay more than a little attention to e-gold, or, as their evangelist Jim Ray likes to call it, \u201cThe little internet payment system that could.\u201dAnyway, Ian Grigg, an expatriate Australian who I can\u2019t really call a cypherpunk \u2013 more of a \u201cmoneypunk\u201d, maybe, since he\u2019s spent a lot of time lately down in Anguilla building things for e-gold, among other people \u2013 sees this cypherpunks rant of mine about internet currency after I forwarded it to dbs, the digital bearer settlement discussion list that I run. Ian observed there that if transaction speed was fast enough, the market would probably converge to a world without cash at all. Shades of Mark Tenney.Since I respect Ian\u2019s opinion, because Ian seems to have read every \u201cAustrian\u201d economist there ever was, and is a great fan of Scottish free banking, not to mention because of all his work for e-gold, which now runs on his \u201cRicardo\u201d web-market-making system, I thought to myself, \u201cOkay. Maybe. Someday. In the meantime, I want IBUC to do cash, dollars preferably, thank you very much, and after that, other actual securities, and, after that, we\u2019ll see if the dollar really does evaporate as the world\u2019s primary exchange currency.\u201d And having said so to the list in reply, I left the discussion there for the time being.Which brings me to a little while ago, when I was half-to-three-quarters of the way through with a nice rant for this column on something else entirely, and ended up throwing it all in the trash.That was because of something I got in email from another friend of mine, one of the best internet transaction lawyers in the business, John Muller, a partner at Bobreck, Fleger and Harrison, in San Francisco. Among other things, John is Chair of the Web Site Working Group of the American Bar Association Joint Subcommittee on Electronic Financial Services (say that ten times fast), and Co-chair of the Automated Transactions and Electronic Agents project of the ABA Cyberspace Law Committee.What John sent me was the most recent Electronic Financial Services Update, the back issues of which can be seen at http://www.abanet.org/buslaw/efss/whatsnew.html, and in that update was \u201cTowards a Moneyless World?\u201d, a paper by Malte Krueger, of the University of Cologne and the University of Western Ontario, for the International Atlantic Economic Conference, which was held in Vienna this past March. Apparently, this paper was also presented in different form to the Second Berlin Conference on Internet Economics a little while later.And, there, after converting PDF to PostScript, and then PDF to ASCII text so I could read it faster, there was a pointer to where my friend Mark Tenney \u2013 and, I bet, Ian Grigg \u2013 got the idea that as transaction latency and transaction costs go to zero, the value function of currency converges to that of more \u201cfinancial\u201d assets: They were quoting, whether they knew it or not, the so-called \u201cNew Monetary Economics\u201d (NME), a phrase coined by Robert Hall, but conceived, in the early 1980\u2019s, by no less a pair of financial luminaries than Eugene Fama, of the Efficient Market Hypothesis, and Fischer Black, of the Black-Sholes option equation. Others, like Krueger, apparently, call this the \u201cBFH system\u201d, in their honor \u2013 or for other reasons, it\u2019s hard for me to tell.Krueger says, of NME/BFH,In the current system money (cash and deposits) is used as medium of exchange and unit of account. In the BFH system there would be no common medium of exchange with a fixed nominal value in terms of the unit of account. Instead, assets with variable prices are used. This implies that, in principle, any asset could serve as a medium of exchange. An example that is often used to illustrate \u2018moneyless\u2019 payments are mutual funds shares. The value of mutual funds\u2019 shares varies with the value of the funds\u2019 assets and within certain limits they can be used for making payments. So, the medium of payment \u2018mutual fund share\u2019 has a value that is not fixed in terms of the commonly used unit of account. Eugene Fama (1980) argues that monetary separation is efficient because the financial system (Fama uses the term \u2018banks\u2019) serves two functions that are independent of each other: the accounting function and the portfolio management function. Banks could fulfill the accounting function without holding assets or using any medium of payment. It would be sufficient to have a unit of account. As an uninvolved third party, banks could just keep records of transactions. The issue of liabilities and the purchase of assets is derived from the second function, the portfolio management function. In this function banks help individuals to hold their wealth in a form they desire.What the above means to me is pretty much what Tenney and Grigg said, that Moore\u2019s law creates an increasingly geodesic, ubiquitous, public internetwork, which, coupled with the financial cryptography of digital bearer settlement, \u201csurfacts\u201d currency into its constituent parts. Why keep something which doesn\u2019t earn you money, in other words? Why not use something which is as risk-free as possible but still earns money while it\u2019s in your possession? Furthermore, the longer money\u2019s going to be in your possession, the more incentive you have to invest in something where short-term volatility isn\u2019t a problem. We\u2019ll leave discussion of my opinion on the \u201caccounting\u201d function as an exercise for the reader.Anyway, Macroeconomists call this division of unit of exchange from unit of account, monetary separation. And, as a result, we get more and more different kinds of exchange with decreasing transaction cost. Banks go back to being \u201ccounting houses\u201d instead of fiduciaries, trustees, keeping track of who owes what to whom, and the returns on money are higher for the users of that money. The advent of the money-market mutual fund, was, of course, a step down this road.As to whether this means the death of currency, Krueger comes down on the side of network effects \u2013 unfortunately conflating them with path-dependency; network effects being cool, and path dependency being balderdash \u2013 and says that the opportunity costs of keeping track of various different asset classes, and, more importantly, exchanging those different asset classes with others just to effect any trade whatsoever in a virtual re-emergence of barter, still costs too darn much, and thus, the internet gives us monetary integration, and not separation. As someone said of Mozart, \u201ctoo many notes\u201d.I\u2019m personally not so sure, Moore\u2019s law being what it is. It might be easy enough with with enough bandwidth and processing power to do all those exchanges and re-balance one\u2019s \u201cportfolio\u201d of money-equivalents, paying people in whatever asset class they want, and still make more money than parking money as dollars in a bank somewhere, or, worse, keeping cash on hand.However, I also think that it\u2019ll be a while, just yet, for that world to emerge, and, frankly, I want to buy things with dollars, and right now.By way of some even more twisted synchronicity, Krueger\u2019s paper then points to my friend Tatsuo Tanaka\u2019s paper on the macroeconomic consequences of internet free banking. Which, oddly enough, I edited and recommended for publication in the peer-reviewed internet journal First Monday four or so years ago. I even invited Tanaka to come up and present the paper at a Digital Commerce Society of Boston luncheon shortly after the paper came out.Tanaka says, first of all, that internet free-banking is like the expatriate-cash Eurodollar market on steroids. Internet free-banking drives the final nail in the coffin of central bank control of any nation\u2019s currency, because, if a currency is stable enough, and maybe even if it isn\u2019t, sooner or later more of the currency is \u201cissued\u201d on a fiduciary basis outside a country, collateralized by foreign-held dollar-denominated accounts, for instance, than is issued by the central bank itself. And the net makes where the money is, heh, immaterial.Unfortunately, Tanaka also says that competition for underwriting cash to the net causes the eventual fractional reservation of digital cash against its denominated currency, and that, sooner or later, crises of confidence in all those different issues, and their various partial reserves, force the creation of, you guessed it, monetary union of some kind. Tanaka liked to wax about the eventual creation of a central bank of cyberspace, thus setting most cypherpunks\u2019 and other free-money advocates\u2019 teeth on edge, mine included, skyward-rolling eyes and all.But the story gets weirder than that. Recently, Douglas Jackson and his crew at e-gold have been taking their association with \u201cmoneypunks\u201d like Mr. Grigg (and, um, others :-) ), to heart lately. They split themselves into a trustee-underwriter relationship of several firms, and, in the process, have created an offshore subsidiary, based in, where else, Anguilla, to, you guessed it, offer fractionally-reserved, (but non-blinded) gold-denominated digital bearer certificates, called, oddly enough, DigiGold.The idea behind DigiGold is to fractionally reserve gold denominated transactions, loaning out the reserve\u2019s other fraction to offset the cost of gold storage, which, as we noted above, at a percent or more a year, is a considerable one if you\u2019re trying to create a currency which is supposed to hold its value. In fact, Ian went so far as to start buying and selling notes denominated in gold recently, apparently as part of his work with DigiGold.\u201cGold-denominated Burmese opium futures\u201d, indeed.For one final bit of weirdness, I eventually got around to reading Glassman and Hassett\u2019s Dow 36,000 article in the Atlantic Monthly, which, at the core of its analysis, notes that among other things and contrary to received wisdom, equities held in the long term are much less risky than even long-term government bonds are, and how the market has been compensating for that for the last few decades or so by driving equity prices slowly upward to their risk-adjusted \u201creasonable\u201d price. Like their title says, they say that the Dow could be at 36,000 and still be \u201creasonable\u201d, whatever that means. Mercy.A splendid read nonetheless, whether you agree with them or not, and the bit about the risk of the equity market certainly makes a compelling argument for a very, very, interesting result for us, in light of all of the above.At the core of all modern financial analysis is the proposition that government bonds, especially short-term ones, are the safest investment. They\u2019re safe because, for instance, the chance of the US government defaulting on any given 90-day T-Bill on any given day is virtually non-existent. T-Bills are literally risk free, and all other investment is calculated against them for riskiness. The Net Present Value equation, for instance, says that if the returns of a proposed investment are less than you would get from a T-Bill, you should forget the investment and keep your money in T-Bills instead.And, at every year of bond maturity, the government bond sits at the lowest point of the risk \u201cwell\u201d for that maturity. Or so I thought, until I saw Glassman and Hassett\u2019s description of what all financial theorists knew already for a fact, that the long-term risk of the overall equity market is much less than that of even government bonds.So. Can we back that \u201czero\u201d equity-market risk down the maturity curve to the present? Maybe, with a derivative or two. I haven\u2019t gone looking for the answer, and it\u2019s press time already. I wouldn\u2019t be surprised, though, and to walk out on a very thin limb, I\u2019m going to assume it to be true.Certainly the idea of, say an S&P 500, or maybe a larger-index-based \u201ccash\u201d starts to make sense, if we can do it. After all, Ian Grigg and his friends are trying, for all intents and purposes, to do roughly the same kind of thing with gold. Gold hops around a bunch, and volatility is probably not a good thing for a currency to have. So any financial engineering you can do to at least take the volatility down a bit would be good. And you\u2019d want to do the same thing with equity indices, because, as a functional perpetuity, a stock can be just as volatile as a 30-year bond might be.What we get, if we do create a low-volatility equity-based currency, is really very interesting.We get what Gene Fama and Fisher Black must have been thinking about back in early eighties heyday of the \u201cNew Monetary Economics\u201d: a completely private form of \u201criskless\u201d return.Think about that for a minute. Not only do we have digital bearer settlement, so we don\u2019t need the nation-state to provide force and ensure the non-repudiation of our transactions, but we don\u2019t even need another kind of force either: the confiscatory force of a nation\u2019s tax system, making for \u201criskless\u201d government securities, which, in turn, undergird our very concept of what risk is.What we get is truly private money. That is, someday we can create a completely synthetic currency based upon a commonly-referenced equity market index.Look, Ma, no currency board, much less a central bank. No guns. No sovereign. And we still get money. Amazing.So now, instead of stepping back to a commodity economy to avoid state control of the monetary supply, using something like gold to anchor value on the net, we can step forward into the information economy, the geodesic economy: All we need to collateralize our transactions is a sufficiently representative and publicly known equity index, with the volatility hedged for short term use using other publicly known derivatives. Presto change-o, a synthetic internet security. And, of course, this works with bearer held stocks, if we ever get those, as well.Finally, anyone who wants to can do this \u2013 well, if their reputation\u2019s good enough. This is finance, after all.Of course, the sticking point all this fun is the state itself, as I said to Mark Tenney more than a year ago. Remember all the book-entry taxes and regulations about bearer ownership of bonds, TEFRA, et. al., here in the U.S., and then exponentiate that number to get the regulatory barriers for bearer equity.It\u2019ll certainly be easier, for the time being, to issue cash denominated in dollars than it would be to try to climb an enormous ziggurat of regulators and legislators, telling all of them that issuing bearer-form equity-index-denominated money would be a good thing, even if it completely removed their central banks, much less their very government bonds, from the center of the financial universe. A lead balloon, indeed. Almost makes you want to believe in path-dependency, that does.But don\u2019t despair. Remember that if digital bearer transactions really do something I\u2019m betting my company on, sooner or later an equity index-based \u201cinternet currency\u201d will in fact emerge as the best way to buy things.Even more interesting, if we\u2019re right, government-extorted revenue will cease to be the foundation upon which the concept of \u201criskless\u201d return \u2013 and all of finance itself \u2013 rests.But that\u2019s probably what Fama and Black had in mind, right?Back to table of contents"}
{"prompt": "A Declaration of the Independence of Cyberspace", "completion": "Governments of the Industrial World, you weary giants of flesh and steel, I come from Cyberspace, the new home of Mind. On behalf of the future, I ask you of the past to leave us alone. You are not welcome among us. You have no sovereignty where we gather.We have no elected government, nor are we likely to have one, so I address you with no greater authority than that with which liberty itself always speaks. I declare the global social space we are building to be naturally independent of the tyrannies you seek to impose on us. You have no moral right to rule us nor do you possess any methods of enforcement we have true reason to fear.Governments derive their just powers from the consent of the governed. You have neither solicited nor received ours. We did not invite you. You do not know us, nor do you know our world. Cyberspace does not lie within your borders. Do not think that you can build it, as though it were a public construction project. You cannot. It is an act of nature and it grows itself through our collective actions.You have not engaged in our great and gathering conversation, nor did you create the wealth of our marketplaces. You do not know our culture, our ethics, or the unwritten codes that already provide our society more order than could be obtained by any of your impositions.You claim there are problems among us that you need to solve. You use this claim as an excuse to invade our precincts. Many of these problems don\u2019t exist. Where there are real conflicts, where there are wrongs, we will identify them and address them by our means. We are forming our own Social Contract. This governance will arise according to the conditions of our world, not yours. Our world is different.Cyberspace consists of transactions, relationships, and thought itself, arrayed like a standing wave in the web of our communications. Ours is a world that is both everywhere and nowhere, but it is not where bodies live.We are creating a world that all may enter without privilege or prejudice accorded by race, economic power, military force, or station of birth.We are creating a world where anyone, anywhere may express his or her beliefs, no matter how singular, without fear of being coerced into silence or conformity.Your legal concepts of property, expression, identity, movement, and context do not apply to us. They are all based on matter, and there is no matter here.Our identities have no bodies, so, unlike you, we cannot obtain order by physical coercion. We believe that from ethics, enlightened self-interest, and the commonweal, our governance will emerge. Our identities may be distributed across many of your jurisdictions. The only law that all our constituent cultures would generally recognize is the Golden Rule. We hope we will be able to build our particular solutions on that basis. But we cannot accept the solutions you are attempting to impose.In the United States, you have today created a law, the Telecommunications Reform Act, which repudiates your own Constitution and insults the dreams of Jefferson, Washington, Mill, Madison, DeToqueville, and Brandeis. These dreams must now be born anew in us.You are terrified of your own children, since they are natives in a world where you will always be immigrants. Because you fear them, you entrust your bureaucracies with the parental responsibilities you are too cowardly to confront yourselves. In our world, all the sentiments and expressions of humanity, from the debasing to the angelic, are parts of a seamless whole, the global conversation of bits. We cannot separate the air that chokes from the air upon which wings beat.In China, Germany, France, Russia, Singapore, Italy and the United States, you are trying to ward off the virus of liberty by erecting guard posts at the frontiers of Cyberspace. These may keep out the contagion for a small time, but they will not work in a world that will soon be blanketed in bit-bearing media.Your increasingly obsolete information industries would perpetuate themselves by proposing laws, in America and elsewhere, that claim to own speech itself throughout the world. These laws would declare ideas to be another industrial product, no more noble than pig iron. In our world, whatever the human mind may create can be reproduced and distributed infinitely at no cost. The global conveyance of thought no longer requires your factories to accomplish.These increasingly hostile and colonial measures place us in the same position as those previous lovers of freedom and self-determination who had to reject the authorities of distant, uninformed powers. We must declare our virtual selves immune to your sovereignty, even as we continue to consent to your rule over our bodies. We will spread ourselves across the Planet so that no one can arrest our thoughts.We will create a civilization of the Mind in Cyberspace. May it be more humane and fair than the world your governments have made before.FDavos, Switzerland\nFebruary 8, 1996"}
{"prompt": "Smart Contracts Glossary", "completion": "Agent: A person or organization, usually represented by a true name or nym. Also, a computer program controlled by, and acting on behalf of, an agent. More generally, a combination of a nym with a persistent pattern of behavior, upon which can be based a reputation. Note that this differs from the legal and business definitions of\"agent\", but corresponds more closely to the economics and computer science uses of the term.Contract: A set of agreements or promises between agents.Parties (aka Principals): Agents who have agreed to the contracting question.Third Parties: Agents who have not agreed to the contract in question.Performance: Carrying out the promises specified in a contract.Contractual Security: A paradigm for making security arrangements between organizations, based on two claims: (1) the primary goal of inter-organization security is to protect and enforce the performance of contracts, and (2) where this goal is achieved, dependence on reputation, outside enforcement, and other factors for the secure performance of that organization's contracts is minimized.Contractual Key Distribution: a paradigm for distributing keys among individuals and organizations, in which the key distribution and certificate structure reflects the contractual arrangements between parties.Protocol: A sequence of messages between multiple agents.Smart contract: A set of promises, including protocols within which the parties perform on the other promises. The protocols are usually implemented with programs on a computer network, orin other forms of digital electronics, thus these contracts are \"smarter\" than their paper-based ancestors. No use of artificial intelligence is implied.Alice and Bob: Our exemplar parties to a smart contract.Eve: Our exemplar eavesdropper, whose objective is to find out valuable information about about a contract and its performance without being a party to that contract.Mallet: Our exemplar active attacker. His objective might either be stealing something of value involved in the performance of a smart contract, or denying it to the parties to the contract. He might either be an economically rational agent, out for pure personal gain,or Byzantine, a worst-case attacker who inflicts the greatest possible damage on one or more of the parties regardless of personal loss.Mediator: A third party involved realtime in the protocols between smart contract parties, trusted with some of the contents and/or performance of that contract.Arbitrator: A third party trusted with some of the contents,and some of the history of performance, of a contract, and trusted by contracted parties to resolve disputes arising from that contract fairly.Unbundling: The principle of distribution of trust. Unbundling of mediation and arbitration functions separates tasks, spreads risk, minimizes vulnerability, and reduces linkability, but often at the cost of greater complexity.Enemy (aka attacker): An agent whose preferences could cause another agent harm; a third party who influences performance of a contract to the detriment of one or both parties.Object: Herein used to refer generically to any kind of digital data, which could be a key, a credential, a contract, a program, or a wide variety of other things.Credential: A claim made by one agent about another.Positive credential: A claim made about an agent, that the agent would prefer to reveal, such as a degree from a prestigious school.Negative credential: A claim made about an agent, that the agent would prefer not to reveal, such as a bad credit rating.Cryptographic protocol: A protocol that uses mathematical principles and keys to accomplish smart contract objectives.Privity: The principle that only the parties to a contract, including its designated arbitrators, need to have knowledge of or control over the contents and performance of that contract. Privity as an objective of smart contract is a generalization of the legal principle of privity. It formalizes the tradition of \"it's none of your business\". Attacks against privity are epitomized by Eve the eavesdropper, a passive observer of contents or performance, and malicious vandal Mallet, who actively interferes with performance or steals value. Privacy and confidentiality, or protecting the value of information about a contract, its parties, and its performance from Eve, is thus subsumed under privity. Privity often comes into conflict with observability and verifiability.Observability: The ability of the parties to a contract to observe each other's performance of that contract, or to prove their performance to the other party. Also, the ability to differentiate between intentional violations of the contract and good faith errors. An important objective of smart contract design that often comes into conflict with privity.Verifiability: The ability of a party to prove to an arbitrator that a contract has been performed or breached, and to differentiate between intentional violation and good faith errors. An important objective of smart contract design that often comes into conflict with privity.Reputable name: A nym or true name that has a good reputation, usually because it carries many positive credentials, has a good credit rating, or is otherwise highly regarded. Companies strive to carry reputable brand names, while professionals such as doctors and lawyers strive to have many good personal recommendations of their name. Reputable names can be difficult to transfer between agents, because reputation assumes persistence of behavior, but such transfer can sometimes occur (for example, the sale of brand names between companies).True name: An identifier that links many different kinds of information about an agent, such as a full birth name or social security number. As in magick, knowing a true name can confer tremendous power to one's enemies. It also can have major economic value among those who cooperate peacefully, as in the use of direct marketing to target product information to those agents most likely to be interested in those particular products.Mix: A cryptographic protocol for messaging, in which analysis of who is talking to whom (traffic analysis) by Eve is prevented by the Russian-doll encryption of the message by the sender with the public keys of each mix operator in the chain, and the mixing of messages by each operator, so that panoptic wiretapper Eve loses track of the messages. Only 1 out of N of the operators needs to be trusted with the traffic information, although Eve can sometimes gather statistics over large numbers of messages to eventually guess who is talking to whom. The communicating parties can also be mutually anonymous, and with normal encryption need trust no other parties with the content of messages. Confidential messaging is necessary for the some of the privity features of Chaumian credentials and bearer securities to be strongly implemented on an actual network. Another confidential messaging system is the \"Dining Cryptographers\" net, also invented by Chaum.Nym: An identifier that links only a small amount of related information about a person, usually that information deemed by the nym holder to be relevant to a particular organization or community. Examples of nyms include electronic bulletin board nicknames, pen names, aliases, and brand names. A nym may gain reputation within its community. For example, a conglomerate may sell a wide variety of brand names, each reputable in its own market niche. With Chaumian credentials, a nym can take advantage of the positive credentials of the holder's other nyms, as provably linked by the is-a-person credential.Name space: a set of short identifiers with a simple syntax, such as telephone numbers, computer-readable Internet address numbers, human-readable Internet domain names, etc.Chaumian credentials: a cryptographic protocol for proving one possesses claims made about oneself by other nyms, without revealing linkages between those nyms.Is-a-person credential: In Chaumian credentials, the true name credential, used to prove the linkage of otherwise unlinkable nyms, and to prevent the transfer of nyms between agents.Key: A focus of obscurity and control; a random number drawn from a name space so large that a lucky guess is vastly improbable. The public key half of an assymetric key pair can also act as a nym.Biometric: Information pattern used to identify a particular body, such as a fingerprint, autograph, retina scan, password, etc.Authentication: Proof that one is communicating with an agent that possesses a particular key.Secret key (symmetric) cryptography: Uses a key shared between agents to communicate with confidentiality and authentication.Public key (assymmetric) cryptography: Uses two keys, the private key and the public key. The public key is used to encrypt objects,and to verify digital signatures. The private key is used to to decrypt and sign objects, and is typically kept secret by one or more key holders. Allows key distribution without exposing the key.Secret sharing: method of splitting a key (and thus, in effect,any object encrypted with that key) into N parts, of which only M are needed to recreate the key, but less than M of the parts provide no information about the key. A potent tool for distributing control over objects between agents.Digital signature: Cryptographic protocol, based on public key cryptography, that proves that an object was in active contact with the private key corresponding to the signature: the object was actively \"signed\" with that key. Probably should have been called a \"digital stamp\" or \"digital seal\" since its function resembles more those methods than an autograph.Bit commitment: A variant of digital signatures, used to commit an object, such as a promise or prediction, without revealing that object until later. It is impossible to unobservably violate the protocol, or to modify the object after it has been committed.Blind signature: digital signature and secret-key encryption protocols that together have the mathematical property of commutativity, so that they can be stripped in reverse of the order they were applied. The effect is that Bob \"signs\" an object, for which he can verify its general form, but cannot see its specific content. Typically the key of the signature defines the meaning of the signed object, rather than the contents of the object signed, so that Bob doesn't end up signing a blank check. Used in digital bearer instruments, where Bob is the clearing agent, and Chaumian credentials, where Bob is the credential issuer.Digital bearer instruments: Objects identified by a unique key,and issued, cleared, and redeemed by a clearing agent. When an the object is transferred, the transferee can request the clearing agent to verify that the key has never before been cleared, and issue a new key. The clearing agent prevents multiple clearing of particular objects, but can be prevented from linking particular objects one or both of the clearing nyms who transferred that object. These instruments come in an \"online\" variety, cleared during every transfer, and thus both verifiable and observable, and an \"offline\" variety, which can be transferred without being cleared, but is only verifiable when finally cleared, by revealing any the clearing nym of any intermediate holder who transferred the object multiple times (a breach of contract). Privacy from the clearing agent can take the form of transferree-unlinkability, transferrer-unlinkability, or \"double blinded\" where both transferrer and transferee are unlinkable by the clearing agent. Digital cash is a popular form of digital bearer instrument.Locality: * immediacy, such as that provided by online clearing of digital bearer instruments * dealing with the agents one knows best * dealing in one's area of specialtyHot Backup: A backup service which comes online upon failure of the current service. Usually triggered by a dead-man switch.Zero-Knowledge Interactive Proof (ZKIP): A cryptographic protocol that can be used to prove that an agent possesses a key (and by weaker implication, that otherwise normally functioning agents who have an incentive to respond properly to the challenge, but fail to do so, do not possess the key), without revealing any information about that key. Currently used for authentication, and in smart weapons for Identification Friend or Foe (IFF).Smart Property: Software or physical devices with the desired characteristics of ownership embedded into them; for example devices that can be rendered of far less value to agents who lack possession of a key, as demonstrated via a zero knowledge interactive proof. Methods of implementing smart property might include OND (cf.), and engrained immobilizing or destructive devices to foil attempts to hot-wire the property.Operation Necessary Data (OND): Data necessary to the operation of smart property. For example, a complex, proprietary firing sequence needed to operate a computerized engine, a CAD file needed to manufacture a specialized part, etc. To avoid theft of service, ZKIP is required to open an encrypted channel to the device. To avoid leaking the OND to Eve, tamper detection combined with a dead-man switch can be used on the device end of the channel.Smart Lien: Sharing control of smart property between parties, usually two parties called the owner and the lien holder. This property may be in the proximate possession of the owner or the lien holder, corresponding to the common-law notions of \"artisan's lien\" and \"innkeeper's lien\" respectively. Might be used to secure lines of credit, insurance policies, and many other kinds of contracts that involve smart property.Security: Represents a basic asset, such as a share of ownership (stock) or a claim debt (bonds, cash).Contingent contract: Contains terms which depend on the choice of a party or a state of the world. An option is an example of a contingent contract.Derivative: A call or put option, future, or synthetic asset;such a contract is \"derived\" from a basic underlying security.Synthetic asset: A derivative constructed, or \"synthesized\", by combining securities and other derivatives. Cash flows for sophisticated synthetics can be calculated to high precision, by means of finely grained decision trees.Cash flow: The expected sequence of payments according to the terms of a contract. From cash flow can be computed the basic financial objectives of a contract, such as net present value.Please send your comments to nszabo (at) law (dot) gwu (dot) eduCopyright \u00a9 1995 by Nick Szabo\nPermission to redistribute without alteration hereby granted"}
{"prompt": "For-Pay Remailers", "completion": "What if you could make money by running a remailer?Right now, most remailer operators are operating out of altruism. This is good in a lot of ways but it has its problems, as recent events have shown:I'm sure we can all think of more. I know that it would be a lot easier to justify continuing to run the remailer to myself if it were bringing in a few dollars a month.I think there are some experiments in for-pay remailers that have been tried. Sameer is, I think, charging for some services, although paerhaps that was just for anonymous return addresses. A long time ago Karl Barrus had a service which required pre-issued \"digital postage stamps\", but I don't think many people used it.The time may be ripe to look at this more seriously. Several factors are coming together:To expand on these:It is obviously difficult to operate a remailer service that charges if other people are offering the equivalent service for free. Since it is pretty easy to start up a remailer, the marginal cost to do so is low, hence the profits are low, too. However, although it is easy to start a remailer, it is not so easy to keep one running in the face of complaints from recipients of abusive mail or inappropriate posts; hassles from sysops, owners, net feeds, or others upwards in that great chain of command; possible law enforcement problems when illegal communications occur; possible threats of lawsuits (such as from the scientologists when their sacred documents are posted), etc. So we should not be misled into thinking that running a remailer is cost free.On the other hand I should be clear that I would not expect to make a killing on this service. Something on the order of a penny a message seems reasonable just at a guess. Maybe it should be a factor of 10 higher or lower.One issue is of course the additional difficulty this will cause in the use of the remailer. There are several things to consider here. On the one hand you could argue that it is already too difficult to use the remailers, and any additional hassles involved with including some kind of payment tokens would kill the market. OTOH I can agree in spirit with the sentiments expressed here recently about the low quality which seems to characterize much of the use of the remailers.I don't look at messages, but occasionally I do see bounces, and very frequently they are ugly little flames or similar worthless material. Now, I hope that I am seeing the dregs, that the kinds of clueless people who make the mistakes which cause me to see the messages are the ones least likely to use the service in a worthwhile manner. But still, it is discouraging. In that context, maybe making the system a little harder to use would be worthwhile, in that it would screen out the casual harrasser. (Or, more realistically, this might just keep the exceptionally motivated harrassers.)In any case, I think the presence of the remailer scripts can make using a for-pay remailer not much more difficult than using a free one. If the cost is as low as I suggested and the inclusion of payment tokens is nearly automatic, then adding costs should not have much negative impact on use, certainly not on meaningful, worthwhile use.And even a modest cost might arrest the wholesale spamming that Detweiler and/or the recent \"Scythe\" seem to love. At least we would be paid for enduring the hassle of the complaints.Now, the next question is the details of the payment. Frankly, I don't think any of the current systems are quite right for us due to our special needs, but things are changing rapidly. Let me describe something about how they work.I know of two systems that are VISA/Mastercard based. One is called First Virtual (http://www.fv.com). They are oriented towards information sales and say that they aren't for service providers, but in practice it looked to me like they could be used for services. When a customer wants to pay, he sends you his FV ID. You send this to FV and they send an email message to the customer asking whether he authorizes the payment. If he says \"yes\", FV credits your account. You get a check every month. Customers who always say \"no\" get booted out of the system (as do merchants who submit bogus bills). They charge 29 cents plus 2 percent per transaction, but merchants can batch up multiple orders by a single customer before sending it in.There are a few problems with a system like this, many of which are somewhat generic to our situation. The most fundamental is that we don't know who our customers are much of the time. In fact, the whole point of the remailer network is that we not know that fact for any case except the first hop in the chain. If we required customers to expose their FV account ID at every hop, it would make it a lot easier to track messages through the network (even if the ID's were hidden in the encryption envelope it seems risky). If we then sent a message to FV saying that we needed to charge ID XXX, and FV responds with an email to the person's home address, this offers more possibilities for tracing.One solution would be only to charge on entry into the remailer net. Perhaps remailer operators would even charge each other then, and the first remailer would charge some larger amount to deal with a \"typical\" chain length? Many interesting possibilities here.Another issue is that the overhead charges by FV would require batching up messages before submitting them. Let me make clear that the batch must consist all of charges to a single user. It doesn't do any good to send one message to FV asking them to please charge a penny to each of 100 VISA accounts. No, you would have to count messages from each user, separately, and when user XXX had sent, say, $1 worth of messages, you could send in the request to FV and get back 70 or so cents.So this adds some overhead and record-keeping that we don't currently have to do, although perhaps it is not so difficult. But it would raise new questions of authenticating FV ID's, and shares some of the negative privacy impacts and message linking issues mentioned above.The other VISA based system is called OpenMarket. I just read about it tonight so I don't know it as well (http://www.openmarket.com). It is pretty tied to the WWW so it would not seem to work for us. Customers get connected to a particular WWW server which authenticates them and charges their VISA card appropriately, then they get redirected to the merchant with some kind of token that says they have paid.The NetBank (email to netbank-intro@agents.com) is a digital-cash like system. Customers get tokens which are basically large secret numbers which have a cash value. They send them to the merchants, and the merchants then send them to the bank which credits their account. The NetBank sends you a check every month.The interesting thing is how customers buy the cash tokens. One way is by connecting to a 900 number with your modem. They charge the customer $10.00 and give him a digital cash token worth that much. Another way is by faxing a check to them. I wasn't clear on how you get the cash token back in that case; I guess they email it to you at an address you specify. From the privacy point of view, these are not that great; 900 numbers have Automatic Number Identification so unless you are willing to tramp out to a pay phone to get your cash then it could be linked to your phone number. And the fax system must have some kind of return address that would link to you.The other problem with NetBank is that the smallest denomination which can be spent is 25 cents. Due to the cash-like nature of the tokens, I don't see a natural way to accumulate several messages into one payment. Maybe we could layer our own low-value digital cash system on top of NetBank, where users could buy our anonymous cash for 25 cents and get enough tokens for 25 messages, then we would settle amongst ourselves (or actually with the anon-mail-token bank). Actually this might help with the privacy problems, too. Anonymous digital cash is heavily patented, though.With a cash-like system, each message would include a numeric token in the header which is the digital cash. The remailer would strip that out and send it in for credit. This is a simple system and could be largely automatic. However there are some tricky issues about cheaters re-using cash.NetBank charges $4 per month, plus, for the 900-number-based cash, 20% off of face value.The last system I'll describe is David Chaum's DigiCash (http://www.digicash.com). Chaum is the inventor of digital cash and he certainly knows his stuff, plus as I said he has the intellectual property pretty well sewed up patent-wise. The DC payment system is also WWW based at present. The customer has to be running a special program on his computer, separate from his web browser. This program holds his digital cash, which is similar conceptually to the NetBank cash but more sophisticated cryptographically. When he wants to buy something, the merchant's web server makes a connection to the customer's DC program, and it transfers the cash to the merchant.DigiCash says they are planning an email based system but for now their emphasis is on the WWW. Right now they are only in beta and not using real money. I don't know when they will be real and email based, and I don't know if they have said what their commission will be. But when this comes up it may be the best approach if small-value transactions can be supported. DigiCash is fully anonymous in the sense that once a customer receives the money, it is \"blinded\" in a special cryptographic way so that the bank cannot associate it with that customer (and no one else can, either). This kind of anonymity fits in very well with our remailer requirements.Well, I know this is a lot of information to work through, but mostly I want people to be aware of the possibilities. Most of this stuff is very, very new, only weeks old, generally. Probably over the next few months we will see a lot more options appear. I am confident that there will soon be payment systems that would provide the technical basis for fee based remailing. I don't expect anyone to get rich by this, but it might help compensate for the risks we all face, and it might serve to improve the quality of the remailer network.Hal Finney\nhal@rain.orgHal Finney Home Page"}
{"prompt": "Politics vs Technology", "completion": "This position seems to be fast becoming cypherpunks dogma, but I don't agree. The notion that we can just fade into cypherspace and ignore the unpleasant political realities is unrealistic, in my view.Have people forgotten the Clipper proposal, with the possible follow-on to make non-Clipper encryption illegal? To the extent this proposal has been or will be defeated, it will happen through political maneuvering, not technology.Have people forgotten the PGP export investigation? Phil Zimmermann hasn't. He and others may be facing the prospect of ten years in prison if they were found guilty of illegal export. If anyone has any suggestions for how to escape from jail into cyberspace I'd like to hear about them.Mike's SecureDrive is a terrific program for protecting privacy. But if we want to keep keys secret from politically-motivated investigations, we have to rely on the very political and non-technological Fifth Amendment (an amendment which Mike Godwin of EFF and others contend does not actually protect disclosure of cryptographic keys). Again, we need to win political, not technological, victories in order to protect our privacy.I even question Mike's point about the government's inability to ban books. Look at the difficulty in keeping PGP available in this country even though it is legal. Not only have FTP sites been steadily closed down, even the key servers have as well. And this is legal software.Sure, this software is currently available overseas, but that is because PGP's only legal limitations are the U.S. patent issues. Imagine how much worse it would be if non-escrowed encryption were made illegal in a broad range of countries, with stringent limits on net access to countries which promote illegal software? Here again, these kinds of decisions will be made in the political realm.Fundamentally, I believe we will have the kind of society that most people want. If we want freedom and privacy, we must persuade others that these are worth having. There are no shortcuts. Withdrawing into technology is like pulling the blankets over your head. It feels good for a while, until reality catches up. The next Clipper or Digital Telephony proposal will provide a rude awakening.Hal Finney\nhal@rain.orgHal Finney Home Page"}
{"prompt": "The Case for Privacy", "completion": "An old science fiction novel features a device that surrounds its bearer with an impenetrable bubble of force. The inventor rapidly discovers that every government and political faction on the planet wants what he has and is prepared to use any means, from persuasion to brute force, to get it. Our hero spends most of the book alternately listening to arguments, trying to decide who are the good guys and using his invention to help him escape attempts to capture him.After about a hundred and fifty pages he realizes that he has been asking the wrong question. The answer to \"what faction can be trusted with a monopoly over the shield\" is \"no.\" The right question is how the shield will affect the world\u2014how it will alter the balance between freedom and oppression, individual and state, small and big. The answer to that is easy. A world where the random individual is armored against anything short of an atomic explosion will be, on net, a better and freer world than the one he is currently living in. He writes out an explanation of how the shield works and spends two days distributing the information to people all over the world. By the time Military Security\u2014the most formidable of his pursuers\u2014catches up with him, it is too late. The cat is out of the bag.Poul Anderson's shield is fiction. The nearest real world equivalent is privacy\u2014my control over other people's access to information about me. Neither my government nor my neighbor can punish my thoughts, because neither can read my mind. That is why thoughts are free. However much other people are offended by what I write, they cannot retaliate unless they know who wrote it, what he looks like, where he lives. That is why Salmon Rushdie is still alive despite the death sentence passed on the author of The Satanic Verses fifteen years ago by Iranian authorities.Defensive weapons can be used for bad purposes; an impenetrable shield would be very useful for a bank robber. But it would be even more useful for the bank teller. Robbing banks would be harder in a world where everyone had the shield than in a world where nobody did.The ability to control other people's access to information about you can be used for bad purposes too. That is the usual argument against privacy\u2014\"If you haven't done anything wrong, what do you have to hide?\" The ability to conceal past crimes from the police and potential victims is useful to a robber. But the ability to conceal what I have that is worth stealing, where it is, how it is protected, is equally useful to the potential victim. Broadly stated, privacy gives each of us more control over his own life\u2014which on average, if not in every case, is likely to lead to a freer world.If I am a bad guy, the police are not the only people I might want to keep secrets from. When courting a wealthy widow, it helps if she does not know that my last three wives drowned in their bath tubs after taking out large life insurance policies. When borrowing money, it helps if the lender does not know that I have declared bankruptcy twice already.But in a world of voluntary transactions\u2014such as loans and marriages\u2014my privacy does not require you to take me on faith. You have the option of not taking me. I have the power to keep my past defaults secret from a potential lender but he has the power to refuse to lend to me if I do. Privacy is my ability to control other people's access to information about me. That does not mean that they cannot get the information\u2014only that they cannot get it without my permission. Someone who offers to take care of my children but refuses to allow me access to the records that would show whether or not he has ever been convicted of child abuse has already told me all I need to know.In some contexts I am willing to let other people know things about me. In others I am eager to. If only lenders knew a little more about my finances I would not be interrupted at dinner by phone calls from people offering to refinance my nonexistent mortgage. If sellers were better informed about what sorts of things I was interested in buying, advertisements would be less of a nuisance and more of a service. Even in a world where I could keep information secret, I often would choose not to. Privacy provides me protection when I want it and only when I want it.Government is not reason. It is not eloquence. It is a force, like fire: a dangerous servant and a terrible master.Privacy includes the ability to keep things secret from the government. The better I can do that, the less able government is to help me\u2014I might be keeping secret my weakness for alcohol, or heroin, or gambling or pornography and so preventing the government from stepping in to protect me from myself. And the better other people can keep secrets from the government, the harder it is for the government to protect me from them. If you view government as a benevolent super being watching over you\u2014a wise and kindly uncle with a long white beard\u2014you will and should reject much of what I am saying.But government is not Uncle Sam or a philosopher king. Government is a set of institutions through which human beings act for human purposes. Its special feature\u2014what differentiates political action from the other ways in which we try to get what we want\u2014is that government is permitted to use force to make people do things. A firm can try to fool me into giving it my money. A tax collector uses more direct methods. A preacher can try to persuade me to renounce my sins. The Drug Enforcement Administration, with the help of the local police, can arrange to have me locked up until I do.Part of the genius of American political culture is the recognition that making it hard for governments to control people is not always a bad thing. Political mechanisms, even in a democracy, give us only very limited control over what government can do to us. Reducing government's ability to do bad things to us, at the cost of limiting its ability to protect us from bad things done to us by ourselves or by other people, may not be such a bad deal. And since government, unlike a private criminal, has overwhelming superiority of physical force, control over what information it can get about me is one of the few ways in which I can limit its ability to control me.I have defined privacy and sketched the reasons why I think it is, on the whole, a good thing. The obvious next questions are where privacy comes from\u2014what determines how much of it we have\u2014and what we can and should do to get more of it.One of the things that determines how much control I have over other people's access to information about me is technology. If someone invents a mind reading machine or a reliable truth drug, my thoughts will no longer be as private as they now are. Or as free.Another is custom\u2014systems of social norms. The more willing my friends and neighbors are to gossip about something, the easier it is for information about that something to get from those who have it to those who want it. That is one reason why Israelis are better informed about how much money their friends and relations make than Americans are and modern Americans better informed about other people's sex lives than nineteenth century Britons were.A final factor is law. In the U.S., the Fourth Amendment to the Constitution prohibits \"unreasonable searches and seizures\" and requires that search warrants shall only be issued with probable cause. The more narrowly courts interpret that restriction, the easier it is to keep secrets from the police. One important example is the series of cases that applied the restriction to wiretaps as well as physical searches. Later cases have ruled on to what extent the use of high tech devices to figure out what people are doing inside their houses\u2014infrared photographs to spot illegal greenhouses growing marijuana, for example\u2014is a search and so requires a warrant.Law and technology interact in complicated ways. For your neighbor's nosy fifteen year old to use a scanner to listen to the phone calls you make on your wireless phone and tell his friends about them is illegal. It is also easy, making that particular legal protection of privacy in practice unenforceable. The substitute is technology\u2014encryption of the signal from the handset to the base station. Similarly with cell phones.As these examples suggest, technological developments can both decrease and increase privacy. So can law. Legal rules that ban or limit technologies for learning things about other people, such as laws against wiretaps, increase privacy. Legal rules that ban or limit technologies for preventing other people from learning things about us, such as restrictions on the use of encryption, decrease it.It used to be that one reason to move from a village to the big city was to get more privacy. Walls were no higher in the city, windows no less transparent. But there were so many more people. In the village, interested neighbors could keep track of what who was doing with whom. In the city, nobody could keep track of everyone.That form of privacy\u2014privacy through obscurity\u2014is doomed. I cannot keep track of the million people who share the city I live in. But the computer on my desk has enough space on its hard drive to hold a hundred pages of information on every man, woman and child in San Jose. With a few hundred dollars worth of additional storage, I could do it for everyone in California, for a few thousand, everyone in the country. And I can do more than store the information. If I had it I could search it\u2014produce, in a matter of seconds, a list of those of my fellow citizens who are left handed gun owners with more than six children. Privacy through obscurity cannot survive modern data processing.As it happens, I do not have a hundred pages worth of information on each of my fellow citizens. But with a little time and effort\u2014too much for a single individual, but not too much for a government, a police department, or a large firm\u2014I could. It is hard to pass through the world without leaving tracks. Somewhere there is a record of every car I have registered, every tax form I have filed, two marriages, one divorce, the birth of three children, thousands of posts to online forums on a wide variety of subjects, four published books, medical records and a great deal more.Much such information, although not all of it, was publicly available in the past. But actually digging it up was a lot of work. The result was that most of us went through life reasonably sure that most of the people we met did not know much about us beyond what we chose to tell them. That will not be true in the future.Data processing is one technology with the potential to sharply reduce privacy. Another is surveillance. One form\u2014already common in England\u2014is a video camera on a pole.A video camera in a park connected to a screen with a police officer watching it is, at first glance, no more a violation of privacy than the same police officer standing in the park watching what is going on. It merely lets the officer do his watching somewhere warm and out of the wet. Add a video recorder and it is arguably an improvement, since the evidence it produces is less subject to mistake or misrepresentation than the memory of the policeman. And, judging by British experience, such surveillance cameras are an effective way of reducing crime. What's the problem?To see the answer, add one more technology\u2014face recognition software. Combine that with a database, put up enough cameras, and we have a record of where everyone was any time of the day and\u2014with suitable cameras\u2014night. The arresting officer, or the prosecuting attorney, no longer has to ask the defendant where he was at eight P.M. of July ninth. All he has to do is enter the defendant's social security number and the date and the computer will tell him. And, if the defendant was in a public place at the time, show him.For a slightly lower tech version of the same issue, consider the humble phone tap. In the past, the main limit on how many phones got tapped by police was not the difficulty of getting a court order but the cost of implementing it. Phone taps are labor intensive\u2014someone has to listen to a lot of phone calls in order to find the ones that matter.That problem has now been solved. Voice recognition software originated by companies such as Dragon Systems and IBM lets computers convert speech into text\u2014a boon for computer users who are slow typists. The same technology means that the police officer listening to someone else's phone calls can now be replaced by a computer. Only when it gets a hit, spots the words or phrases it has been programmed to listen for, does it need to call in a human being. Computers work cheap.In an old comedy thriller (The President's Analyst, starring James Coburn) the hero, having temporarily escaped his pursuers and made it to a phone booth, calls a friendly CIA agent to come rescue him. When he tries to leave the booth, the door won't open. Down the road comes a phone company truck loaded with booths. The truck's crane picks up the one containing the analyst, deposits it in the back, replaces it with an empty booth and drives off.A minute later a helicopter descends containing the CIA agent and a KGB agent who is his temporary ally. They look in astonishment at the empty phone booth. The American speaks first:\"It can't be. Every phone in America tapped?\"The response (you will have to imagine the Russian accent)\"Where do you think you are, Russia?\"A great scene in a very funny movie\u2014but it may not be a joke much longer. The digital wiretap bill, pushed through Congress by the FBI a few years ago, already requires phone companies to provide law enforcement with the ability to simultaneously tap one percent of all phones in a selected area. There is no obvious reason why that cannot be expanded in the future. My current estimate is that the dedicated hardware to do the listening part of the job\u2014for every phone call in the U.S.\u2014would cost less than a billion dollars. And it is getting cheaper.So far I have been discussing technologies that already exist. Fast forward a little further and surveillance need no longer be limited to public places. Video cameras are getting smaller. It should not be all that long before we can build one with the size\u2014and the aerodynamic characteristics\u2014of a mosquito.Here again, if we regard government law enforcement agents as unambiguously good guys, there is no problem. The better our record of where everyone was when, the easier it will be to catch and convict criminals.The same technology would make keeping track of dissidents, or political opponents, or members of an unpopular religion, or people with the wrong sexual tastes, or people who read the wrong books, or anyone else, a great deal easier than it now is. It is true that the random government is rather less likely to have bad intentions than the random criminal. But if it does have bad intentions it can do a great deal more damage.The technologies I have been discussing so far\u2014database and face recognition software, surveillance hardware\u2014have the potential to make this a much less private world. So do other technologies that I have not covered: improvements in lie detectors and interrogation drugs to learn what we think, biometric identification by fingerprints, retinal patterns, DNA to learn who we are, with or without our permission. The future implications of such developments are sufficiently strong to have convinced at least one thoughtful observer that the best we can hope for in the future is a transparent society, a world without privacy where the police can watch us but we can also watch them (Brin 1999). I would find the symmetry of that future more appealing if it did not conceal an important asymmetry: They can arrest us and we cannot arrest them.But there are other technologies.We start with an old problem: How to communicate with someone without letting other people know what you are saying. There are a number of familiar solutions. If worried about eavesdroppers, check under the eaves. To be safer still, hold your private conversation in the middle of a large, open field, or a boat in the middle of a lake. The fish are not interested and nobody else can hear.That no longer works. The middle of a lake is still within range of a shotgun mike. Eaves do not have to contain eavesdroppers\u2260just a microphone and a transmitter. Phone lines can be tapped, cordless or cell phone messages intercepted. An email bounces through multiple computers on its way to its destination\u00e3anyone controlling one of those computers can save a copy for himself.The solution is encryption. Scramble the message. Provide the intended recipient with the formula for unscrambling it. Now it does not matter if someone intercepts your mail. He can't read it.There is still a problem. In order to read my scrambled message you need the key\u2260the formula describing how to unscramble it. If I do not have a safe way of sending you messages, I may not have a safe way of sending you the key either. If I sent it by a trusted messenger but made a small mistake as to who he was really working for, someone else now has a copy and can use it decrypt my future messages to you.About twenty-five years ago, this problem was solved. The solution is public key encryption. It works by using two keys, each of which decrypts what the other encrypts. One of the two\u2014my public key\u2014I make available to anyone who might want to send me a message. The other never leaves my hands. Someone who wants to communicate with me encrypts his messages with my public key. I use my private key to decrypt them.Public key encryption provides a free bonus\u2014digital signatures. In order to prove that a message was sent by me I can encrypt it using my private key. The recipient decrypts it using my public key. The fact that what comes out is text rather than gibberish proves it was encrypted with the matching private key\u2014which only I have. Hence, unless I have been very careless, the message is from me.Imagine a world where public key encryption is in general use. Add in related technologies such as anonymous digital money, to permit payments that leave no paper trail, and anonymous remailers, to keep who I am talking to, as well as what I am saying, private\u2014for details see (Friedman 1996). In that world I can email someone\u2014anyone\u2014with reasonable certainty that nobody else can read the message. I can have telephone conversations without worrying about who may be listening. In that world I can if I wish establish an online persona\u2014an identity defined by my digital signature\u2014while keeping control over the link between that and my realspace persona. However much my online persona offends someone\u2014even the rulers of Iran\u2014there is very little anyone can do about it. It is hard to murder someone when you don't know his name, what he looks like, or what continent he is on.I have been describing things we already know how to do. Most can already be done\u2014using free software that runs on the computers most of us have. I now take a small step forward to add one more element to the mix: Virtual reality. Using goggles and earphones\u2014if we are willing to step further into science fiction, direct links between mind and computer\u2014we create the illusion of seeing, hearing, perhaps tasting and touching. The world of strong privacy expands from text messages and phone conversations to something very much like the real world we currently live in. Just let your fingers do the walking.I have described two clusters of technologies. One\u2014database, voice and text recognition, surveillance\u2014has the potential to reduce privacy to the point where those who control the technology know very nearly everything that everyone does. The other\u2014encryption, online communication, virtual reality\u2014has the potential to increase privacy to the point where individuals have nearly total control over other people's access to information about them. What if we get both?It will be an interesting world. Everything you do in realspace will be known to the authorities, perhaps to everyone\u2014David Brin's Transparent Society. But most of the important stuff\u2014all transactions involving information, ideas, arguments, beliefs\u2014will have been moved to cyberspace, protected by the strong privacy of encryption. Freedom of speech will no longer depend on how the Supreme Court interprets the First Amendment. It will be protected, instead, by the laws of mathematics\u2014which so far, at least, heavily favor defense over offense, encryption over cracking.There will be\u2014already have been\u2014attempts to use law to block both futures. Supporters of privacy will try to get laws restricting the ability of law enforcement\u2014and other people\u2014to use technology to learn our secrets. Opponents of privacy will try to get laws restricting the ability of private individuals to use encryption to protect their secrets.There are at least two legal approaches to preserving privacy in the face of technologies such as computer databases and surveillance. One is to use law to prevent other people from getting information\u2014a data base is of no use if there is nothing in it. The other is to permit other people to get information but use law to limit what they can do with it.An example of the first approach is regulation of wire tapping and other forms of surveillance\u2014both laws against private surveillance and laws restricting surveillance by law enforcement agents. Such restrictions can keep some information about me from getting to other people. But they do nothing to protect the vast amount of information that I generate by going about my daily life in the public view\u2014buying and selling, marrying and getting divorced, writing and talking.An example of the second approach is the web of restrictions, legal, contractual, and customary, on the use of confidential information. I cannot keep my doctor from having access to the medical information he creates when he examines me and uses when he prescribes for me. But I can, to some limited degree, prevent him from sharing that information with other people. Credit bureaus are free to collect information on people in order to advise other people as to whether to lend them money but, under current Federal law, they are only permitted to release that information in response to requests from people who have a legitimate need for it.As the example of credit bureaus suggests, there are practical difficulties with protecting privacy by letting other people have information and then controlling what they do with it. Credit agencies could not serve their intended purpose at any reasonable cost if they engaged in an extensive investigation of everyone who asked for information. And even if the agency limits itself to giving the information to people who can prove they are entitled to it, there is no way it can control who they then give it to. It is probably prudent to assume that what the credit agency knows about you any else can know if he really wants to. The forms you sign when you shift to a new doctor include an extensive list of people to whom and circumstances under which your medical information will be made available, so it might be equally prudent not to rely too much on your medical privacy.As long as we limit our options to current technologies for protecting privacy, the outlook does not look good. We might succeed in restricting the use of surveillance, wiretapping, and similar technologies, although attempts to restrict their use by law enforcement face serious opposition by those concerned with the threat of crime and terrorism. But most information about us is public, and once information is out it is hard to control how other people use it or who they give it to.The technologies of strong privacy offer at least a partial solution. If I make a purchase with a credit card, I create a paper trail\u2014someone, somewhere, knows what I bought. Even if I use cash, a purchase in real space requires me to walk into a store where someone sees me\u2014the information about what I bought is now his as well as mine. In a world where the relevant software is a little better than it now is\u2014say ten years in the future\u2014that someone is a store video camera linked to facial recognition software linked to a database. Stores, after all, like to know who their customers are.If, however, I buy something over the phone or over the internet, using the digital equivalent of cash\u2014anonymous digital currency\u2014only I know that I bought it. If the something is not a physical object that must be delivered to me but information\u2014music, data, software\u2014I can collect my purchase online without ever revealing my identity or location.Thus the technologies of encryption and computer networking can permit us, to a considerable extent, to move through the world without leaving footprints behind. If I want to receive advertising based on my past purchases\u2014as it happens I often do\u2014I can choose to make those purchases under my real name and provide my real address. If I want to receive the advertising without making my acts publicly observable\u2014perhaps I am purchasing pornography\u2014I can do it via an online identity. The link that ties my realspace body to my cyberspace persona is under my control. I have privacy\u2014control over other people's access to information about me.If we go a little further into science fiction I could even have privacy from my doctor. He knows the information that an examination\u2014via remote controlled devices\u2014revealed about me. He does not need to know what my name is, my face looks like, or where I live. It is not likely that I would want to carry my privacy that far\u2014but I could.So far I have been considering ways in which we might preserve privacy against the threat posed by technology. But there is another side to the story. For those who think that we already have too much privacy, what I view as the solution may look more like the problem. There have already been attempts to restrict the use of encryption to protect privacy. There will be more.Suppose I concede, at least for the purposes of argument, that it is possible to have too much privacy as well as too little. Further, and less plausibly, suppose I believed that the strong privacy provided by encryption is a serious problem. How might one use law to solve it?One difficulty is that encryption regulation poses the problem summed up in the slogan\u2014\"when guns are outlawed, only outlaws have guns.\" The mathematics of public key encryption have been public for decades. The software to do it already exists in a variety of forms, some of them freely available. Given the nature of software, once you have a program you can make an unlimited number of copies. Keeping encryption software out of the hands of spies, terrorists, and competent criminals is not a practical option. They probably have it already, and if they don't they can easily get it. The only people affected by a law against encryption software are the law abiding.What about banning or restricting the use of encryption\u2014at least encryption that cannot be broken by law enforcement agents? To enforce such a ban law enforcement agencies could randomly monitor all communication systems, looking for illegally encrypted messages. One practical problem is the enormous volume of information flowing over computer networks. A second and even more intractable problem is that while it is easy enough to tell whether a message consists of text written in English, it is very much harder\u2014in practice impossible\u2014to identify other sorts of content well enough to be sure that they do not contain encrypted messages.Consider a three million pixel digital photo. To conceal a million character long encrypted message\u2014an average sized novel\u2014I replace the least significant bit of each of the numbers describing the color of a pixel with one bit of the message. The photo is now a marginally worse picture than it was\u2014but there is no way an FBI agent, or a computer working for an FBI agent, can know precisely what the photo ought to look like.Short of banning communication over computer networks or at least restricting it to text messages, there is no way that law enforcement can keep sophisticated criminals, spies, or terrorists from using encryption. What can be done is to put limits on the encryption software used by the rest of us\u2260to insist, for example, that if AOL or Microsoft builds encryption into their programs it must contain a back door permitting properly authorized persons to read the message without the key.This still leaves the problem of how to give law enforcement what it wants without imposing unacceptably high costs on the rest of us. Consider the description of adequate regulation given by Louis Freeh, at the time the head of the FBI\u2014the ability to crack any encrypted message in half an hour. The equivalent in realspace would be legal rules that let properly authorized law enforcement agents open any lock in the country in half an hour. That includes not only the lock on your front door but the locks protecting bank vaults, trade secrets, lawyers' records, lists of contributors to unpopular causes, and much else.Encryption provides the locks for cyberspace. If all legal encryption comes with a mandatory back door accessible in half an hour to any police officer with a court order, everything in cyberspace is vulnerable to a private criminal with the right contacts. Those locks have billions of dollars worth of stuff behind them\u2260money in banks, trade secrets in computers and in messages. If being a police officer gives you access to locks with billions of dollars behind them, in cash, diamonds, or information, some cops will become criminals and some criminals will become cops.In one important way, the consequence for cyberspace is even worse than the equivalent in realspace. If a police officer opens a safe and pockets a stack of cash or a bag of diamonds, the owner can see that something is missing and demand it back. But when information is copied the original is still there. If the officer who has decrypted your communications or stored data assures you that he found nothing relevant to his investigation and so took nothing away, there is no way to prove he is lying.For encryption regulation to be useful it must either prevent the routine use of encryption or make it easy for law enforcement agents to access encrypted data and messages. Not only would that seriously handicap routine transactions, it would make computer crime easier by restricting the technology best suited to defend against it. And what we get in exchange is protection not against the use of encryption by sophisticated criminals and terrorists\u2260there is no way of providing that\u2260but only against its use by ordinary people and unsophisticated criminals. It does not look like a very attractive deal.Some years ago Professor Etzioni, who has contributed a chapter to this volume, published a book arguing for some restrictions on privacy as ways of promoting the common good. In reading it, I was struck by two differences between our views that explain much of the difference in our conclusions.The first was that I did, and he did not, define privacy in the context of freedom of association. Consider the question of airlines requiring their pilots to be tested for drugs and alcohol. Professor Etzioni regards that as a (desirable) restriction on the pilots' privacy. I agree that it is desirable but not that it restricts privacy.In a society where privacy is protected you have a right not to be tested. You do not have a right to be hired to fly airplanes\u2014and, if you choose to exercise your right not to be tested, you should not be surprised if the airline exercises its right not to hire you. The background legal principle is not that I have a right to be hired as a pilot or that United Airlines has a right to have me fly their planes. The background principle is that they can hire me to fly their planes if and only if both they and I agree. Given that principle of free association many\u2014although not all\u2014of the problems that Professor Etzioni sees with privacy vanish.The second difference has to do with our different views of government. While Professor Etzioni makes occasional references to the risk of some future oppressive government misusing information, he does not take seriously similar concerns with regard to our current government. His implicit assumption is that government is to be viewed as a benevolent agent standing above the human struggle, not as a mechanism through which individuals seek to achieve their goals, often at the expense of other individuals. That is not a view that strikes me as realistic.Privacy, like almost anything else, can be used for good or bad purposes. My thesis in this chapter is that, on net, more privacy makes the world a better place. It does so because it is an essentially defensive weapon, a way of reducing the ability of other people to control us.Reducing the ability of other people to control us is not always a good thing\u2014someone may, after all, want to control me for my own good or control you to keep you from hurting me. But we live in a world where too much control is more of a problem than too little. In the entire world over the past century, something on the order of ten million people have been killed by private murderers. Between a hundred and two hundred million have been killed by the governments that ruled them (Rummel (1999) estimates about 170 million from 1900 to 1987). Quite a lot of individual pain, suffering, injustice has been due to the acts of private individuals; some could have been prevented by better law enforcement. But mass pain, suffering and injustice has been very nearly a monopoly of governments. If governments were better able to control us, there would have been more of it. And at the individual level, while privacy can be used to protect criminals against police, it can also be used to protect victims against criminals.It is tempting to try for the best of both worlds\u2014to restrict the privacy of bad people while protecting that of good, permit governments to collect detailed information about us but only allow it to be used for good purposes. But somebody must decide who are the good people and the bad, what purposes are worthy or unworthy. Whoever that somebody is will have his own agenda, his own purposes. Angels are in short supply.To put the matter differently, \"cannot\" is better protection than \"may not.\" If we permit law enforcement agents to know everything about everybody but forbid them fro using that information against individuals with unpopular views or political opponents of the party in power, we are protected only by a \"may not.\" The same is true if private parties are able to collect information but restricted in what they may do with it. If the law keeps the information from being collected in the first place, we are protected by a cannot\u2014however corrupt or dishonest they are, or however convinced that they are working for a greater good, people cannot use information they do not have.\"Cannot\" at one level may depend on \"may not\" at another. You cannot use information that you do not have. You do not have it because you may not collect it. But even if the law forbids wiretaps or unauthorized surveillance, a sufficiently determined agency\u2014or a sufficiently competent private criminal\u2014can violate the law. That is where technologies that support privacy come into the picture. In a world where encryption is routine it does you no good to tap my phone because you cannot understand what I am saying. It does no good to intercept my email because you cannot read it. \"Cannot\" is better than \"may not.\"We can and should fight a delaying action against the use of technology to restrict privacy. But in the long run technology\u2014useful technology\u2014is hard to stop. In the long run, the real battle will be the one fought in defense of technologies that protect privacy. That one we might win.Brin, David (1999), The Transparent Society: Will Technology Force Us to Choose Between Privacy and Freedom? Perseus (The first chapter is webbed at http://www.kithrup.com/brin/tschp1.html)Etzioni, Amitai (1999), The Limits of Privacy, Basic Books.Friedman, David (1996) \"A World of Strong Privacy: Promises and Perils of Encryption,\" Social Philosophy and Policy, pp. 212-228. Webbed at http://www.daviddfriedman.com/Academic/Strong_Privacy/Strong_Privacy.htmlRummel, Rudolph J. (1999), Statistics of democide: Genocide and mass murder since 1900, Lit Verlag.Anderson, Poul, ShieldEllen Frankel Paul, Fred D. Miller, Jr., & Jeffrey Paul (Eds). (2000) The Right to Privacy, Cambridge University Press.http://www.mega.nu:8080/ampp/rummel/20th.htm (detailed statistics on 20th century democide)http://www.daviddfriedman.com/future_imperfect_draft/future_imperfect.html (Much more detailed account of encryption, surveillance, and much else.)David Friedman is a professor of law at Santa Clara University; his specialty is the economic analysis of law and his current interests include the effect of technology on the world over the next few decades. His most recent book is Law's Order: What Economics has to do with Law and Why It Matters. You can learn more than you want to know about both him and his ideas at www.daviddfriedman.com."}
{"prompt": "Money, Blockchains, and Social Scalability", "completion": "Blockchains are all the rage. The oldest and biggest blockchain of them all is Bitcoin, which over its eight-year history so far starshipped in value from 10,000 bitcoins per pizza (before there were exchanges that priced bitcoin in traditional currencies) to over $1,000 per bitcoin. As of this writing Bitcoin has a market capitalization of over $16 billion. Running non-stop for eight years, with almost no financial loss on the chain itself, it is now in important ways the most reliable and secure financial network in the world.The secret to Bitcoin\u2019s success is certainly not its computational efficiency or its scalability in the consumption of resources. Specialized Bitcoin hardware is designed by highly paid experts to perform only one particular function\u2014to repetitively solve a very specific and intentionally very expensive kind of computational puzzle. That puzzle is called a proof-of-work, because the sole output of the computation is just a proof that the computer did a costly computation. Bitcoin\u2019s puzzle-solving hardware probably consumes in total over 500 megawatts of electricity. And that is not the only feature of Bitcoin that strikes an engineer or businessman who is focused on minimizing resource costs as highly quixotic. Rather than reduce its protocol messages to be as few as possible, each Bitcoin-running computer sprays the Internet with a redundantly large number of \u201cinventory vector\u201d packets to make very sure that all messages get accurately through to as many other Bitcoin computers as possible. As a result, the Bitcoin blockchain cannot process as many transactions per second as a traditional payment network such as PayPal or Visa. Bitcoin offends the sensibilities of resource-conscious and performance-measure-maximizing engineers and businessmen alike.Instead, the secret to Bitcoin\u2019s success is that its prolific resource consumption and poor computational scalability is buying something even more valuable: social scalability. Social scalability is the ability of an institution\u2014a relationship or shared endeavor, in which multiple people repeatedly participate, and featuring customs, rules, or other features which constrain or motivate participants\u2019 behaviors\u2014to overcome shortcomings in human minds and in the motivating or constraining aspects of said institution that limit who or how many can successfully participate. Social scalability is about the ways and extents to which participants can think about and respond to institutions and fellow participants as the variety and numbers of participants in those institutions or relationships grow. It's about human limitations, not about technological limitations or physical resource constraints. There are separate engineering disciplines, such as computer science, for assessing the physical limitations of a technology itself, including the resource capacities needed for a technology to handle a greater number of users or a greater rate of use. Those engineering scalability disciplines are not, except by way of contrast with social scalability, the subject of this essay.Even though social scalability is about the cognitive limitations and behavior tendencies of minds, not about the physical resource limitations of machines, it makes eminent sense, and indeed is often crucial, to think and talk about the social scalability of a technology that facilitates an institution. The social scalability of an institutional technology depends on how that technology constrains or motivates participation in that institution, including protection of participants and the institution itself from harmful participation or attack. One way to estimate the social scalability of an institutional technology is by the number of people who can beneficially participate in the institution. Another way to estimate social scalability is by the extra benefits and harms an institution bestows or imposes on participants, before, for cognitive or behavioral reasons, the expected costs and other harms of participating in an institution grow faster than its benefits. The cultural and jurisdictional diversity of people who can beneficially participate in an institution is also often important, especially in the global Internet context. The more an institution depends on local laws, customs, or language, the less socially scalable it is.Without institutional and technological innovations of the past, participation in shared human endeavors would usually be limited to at most about 150 people\u2014the famous \u201cDunbar number\u201d. In the Internet era, new innovations continue to scale our social capabilities. In this article I will discuss how blockchains, and in particular public blockchains that implement cryptocurrencies, increase social scalability, even at a dreadful reduction in computational efficiency and scalability.Cognitive capacity\u2014here in the form of the relative size of a species\u2019 neocortex\u2014set limits on how large primate groups can be. Maintaining animal or intimate human groups requires extensive emotional communications and investments in relationships, such as grooming in primates and gossiping, humor, story-telling, and other conversations, songs, and play in traditional human groups. Overcoming human cognitive limits to who or how many people can participate in an institution\u2014the famous \u201cDunbar number\u201d of around 150 people\u2014requires institutional and technological innovation. (Source)Innovations in social scalability involve institutional and technological improvements that move function from mind to paper or mind to machine, lowering cognitive costs while increasing the value of information flowing between minds, reducing vulnerability, and/or searching for and discovering new and mutually beneficial participants. Alfred North Whitehead said, \u201cIt is a profoundly erroneous truism, repeated by all copy-books and by eminent people when they are making speeches, that we should cultivate the habit of thinking what we are doing. The precise opposite is the case. Civilization advances by extending the number of important operations which we can perform without thinking about them.\u201d Friedrich Hayek added: \u201cWe make constant use of formulas, symbols, and rules whose meaning we do not understand and through the use of which we avail ourselves of the assistance of knowledge which individually we do not possess. We have developed these practices and institutions by building upon habits and institutions which have proved successful in their own sphere and which have in turn become the foundation of the civilization we have built up.\u201dA wide variety of innovations reduce our vulnerability to fellow participants, intermediaries, and outsiders, and thereby lower our need to spend our scarce cognitive capacities worrying about how an increasingly large number of increasingly diverse people might behave. Another class of improvements motivates the accurate collection and transmission of valuable information between an increasing number and variety of participants. Yet other advances enable a wider number or variety of mutually beneficial participants can discover each other. All these kinds of innovations have over the course of human prehistory and history improved social scalability, sometimes dramatically so, making our modern civilization with its vast global population feasible. Modern information technology (IT), especially by making use of the historically recent discoveries of computer science, can often discover many more mutually beneficial matches, can improve motivations for information quality, and can reduce the need for trust within certain kinds of institutional transactions, with respect to an increasingly large number and variety of people, thereby further increasing social scalability in some very important ways.Information flows between minds\u2014what I have called intersubjective protocols\u2014include spoken and written words, custom (tradition), the contents of law (its rules, customs, and case precedents), a variety of other symbols (e.g. \u201cstar\u201d ratings common in online reputation systems), and market prices, among many others.Trust minimization is reducing the vulnerability of participants to each other\u2019s and to outsiders\u2019 and intermediaries\u2019 potential for harmful behavior. Most institutions which have undergone a lengthy cultural evolution, such as law (which lowers vulnerability to violence, theft, and fraud), as well as technologies of security, reduce, on balance, and in more ways than the reverse, our vulnerabilities to, and thus our needs to trust, our fellow humans, compared with our vulnerabilities before these institutions and technologies evolved. In most cases an often trusted and sufficiently trustworthy institution (such as a market) depends on its participants trusting, usually implicitly, another sufficiently trustworthy institution (such as contract law). These trusted institutions in turn traditionally implement a variety of accounting, legal, security, or other controls that make them usually and sufficiently, at least for facilitating the functionality of their client institutions, trustworthy, by minimizing vulnerability to their own participants (such as accountants, lawyers, regulators, and investigators). An innovation can only partially take away some kinds of vulnerability, i.e. reduce the need for or risk of trust in other people. There is no such thing as a fully trustless institution or technology.The nonexistence of complete trustlessness is true even of our strongest security technology, encryption. Although some cryptographic protocols do guarantee certain specific data relationships with astronomically high probability against opponents with astronomically high computing power, they do not provide complete guarantees when accounting for all possible behaviors of all participants. For example, encryption can strongly protect an e-mail from direct eavesdropping by third parties, but the sender still trusts the recipient to not forward or otherwise divulge the contents of that email, directly or indirectly to any undesired third parties. As another example, in our strongest consensus protocols harmful behavior by certain fractions of participants or intermediaries well short of 100% (as measured by their computing power, stake-holding, or individuation and counting) can compromise the integrity of transactions or information flows between participants and thereby on balance harm the participants. The historically recent breakthroughs of computer science can reduce vulnerabilities, often dramatically so, but they are far from eliminating all kinds of vulnerabilities to the harmful behavior of any potential attacker.Matchmaking is facilitating the mutual discovery of mutually beneficial participants. Matchmaking is probably the kind of social scalability at which the Internet has most excelled. Social networks like Usenet News, Facebook, and Twitter facilitate the mutual discovery of like-minded or otherwise mutually entertaining or mutually informing people (and even future spouses!). After they have allowed people more likely to be of mutual benefit to discover each other, social networks then facilitate relationships at various levels of personal investment, from casual to frequent to obsessive. Christopher Allen among others has done some interesting and detailed analyses about group size and time spent mutually interacting in online games and associated social networks.eBay, Uber, AirBnB, and online financial exchanges have brought social scalability via often great improvements in commercial matchmaking: searching for, finding, bringing together, and facilitating the negotiation of mutually beneficial commercial or retail deals. These or related services also facilitate performances such as payment and shipping, as well as verification that other obligations undertaken by strangers in these deals have been performed and communication about the quality of such performances (as with \u201cstar rating\u201d systems, Yelp reviews, and the like).Whereas the main social scalability benefit of the Internet has been matchmaking, the predominant direct social scalability benefit of blockchains is trust minimization. A blockchain can reduce vulnerability by locking in the integrity of some important performances (such as the creation and payment of money) and some important information flows, and in the future may reduce the vulnerability of the integrity of some important matchmaking functions. Trust in the secret and arbitrarily mutable activities of a private computation can be replaced by verifiable confidence in the behavior of a generally immutable public computation. This essay will focus on such vulnerability reduction and its benefit in facilitating a standard performance beneficial to a wide variety of potential counterparties, namely trust-minimized money.Money and markets directly benefit the participants in each particular trade by the market matching a buyer with a mutually beneficial seller and by a widely acceptable and standardized counter-performance (money). I use markets here in the sense Adam Smith used the term: not as a specific place or service where buyers and sellers are brought together (although it might sometimes involve these), but rather the broad set of typically pairwise exchanges whereby the supply chain that makes a product is coordinated.Money and markets also incentivize creation of more accurate price signals that reduce negotiation costs and errors for participants in other similar exchanges. The potent combination of money and market thereby allowed a far higher number and variety of participants to coordinate their economic activities than previous exchange institutions, which more resembled bilateral monopolies than competitive markets.Markets and money involve matchmaking (bringing together buyer and seller), trust reduction (trusting in the self-interest rather than in the altruism of acquaintances and strangers), scalable performance (via money, a widely acceptable and reusable medium for counter-performance), and quality information flow (market prices).The greatest early thinker about money and markets was Adam Smith. At the dawn of the industrial revolution in Britain, Smith observed in The Wealth of Nations how making even the most humble of products depended, directly and indirectly, on the work of large numbers of a wide variety of people:Observe the accommodation of the most common artificer or day-laborer in a civilized and thriving country, and you will perceive that the number of people of whose industry a part, though but a small part, has been employed in procuring him this accommodation, exceeds all computation. The woolen coat, for example, which covers the day laborer, as coarse and rough as it may appear, is the produce of the joint labor of a great multitude of workmen. The shepherd, the sorter of the wool, the wool-comber or carder, the dyer, the scribbler, the spinner, the weaver, the fuller, the dresser, with many others, must all join their different arts in order to complete even this homely production. How many merchants and carriers, besides, must have been employed in transporting the materials from some of those workmen to others who often live in a very distant part of the country! How much commerce and navigation in particular, how many shipbuilders, sailors, sail makers, rope makers, must have been employed in order to bring together the different drugs made use of by the dyer, which often come from the remotest corners of the world! What a variety of labor, too, is necessary in order to produce the tools of the meanest of those workmen! To say nothing of such complicated machines as the ship of the sailor, the mill of the fuller, or even the loom of the weaver, let us consider only what a variety of labor is requisite in order to form that very simple machine, the shears with which the shepherd clips the wool. The miner, the builder of the furnace for smelting the ore, the feller of the timber, the burner of the charcoal to be made use of in the smelting-house, the brick maker, the brick layer, the workmen who attend the furnace, the millwright, the forger, the smith, must all of them join their different arts in order to produce them. Were we to examine, in the same manner, all the different parts of his dress and household furniture, the coarse linen shirt which he wears nest his skin, the shoes which cover his feet, the bed which he lies on, and all the different parts which compose it, the kitchen grate at which be prepares his victuals, the coals which he makes use of for that purpose, dug from the bowels of the earth, and brought to him perhaps by a long sea and a long land carriage, all the other utensils of his kitchen, all the furniture of his table, the knives and forks, the earthen or pewter plates upon which he serves up and divides his victuals, the different hands employed in preparing his bread and his beer, the glass window which lets in the heat and the light, and keeps out the wind and the rain, with all the knowledge and art requisite for preparing that beautiful and happy invention, without which these northern parts of the world could scarce have afforded a very comfortable habitation, together with the tools of all the different workmen employed in producing those different conveniences; if we examine, I say, all these things, and consider what a variety of labor is employed about each of them, we shall be sensible that without the assistance and co-operation of many thousands, the very meanest person in a civilized country could not be provided, even according to what we may falsely imagine the easy and simple manner in which he is commonly accommodated.And this was before the many successive waves of industrial revolution and globalization between 1776 and now that refined, elaborated, and extended the division of labor many times more. Rather than trusting in the unlikely altruism of so many strangers, markets and money create many pairings of mutual benefit and thus motivate this large network of mutually oblivious people to act in our interests:In civilized society man stands at all times in need of the cooperation and assistance of great multitudes, while his whole life is scarce sufficient to gain the friendship of a few persons\u2026[In contrast to other animals,] man has an almost constant occasion for the help of his brethren, and it is vain for him to expect it from their benevolence only\u2026 [Exchange is the] manner in which we obtain from another the far greater part of those good offices which we stand in need of. It is not from the benevolence of the butcher, the brewer, or the baker, that we expect our dinner, but from their regard for their own interest.Smith goes on to describe how division of labor, and thus labor productivity, depends on the extent of the network of pairwise exchanges: \u201cAs it is the power of exchanging that gives occasion to the division of labor, so the extent of this division must always be limited by the extent of that power, or, in other words, by the extent of the market\u201d. As the exchange network around a country and around the globe grows, involving a greater number and variety of producers, so grows the division of labor and thereby labor productivity.Money facilitates social scalability by increasing the opportunities for this exchange. By lowering coincidence problems (coincidence-of-wants in exchange and coincidence-of-want-and-event in unilateral transfers), via a widely acceptable and reusable form of wealth storage and transfer, money greatly lowered transaction costs, making possible more exchanges of a greater variety of goods and services involving exchanges and other wealth transfer relationships with a much larger number and much wider variety of people.A wide variety of media, from oral language itself, clay, paper, telegraph, radio, and computer networks, have served to communicate offers, acceptances, and the resulting deals and prices, as well as performance monitoring and other business communications.One of the most knowledgeable observations of the price network produced by markets and money can be found in Friedrich Hayek\u2019s essay, \u201cThe Use of Knowledge in Society\u201d:In a system in which the knowledge of the relevant facts is dispersed among many people, prices can act to coordinate the separate actions of different people\u2026in any society in which many people collaborate, this planning, whoever does it, will in some measure have to be based on knowledge which, in the first instance, is not given to the planner but to somebody else, which somehow will have to be conveyed to the planner. The various ways in which the knowledge on which people base their plans is communicated to them is the crucial problem for any theory explaining the economic process, and the problem of what is the best way of utilizing knowledge initially dispersed among all the people is at least one of the main problems of economic policy\u2014or of designing an efficient economic system\u2026 The mere fact that there is one price for any commodity\u2014or rather that local prices are connected in a manner determined by the cost of transport, etc.\u2014brings about the solution which (it is just conceptually possible) might have been arrived at by one single mind possessing all the information which is in fact dispersed among all the people involved in the process\u2026 The marvel is that in a case like that of a scarcity of one raw material, without an order being issued, without more than perhaps a handful of people knowing the cause, tens of thousands of people whose identity could not be ascertained by months of investigation, are made to use the material or its products more sparingly; i.e., they move in the right direction\u2026.The price system is just one of those formations which man has learned to use (though he is still very far from having learned to make the best use of it) after he had stumbled upon it without understanding it. Through it not only a division of labor but also a coordinated utilization of resources based on an equally divided knowledge has become possible\u2026a solution is produced by the interactions of people each of whom possesses only partial knowledge.Where long ago we used clay, and more recently paper, today programs and protocols running on our computers and data networks implement most of our commercial dealings. While this has greatly improved matchmaking and information flow, it has come at the cost of an increase in vulnerability to harmful behavior.As networks grow, more people with fewer mutually understood habits of and constraints on behavior are added. Security via root-trusting access control, designed for small and chummy offices like Bell Labs where co-workers were well known and income and expenditures well controlled by paper procedures rather than performed on these office computers, breaks down as an efficient and effective security mechanism as organizations become larger, as organizational boundaries are crossed, and as more valuable and concentrated resources such as money are put on or activated via the computers. The more strangers one receives emails from, the more likely one is likely to get a phishing attack or a malware-laced attachment. Traditional computer security is not very socially scalable. As I describe in \u201cThe Dawn of Trustworthy Computing\u201d:When we currently use a smart phone or a laptop on a cell network or the Internet, the other end of these interactions typically run on other solo computers, such as web servers. Practically all of these machines have architectures that were designed to be controlled by a single person or a hierarchy of people who know and trust each other. From the point of view of a remote web or app user, these architectures are based on full trust in an unknown \u201croot\u201d administrator, who can control everything that happens on the server: they can read, alter, delete, or block any data on that computer at will. Even data sent encrypted over a network is eventually unencrypted and ends up on a computer controlled in this total way. With current web services we are fully trusting, in other words we are fully vulnerable to, the computer, or more specifically the people who have access to that computer, both insiders and hackers, to faithfully execute our orders, secure our payments, and so on. If somebody on the other end wants to ignore or falsify what you've instructed the web server to do, no strong security is stopping them, only fallible and expensive human institutions, which often stop at national borders.Many server computers are not valuable enough for insiders or outsiders to attack. But an increasing number of others contain valuable concentrations of resources, motivating attack. Centralized root-trusting security scales poorly. As the resources controlled by computers become more valuable and more concentrated, traditional root-trusting security becomes more like the \u201ccall the cop\u201d security we are used to in the physical world. Fortunately, with blockchains we can do much better for many of our most important computations.Scalable markets and prices require scalable money. Scalable money requires scalable security, so that a greater number and variety of people can use the currency without losing its integrity against forgery, inflation, and theft.An individual or group communicating under the name \u201cSatoshi Nakamoto\u201d brought Bitcoin to the Internet in 2009. Satoshi\u2019s breakthrough with money was to provide social scalability via trust minimization: reducing vulnerability to counterparties and third parties alike. By substituting computationally expensive but automated security for computationally cheap but institutionally expensive traditional security, Satoshi gained a nice increase in social scalability. A set of partially trusted intermediaries replaces a single and fully trusted intermediary.Financial controls on computational steroids: a blockchain as an army of robots, each checking up on each other\u2019s work.When we can secure the most important functionality of a financial network by computer science rather than by the traditional accountants, regulators, investigators, police, and lawyers, we go from a system that is manual, local, and of inconsistent security to one that is automated, global, and much more secure. Cryptocurrencies, when implemented properly on public blockchains, can substitute an army of computers for a large number of traditional banking bureaucrats. \u201cThese block chain computers will allow us to put the most crucial parts of our online protocols on a far more reliable and secure footing, and make possible fiduciary interactions that we previously dared not do on a global network.\u201d (Source)The characteristics most distinctively valuable in blockchain technology in general, and Bitcoin in particular \u2014 for examplecome from the high levels of security and reliability a blockchain can maintain without human intervention. Without that high security it\u2019s just a gratuitously wasteful distributed database technology still tied to the local bureaucracies it would have to depend upon for its integrity.Since the mid-20th century computing has increased in efficiency by many orders of magnitude, but humans are using the same brains. This has created plenty of possibility for overcoming human limitations, and institutions based solely on human minds, with computational capabilities, including in security, doing what they do best, with human minds doing what they still do best. As a result, humans have no more raw mental ability to scale up our institutions than we ever have. But there is plenty of potential for improving social scalability by replacing some human functions with computational ones. (An important note\u2014this argument depends on the slope, not the absolute position, of the human ability line. The absolute position shown above is arbitrary and depends on what human \u201ccomputation\u201d we are measuring).A new centralized financial entity, a trusted third party without a \u201chuman blockchain\u201d of the kind employed by traditional finance, is at high risk of becoming the next Mt. Gox; it is not going to become a trustworthy financial intermediary without that bureaucracy.Computers and networks are cheap. Scaling computational resources requires cheap additional resources. Scaling human traditional institutions in a reliable and secure manner requires increasing amounts accountants, lawyers, regulators, and police, along with the increase in bureaucracy, risk, and stress that such institutions entail. Lawyers are costly. Regulation is to the moon. Computer science secures money far better than accountants, police, and lawyers.In computer science there are fundamental security versus performance tradeoffs. Bitcoin's automated integrity comes at high costs in its performance and resource usage. Nobody has discovered any way to greatly increase the computational scalability of the Bitcoin blockchain, for example its transaction throughput, and demonstrated that this improvement does not compromise Bitcoin\u2019s security.It is probable that no such big but integrity-preserving performance improvement is possible for the Bitcoin blockchain; this may be one of these unavoidable tradeoffs. Compared to existing financial IT, Satoshi made radical tradeoffs in favor of security and against performance. The seemingly wasteful process of mining is the most obvious of these tradeoffs, but Bitcoin also makes others. Among them is that it requires high redundancy in its messaging. Mathematically provable integrity would require full broadcast between all nodes. Bitcoin can\u2019t achieve that but to even get anywhere close to a good approximation of it requires a very high level of redundancy. So a 1 MB block consumes far more resources than a 1 MB web page, because it has to be transmitted, processed, and stored with high redundancy for Bitcoin to achieve its automated integrity.These necessary tradeoffs, sacrificing performance in order to achieve the security necessary for independent, seamlessly global, and automated integrity, mean that the Bitcoin blockchain itself cannot possibly come anywhere near Visa transaction-per-second numbers and maintain the automated integrity that creates its distinctive advantages versus these traditional financial systems. Instead, a less trust-minimized peripheral payment network (possibly Lightning) will be needed to bear a larger number of lower-value bitcoin-denominated transactions than Bitcoin blockchain is capable of, using the Bitcoin blockchain to periodically settle with one high-value transaction batches of peripheral network transactions.Bitcoin supports a lower rate transactions than Visa or PayPal, but due to its stronger automated security these can be much more important transactions. Anybody with a decent Internet connection and a smart phone who can pay $0.20-$2 transaction fees\u2014substantially lower than current remittance fees\u2014can access Bitcoin any where on the globe. Lower value transactions with lower fees will need to be implemented on peripheral bitcoin networks.When it comes to small-b bitcoin, the currency, there is nothing impossible about paying retail with bitcoin the way you\u2019d pay with a fiat currency \u2014 bitcoin-denominated credit and debt cards, for example, with all the chargeback and transactions-per-second capabilities of a credit or debit card. And there are also clever ways to do peripheral bitcoin retail payments in which small value payments happen off-chain and are only periodically bulk-settled on the Capital-B Bitcoin blockchain. That blockchain is going to evolve into a high-value settlement layer as bitcoin use grows, and we will see peripheral networks being used for small-b bitcoin retail transactions.When I designed bit gold I already knew consensus did not scale to large transaction throughputs securely, so I designed it with a two-tier architecture: (1) bit gold itself, the settlement layer, and (2) Chaumian digital cash, a peripheral payment network which would provide retail payments with high transactions-per-second performance and privacy (through Chaumian blinding), but would like Visa be a trusted third party and thus require a \u201chuman blockchain\u201d of accountants, etc. to operate with integrity. The peripheral payment network can involve only small value transactions, thereby requiring much less of a human army to avoid the fate of Mt. Gox.Ralph Merkle: pioneer of public-key cryptography and inventor of hierarchical hash-tree structures (Merkle trees).Money requires social scalability in its design, via security. For example it should be very hard for any participant or intermediary to forge money (to dilute the supply curve leading to undue or unexpected inflation). Gold can have value anywhere in the world and is immune from hyperinflation because its value doesn\u2019t depend on a central authority. Bitcoin excels at both these factors and runs online, enabling somebody in Albania to use Bitcoin to pay somebody in Zimbabwe with minimal trust in or and no payment of quasi-monopoly profits to intermediaries, and with minimum vulnerability to third parties.There are all sorts of definitions of \u201cblockchain\u201d out there, almost all of them just implicitly broad hand-waving amid the mountains of marketing hype. I suggest a clear definition that can be communicated to lay people. It is a blockchain if it has blocks and it has chains. The \u201cchains\u201d should be Merkle trees or other cryptographic structures with a similar integrity functionality of post-unforgeable integrity. Also the transactions and any other data whose integrity is protected by a blockchain should be replicated in a way objectively tolerant to worst-case malicious problems and actors to as high a degree as possible (typically the system can behave as previously specified up to a fraction of 1/3 to 1/2 of the servers maliciously trying to subvert it to behave differently).Bitcoin\u2019s socially scalable security, based on computer science rather than on police and lawyers, allows, for example, customers in Africa to pay suppliers in China seamlessly across borders. A private blockchain cannot accomplish this feat nearly as easily, since it would require an identification scheme, certificate authority, and PKI shared between these various jurisdictions. (Source)Because of this fraction, and because of the (hopefully very rare) need to update software in a manner that renders prior blocks invalid\u2014an even riskier situation called a hard fork\u2014blockchains also need a human governance layer that is vulnerable to fork politics. The most successful blockchain, Bitcoin, has maintained its immutable integrity via decentralized decision-making among experts in the technology combined with a strong dogma of immutability, under which only the most important and rare bug fixes and design improvements, that cannot be made any other way, justify a hard fork. Under this philosophy of governance accounting or legal decisions (such as altering an account balance or undoing a transaction) never justify a hard fork, but should be accomplished by traditional governance outside of (or on top of) the system (e.g. via a court injunction forcing a Bitcoin user to send a new transaction that effectively undoes the old one, or confiscating the particular keys and thus the particular holdings of a particular user).To say that data is post-unforgeable or immutable means that it can\u2019t be undetectably alteredafter being committed to the blockchain. Contrary to some hype this doesn\u2019t guarantee anything about a datum\u2019s provenance, or its truth or falsity, before it was committed to the blockchain. That requires additional protocols, often including expensive traditional controls. Blockchains don\u2019t guarantee truth; they just preserve truth and lies from later alteration, allowing one to later securely analyze them, and thus be more confident in uncovering the lies. Typical computers are computational etch-a-sketch, while blockchains are computational amber. Important data should be committed to blockchain amber as early as possible, ideally directly from and cryptographically signed by the device in which it was generated, to maximize the blockchain\u2019s benefit in securing its integrity.A Merkle tree of four transactions (tx0 through tx3). Combined with a proper replication and chains of transaction blocks protected by proof-of-work, Merkle trees can make data such as transactions post-unforgeable by consensus. In Bitcoin, a Merkle root hash securely summarizes and is used to verify the unaltered state of all the transactions in a block.My own 1998 \u201csecure property title\u201d architecture had Merkle trees and replication of data tolerant against an objective fraction of arbitrarily faulty software or malicious actors, but not blocks. It demonstrated my theory that you could protect the integrity of globally shared data and transactions, and use that ability to design a cryptocurrency (bit gold). It did not have the more efficient and computationally scalable blocks-and-ledger system that Bitcoin does. Also like today\u2019s private blockchains, secure property titles assumed and required securely distinguishable and countable nodes.Given the objective 51% hashrate attack limit to some important security goals of public blockchains like Bitcoin and Ethereum, we actually do care about the distinguishable identity of the most powerful miners to answer the question \u201ccan somebody convince and coordinate the 51%?Blockchain security is objectively limited and blockchain governance is heavily influenced by the potential for a 51% attack. An attack of course does not have to be called an \u201cattack\u201d by the attackers; instead they might call it \u201cenlightened governance\u201d or \u201cdemocracy in action\u201d. Indeed some kinds of software updates needed to fix bugs or otherwise improve the protocol require a soft fork. Some other kinds of software updates require hard forks, which in Bitcoin pose an even greater security and continuity risks than soft forks. Blockchains, although reducing trust far more than any other network protocols, are still far from trustless. Miners are partially trusted fiduciaries, and those who are not expert developers or computer scientists who have invested a great deal of time in learning the design principles and codebase of a blockchain must place a great deal of faith in the expert developer community, much as non-specialists who want to understand the results of a specialized science do of the corresponding scientists. During a hard fork exchanges can also be very influential by deciding which fork to support with their order books and trade symbol continuity.Public blockchains thus mostly but not entirely dodge the identity-is-hard bullet and take care of its remaining problem of identifying the most powerful miners at a higher \u201cwet\u201d/\u201csocial\u201d level, where it is probably more appropriate, rather than trying to securely map such an inherently wet (brain-based) concept onto the protocol, as PKI (public key infrastructure) rather awkwardly tries to do.So I think some of the \u201cprivate blockchains\u201d qualify as bona fide blockchains; others should go under the broader rubric of \u201cdistributed ledger\u201d or \u201cshared database\u201d or similar. They are all very different from and not nearly as socially scalable as public and permissionless blockchains like Bitcoin and Ethereum.All of the following are very similar in requiring an securely identified (distinguishable and countable) group of servers rather than the arbitrary anonymous membership of miners in public blockchains. In other words, they require some other, usually far less socially scalable, solution to the Sybil (sockpuppet) attack problem:The dominant, but usually not very socially scalable, way to identify a group of servers is with a PKI based on trusted certificate authorities (CAs). To avoid the problem that merely trusted third parties are security holes, reliable CAs themselves must be expensive, labor-intensive bureaucracies that often do extensive background checks themselves or rely on others (e.g. Dun and Bradstreet for businesses) to do so. (I once led a team that designed and built such a CA). CAs also act as a gatekeeper, rendering these permissioned systems. CAs can become singular points of political control and failure. \u201cPublic blockchains are automated, secure, and global, but identity is labor-intensive, insecure, and local.\u201dPKI-enabled private blockchains are a nice for banks and some other large enterprises because they already have mature in-house PKIs that cover the employees, partners, and private servers needed to approve important transactions. Bank PKIs are relatively reliable. We also have semi-reliable CAs for web servers, but not generally speaking for web clients, even though people have been working on the problem of client certificates since the invention of the web: for example advertisers would love to have a more secure alternative to phone numbers and cookies for tracking customer identities. Yet it hasn\u2019t happened.PKI can work well for some important things and people but it is not nearly so nice or so easy for lesser entities. Its social scalability is limited by the traditional wet identity bureaucracy on which it depends.Some significant thefts in the broader bitcoin ecosystem. Whereas the Bitcoin blockchain itself is probably the most secure financial network in existence (and indeed must remain far more secure than traditional payment networks in order to maintain its low governance costs and seamless cross-border capability), its peripheral services based on older centralized web servers are very insecure. (Source: author)We need more socially scalable ways to securely count nodes, or to put it another way to with as much robustness against corruption as possible, assess contributions to securing the integrity of a blockchain. That is what proof-of-work and broadcast-replication are about: greatly sacrificing computational scalability in order to improve social scalability. That is Satoshi\u2019s brilliant tradeoff. It is brilliant because humans are far more expensive than computers and that gap widens further each year. And it is brilliant because it allows one to seamlessly and securely work across human trust boundaries (e.g. national borders), in contrast to \u201ccall-the-cop\u201d architectures like PayPal and Visa that continually depend on expensive, error-prone, and sometimes corruptible bureaucracies to function with a reasonable amount of integrity.The rise of the Internet as seen the rise of a variety of online institutions, among them social networks, \u201clong-tail\u201d retail (e.g. Amazon), and a variety of services that allow small and dispersed buyers and sellers to find and do business with each other (eBay, Uber, AirBnB, etc.) These are just the initial attempts to take advantage of our new abilities. Due to the massive improvements in information technology over recent decades, the number and variety of people who can successfully participate in an online institution is far less often restricted by the objective limits of computers and networks than it is by limitations of mind and institution that have usually have not yet been sufficiently redesigned or further evolved to take advantage of those technological improvements.These initial Internet efforts have been very centralized. Blockchain technology, which implements data integrity via computer science rather than via \u201ccall the cops\u201d, has so far made possible trust-minimized money\u2014cryptocurrencies\u2014and will let us make progress in other financial areas as well as other areas where transactions can be based primarily on data available online.This is not to say that adapting our institutions to our new capabilities will be easy, or indeed in particular cases anything short of difficult and improbable. Utopian schemes are very popular in the blockchain community, but they are not viable options. Reverse-engineering our highly evolved traditional institutions, and even reviving in new form some old ones, will usually work better than designing from scratch, than grand planning and game theory. One important strategy for doing so was demonstrated by Satoshi\u2014sacrifice computational efficiency and scalability\u2014consume more cheap computational resources\u2014in order to reduce and better leverage the great expense in human resources needed to maintain the relationships between strangers involved modern institutions such as markets, large firms, and governments."}
{"prompt": "The Idea of Smart Contracts", "completion": "What is the meaning and purpose of \"security\"? How does it relate the the relationships we have? I argue that the formalizations of our relationships\u2014especially contracts\u2014provide the blueprint for ideal security.Many kinds of contractual clauses (such as collateral, bonding, delineation of property rights, etc.) can be embedded in the hardware and software we deal with, in such a way as to make breach of contract expensive (if desired, sometimes prohibitively so) for the breacher. A canonical real-life example, which we might consider to be the primitive ancestor of smart contracts, is the humble vending machine. Within a limited amount of potential loss (the amount in the till should be less than the cost of breaching the mechanism), the machine takes in coins, and via a simple mechanism, which makes a freshman computer science problem in design with finite automata, dispense change and product according to the displayed price. The vending machine is a contract with bearer: anybody with coins can participate in an exchange with the vendor. The lockbox and other security mechanisms protect the stored coins and contents from attackers, sufficiently to allow profitable deployment of vending machines in a wide variety of areas.Smart contracts go beyond the vending machine in proposing to embed contracts in all sorts of property that is valuable and controlled by digital means. Smart contracts reference that property in a dynamic, often proactively enforced form, and provide much better observation and verification where proactive measures must fall short.As another example, consider a hypothetical digital security system for automobiles. The smart contract design strategy suggests that we successively refine security protocols to more fully embed in a property the contractual terms which deal with it. These protocols would give control of the cryptographic keys for operating the property to the person who rightfully owns that property, based on the terms of the contract. In the most straightforward implementation, the car can be rendered inoperable unless the proper challenge-response protocol is completed with its rightful owner, preventing theft.If the car is being used to secure credit, strong security implemented in this traditional way would create a headache for the creditor - the repo man would no longer be able to confiscate a deadbeat's car. To redress this problem, we can create a smart lien protocol: if the owner fails to make payments, the smart contract invokes the lien protocol, which returns control of the car keys to the bank. This protocol might be much cheaper and more effective than a repo man. A further reification would provably remove the lien when the loan has been paid off, as well as account for hardship and operational exceptions. For example, it would be rude to revoke operation of the car while it's doing 75 down the freeway.In this process of successive refinement we've gone from a crude security system to a reified contract:Mature security systems will be undertaking different behavior for different contracts. To continue with our example, if the automobile contract were a lease, the final payment would switch off leasee access; for purchase on credit, it would switch off creditor access. A security system, by successive redesign, increasingly approaches the logic of the contract which governs the rights and obligations covering the object, information, or computation being secured. Qualitatively different contractual terms, as well as technological differences in the property, give rise to the need for different protocols.(Derived from \"Formalizing and Securing Relationships on Public Networks\", by Nick Szabo)A related article discusses a formal language for analyzing contracts and specifying smart contracts.Please send your comments to nszabo (at) law (dot) gwu (dot) eduCopyright \u00a9 1997 by Nick Szabo\nPermission to redistribute without alteration hereby granted"}
{"prompt": "Cyberspace, Crypto Anarchy, and Pushing Limits", "completion": "This messages touches on two topics of recent interest (to some) here:Setting up payment systems for message transmission, to handle the issues of \u201cmailbombing\u201d and \u201cflooding\u201d in a more natural way (locality of reference, user of a service pays, avoidance of the \u201cMorris Worm\u201d explosion effects which could\u2019ve happened with Detweiler bombed us, as Hal noted).The general issue of \u201cCyberspace.\u201d This lies at the root of some recent disagreements here, and is worthy of more discussion. Crypto will make this a very real cusp issue in the next several years.Why debate it now? What could possibly come out of such a debate?It happens that I\u2019m reading a wonderful new book by Kip Thorne, entitled \u201cBlack Holes and Space Warps.\u201d This is widely available in bookstores, in hardback only at this time. ($30, but it\u2019s a whopping big book, and I got it at Barnes and Noble for $24. Speaking of Barnes and Noble, the Santa Clara store is selling Li and Vitanyi\u2019s \u201cIntro. to Kolmogorov Complexity\u201d book for $44, before the 20% hardback discount, which may be a mispricingm, as I paid $60 for mine. Check it out if you\u2019re interested....I think there were two copies.)Thorne has spent 30 years studying gravitational collapse and black holes, and was a coauthor of the famed 1973 book on \u201cGravitation,\u201d which I got to use in a Xeroxed form for my general relativity class in 1973.The point? Thorne describes his involvement with Carl Sagan in working out the physics of time travel via wormholes. Thorne had an epiphany: however unlikely the engineering or financing of something is, there is something valuable to be gained in examining the absolute limits of what is possible without regard for engineering practicalities. Thus, he and his students looked into the implications of an extremely advanced civilization able to somehow hold open the mouth of a wormhole. The conclusions are fascinating and led to a new line of thinking about the structure of space-time.Pushing limits and seeing \u201cideal\u201d behavior is invigorating.The connection to crypto is this: Perhaps we should be thinking more about the implicaitons and effects of strong crypto, digital money, ideal remailers, etc., assuming that certain practical problems that bedevil us today are, or soon will be, solved. To some extent we already do this, as when we discuss Chaum\u2019s ideal mixes in the same way engineer\u2019s discuss ideal op amps--a useful abstraction of behavior in the limit that lesser, real world implementations can then be contrasted with.And of course many of us have found Vernor Vinge\u2019s \u201cTrue Names\u201d to be an excellent (and quickly readable) treatment of how things could work in a world of fast, cheap, and secure communication. Other writers have seen things differently (e.g., \u201cShockwave Rider,\u201d \u201c1984,\u201d \u201cSnow Crash\u201d).Here, to cut to the chase, are some brief statements of what I see as the \u201cbehavior in the limits.\u201d I won\u2019t elaborate on them right now.\u201cPay as you go\u201d is the natural way to handle most economic transactions. There are exceptions, of course, such as insurance, contracts for future perfomance, etc., but for the most part money is used to mediate immediate exchanges. For a timely example, why can your enemies not \u201cjunk mail bomb\u201d you with truly large (tons) of junk mail? Junk mail, as we call it, is in relatively small volumes (at most a mailbox full, except for celebrities perhaps) because of one simple thing: someone has to pay for the delivery! There is no possibility of a \u201cfree\u201d way to \u201cMake 19 copies of this ton of garbabe and mail them to your enemies.\u201d That there is with software--the remailer bombing by Detweiler, the 1988 Morris Worm, the \u201cDave Rhodes\u201d chain letters--is due to some flaws in the current Net model:costs of message trasnmission are not directly borne by senders (encourage overuse by some of scarce resources, a la the \u201ctragedy of the commons\u201d).sites and remailers will respond to \u201cinstructions\u201d to send the message on, to make copies of it, etc.I thus consider it imperative that we develop as quickly as we can the following:payment systems for message transmission (I\u2019ve argued for \u201cdigital postage\u201d as a first and comparatively easy application of digital money, others have as well, and Ray Cromwell just today issued his own proposal....time we get going on this. And lest you think I\u2019m calling for altruism here, I think some fortunes will be made in this area.)anonymous or identity-obscuring protocols, a la Chaum.a general move away from \u201ccommons\u201d-oriented systems, which breed the notions of \u201cfair access\u201d and such. If the \u201cproblem\u201d is that poor people cannot--it is alleged--afford a $17 a month Net connection (what Netcom charges, in about 25 cities and growing), then my solution would be to simply subsidize their bill. (I\u2019m not advocating this, nor do I think it wise to subsidize anyone\u2019s phone, Net, or dinner bills, but better this than \u201cnationalizing\u201d networks and thus creating more confusion and less efficiency for all.)Connectivity will be altered dramatically, The \u201cdistance\u201d in cyberspace is already uncorrelated to physical distance. (Hardly surprising, as this was apparent with the telephone. But a useful way of looking at cyberspace, as being a space of radically altered connectivities and distances.)Local access to service, the phone or cable lines that reach the home or office, is a potential bottleneck. But once a connection is made to a local node where multiple competitors exist (that is, once beyond the local government-granted monopoly), the possibility of \u201ccensorship\u201d decreases rapidly, for several reasons.thus, push for \u201cencrypted access\u201d lines from a terminal node (home, office) to a point with unlimited connectivity.this is the situation I now have with my PacBell line and Netcom: PacBell doesn\u2019t \u201ccare\u201d what I use the local line for, and once outside, I can dial a less-censorious Netcom rather than a Big Brotherish AOL or Prodigy.Cyberspace is infinitely colonizable. No limits to growth. (Assumption: realization of cyberspace is on various machines and networks, which are not free, nor infinite. But the \u201cno limits\u201d comes from ease with which those near a \u201cboundary\u201d can simply push out that boundary with more CPU resource, more networks, etc.).Crypto means access to \u201cregions\u201d can be controlled by \u201cowners\u201d:\u201cmy house, my rules\u201d enforced locally, without central State authorityessentially unbreakable security (in crypto sense)By the way, strong crypto is the \u201cbuilding material\u201d of cyberspace...the mortar, the bricks, the support beams, the walls. Nothing else can provide the \u201cpermanence\u201d...without crypto, the walls are subject to collapse at the first touch by a malicious person or agency. With crypto, not even a 100 megaton H-bomb can breach the walls.(If you think I\u2019m exaggerating, do some calculations on the energy to break a 1000-decimal-digit modulus.)No \u201czoning laws\u201d will be needed, or possible, in cyberspace. (Neil Stephenson\u2019s \u201cSnow Crash,\u201d while a wonderful and thought-provoking read, got it wrong here: cyberspace is too extensible and locally controllable.)Physical location of cyberspace locations will be increasingly hard to pin down. A vast \u201clabyrinth of rooms and corridors\u201d might be physically instantiated on a computer in Malaysia, while a \u201cvirtual gambling hall\u201d is being run via cryptographic cutouts (remailers) from someone\u2019s bedroom in Provo, Utah.The talk about \u201caccess rules\u201d is thus shown to be meaningless, unless the governments crack down on networks, crypto, and private systems in a way far beyond anything now being talked about.This is the \u201ccrypto anarchy\u201d I have been writing about since 1988. Cyberspace will turn out to be a far vaster frontier than anything we have seen so far. With \u201conly\u201d 10^70 or so particles in the entire universe, there\u2019s vastly more \u201cspace\u201d (address space, key space, etc.) in even a relatively small set of digits. Cyberspace is mathematical space, and its spaciousness is truly unlimited.And we\u2019ll be moving our trade, our entertainment, and much of our lives into cyberspace a whole lot faster than we\u2019ll be slowly moving into low Earth orbit and beyond. In fact, I consider that I\u2019m already half-way in. In a few years, with Mosaic-like one-touch connectivity, with a plethora of network choices, with secure remailers and similar tools to anonymize my transactions, I\u2019ll be so far in there\u2019ll be turning back.Enough for these remarks right now. I think it makes sense to take a slightly longer-range view of the inevitable trends, to see where we\u2019re going, to see what issues need more work.I hope some of you agree with me.--Tim May"}
{"prompt": "Confidential Auditing", "completion": "The auditing function is a vast and indispensable part of the modern economy. Auditing controls allow, among other things, employers to delegate resources and authority to employees, franchisors to delegate to franchisees, stockholders to delegate to management, advertisers to count eybeballs, marketers to gather more reliable data on customers, and make possible a wide variety of other such relationships. Auditing controls might fairly be called the security protocols of capitalism.A recent general survey showed that 83% of Americans are \"very concerned\" about their privacy on the Internet. One can expect even stronger figures from European customers, who have more first-hand experience with private data, much of it originally compiled for innocuous reasons, being used for political repression. Businesses recognize the shortcomings of NDAs and are looking for more reliable ways to protect confidential data. The vast majority of e-commerce customers are concerned about privacy.Auditing is in deep conflict with efforts towards greater privacy. Auditors have an ethic of recording, investigating, and reporting as much as possible, and often see privacy efforts as attempts to prevent auditing and potentially cover up fraud. Indeed, the recent multi-$billion failures of Baring's Bank and the Long Term Capital hedge fund, and more generally the recent problems with \"crony capitalism\" which have shorn stockholders and creditors of over $1 trillion, have been ascribed to such secrecy[3]. At the top of the list of current IMF reforms is \"openness\", a buzzword for the introduction of greater auditing controls and reporting requirements.Since auditing controls are used to secure trillions of dollars of transactions every year, they are not going away, and indeed will likely grow more effective and intrusive. On the other hand, we now have at our disposal the many breakthroughs achieved over the last two decades in modern cryptography. Can we use these to strike a better balance between auditing and privacy? I have come up with an architecture which uses such protocols to greatly improve this tradeoff: confidential auditing.We can achieve auditing logs unforgeable after commitment via secure timestamps[1]. We can then achieve to a great extent unforgeability prior to commitment, with segregation of duties via multiparty integrity constraints[2]. We then audit these commitments via multiparty private computations[4]. This combination allows a wide variety of transactions, conducted with normal efficiency, to be observed and verified by selected arbitrators or auditors, via more expensive private computations applied to randomly sampled commitments. This maintains a high degree of confidentiality for the inputs.The participants in this mutually confidential auditing protocol can verify that the books match the details of transactions stored in a previously committed transaction log, and that the numbers add up correctly. The participants can compute summary statistics on their confidentially shared transaction logs, including cross-checking of the logs against counterparties to a transaction, without revealing those logs. They only learn what can be inferred from the statistics, can't see the details of the transactions.Assuming many practical details I have glossed over in this sketch (such as the efficiency of auditing computations, the availability of digital transaction records in standard format, etc.), confidential auditing can bring a substantial improvement over current practices. Currently the details of all an organization's transactions, including for example medical records in an HMO and transactions in top-secret government programs, are either exposed directly to auditors, or are immune from auditing, allowing fraud.With mutually confidential auditing we will be able to gain high confidence in the factuality of counterparties' claims and reports without revealing identifying and other detailed information from the transactions underlying those reports. This will provide the basis for solid reputation systems, and other trusted third party systems, that maintain integrity across time, communications, summarization, and preserve confidentiality for transaction participants. With confidential auditing we will often be able to have both openness and privacy.BLLV98 A. Buldas, P. Laud, H. Lipmaa, J. Villemson, \"Time-Stamping with Binary Linking Schemes\", Crypto 98 \u21a9Szabo, in progress \u21a9See recent back issues of The Wall Street Journal and The Economist \u21a9Overview, http://szabo.best.vwh.net/msc.html; Quorum systems model, http://szabo.best.vwh.net/quorum.html \u21a9[B91] D. Beaver, \"Efficient Multiparty Protocols Using Circuit Randomization\", ACM STOC 91[RB89] T. Rabin & M. Ben-Or, \"Verifiable Secret Sharing and Multiparty Protocols with Honest Majority\", ACM STOC 89[GRR98] R. Gennaro, T. Rabin, & M. Rabin: \"Simplified VSS and Fast-Track Multiparty Computations\", PODC 98"}
{"prompt": "Proplets: Devices for Controlling Property", "completion": "Civilization has highly evolved practices for determining whether certain actions are allowable or not, or who should prevail in a dispute, namely law. Such a body of knowledge cannot be reinvented from scratch, so instead e-commerce security should draw heavily on it\u2014building property rights, contract and tort law into technology at a very basic level. Proplets define the basic security architecture for local evidence gathering, enforcement, and negotiation of such laws.Proplets do not rely on central planning, AI, or a single trusted third party for any function. Central planning is not able to account for the distributed and diverse knowledge and preferences of different people. A \"trusted third party\" is a nice-sounding synonym for a wide-open security hole that a designer chooses to overlook. Proplet design places strong emphasis on eliminating such exposures.The key is building in, at the most basic level of technology, code (in both the legal and software sense) that allows a widely distributed people, each person having his own unique information, circumstances, and preferences, to cooperate within well known, mutually agreeable, and strongly enforced constraints. With these constraints the risks and benefits of technology are balanced, weapons are monitored and securely restricted in their use to only very narrow, specific, lawful conditions, and for every person there is more profit from peace than from destruction.The goal of proplet design is to control physical objects with digital protocols. Proplets protect its structure and function from non-owners, and observe the environment for phenomena impinging on a region, on matter, or on its owner. A proplet is an electromechanical device (e.g. a MEMS device) with the following core abilities:A proplet may optionally also have the following abilities:No computational module can be read or controlled by physical tampering\u2014it will shut down, erase itself, or even self-destruct depending on the severity of tampering. Computational modules are \"transparent\" to their publically registered controller and opaque to other entities.Only protocols that are simple and composable with provable security govern the communications between the security kernel (private key operations), control box, sandbox, and other components of a computation modules. Similarly for communications between modules and between proplets.How does a proplet find out who owns it, or a guest module who controls it? There are two basic ways:A proplet's guest modules are publicly listed and transferred independently of each other and of the proplet's ownership module.With the home proplet alternative, biometric control of the home proplets may replace public ownership records.Proplets control electronics directly from ownership or guest modules. Proplets control machinery via entanglement. Entanglement can take at least two forms:Entanglment designs have in common that they make it too expensive for the attacker to steal the electronics or machinery by severing it from the controlling proplet.Deeds, in the context of replicated property titles and proplets, are smart contracts executed by a deed module. The current owner may add new deeds agreed to (but not remove old ones) by drafting signing and signing such a smart contract with other current property owners. The deed binds both properties (perhaps to different terms, depending on what the two current owners have negotiatied). The deed modules can be audited at any time by the contemporary owners of other proplets bound to the deeds. Founders of competing property title registries define master deeds, or tort laws, to govern disputes within registry properties. They also define tort law for disputes between their properties and properties defined by other registires, by coming to agreements with those registry founders. Founders also create the initial allocations.Founders are often the manufacturers of proplets. They build in a particular registry as authoratative for their proplets as well as designing an accompanying tort law.For example, the founder of registry of fixtures in a spatial region can sign an agreement with a movable property (chattel) registry, governing the behavior of chattel moving through space and interacting with fixtures. The manufacturers of chattel and fixtures program their proplets to respect the appropriate registries and constrain their sensors and effectors to follow the tort law that has been agreed to.Proplets combine our most highly evolved practices for cooperation on a large scale with a technology architecture suitable for advances well into the future, even well into posthuman civilization. Proplets provide a much sounder footing for solving the problems of high technology cooperation including problems such as privacy, weapons of mass destruction, and other abuses of the power of advanced technology.\"Computer Security as the Future of Law\", Mark Miller\n\"Formalizing and Securing Relationships on Public Networks\", Nick Szabo\n\"Secure Property Titles\", Nick SzaboMy thanks to Gregory Burch, J.D. for his helpful questions.Please send your comments to nszabo (at) law (dot) gwu (dot) edu"}
